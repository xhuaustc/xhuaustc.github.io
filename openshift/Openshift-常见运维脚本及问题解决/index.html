<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Openshift-常见运维脚本及问题解决 | Michael Blog</title><meta name="author" content="Michael Pan"><meta name="copyright" content="Michael Pan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1.扩容计算结点在执行扩容前需检查扩容节点的以下几点信息：  内核版本 selinux已经开启enforcing docker数据盘已经就绪 &#x2F;etc&#x2F;resolv.conf配置正确 hostname已经设置 时间同步已配置 在每个节点都能解析新增节点的域名，如果是通过&#x2F;etc&#x2F;hosts来配置域名解析，需要在配置后重启所有节点的dnsmasq服务 dock">
<meta property="og:type" content="article">
<meta property="og:title" content="Openshift-常见运维脚本及问题解决">
<meta property="og:url" content="https://xhua.eu.org/openshift/Openshift-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/index.html">
<meta property="og:site_name" content="Michael Blog">
<meta property="og:description" content="1.扩容计算结点在执行扩容前需检查扩容节点的以下几点信息：  内核版本 selinux已经开启enforcing docker数据盘已经就绪 &#x2F;etc&#x2F;resolv.conf配置正确 hostname已经设置 时间同步已配置 在每个节点都能解析新增节点的域名，如果是通过&#x2F;etc&#x2F;hosts来配置域名解析，需要在配置后重启所有节点的dnsmasq服务 dock">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/80ad677abfc8210c0f9eb91a5e2465d9f40dd419ca0f2937a12ed348f15ef874.png">
<meta property="article:published_time" content="2020-05-22T12:30:00.000Z">
<meta property="article:modified_time" content="2025-09-30T11:52:34.814Z">
<meta property="article:author" content="Michael Pan">
<meta property="article:tag" content="openshift">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/80ad677abfc8210c0f9eb91a5e2465d9f40dd419ca0f2937a12ed348f15ef874.png"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ee7822a9c1b896de5649988ed5a9dc89c8f46fb54dd442f2d9c74721a05fa708.png"><link rel="canonical" href="https://xhua.eu.org/openshift/Openshift-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Openshift-常见运维脚本及问题解决',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-09-30 19:52:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/87ab7c10242ff1ab32f46f7c7b335d0581d3885fa40b8e3dc1d97014e67ea56d.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">249</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">71</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/xhuaustc/images@main/80ad677abfc8210c0f9eb91a5e2465d9f40dd419ca0f2937a12ed348f15ef874.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Michael Blog"><span class="site-name">Michael Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Openshift-常见运维脚本及问题解决</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-05-22T12:30:00.000Z" title="发表于 2020-05-22 20:30:00">2020-05-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-30T11:52:34.814Z" title="更新于 2025-09-30 19:52:34">2025-09-30</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Openshift-常见运维脚本及问题解决"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="1-扩容计算结点"><a href="#1-扩容计算结点" class="headerlink" title="1.扩容计算结点"></a>1.扩容计算结点</h2><p>在执行扩容前需检查扩容节点的以下几点信息：</p>
<ul>
<li>内核版本</li>
<li>selinux已经开启enforcing</li>
<li>docker数据盘已经就绪</li>
<li>&#x2F;etc&#x2F;resolv.conf配置正确</li>
<li>hostname已经设置</li>
<li>时间同步已配置</li>
<li>在每个节点都能解析新增节点的域名，如果是通过&#x2F;etc&#x2F;hosts来配置域名解析，需要在配置后重启所有节点的dnsmasq服务</li>
<li>docker证书的问题需要添加到自动化配置中来，特别是私有镜像仓库的证书。有三个地方：<ol>
<li>&#x2F;etc&#x2F;sysconfig&#x2F;docker配置，</li>
<li>&#x2F;etc&#x2F;pki&#x2F;ca-trust&#x2F;source&#x2F;anchors&#x2F;目录下的证书，</li>
<li>&#x2F;etc&#x2F;docker&#x2F;certs.d下docker拉取镜像认证证书</li>
</ol>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># /etc/ansible/hosts</span><br><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">etcd</span><br><span class="line">new_nodes</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">[new_nodes]</span><br><span class="line">node04.internal.aws.testdrive.openshift.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;apps&#x27;&#125;&quot; openshift_hostname=node04.internal.aws.testdrive.openshift.com openshift_public_hostname=node04.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node05.internal.aws.testdrive.openshift.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;apps&#x27;&#125;&quot; openshift_hostname=node05.internal.aws.testdrive.openshift.com openshift_public_hostname=node05.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node06.internal.aws.testdrive.openshift.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;apps&#x27;&#125;&quot; openshift_hostname=node06.internal.aws.testdrive.openshift.com openshift_public_hostname=node06.580763383722.aws.testdrive.openshift.com</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>在dns中配置新增的节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml</span><br></pre></td></tr></table></figure>
<p><code>注意：</code>如果集群是通过&#x2F;etc&#x2F;hosts文件来配置的解析，则需在添加好对应配置关系后，重启所有节点的dnsmasq。否则会报“could not find csr for nodes”的错误。</p>
<h2 id="2-OpenShift-Metrics"><a href="#2-OpenShift-Metrics" class="headerlink" title="2.OpenShift Metrics"></a>2.OpenShift Metrics</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">[OSEv3:vars]</span><br><span class="line">...</span><br><span class="line">openshift_metrics_install_metrics=true</span><br><span class="line">openshift_metrics_cassandra_storage_type=pv</span><br><span class="line">openshift_metrics_cassandra_pvc_size=10Gi</span><br><span class="line">openshift_metrics_hawkular_hostname=metrics.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-metrics.yml</span><br></pre></td></tr></table></figure>

<h2 id="3-OpenShift-Logging"><a href="#3-OpenShift-Logging" class="headerlink" title="3.OpenShift Logging"></a>3.OpenShift Logging</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">[OSEv3:vars]</span><br><span class="line">...</span><br><span class="line">openshift_logging_install_logging=true</span><br><span class="line">openshift_logging_namespace=logging</span><br><span class="line">openshift_logging_es_pvc_size=10Gi</span><br><span class="line">openshift_logging_kibana_hostname=kibana.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">openshift_logging_public_master_url=https://kibana.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-logging.yml</span><br></pre></td></tr></table></figure>

<h2 id="4-OpenShift-Multitenant-Networking"><a href="#4-OpenShift-Multitenant-Networking" class="headerlink" title="4.OpenShift Multitenant Networking"></a>4.OpenShift Multitenant Networking</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os_sdn_network_plugin_name=redhat/openshift-ovs-multitenant</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># net-proj.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># create NetworkA, NetworkB projects</span><br><span class="line">/usr/bin/oc new-project netproj-a</span><br><span class="line">/usr/bin/oc new-project netproj-b</span><br><span class="line"></span><br><span class="line"># deploy the DC definition into the projects</span><br><span class="line">/usr/bin/oc create -f /opt/lab/support/ose.yaml -n netproj-a</span><br><span class="line">/usr/bin/oc create -f /opt/lab/support/ose.yaml -n netproj-b</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">#ose.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: ose</span><br><span class="line">  labels:</span><br><span class="line">    run: ose</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    type: Rolling</span><br><span class="line">    rollingParams:</span><br><span class="line">      updatePeriodSeconds: 1</span><br><span class="line">      intervalSeconds: 1</span><br><span class="line">      timeoutSeconds: 600</span><br><span class="line">      maxUnavailable: 25%</span><br><span class="line">      maxSurge: 25%</span><br><span class="line">    resources:</span><br><span class="line">  triggers:</span><br><span class="line">    -</span><br><span class="line">      type: ConfigChange</span><br><span class="line">  replicas: 1</span><br><span class="line">  test: false</span><br><span class="line">  selector:</span><br><span class="line">    run: ose</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        run: ose</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        -</span><br><span class="line">          name: ose</span><br><span class="line">          image: &#x27;registry.access.redhat.com/openshift3/ose:v3.5&#x27;</span><br><span class="line">          command:</span><br><span class="line">            - bash</span><br><span class="line">            - &#x27;-c&#x27;</span><br><span class="line">            - &#x27;while true; do sleep 60; done&#x27;</span><br><span class="line">          resources:</span><br><span class="line">          terminationMessagePath: /dev/termination-log</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      securityContext:</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#podbip.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">/usr/bin/oc get pod -n netproj-b $(oc get pod -n netproj-b | awk &#x27;/ose-/ &#123;print $1&#125;&#x27;) -o jsonpath=&#x27;&#123;.status.podIP&#125;&#123;&quot;\n&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<h3 id="将netproj-a网络与netproj-b网络连接"><a href="#将netproj-a网络与netproj-b网络连接" class="headerlink" title="将netproj-a网络与netproj-b网络连接"></a>将netproj-a网络与netproj-b网络连接</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc adm pod-network join-projects netproj-a --to=netproj-b</span><br><span class="line">oc get netnamespace</span><br></pre></td></tr></table></figure>

<h3 id="将netproj-a网络脱离"><a href="#将netproj-a网络脱离" class="headerlink" title="将netproj-a网络脱离"></a>将netproj-a网络脱离</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc adm pod-network isolate-projects netproj-a</span><br><span class="line">oc get netnamespace</span><br><span class="line">oc exec -n netproj-a $POD_A_NAME -- ping -c1 -W1 $POD_B_IP</span><br></pre></td></tr></table></figure>

<h2 id="5-Node管理"><a href="#5-Node管理" class="headerlink" title="5.Node管理"></a>5.Node管理</h2><h3 id="将Node隔离出集群"><a href="#将Node隔离出集群" class="headerlink" title="将Node隔离出集群"></a>将Node隔离出集群</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --schedulable=false</span><br></pre></td></tr></table></figure>

<h3 id="查看指定Node上运行的pod"><a href="#查看指定Node上运行的pod" class="headerlink" title="查看指定Node上运行的pod"></a>查看指定Node上运行的pod</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --list-pods</span><br></pre></td></tr></table></figure>

<h3 id="迁移指定Node上的pod"><a href="#迁移指定Node上的pod" class="headerlink" title="迁移指定Node上的pod"></a>迁移指定Node上的pod</h3><h4 id="模拟迁移"><a href="#模拟迁移" class="headerlink" title="模拟迁移"></a>模拟迁移</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --evacuate --dry-run</span><br></pre></td></tr></table></figure>
<h4 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --evacuate</span><br></pre></td></tr></table></figure>

<h3 id="恢复Node的可调度"><a href="#恢复Node的可调度" class="headerlink" title="恢复Node的可调度"></a>恢复Node的可调度</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --schedulable=true</span><br></pre></td></tr></table></figure>

<h3 id="创建volume"><a href="#创建volume" class="headerlink" title="创建volume"></a>创建volume</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc volume dc/file-uploader --add --name=my-shared-storage \</span><br><span class="line">-t pvc --claim-mode=ReadWriteMany --claim-size=5Gi \</span><br><span class="line">--claim-name=my-shared-storage --mount-path=/opt/app-root/src/uploaded</span><br></pre></td></tr></table></figure>

<h3 id="Increasing-Storage-Capacity-in-CNS"><a href="#Increasing-Storage-Capacity-in-CNS" class="headerlink" title="Increasing Storage Capacity in CNS"></a>Increasing Storage Capacity in CNS</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line"></span><br><span class="line">[cns]</span><br><span class="line">node01.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node02.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node03.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node04.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node05.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node06.580763383722.aws.testdrive.openshift.com</span><br><span class="line"></span><br><span class="line">[...]</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /opt/lab/support/configure-firewall.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc label node/node04.internal.aws.testdrive.openshift.com storagenode=glusterfs</span><br><span class="line">oc label node/node05.internal.aws.testdrive.openshift.com storagenode=glusterfs</span><br><span class="line">oc label node/node06.internal.aws.testdrive.openshift.com storagenode=glusterfs</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HEKETI_CLI_SERVER=http://heketi-container-native-storage.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">export HEKETI_CLI_USER=admin</span><br><span class="line">export HEKETI_CLI_KEY=myS3cr3tpassw0rd</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">#/opt/lab/support/topology-extended.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;clusters&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;nodes&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node01.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.1.30&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node02.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.3.130&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 2</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node03.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.4.150&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 3</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;nodes&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node04.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.1.23&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node05.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.3.141&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 2</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node06.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.4.234&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 3</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli topology load --json=/opt/lab/support/topology-extended.json</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli topology info ##得到Cluster ID</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># /opt/lab/support/second-cns-storageclass.yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1beta1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: cns-silver</span><br><span class="line">provisioner: kubernetes.io/glusterfs</span><br><span class="line">parameters:</span><br><span class="line">  resturl: &quot;http://heketi-container-native-storage.apps.580763383722.aws.testdrive.openshift.com&quot;</span><br><span class="line">  restauthenabled: &quot;true&quot;</span><br><span class="line">  restuser: &quot;admin&quot;</span><br><span class="line">  volumetype: &quot;replicate:3&quot;</span><br><span class="line">  clusterid: &quot;INSERT-CLUSTER-ID-HERE&quot;</span><br><span class="line">  secretNamespace: &quot;default&quot;</span><br><span class="line">  secretName: &quot;cns-secret&quot;</span><br></pre></td></tr></table></figure>
<h3 id="添加已有节点的盘"><a href="#添加已有节点的盘" class="headerlink" title="添加已有节点的盘"></a>添加已有节点的盘</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 获取NODEID</span><br><span class="line">heketi-cli node list | grep ca777ae0285ef6d8cd7237c862bd591c（CLUSTERID）</span><br><span class="line"></span><br><span class="line">heketi-cli device add --name=/dev/xvde --node=33e0045354db4be29b18728cbe817605(NODEID)</span><br></pre></td></tr></table></figure>

<h3 id="移除有问题的盘"><a href="#移除有问题的盘" class="headerlink" title="移除有问题的盘"></a>移除有问题的盘</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli node info 33e0045354db4be29b18728cbe817605（NODEID）</span><br></pre></td></tr></table></figure>
<p>以上的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Node Id: 33e0045354db4be29b18728cbe817605</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: ca777ae0285ef6d8cd7237c862bd591c</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: node04.internal.aws.testdrive.openshift.com</span><br><span class="line">Storage Hostname: 10.0.1.23</span><br><span class="line">Devices:</span><br><span class="line">Id:01c94798bf6b1af87974573b420c4dff   Name:/dev/xvdd           State:online    Size (GiB):9       Used (GiB):1       Free (GiB):8</span><br><span class="line">Id:da91a2f1c9f62d9916831de18cc09952   Name:/dev/xvde           State:online    Size (GiB):9       Used (GiB):1       Free (GiB):8</span><br></pre></td></tr></table></figure>
<p>移除盘</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli device disable 01c94798bf6b1af87974573b420c4dff</span><br></pre></td></tr></table></figure>

<h2 id="6-给Registry组件添加Volume"><a href="#6-给Registry组件添加Volume" class="headerlink" title="6.给Registry组件添加Volume"></a>6.给Registry组件添加Volume</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc volume dc/docker-registry --add --name=registry-storage -t pvc \</span><br><span class="line">--claim-mode=ReadWriteMany --claim-size=5Gi \</span><br><span class="line">--claim-name=registry-storage --overwrite</span><br></pre></td></tr></table></figure>
<h2 id="7-更改dc的镜像"><a href="#7-更改dc的镜像" class="headerlink" title="7.更改dc的镜像"></a>7.更改dc的镜像</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc patch dc nginx -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;template&quot;:&#123;&quot;spec&quot;:&#123;&quot;containers&quot;:[&#123;&quot;name&quot;:&quot;nginx&quot;,&quot;image&quot;:&quot;harbor.apps.example.com/public/nginx:1.14&quot;&#125;]&#125;&#125;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure>
<h2 id="8-给A项目授予拉取B项目IS的权限"><a href="#8-给A项目授予拉取B项目IS的权限" class="headerlink" title="8.给A项目授予拉取B项目IS的权限"></a>8.给A项目授予拉取B项目IS的权限</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc policy add-role-to-user system:image-puller system:serviceaccount:A:default -n B</span><br></pre></td></tr></table></figure>
<h2 id="9-给Jenkins授予管理A项目资源的权限"><a href="#9-给Jenkins授予管理A项目资源的权限" class="headerlink" title="9.给Jenkins授予管理A项目资源的权限"></a>9.给Jenkins授予管理A项目资源的权限</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc policy add-role-to-user edit system:serviceaccount:jenkins:jenkins -n A</span><br></pre></td></tr></table></figure>
<h2 id="10-手动维护etcd"><a href="#10-手动维护etcd" class="headerlink" title="10.手动维护etcd"></a>10.手动维护etcd</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.com:2379,https://master2.os10.openshift.com:2379,https://master3.os10.openshift.com:2379 endpoint health</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.com:2379,https://master2.os10.openshift.com:2379,https://master3.os10.openshift.com:2379 get / --prefix --keys-only</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.com:2379,https://master2.os10.openshift.com:2379,https://master3.os10.openshift.com:2379 del /kubernetes.io/pods/bookinfo/nginx-4-bkdb4</span><br></pre></td></tr></table></figure>
<h2 id="11-执行镜像对应的任务"><a href="#11-执行镜像对应的任务" class="headerlink" title="11.执行镜像对应的任务"></a>11.执行镜像对应的任务</h2><p>–restart&#x3D;Always 默认值，创建一个deploymentconfig<br>–restart&#x3D;OnFailure 创建一个Job（但是实践证实为一个Pod）<br>–restart&#x3D;OnFailure –schedule&#x3D;”0&#x2F;5 * * * *” 创建一个Cron Job<br>–restart&#x3D;Never 创建一个单独的Pod</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc run nginx -it --rm  --image=nginx --restart=OnFailure  ls</span><br><span class="line">oc run nginx -it --rm  --image=nginx --restart=OnFailure  bash</span><br></pre></td></tr></table></figure>
<h2 id="12-清理主机容器"><a href="#12-清理主机容器" class="headerlink" title="12.清理主机容器"></a>12.清理主机容器</h2><p>当容器存储docker-storage的storage-driver引擎使用devicemapper时会出现如下错误：<code>devmapper: Thin Pool has 162394 free data blocks which is less than minimum required 163840 free data blocks. Create more free space in thin pool or use dm.min_free_space option to change behavior</code>。这个时候需要清理下容器主机的存储。<br>具体操作如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 清理exited进程：</span><br><span class="line">exited_containers=$(docker ps -q -f status=exited); if [ &quot;$exited_containers&quot; != &quot;&quot; ]; then docker rm $exited_containers; fi</span><br><span class="line"># 清理dangling volumes：</span><br><span class="line">dangling_volumes=$(docker volume ls -qf dangling=true); if [ &quot;$dangling_volumes&quot; != &quot;&quot; ]; then docker volume rm $dangling_volumes; fi</span><br><span class="line"># 清理dangling image：</span><br><span class="line">dangling_images=$(docker images --filter &quot;dangling=true&quot; -q --no-trunc); if [ &quot;$dangling_images&quot; != &quot;&quot; ]; then docker rmi $dangling_images; fi</span><br></pre></td></tr></table></figure>
<p>参考文档 <a target="_blank" rel="noopener" href="http://www.cnblogs.com/mhc-fly/p/9324425.html">http://www.cnblogs.com/mhc-fly/p/9324425.html</a><br>还可在不同在子命令下执行 prune，这样删除的就是某类资源：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker container prune -f <span class="comment"># 删除所有退出状态的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume prune -f <span class="comment"># 删除未被使用的数据卷</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image prune -f <span class="comment"># 删除 dangling 或所有未被使用的镜像</span></span></span><br></pre></td></tr></table></figure>
<h2 id="13-Node节点内存与CPU预留"><a href="#13-Node节点内存与CPU预留" class="headerlink" title="13.Node节点内存与CPU预留"></a>13.Node节点内存与CPU预留</h2><p><code>/etc/origin/node/node-config.yaml</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeletArguments:</span><br><span class="line">  system-reserved:</span><br><span class="line">  - cpu=200m</span><br><span class="line">  - memory=1G</span><br><span class="line">  kube-reserved:</span><br><span class="line">  - cpu=200m</span><br><span class="line">  - memory=1G</span><br></pre></td></tr></table></figure>
<h2 id="14-用oc-get只查看dc的镜像名"><a href="#14-用oc-get只查看dc的镜像名" class="headerlink" title="14.用oc get只查看dc的镜像名"></a>14.用oc get只查看dc的镜像名</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@maser]$ oc get dc test-app --template=&#123;&#123;range.spec.template.spec.containers&#125;&#125;&#123;&#123;.image&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line">registry.example.com/test/test-app:1.13</span><br></pre></td></tr></table></figure>
<p>获取第一个dc的第一个容器的镜像</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@maser]$ </span><span class="language-bash">oc get dc --template=<span class="string">&#x27;&#123;&#123;with $dc:=(index .items 0)&#125;&#125;&#123;&#123;with $container:=(index $dc.spec.template.spec.containers 0)&#125;&#125;&#123;&#123;$container.image&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure>
<p>或者使用–jsonpath</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@maser]$ </span><span class="language-bash">oc get dc -o jsonpath=<span class="string">&#x27;&#123;range.items[*]&#125;&#123;range .spec.template.spec.containers[*]&#125;&#123;.image&#125;&#123;&quot;\n&quot;&#125;&#123;end&#125;&#123;end&#125;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">[root@maser]$ </span><span class="language-bash">oc get dc -o jsonpath=<span class="string">&#x27;&#123;.items[0].spec.template.spec.containers[0].image&#125;&#123;&quot;\n&quot;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure>

<h2 id="15-Openshift-Webconsole支持私有镜像仓库"><a href="#15-Openshift-Webconsole支持私有镜像仓库" class="headerlink" title="15.Openshift Webconsole支持私有镜像仓库"></a>15.Openshift Webconsole支持私有镜像仓库</h2><ul>
<li>创建私有镜像仓库的证书<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@registry ~]# mkdir /etc/crts/ &amp;&amp; cd /etc/crts</span><br><span class="line">[root@registry ~]# openssl req \</span><br><span class="line">   -newkey rsa:2048 -nodes -keyout example.com.key \</span><br><span class="line">   -x509 -days 365 -out example.com.crt -subj \</span><br><span class="line">   &quot;/C=CN/ST=GD/L=SZ/O=Global Security/OU=IT Department/CN=*.example.com&quot;</span><br></pre></td></tr></table></figure></li>
<li>将私有镜像仓库的CA文件拷贝到镜像仓库所在服务器的<code>/etc/pki/ca-trust/source/anchors/</code>目录下</li>
<li>在镜像仓库中配置tls，如果是docker-distribution <code>/etc/docker-distribution/registry/config.yml</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http:</span><br><span class="line">   addr: :443</span><br><span class="line">   tls:</span><br><span class="line">       certificate: /etc/crts/example.com.crt</span><br><span class="line">       key: /etc/crts/example.com.key</span><br></pre></td></tr></table></figure></li>
<li>重启docker-distribution<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@registry ~]# systemctl daemon-reload &amp;&amp; systemctl restart docker-distribution &amp;&amp; systemctl enable docker-distribution</span><br></pre></td></tr></table></figure></li>
<li>在镜像仓库所在服务器上执行<code>update-ca-trust extract</code></li>
<li>将私有镜像仓库的CA文件拷贝到每台Openshift节点的<code>/etc/pki/ca-trust/source/anchors/</code>目录下</li>
<li>每台Openshift节点上执行<code>update-ca-trust extract</code></li>
</ul>
<h2 id="16-Docker支持私有镜像仓库tls认证"><a href="#16-Docker支持私有镜像仓库tls认证" class="headerlink" title="16.Docker支持私有镜像仓库tls认证"></a>16.Docker支持私有镜像仓库tls认证</h2><p>&#x2F;etc&#x2F;docker&#x2F;certs.d目录下创建对应的域名目录，如私有镜像仓库的域名为:example.harbor.com</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /etc/docker/certs.d/example.harbor.com</span><br></pre></td></tr></table></figure>
<p>将私有镜像仓库的CA文件拷贝到该目录下即可。</p>
<h2 id="17-查看etcd数据"><a href="#17-查看etcd数据" class="headerlink" title="17.查看etcd数据"></a>17.查看etcd数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">etcdctl --cert-file=/etc/origin/master/master.etcd-client.crt --key-file /etc/origin/master/master.etcd-client.key --ca-file /etc/origin/master/master.etcd-ca.crt --endpoints=&quot;https://master1.os10.openshift.example.com:2379,https://master2.os10.openshift.example.com:2379,https://master3.os10.openshift.example.com:2379&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.example.com:2379,https://master2.os10.openshift.example.com:2379,https://master3.os10.openshift.example.com:2379 endpoint health</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.example.com:2379,https://master2.os10.openshift.example.com:2379,https://master3.os10.openshift.example.com:2379 get / --prefix --keys-only</span><br></pre></td></tr></table></figure>
<h2 id="计算某个项目project下所有pod的limits-cpu-x2F-memory的总和"><a href="#计算某个项目project下所有pod的limits-cpu-x2F-memory的总和" class="headerlink" title="计算某个项目project下所有pod的limits cpu&#x2F;memory的总和"></a>计算某个项目project下所有pod的limits cpu&#x2F;memory的总和</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 计算pod总的limits cpu的总和</span><br><span class="line">data=$(pods=`oc get pod|awk &#x27;&#123;print $1&#125;&#x27;|grep -v NAME`; for pod in $pods; do oc get pod $pod --template=&#123;&#123;range.spec.containers&#125;&#125;&#123;&#123;.resources.limits.cpu&#125;&#125;&#123;&#123;println&#125;&#125;&#123;&#123;end&#125;&#125;; done); i=0; for j in $(echo $data); do i=$(($i+$j)); done ; echo $i;</span><br><span class="line">## 18.计算pod总的limits memory的总和</span><br><span class="line">data=$(pods=`oc get pod|awk &#x27;&#123;print $1&#125;&#x27;|grep -v NAME`; for pod in $pods; do oc get pod $pod --template=&#123;&#123;range.spec.containers&#125;&#125;&#123;&#123;.resources.limits.memory&#125;&#125;&#123;&#123;println&#125;&#125;&#123;&#123;end&#125;&#125;; done);i=0; for j in $(echo $data); do mj=$(echo $j|cut -dG -f1); i=$(($i+$mj)); done; echo $i;</span><br></pre></td></tr></table></figure>
<h2 id="19-DNSMasq启动失败报错“DBus-error-Connection-“-1-180”-is-not-allowed-to-own-the-service-“uk-org-thekelleys-dnsmasq”-”"><a href="#19-DNSMasq启动失败报错“DBus-error-Connection-“-1-180”-is-not-allowed-to-own-the-service-“uk-org-thekelleys-dnsmasq”-”" class="headerlink" title="19.DNSMasq启动失败报错“DBus error: Connection “:1.180” is not allowed to own the service “uk.org.thekelleys.dnsmasq” ”"></a>19.DNSMasq启动失败报错“DBus error: Connection “:1.180” is not allowed to own the service “uk.org.thekelleys.dnsmasq” ”</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/dbus-1/system.d/dnsmasq.conf</span><br><span class="line">&lt;!DOCTYPE busconfig PUBLIC</span><br><span class="line"> &quot;-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN&quot;</span><br><span class="line"> &quot;http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd&quot;&gt;</span><br><span class="line">&lt;busconfig&gt;</span><br><span class="line">	&lt;policy user=&quot;root&quot;&gt;</span><br><span class="line">		&lt;allow own=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">		&lt;allow send_destination=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">	&lt;/policy&gt;</span><br><span class="line">	&lt;policy context=&quot;default&quot;&gt;</span><br><span class="line">                &lt;allow own=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">                &lt;allow send_destination=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">        &lt;/policy&gt;</span><br><span class="line">&lt;/busconfig&gt;</span><br><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl restart dbus</span><br><span class="line">$ systemctl restart dnsmasq</span><br></pre></td></tr></table></figure>

<h2 id="20-ssh特别慢，卡在debug1-pledge-network位置"><a href="#20-ssh特别慢，卡在debug1-pledge-network位置" class="headerlink" title="20.ssh特别慢，卡在debug1: pledge: network位置"></a>20.ssh特别慢，卡在<code>debug1: pledge: network</code>位置</h2><p>重启下systemd-logind</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart systemd-logind</span></span><br></pre></td></tr></table></figure>
<p>如果是卡在Authentication上，可以把ssh client端的StrictHostKeyChecking设置为no</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/ssh/ssh_config</span></span><br><span class="line">Host *</span><br><span class="line">          GSSAPIAuthentication no</span><br><span class="line">          StrictHostKeyChecking no</span><br></pre></td></tr></table></figure>
<h2 id="21-清理私有镜像仓库"><a href="#21-清理私有镜像仓库" class="headerlink" title="21.清理私有镜像仓库"></a>21.清理私有镜像仓库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /usr/bin/cleanregistry.sh &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">!/bin/bash</span></span></span><br><span class="line">oc login -u admin -p password</span><br><span class="line">oc adm prune builds --orphans --keep-complete=25 --keep-failed=5 --keep-younger-than=60m --confirm</span><br><span class="line">oc adm prune deployments --orphans --keep-complete=25 --keep-failed=10 --keep-younger-than=60m --confirm</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">oc rollout latest docker-registry -n default</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">sleep 20</span></span></span><br><span class="line">oc adm prune images --keep-younger-than=400m --confirm</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">crontab -l</span></span></span><br><span class="line">0 0 * * * /usr/bin/cleanregistry.sh &gt;&gt; /var/log/cleanregistry.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure>

<h2 id="22-docker-run覆盖entrypoint"><a href="#22-docker-run覆盖entrypoint" class="headerlink" title="22.docker run覆盖entrypoint"></a>22.docker run覆盖entrypoint</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --entrypoint=<span class="string">&quot;/bin/bash&quot;</span> --<span class="built_in">rm</span> -it xhuaustc/nginx-openshift-router:1.15</span></span><br></pre></td></tr></table></figure>
<h2 id="23-oc-image-mirror同步镜像"><a href="#23-oc-image-mirror同步镜像" class="headerlink" title="23.oc image mirror同步镜像"></a>23.oc image mirror同步镜像</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc image mirror myregistry.com/myimage:latest docker.io/myrepository/myimage:stable --insecure=<span class="literal">true</span></span></span><br></pre></td></tr></table></figure>

<h2 id="24-开通端口防火墙"><a href="#24-开通端口防火墙" class="headerlink" title="24.开通端口防火墙"></a>24.开通端口防火墙</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vi /etc/sysconfig/iptables</span></span><br><span class="line">-A OS_FIREWALL_ALLOW -p tcp -m state --state NEW -m tcp  --dport 9100 -j ACCEPT</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemctl restart iptables</span></span><br></pre></td></tr></table></figure>

<h2 id="25-查看crt证书有效时间"><a href="#25-查看crt证书有效时间" class="headerlink" title="25.查看crt证书有效时间"></a>25.查看crt证书有效时间</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -noout -text -<span class="keyword">in</span> ca.crt | grep Validity -A2</span></span><br><span class="line">    Validity</span><br><span class="line">        not Before: Sep 7 08:48.13 2018 GMT</span><br><span class="line">        not After: Sep 6 08:48.14 2020 GMT</span><br></pre></td></tr></table></figure>
<h2 id="26-将主机设为不可调度"><a href="#26-将主机设为不可调度" class="headerlink" title="26.将主机设为不可调度"></a>26.将主机设为不可调度</h2><p>方法一：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm cordon <span class="variable">$nodename</span></span></span><br></pre></td></tr></table></figure>
<p>方法二：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm manage-node --schedulable=<span class="literal">false</span> <span class="variable">$nodename</span></span></span><br></pre></td></tr></table></figure>
<h2 id="27-驱逐主机上的POD"><a href="#27-驱逐主机上的POD" class="headerlink" title="27.驱逐主机上的POD"></a>27.驱逐主机上的POD</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm manage-node --evacuate <span class="variable">$nodename</span></span></span><br></pre></td></tr></table></figure>
<h2 id="28-Service的域名"><a href="#28-Service的域名" class="headerlink" title="28.Service的域名"></a>28.Service的域名</h2><p>正常情况下<br>Service的域名格式为：<code>service-name.project-name.svc.cluster.local</code><br>对应的IP是Service Cluster IP<br>设置Service的clusterIP&#x3D;None，同时该Pod需要添加subdomain字段，如果是statefulset资源需要添加serviceName字段。<br>Service的域名格式为：<code>service-name.project-name.svc.cluster.local</code><br>对应的IP是后台对应的Pod的容器的IP<br>同时后台对应的Pod都有DNS记录，格式为<code>pod-name.service-name.project-name.svc.cluster.local</code></p>
<h2 id="29-查看Docker镜像的构建历史命令"><a href="#29-查看Docker镜像的构建历史命令" class="headerlink" title="29.查看Docker镜像的构建历史命令"></a>29.查看Docker镜像的构建历史命令</h2><p><code>docker history $&#123;镜像名/ID&#125; -H --no-trunc | awk -F&quot;[ ]&#123;3,&#125;&quot; &#39;&#123;print $3&#125;&#39; | sed -n -e  &quot;s#/bin/sh -c##g&quot; -e &quot;s/#(nop)  //g&quot; -e  &#39;2,$p&#39; | sed  &#39;1!G;h;$!d&#39;</code></p>
<p>例如查看镜像mysql:5.6.41的构建命令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ docker history mysql:5.6.41 -H --no-trunc | awk -F&quot;[ ]&#123;3,&#125;&quot; &#x27;&#123;$1=&quot;&quot;;$2=&quot;&quot;;$(NF-1)=&quot;&quot;;print $0&#125;&#x27; | sed -n -e  &quot;s#/bin/sh -c##g&quot; -e &quot;s/#(nop)  //g&quot; -e  &#x27;2,$p&#x27; | sed  &#x27;1!G;h;$!d&#x27;</span><br><span class="line">   #(nop) ADD file:f8f26d117bc4a9289b7cd7447ca36e1a70b11701c63d949ef35ff9c16e190e50 in /</span><br><span class="line">   CMD [&quot;bash&quot;]</span><br><span class="line">   groupadd -r mysql &amp;&amp; useradd -r -g mysql mysql</span><br><span class="line">   apt-get update &amp;&amp; apt-get install -y --no-install-recommends gnupg dirmngr &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">   ENV GOSU_VERSION=1.7</span><br><span class="line">   set -x  &amp;&amp; apt-get update &amp;&amp; apt-get install -y --no-install-recommends ca-certificates wget &amp;&amp; rm -rf /var/lib/apt/lists/*  &amp;&amp; wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)&quot;  &amp;&amp; wget -O /usr/local/bin/gosu.asc &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc&quot;  &amp;&amp; export GNUPGHOME=&quot;$(mktemp -d)&quot;  &amp;&amp; gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4  &amp;&amp; gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu  &amp;&amp; gpgconf --kill all  &amp;&amp; rm -rf &quot;$GNUPGHOME&quot; /usr/local/bin/gosu.asc  &amp;&amp; chmod +x /usr/local/bin/gosu  &amp;&amp; gosu nobody true  &amp;&amp; apt-get purge -y --auto-remove ca-certificates wget</span><br><span class="line">   mkdir /docker-entrypoint-initdb.d</span><br><span class="line">   apt-get update &amp;&amp; apt-get install -y --no-install-recommends pwgen perl  &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">   set -ex;  key=&#x27;A4A9406876FCBD3C456770C88C718D3B5072E1F5&#x27;;  export GNUPGHOME=&quot;$(mktemp -d)&quot;;  gpg --keyserver ha.pool.sks-keyservers.net --recv-keys &quot;$key&quot;;  gpg --export &quot;$key&quot; &gt; /etc/apt/trusted.gpg.d/mysql.gpg;  gpgconf --kill all;  rm -rf &quot;$GNUPGHOME&quot;;  apt-key list &gt; /dev/null</span><br><span class="line">   ENV MYSQL_MAJOR=5.6</span><br><span class="line">   ENV MYSQL_VERSION=5.6.41-1debian9</span><br><span class="line">   echo &quot;deb http://repo.mysql.com/apt/debian/ stretch mysql-$&#123;MYSQL_MAJOR&#125;&quot; &gt; /etc/apt/sources.list.d/mysql.list</span><br><span class="line">   &#123; echo mysql-community-server mysql-community-server/data-dir select &#x27;&#x27;; echo mysql-community-server mysql-community-server/root-pass password &#x27;&#x27;; echo mysql-community-server mysql-community-server/re-root-pass password &#x27;&#x27;; echo mysql-community-server mysql-community-server/remove-test-db select false;  &#125; | debconf-set-selections  &amp;&amp; apt-get update &amp;&amp; apt-get install -y mysql-server=&quot;$&#123;MYSQL_VERSION&#125;&quot; &amp;&amp; rm -rf /var/lib/apt/lists/*  &amp;&amp; rm -rf /var/lib/mysql &amp;&amp; mkdir -p /var/lib/mysql /var/run/mysqld  &amp;&amp; chown -R mysql:mysql /var/lib/mysql /var/run/mysqld  &amp;&amp; chmod 777 /var/run/mysqld  &amp;&amp; find /etc/mysql/ -name &#x27;*.cnf&#x27; -print0 | xargs -0 grep -lZE &#x27;^(bind-address|log)&#x27; | xargs -rt -0 sed -Ei &#x27;s/^(bind-address|log)/#&amp;/&#x27;  &amp;&amp; echo &#x27;[mysqld]\nskip-host-cache\nskip-name-resolve&#x27; &gt; /etc/mysql/conf.d/docker.cnf</span><br><span class="line">   VOLUME [/var/lib/mysql]</span><br><span class="line">   #(nop) COPY file:b79e447a4154d7150da6897e9bfdeac5eef0ebd39bb505803fdb0315c929d983 in /usr/local/bin/</span><br><span class="line">   ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compat</span><br><span class="line">   ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]</span><br><span class="line">   EXPOSE 3306/tcp</span><br><span class="line">   CMD [&quot;mysqld&quot;]</span><br></pre></td></tr></table></figure>
<h2 id="30-应用在完成Build后推送到内部镜像仓库如下报错误"><a href="#30-应用在完成Build后推送到内部镜像仓库如下报错误" class="headerlink" title="30.应用在完成Build后推送到内部镜像仓库如下报错误"></a>30.应用在完成Build后推送到内部镜像仓库如下报错误</h2><p><code> Pushing image docker-registry.default.svc:5000/apb/my-test-apb:latest ...</code><br><code>Pushed 0/15 layers, 0% complete</code><br><code>Registry server Address:</code><br><code>Registry server User Name: serviceaccount</code><br><code>Registry server Email: serviceaccount@example.org</code><br><code>Registry server Password: &lt;&lt;non-empty&gt;&gt;</code><br><code>error: build error: Failed to push image: unauthorized: unable to validate token</code></p>
<p>此时很大可能是因为一些变更，导致镜像仓库的Token有变化，但是镜像仓库未重启，重启镜像仓库即可恢复。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ oc get pod -n default | grep docker-registry</span><br><span class="line">docker-registry-1-8tjhk                   1/1       Running            0          4m</span><br><span class="line">$ oc delete pod `oc get pod -n default | grep docker-registry | awk &#x27;&#123;print $1&#125;&#x27;`</span><br></pre></td></tr></table></figure>
<h2 id="31-为容器用户指定用户名"><a href="#31-为容器用户指定用户名" class="headerlink" title="31.为容器用户指定用户名"></a>31.为容器用户指定用户名</h2><ol>
<li>在镜像构建中将文件&#x2F;etc&#x2F;passwd设置为容器启动用户可写<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN chmod g=u /etc/passwd</span><br></pre></td></tr></table></figure></li>
<li>容器启动时设置用户名<br>ENTRYPOINT&#x2F;CMD 脚本中添加设置用户名代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">USER_NAME=$&#123;USER_NAME:-ocpuid&#125;</span><br><span class="line">USER_ID=$(id -u)</span><br><span class="line">if ! whoami &amp;&gt; /dev/null; then</span><br><span class="line">  if [ -w /etc/passwd ]; then</span><br><span class="line">    echo &quot;$&#123;USER_NAME&#125;:x:$&#123;USER_ID&#125;:0:$&#123;USER_NAME&#125; user:$&#123;HOME&#125;:/sbin/nologin&quot; &gt;&gt; /etc/passwd</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line">exec &quot;$@&quot;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="32-升级Docker"><a href="#32-升级Docker" class="headerlink" title="32.升级Docker"></a>32.升级Docker</h2><p>升级不同OpenShift组件的思路是一样，主要是如下两条。</p>
<ul>
<li>逐个节点升级</li>
<li>升级前将业务应用迁走</li>
</ul>
<ol>
<li>更新yum源中的docker包<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp docker-rpm/* ./extras/Packages/d/</span><br><span class="line">$ createrepo --update extras</span><br></pre></td></tr></table></figure></li>
<li>迁移节点上的POD并将它设置为不可调度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm drain &lt;node_name&gt; --force --delete-local-data --ignore-daemonsets</span><br></pre></td></tr></table></figure></li>
<li>排除不需要升级的软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ atomic-openshift-docker-excluder exclude</span><br><span class="line">$ atomic-openshift-excluder exclude</span><br></pre></td></tr></table></figure></li>
<li>升级docker<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum clean all</span><br><span class="line">$ yum update docker</span><br></pre></td></tr></table></figure></li>
<li>重启服务或者重启主机</li>
</ol>
<p>Master节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart docker</span><br><span class="line">$ master-restart api</span><br><span class="line">$ master-restart controllers</span><br><span class="line">$ systemctl restart origin-node</span><br></pre></td></tr></table></figure>
<p>Node节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart docker</span><br><span class="line">$ systemctl restart origin-node</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ reboot</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>将节点设置为可调度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm uncordon &lt;node_name&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="33-获取Token并请求OpenShift-ASB服务的例子"><a href="#33-获取Token并请求OpenShift-ASB服务的例子" class="headerlink" title="33.获取Token并请求OpenShift ASB服务的例子"></a>33.获取Token并请求OpenShift ASB服务的例子</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ curl -k -H &quot;Authorization: Bearer `oc serviceaccounts get-token asb-client`&quot; https://$(oc get routes -n openshift-ansible-service-broker --no-headers | awk &#x27;&#123;print $2&#125;&#x27;)/osb/v2/catalog</span><br><span class="line">&#123;</span><br><span class="line">  &quot;paths&quot;: [</span><br><span class="line">    &quot;/ansible-service-broker/&quot;,</span><br><span class="line">    &quot;/apis&quot;,</span><br><span class="line">    &quot;/healthz&quot;,</span><br><span class="line">    &quot;/healthz/ping&quot;,</span><br><span class="line">    &quot;/healthz/poststarthook/generic-apiserver-start-informers&quot;,</span><br><span class="line">    &quot;/metrics&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="34-调用OpenShift-API获取Pod信息"><a href="#34-调用OpenShift-API获取Pod信息" class="headerlink" title="34.调用OpenShift API获取Pod信息"></a>34.调用OpenShift API获取Pod信息</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get --raw /api/v1/namespaces/&lt;namespace-name&gt;/pods/&lt;pod-name&gt; | json_reformat</span><br></pre></td></tr></table></figure>
<h2 id="35-使用HostPath挂载本地目录"><a href="#35-使用HostPath挂载本地目录" class="headerlink" title="35.使用HostPath挂载本地目录"></a>35.使用HostPath挂载本地目录</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ chcon -Rt svirt_sandbox_file_t /testHostPath</span><br><span class="line">or</span><br><span class="line">$ chcon -R unconfined_u:object_r:svirt_sandbox_file_t:s0 /testHostPath</span><br><span class="line">or</span><br><span class="line">$ semanage fcontext -a -t svirt_sandbox_file_t &#x27;/testHostPath(/.*)?&#x27;</span><br><span class="line">$ restorecon -Rv /testHostPath</span><br><span class="line"># 确认设置 semanage fcontext -l | grep testHostPath</span><br><span class="line"># 确认文件生效 ls -Z /testHostPath</span><br><span class="line"></span><br><span class="line"># 删除 配置: semanage fcontext -d &#x27;/testHostPath(/.*)?&#x27;</span><br></pre></td></tr></table></figure>
<h2 id="36-将搜索镜像导出到本地文件脚本"><a href="#36-将搜索镜像导出到本地文件脚本" class="headerlink" title="36.将搜索镜像导出到本地文件脚本"></a>36.将搜索镜像导出到本地文件脚本</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker image | grep redis | awk &#x27;&#123;image=$1; gsub(/.*\//, &quot;&quot;, $1); printf(&quot;docker save -o %s.tar %s:%s\n&quot;, $1, image, $2)&#125;&#x27; | xargs -i bash -c &quot;&#123;&#125;&quot;</span><br></pre></td></tr></table></figure>
<h2 id="37-Docker日志中有错误-container-kill-failed-because-of-container-not-found-or-no-such-process"><a href="#37-Docker日志中有错误-container-kill-failed-because-of-container-not-found-or-no-such-process" class="headerlink" title="37.Docker日志中有错误 container kill failed because of container not found or no such process"></a>37.Docker日志中有错误 <code>container kill failed because of container not found or no such process</code></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 定期检查docker日志</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">journalctl -r -u docker --since <span class="string">&#x27;1 day ago&#x27;</span> --no-pager | grep -i error</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 处理办法重启docker</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart docker</span></span><br></pre></td></tr></table></figure>

<h2 id="38-查看所有应用重启次数，并且排序"><a href="#38-查看所有应用重启次数，并且排序" class="headerlink" title="38.查看所有应用重启次数，并且排序"></a>38.查看所有应用重启次数，并且排序</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod --sort-by=<span class="string">&#x27;.status.containerStatuses[0].restartCount&#x27;</span> --all-namespace | <span class="built_in">sort</span> -rn -k10</span></span><br></pre></td></tr></table></figure>

<h2 id="39-docker拉取镜像报错：400-unsupported-docker-v1-repository-request"><a href="#39-docker拉取镜像报错：400-unsupported-docker-v1-repository-request" class="headerlink" title="39.docker拉取镜像报错：400 unsupported docker v1 repository request"></a>39.docker拉取镜像报错：400 unsupported docker v1 repository request</h2><p>docker的配置中添加<code>--disable-legacy-registry</code>配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/sysconfig/docker</span></span><br><span class="line">...</span><br><span class="line">OPTIONS=&#x27;... --disable-legacy-registry ...&#x27;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>原因：当docker客户端通过v2 API请求镜像库，而镜像不存在，客户端会尝试使用v1 API请求镜像仓库，而镜像仓库不支持v1 API请求，则会返回该错误。</p>
<h2 id="40-应用日志无法查看，oc-exec也无法进入容器"><a href="#40-应用日志无法查看，oc-exec也无法进入容器" class="headerlink" title="40.应用日志无法查看，oc exec也无法进入容器"></a>40.应用日志无法查看，oc exec也无法进入容器</h2><p>报错<code>Error from server: Get https://master.example.com:8443/containerLogs/namespace/pod-name/console: remote error: tls: internal error</code><br>处理办法，查看csr，并将它们手动授信</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get csr</span><br><span class="line">$ oc get csr -o name | xargs oc adm certificate approve</span><br></pre></td></tr></table></figure>
<h2 id="41-netmanager工具设置了dns，无法直接通过-x2F-etc-x2F-resolv-conf文件更改"><a href="#41-netmanager工具设置了dns，无法直接通过-x2F-etc-x2F-resolv-conf文件更改" class="headerlink" title="41.netmanager工具设置了dns，无法直接通过&#x2F;etc&#x2F;resolv.conf文件更改"></a>41.netmanager工具设置了dns，无法直接通过&#x2F;etc&#x2F;resolv.conf文件更改</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ nmcli con show # 查看所有的网络连接</span><br><span class="line">$ nmcli con show &lt;net-connect-name&gt; #查看网络连接详情，可查看dns的配置</span><br><span class="line">$ nmcli con mod &lt;net-connect-name&gt; -ipv4.dns &lt;dns-server-ip&gt; #删除指定的dns ip</span><br><span class="line">$ nmcli con mod &lt;net-connect-name&gt; +ipv4.dns &lt;dns-server-ip&gt; #添加指定的dns ip</span><br></pre></td></tr></table></figure>
<h2 id="42-查看集群当前计算节点资源的分配率"><a href="#42-查看集群当前计算节点资源的分配率" class="headerlink" title="42.查看集群当前计算节点资源的分配率"></a>42.查看集群当前计算节点资源的分配率</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nodes=$(oc get node --selector=node-role.kubernetes.io/compute=<span class="literal">true</span> --no-headers | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>); <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$nodes</span>; <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">$i</span>; oc describe node <span class="variable">$i</span> | grep Resource -A 3 | grep -v <span class="string">&#x27;\-\-\-&#x27;</span>; <span class="keyword">done</span></span></span><br><span class="line">node1</span><br><span class="line">  Resource    Requests          Limits</span><br><span class="line">  cpu         10445m (65%)      25770m (161%)</span><br><span class="line">  memory      22406Mi (34%)     49224Mi (76%)</span><br><span class="line">node2</span><br><span class="line">  Resource    Requests          Limits</span><br><span class="line">  cpu         8294m (51%)   25620m (160%)</span><br><span class="line">  memory      18298Mi (28%)     48600Mi (75%)</span><br></pre></td></tr></table></figure>
<h2 id="43-安装时master-api服务无法访问etcd"><a href="#43-安装时master-api服务无法访问etcd" class="headerlink" title="43.安装时master api服务无法访问etcd"></a>43.安装时master api服务无法访问etcd</h2><p>master主机绑定多张网卡，在&#x2F;etc&#x2F;ansible&#x2F;hosts中需要指定etcd_ip，如下所示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[etcd]</span><br><span class="line">master.example.com etcd_ip=10.1.2.3</span><br></pre></td></tr></table></figure>
<p>另外需要确保，etcd所在主机的hostname所指定的ip确切为etcd_ip指定的ip。</p>
<h2 id="44-安装时master节点有多张网卡，如何指定masterIP"><a href="#44-安装时master节点有多张网卡，如何指定masterIP" class="headerlink" title="44.安装时master节点有多张网卡，如何指定masterIP"></a>44.安装时master节点有多张网卡，如何指定masterIP</h2><p>在master安装时master-config.yml中设置的masterIP为openshift.common.ip，为节点的默认网卡。可以通过编辑<code>roles/openshift_facts/library/openshift_facts.py</code>文件来设置该ip</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def get_defaults(self, roles):</span><br><span class="line">    &quot;&quot;&quot; Get default fact values</span><br><span class="line">        Args:</span><br><span class="line">            roles (list): list of roles for this host</span><br><span class="line">        Returns:</span><br><span class="line">            dict: The generated default facts</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    defaults = &#123;&#125;</span><br><span class="line">    ip_addr = self.system_facts[&#x27;ansible_default_ipv4&#x27;][&#x27;address&#x27;]</span><br><span class="line">    exit_code, output, _ = module.run_command([&#x27;hostname&#x27;, &#x27;-f&#x27;])  # noqa: F405</span><br><span class="line">    hostname_f = output.strip() if exit_code == 0 else &#x27;&#x27;</span><br><span class="line">    hostname_values = [hostname_f, self.system_facts[&#x27;ansible_nodename&#x27;],</span><br><span class="line">                       self.system_facts[&#x27;ansible_fqdn&#x27;]]</span><br><span class="line">    hostname = choose_hostname(hostname_values, ip_addr).lower()</span><br><span class="line">    exit_code, output, _ = module.run_command([&#x27;hostname&#x27;])  # noqa: F405</span><br><span class="line">    raw_hostname = output.strip() if exit_code == 0 else hostname</span><br><span class="line"></span><br><span class="line">    defaults[&#x27;common&#x27;] = dict(ip=ip_addr,</span><br><span class="line">                              public_ip=ip_addr,</span><br><span class="line">                              raw_hostname=raw_hostname,</span><br><span class="line">                              hostname=hostname,</span><br><span class="line">                              public_hostname=hostname,</span><br></pre></td></tr></table></figure>
<p>另外可以通过将目标网卡设置为默认网卡来解决。<br>还有OpenShift通过更新hosts也可以来配置，通过设置openshift_node_groups来设置<code>kubeletArguments.node-ip</code>的值，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;name&#x27;: &#x27;node-config-node1&#x27;, &#x27;labels&#x27;: [&#x27;...,...&#x27;], &#x27;edits&#x27;: [&#123; &#x27;key&#x27;: &#x27;kubeletArguments.node-ip&#x27;,&#x27;value&#x27;: [&#x27;x.x.x.x&#x27;]&#125;]&#125;</span><br></pre></td></tr></table></figure>

<h2 id="45-部署集群时，采用自定义证书，Master1节点报x509-certificate-signed-by-unknown-authority错误"><a href="#45-部署集群时，采用自定义证书，Master1节点报x509-certificate-signed-by-unknown-authority错误" class="headerlink" title="45.部署集群时，采用自定义证书，Master1节点报x509: certificate signed by unknown authority错误"></a>45.部署集群时，采用自定义证书，Master1节点报x509: certificate signed by unknown authority错误</h2><p>检查ansible inventory hosts文件中自定义证书名是否与openshift默认的组件证书名重复了。如ca.crt等</p>
<h2 id="46-部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置"><a href="#46-部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置" class="headerlink" title="46.部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置"></a>46.部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip route</span></span><br><span class="line">10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 102</span><br><span class="line">172.16.10.0/24 dev eth1 proto kernel scope link src 172.16.10.11 metric 101</span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">## 添加默认路由</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip route add default via 172.16.10.1</span></span><br></pre></td></tr></table></figure>
<h2 id="47-删除指定文件夹下最近一个月的文件"><a href="#47-删除指定文件夹下最近一个月的文件" class="headerlink" title="47. 删除指定文件夹下最近一个月的文件"></a>47. 删除指定文件夹下最近一个月的文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">find /dir -<span class="built_in">type</span> f -mtime +30 -<span class="built_in">exec</span> <span class="built_in">rm</span> -rf &#123;&#125; \;</span></span><br></pre></td></tr></table></figure>
<h2 id="48-pod报the-node-was-low-on-resource-ephemeral-storage而被驱逐"><a href="#48-pod报the-node-was-low-on-resource-ephemeral-storage而被驱逐" class="headerlink" title="48.pod报the node was low on resource ephemeral-storage而被驱逐"></a>48.pod报<code>the node was low on resource ephemeral-storage</code>而被驱逐</h2><p>pod应用临时存储空间不足导致错误，需要查看本地磁盘，特别是&#x2F;var&#x2F;lib&#x2F;origin所在磁盘的空间情况。</p>
<h2 id="49-自签证书"><a href="#49-自签证书" class="headerlink" title="49.自签证书"></a>49.自签证书</h2><ol>
<li>根证书创建<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out ca.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -x509 -days 36500 -key ca.key -out ca.crt -subj <span class="string">&quot;/C=CN/ST=shanxi/L=taiyuan/O=cn/OU=test/CN=example.com&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#或者 openssl req -new -x509 -days 36500 -key ca.key -out ca.crt 手动输入配置</span></span></span><br></pre></td></tr></table></figure></li>
<li>创建证书并使用根证书签发<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out app.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -key app.key -out app.csr</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -req -<span class="keyword">in</span> app.csr -CA ca.crt -CAkey ca.key -out app.crt -days 3650  -CAcreateserial</span></span><br></pre></td></tr></table></figure></li>
<li>使用 Openssl 工具查看证书信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -dates</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -subject</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -text</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="50-ETCD某个节点无法重启，报错rafthttp-the-clock-difference-against-peer-27de23fad174dca-is-too-high-1m16-89887s-gt-1s"><a href="#50-ETCD某个节点无法重启，报错rafthttp-the-clock-difference-against-peer-27de23fad174dca-is-too-high-1m16-89887s-gt-1s" class="headerlink" title="50. ETCD某个节点无法重启，报错rafthttp: the clock difference against peer 27de23fad174dca is too high [1m16.89887s &gt; 1s]"></a>50. ETCD某个节点无法重启，报错<code>rafthttp: the clock difference against peer 27de23fad174dca is too high [1m16.89887s &gt; 1s]</code></h2><p>检查ETCD服务器的时间是否同步，如果不同步，强制同步后，ETCD会自动恢复。</p>
<h2 id="51-查看最近一小时的Event-告警事件"><a href="#51-查看最近一小时的Event-告警事件" class="headerlink" title="51. 查看最近一小时的Event 告警事件"></a>51. 查看最近一小时的Event 告警事件</h2><p>集群默认保留最近1小时的Event事件，通过field-selector过滤掉正常的事件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get event --field-selector=<span class="built_in">type</span>=Warning --all-namespaces</span></span><br></pre></td></tr></table></figure>
<h2 id="52-获取Alertmanager的告警信息"><a href="#52-获取Alertmanager的告警信息" class="headerlink" title="52. 获取Alertmanager的告警信息"></a>52. 获取Alertmanager的告警信息</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec -it alertmanager-main-0 -c alertmanager -n openshift-monitoring -- amtool alert query &#x27;severity=critical&#x27; --alertmanager.url http://localhost:9093</span><br></pre></td></tr></table></figure>
<h2 id="53-获取statefulset中的Pod的序号"><a href="#53-获取statefulset中的Pod的序号" class="headerlink" title="53. 获取statefulset中的Pod的序号"></a>53. 获取statefulset中的Pod的序号</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[ $(hostname) =~ -([0-9]+)$ ]]  || exit</span><br><span class="line">ordinal=$&#123;BASH_REMATCH[1]&#125;</span><br></pre></td></tr></table></figure>
<p>其中<code>ordinal</code>即为statefulset中的序号，一般可用在initContainers中对Pod进行初始化配置设置，具体生产实践中可灵活使用。</p>
<h2 id="54-清理镜像仓库中的镜像"><a href="#54-清理镜像仓库中的镜像" class="headerlink" title="54. 清理镜像仓库中的镜像"></a>54. 清理镜像仓库中的镜像</h2><p><code>镜像仓库必须开启可删除功能</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -k -I -H <span class="string">&quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot;</span> -I http://localhost:5000/v2/openshift/ocp-router/manifests/v3.11.129</span></span><br><span class="line">获取镜像层的sha256值</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -X DELETE http://localhost:5000/v2/openshift/ocp-router/manifests/sha256:39ad17c3e10f902d8b098ee5128a87d4293b6d07cbc2d1e52ed9ddf0076e3cf9</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="comment">#登录到镜像仓库</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">registry garbage-collect /etc/docker-distribution/registry/config.yml</span></span><br></pre></td></tr></table></figure>
<h2 id="55-AIX部署NFS服务，应用POD无法挂载mount-nfs-Remote-I-O-error"><a href="#55-AIX部署NFS服务，应用POD无法挂载mount-nfs-Remote-I-O-error" class="headerlink" title="55. AIX部署NFS服务，应用POD无法挂载mount.nfs: Remote I/O error."></a>55. AIX部署NFS服务，应用POD无法挂载<code>mount.nfs: Remote I/O error.</code></h2><p>默认情况下，NFS客户端通过NFSv4协议访问NFS服务，如果AIX部署NFS时不支持NFSv4协议，则在挂载时会报<code>mount.nfs: Remote I/O error.</code>的错误。可通过<code>nfsstat -s</code>查看服务端支持的NFS版本。<br>有两种解决方法：</p>
<ol>
<li>重新配置NFS Server，让其支持NFSv4；</li>
<li>配置PV，强制使用NFSv3来访问后端NFS服务。<br>参考配置如下：spec.mountOptions<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0003</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  mountOptions:</span><br><span class="line">    - hard</span><br><span class="line">    - nfsvers=3</span><br><span class="line">  nfs:</span><br><span class="line">    path: /tmp</span><br><span class="line">    server: 172.17.0.2</span><br></pre></td></tr></table></figure>
另外也可以通过添加<code>annotations.volume.beta.kubernetes.io/mount-options</code>来设置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc patch pv pv0003 -p &#x27;&#123;&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&quot;volume.beta.kubernetes.io/mount-options&quot;:&quot;rw,nfsvers=3&quot;&#125;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure>
参考文章：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/">https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/</a></li>
</ol>
<h2 id="56-将POD从副本控制器中脱离"><a href="#56-将POD从副本控制器中脱离" class="headerlink" title="56. 将POD从副本控制器中脱离"></a>56. 将POD从副本控制器中脱离</h2><p>在应用运行过程中，某些场景下，需要将某个POD从业务流量中脱离。例如在问题排查时，一旦应用重启，将不易于具体线上问题的排查，这时我们需要在尽快恢复应用的情况下，保留问题POD的状态。<br>方法很简单，就是利用Label。我们知道在K8S&#x2F;OCP中，各种资源的关系都是通过Label来建立的，只需要将POD的Label去掉，让它就会成为一个孤立的POD，应用的迭代不会对POD的生命周期有影响，同时业务流量也不会分发到该POD。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc label pod xxx-pod --list //查看当前pod所有label</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc label pod xxx-pod &lt;LABEL-A&gt;-  &lt;LABEL-B&gt;- //删除关联的LABEL</span></span><br></pre></td></tr></table></figure>
<h2 id="57-Node状态变为NotReady，且检查状态为Unknown"><a href="#57-Node状态变为NotReady，且检查状态为Unknown" class="headerlink" title="57. Node状态变为NotReady，且检查状态为Unknown."></a>57. Node状态变为NotReady，且检查状态为Unknown.</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/85163586fd84e228718d24e7b9207a672004f64164519854aa8d435a203594ad.png" alt="Status">  </p>
<p>可检查下CSR，是否存在Pending</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get csr</span><br></pre></td></tr></table></figure>
<p>批准这些CSR即可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ oc get csr -o name | xargs oc adm certificate approve</span><br><span class="line">或</span><br><span class="line">$ kubectl get csr -o name | xargs kubectl certificate approve</span><br></pre></td></tr></table></figure>
<h2 id="58-No-space-left-on-device，但df-h查看空间空空的"><a href="#58-No-space-left-on-device，但df-h查看空间空空的" class="headerlink" title="58. No space left on device，但df -h查看空间空空的"></a>58. No space left on device，但<code>df -h</code>查看空间空空的</h2><p>还需要检查一下inodes </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">df</span> -ih</span></span><br><span class="line">Filesystem     Inodes IUsed IFree IUse% Mounted on</span><br><span class="line">/dev/sdb          16M  502K   16M    4% /</span><br></pre></td></tr></table></figure>
<p><strong>如果发现IUse% 为100，就没法再存储数据了。</strong><br>解决办法 ： rm -rf 一些小而多的文件，如日志等。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://xhua.eu.org">Michael Pan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://xhua.eu.org/openshift/Openshift-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/">https://xhua.eu.org/openshift/Openshift-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://xhua.eu.org" target="_blank">Michael Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/openshift/">openshift</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/80ad677abfc8210c0f9eb91a5e2465d9f40dd419ca0f2937a12ed348f15ef874.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/DevOps/Vagrant%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A1%AC%E7%9B%98%E6%89%A9%E5%AE%B9/" title="Vagrant扩展虚拟机盘"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/dbdae12659719bbc8950b11f32a73f7e3b19c5b6ea04569b246faa257db88a96.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Vagrant扩展虚拟机盘</div></div></a></div><div class="next-post pull-right"><a href="/DevOps/%E4%BD%BF%E7%94%A8Ansible-Tower%E4%B8%8EJenkins%E9%9B%86%E6%88%90%E5%AE%9E%E7%8E%B0CI-CD/" title="使用Ansible-Tower与Jenkins集成实现CI-CD"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/417cb66870058dd036ecb4dd3a5f72dc88b36b52abfdda5217a1e56abbc6d983.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">使用Ansible-Tower与Jenkins集成实现CI-CD</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/openshift/OpenShift%E5%8E%8B%E6%B5%8B%E5%B7%A5%E4%BD%9C%E5%BF%85%E4%B8%8D%E5%8F%AF%E5%B0%91%EF%BC%8C%E4%BD%BF%E7%94%A8Jmeter%E6%90%9E%E8%B5%B7%E6%9D%A5/" title="OpenShift压测工作必不可少，使用Jmeter搞起来"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/512fcb2e6bfc0f403c4fb13abdcd4e8887f67e51fd96f5cccec18af22370b029.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-21</div><div class="title">OpenShift压测工作必不可少，使用Jmeter搞起来</div></div></a></div><div><a href="/openshift/Ansible%E7%9A%84k8s%E6%A8%A1%E5%9D%97%E5%AE%8C%E5%85%A8%E5%85%BC%E5%AE%B9OpenShift%E8%B5%84%E6%BA%90/" title="Ansible的k8s模块完全兼容OpenShift资源"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/fc72af997388e4feba0fe78e3f5d658b0eab7b435848821d8d70366eab9bff10.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-20</div><div class="title">Ansible的k8s模块完全兼容OpenShift资源</div></div></a></div><div><a href="/openshift/Calico-BGP%E9%9B%86%E7%BE%A4%E5%A4%96%E9%83%A8%E4%B8%8E%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E6%89%93%E9%80%9A/" title="Calico-BGP集群外部与集群网络打通"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-20</div><div class="title">Calico-BGP集群外部与集群网络打通</div></div></a></div><div><a href="/openshift/CentOS%E4%B8%8AOpenLDAP-Server%E4%BD%BF%E7%94%A8cn=config%E6%96%B9%E5%BC%8F%E9%85%8D%E7%BD%AE/" title="CentOS上OpenLDAP-Server使用cn&#x3D;config方式配置"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/981acb9f90eee67551a5c9aefaa8fa8299661e7c7d8df631e7275d81783ece51.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-20</div><div class="title">CentOS上OpenLDAP-Server使用cn&#x3D;config方式配置</div></div></a></div><div><a href="/openshift/CentOS%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%8F%8C%E4%B8%BB%E9%AB%98%E5%8F%AF%E7%94%A8OpenLDAP-Server/" title="CentOS上搭建双主高可用OpenLDAP-Server"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/d4c7918cf1ea787335aca05ec8834b1b3d2e83d12ecb9fdfd5911ce3016f2ea2.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-20</div><div class="title">CentOS上搭建双主高可用OpenLDAP-Server</div></div></a></div><div><a href="/openshift/Ceph%E7%9A%84%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%8F%8Aopenshift%E4%B8%8A%E4%BD%BF%E7%94%A8ceph-rbd%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8/" title="Ceph的搭建流程及openshift上使用ceph-rbd实现动态存储"><img class="cover" src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4328c75cf6fc869f4b312ec595d7c5ea52567c3ba061d57733a7ddb5f01cbf25.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-20</div><div class="title">Ceph的搭建流程及openshift上使用ceph-rbd实现动态存储</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%89%A9%E5%AE%B9%E8%AE%A1%E7%AE%97%E7%BB%93%E7%82%B9"><span class="toc-text">1.扩容计算结点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-OpenShift-Metrics"><span class="toc-text">2.OpenShift Metrics</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-OpenShift-Logging"><span class="toc-text">3.OpenShift Logging</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-OpenShift-Multitenant-Networking"><span class="toc-text">4.OpenShift Multitenant Networking</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86netproj-a%E7%BD%91%E7%BB%9C%E4%B8%8Enetproj-b%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5"><span class="toc-text">将netproj-a网络与netproj-b网络连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86netproj-a%E7%BD%91%E7%BB%9C%E8%84%B1%E7%A6%BB"><span class="toc-text">将netproj-a网络脱离</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Node%E7%AE%A1%E7%90%86"><span class="toc-text">5.Node管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86Node%E9%9A%94%E7%A6%BB%E5%87%BA%E9%9B%86%E7%BE%A4"><span class="toc-text">将Node隔离出集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9ANode%E4%B8%8A%E8%BF%90%E8%A1%8C%E7%9A%84pod"><span class="toc-text">查看指定Node上运行的pod</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%81%E7%A7%BB%E6%8C%87%E5%AE%9ANode%E4%B8%8A%E7%9A%84pod"><span class="toc-text">迁移指定Node上的pod</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E6%8B%9F%E8%BF%81%E7%A7%BB"><span class="toc-text">模拟迁移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%81%E7%A7%BB"><span class="toc-text">迁移</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%81%A2%E5%A4%8DNode%E7%9A%84%E5%8F%AF%E8%B0%83%E5%BA%A6"><span class="toc-text">恢复Node的可调度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAvolume"><span class="toc-text">创建volume</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Increasing-Storage-Capacity-in-CNS"><span class="toc-text">Increasing Storage Capacity in CNS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E5%B7%B2%E6%9C%89%E8%8A%82%E7%82%B9%E7%9A%84%E7%9B%98"><span class="toc-text">添加已有节点的盘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A7%BB%E9%99%A4%E6%9C%89%E9%97%AE%E9%A2%98%E7%9A%84%E7%9B%98"><span class="toc-text">移除有问题的盘</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%BB%99Registry%E7%BB%84%E4%BB%B6%E6%B7%BB%E5%8A%A0Volume"><span class="toc-text">6.给Registry组件添加Volume</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E6%9B%B4%E6%94%B9dc%E7%9A%84%E9%95%9C%E5%83%8F"><span class="toc-text">7.更改dc的镜像</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E7%BB%99A%E9%A1%B9%E7%9B%AE%E6%8E%88%E4%BA%88%E6%8B%89%E5%8F%96B%E9%A1%B9%E7%9B%AEIS%E7%9A%84%E6%9D%83%E9%99%90"><span class="toc-text">8.给A项目授予拉取B项目IS的权限</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E7%BB%99Jenkins%E6%8E%88%E4%BA%88%E7%AE%A1%E7%90%86A%E9%A1%B9%E7%9B%AE%E8%B5%84%E6%BA%90%E7%9A%84%E6%9D%83%E9%99%90"><span class="toc-text">9.给Jenkins授予管理A项目资源的权限</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%89%8B%E5%8A%A8%E7%BB%B4%E6%8A%A4etcd"><span class="toc-text">10.手动维护etcd</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E6%89%A7%E8%A1%8C%E9%95%9C%E5%83%8F%E5%AF%B9%E5%BA%94%E7%9A%84%E4%BB%BB%E5%8A%A1"><span class="toc-text">11.执行镜像对应的任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E6%B8%85%E7%90%86%E4%B8%BB%E6%9C%BA%E5%AE%B9%E5%99%A8"><span class="toc-text">12.清理主机容器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-Node%E8%8A%82%E7%82%B9%E5%86%85%E5%AD%98%E4%B8%8ECPU%E9%A2%84%E7%95%99"><span class="toc-text">13.Node节点内存与CPU预留</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E7%94%A8oc-get%E5%8F%AA%E6%9F%A5%E7%9C%8Bdc%E7%9A%84%E9%95%9C%E5%83%8F%E5%90%8D"><span class="toc-text">14.用oc get只查看dc的镜像名</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-Openshift-Webconsole%E6%94%AF%E6%8C%81%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93"><span class="toc-text">15.Openshift Webconsole支持私有镜像仓库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-Docker%E6%94%AF%E6%8C%81%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93tls%E8%AE%A4%E8%AF%81"><span class="toc-text">16.Docker支持私有镜像仓库tls认证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-%E6%9F%A5%E7%9C%8Betcd%E6%95%B0%E6%8D%AE"><span class="toc-text">17.查看etcd数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9F%90%E4%B8%AA%E9%A1%B9%E7%9B%AEproject%E4%B8%8B%E6%89%80%E6%9C%89pod%E7%9A%84limits-cpu-x2F-memory%E7%9A%84%E6%80%BB%E5%92%8C"><span class="toc-text">计算某个项目project下所有pod的limits cpu&#x2F;memory的总和</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#19-DNSMasq%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E6%8A%A5%E9%94%99%E2%80%9CDBus-error-Connection-%E2%80%9C-1-180%E2%80%9D-is-not-allowed-to-own-the-service-%E2%80%9Cuk-org-thekelleys-dnsmasq%E2%80%9D-%E2%80%9D"><span class="toc-text">19.DNSMasq启动失败报错“DBus error: Connection “:1.180” is not allowed to own the service “uk.org.thekelleys.dnsmasq” ”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#20-ssh%E7%89%B9%E5%88%AB%E6%85%A2%EF%BC%8C%E5%8D%A1%E5%9C%A8debug1-pledge-network%E4%BD%8D%E7%BD%AE"><span class="toc-text">20.ssh特别慢，卡在debug1: pledge: network位置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#21-%E6%B8%85%E7%90%86%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93"><span class="toc-text">21.清理私有镜像仓库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-docker-run%E8%A6%86%E7%9B%96entrypoint"><span class="toc-text">22.docker run覆盖entrypoint</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-oc-image-mirror%E5%90%8C%E6%AD%A5%E9%95%9C%E5%83%8F"><span class="toc-text">23.oc image mirror同步镜像</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#24-%E5%BC%80%E9%80%9A%E7%AB%AF%E5%8F%A3%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-text">24.开通端口防火墙</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#25-%E6%9F%A5%E7%9C%8Bcrt%E8%AF%81%E4%B9%A6%E6%9C%89%E6%95%88%E6%97%B6%E9%97%B4"><span class="toc-text">25.查看crt证书有效时间</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#26-%E5%B0%86%E4%B8%BB%E6%9C%BA%E8%AE%BE%E4%B8%BA%E4%B8%8D%E5%8F%AF%E8%B0%83%E5%BA%A6"><span class="toc-text">26.将主机设为不可调度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#27-%E9%A9%B1%E9%80%90%E4%B8%BB%E6%9C%BA%E4%B8%8A%E7%9A%84POD"><span class="toc-text">27.驱逐主机上的POD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#28-Service%E7%9A%84%E5%9F%9F%E5%90%8D"><span class="toc-text">28.Service的域名</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#29-%E6%9F%A5%E7%9C%8BDocker%E9%95%9C%E5%83%8F%E7%9A%84%E6%9E%84%E5%BB%BA%E5%8E%86%E5%8F%B2%E5%91%BD%E4%BB%A4"><span class="toc-text">29.查看Docker镜像的构建历史命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#30-%E5%BA%94%E7%94%A8%E5%9C%A8%E5%AE%8C%E6%88%90Build%E5%90%8E%E6%8E%A8%E9%80%81%E5%88%B0%E5%86%85%E9%83%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E5%A6%82%E4%B8%8B%E6%8A%A5%E9%94%99%E8%AF%AF"><span class="toc-text">30.应用在完成Build后推送到内部镜像仓库如下报错误</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#31-%E4%B8%BA%E5%AE%B9%E5%99%A8%E7%94%A8%E6%88%B7%E6%8C%87%E5%AE%9A%E7%94%A8%E6%88%B7%E5%90%8D"><span class="toc-text">31.为容器用户指定用户名</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#32-%E5%8D%87%E7%BA%A7Docker"><span class="toc-text">32.升级Docker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#33-%E8%8E%B7%E5%8F%96Token%E5%B9%B6%E8%AF%B7%E6%B1%82OpenShift-ASB%E6%9C%8D%E5%8A%A1%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="toc-text">33.获取Token并请求OpenShift ASB服务的例子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#34-%E8%B0%83%E7%94%A8OpenShift-API%E8%8E%B7%E5%8F%96Pod%E4%BF%A1%E6%81%AF"><span class="toc-text">34.调用OpenShift API获取Pod信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#35-%E4%BD%BF%E7%94%A8HostPath%E6%8C%82%E8%BD%BD%E6%9C%AC%E5%9C%B0%E7%9B%AE%E5%BD%95"><span class="toc-text">35.使用HostPath挂载本地目录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#36-%E5%B0%86%E6%90%9C%E7%B4%A2%E9%95%9C%E5%83%8F%E5%AF%BC%E5%87%BA%E5%88%B0%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E8%84%9A%E6%9C%AC"><span class="toc-text">36.将搜索镜像导出到本地文件脚本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#37-Docker%E6%97%A5%E5%BF%97%E4%B8%AD%E6%9C%89%E9%94%99%E8%AF%AF-container-kill-failed-because-of-container-not-found-or-no-such-process"><span class="toc-text">37.Docker日志中有错误 container kill failed because of container not found or no such process</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#38-%E6%9F%A5%E7%9C%8B%E6%89%80%E6%9C%89%E5%BA%94%E7%94%A8%E9%87%8D%E5%90%AF%E6%AC%A1%E6%95%B0%EF%BC%8C%E5%B9%B6%E4%B8%94%E6%8E%92%E5%BA%8F"><span class="toc-text">38.查看所有应用重启次数，并且排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#39-docker%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E6%8A%A5%E9%94%99%EF%BC%9A400-unsupported-docker-v1-repository-request"><span class="toc-text">39.docker拉取镜像报错：400 unsupported docker v1 repository request</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#40-%E5%BA%94%E7%94%A8%E6%97%A5%E5%BF%97%E6%97%A0%E6%B3%95%E6%9F%A5%E7%9C%8B%EF%BC%8Coc-exec%E4%B9%9F%E6%97%A0%E6%B3%95%E8%BF%9B%E5%85%A5%E5%AE%B9%E5%99%A8"><span class="toc-text">40.应用日志无法查看，oc exec也无法进入容器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#41-netmanager%E5%B7%A5%E5%85%B7%E8%AE%BE%E7%BD%AE%E4%BA%86dns%EF%BC%8C%E6%97%A0%E6%B3%95%E7%9B%B4%E6%8E%A5%E9%80%9A%E8%BF%87-x2F-etc-x2F-resolv-conf%E6%96%87%E4%BB%B6%E6%9B%B4%E6%94%B9"><span class="toc-text">41.netmanager工具设置了dns，无法直接通过&#x2F;etc&#x2F;resolv.conf文件更改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#42-%E6%9F%A5%E7%9C%8B%E9%9B%86%E7%BE%A4%E5%BD%93%E5%89%8D%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E8%B5%84%E6%BA%90%E7%9A%84%E5%88%86%E9%85%8D%E7%8E%87"><span class="toc-text">42.查看集群当前计算节点资源的分配率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#43-%E5%AE%89%E8%A3%85%E6%97%B6master-api%E6%9C%8D%E5%8A%A1%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AEetcd"><span class="toc-text">43.安装时master api服务无法访问etcd</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#44-%E5%AE%89%E8%A3%85%E6%97%B6master%E8%8A%82%E7%82%B9%E6%9C%89%E5%A4%9A%E5%BC%A0%E7%BD%91%E5%8D%A1%EF%BC%8C%E5%A6%82%E4%BD%95%E6%8C%87%E5%AE%9AmasterIP"><span class="toc-text">44.安装时master节点有多张网卡，如何指定masterIP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#45-%E9%83%A8%E7%BD%B2%E9%9B%86%E7%BE%A4%E6%97%B6%EF%BC%8C%E9%87%87%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%81%E4%B9%A6%EF%BC%8CMaster1%E8%8A%82%E7%82%B9%E6%8A%A5x509-certificate-signed-by-unknown-authority%E9%94%99%E8%AF%AF"><span class="toc-text">45.部署集群时，采用自定义证书，Master1节点报x509: certificate signed by unknown authority错误</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#46-%E9%83%A8%E7%BD%B2%E6%97%B6%E7%BD%91%E7%BB%9C%E9%94%99%E8%AF%AF%EF%BC%8C%E9%9C%80%E8%A6%81%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E9%85%8D%E7%BD%AE%E4%BA%86%E9%BB%98%E8%AE%A4%E8%B7%AF%E7%94%B1%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%EF%BC%8C%E5%88%99%E9%9C%80%E8%A6%81%E8%AE%BE%E7%BD%AE"><span class="toc-text">46.部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#47-%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E6%9C%80%E8%BF%91%E4%B8%80%E4%B8%AA%E6%9C%88%E7%9A%84%E6%96%87%E4%BB%B6"><span class="toc-text">47. 删除指定文件夹下最近一个月的文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#48-pod%E6%8A%A5the-node-was-low-on-resource-ephemeral-storage%E8%80%8C%E8%A2%AB%E9%A9%B1%E9%80%90"><span class="toc-text">48.pod报the node was low on resource ephemeral-storage而被驱逐</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#49-%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6"><span class="toc-text">49.自签证书</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#50-ETCD%E6%9F%90%E4%B8%AA%E8%8A%82%E7%82%B9%E6%97%A0%E6%B3%95%E9%87%8D%E5%90%AF%EF%BC%8C%E6%8A%A5%E9%94%99rafthttp-the-clock-difference-against-peer-27de23fad174dca-is-too-high-1m16-89887s-gt-1s"><span class="toc-text">50. ETCD某个节点无法重启，报错rafthttp: the clock difference against peer 27de23fad174dca is too high [1m16.89887s &gt; 1s]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#51-%E6%9F%A5%E7%9C%8B%E6%9C%80%E8%BF%91%E4%B8%80%E5%B0%8F%E6%97%B6%E7%9A%84Event-%E5%91%8A%E8%AD%A6%E4%BA%8B%E4%BB%B6"><span class="toc-text">51. 查看最近一小时的Event 告警事件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#52-%E8%8E%B7%E5%8F%96Alertmanager%E7%9A%84%E5%91%8A%E8%AD%A6%E4%BF%A1%E6%81%AF"><span class="toc-text">52. 获取Alertmanager的告警信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#53-%E8%8E%B7%E5%8F%96statefulset%E4%B8%AD%E7%9A%84Pod%E7%9A%84%E5%BA%8F%E5%8F%B7"><span class="toc-text">53. 获取statefulset中的Pod的序号</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#54-%E6%B8%85%E7%90%86%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E4%B8%AD%E7%9A%84%E9%95%9C%E5%83%8F"><span class="toc-text">54. 清理镜像仓库中的镜像</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#55-AIX%E9%83%A8%E7%BD%B2NFS%E6%9C%8D%E5%8A%A1%EF%BC%8C%E5%BA%94%E7%94%A8POD%E6%97%A0%E6%B3%95%E6%8C%82%E8%BD%BDmount-nfs-Remote-I-O-error"><span class="toc-text">55. AIX部署NFS服务，应用POD无法挂载mount.nfs: Remote I&#x2F;O error.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#56-%E5%B0%86POD%E4%BB%8E%E5%89%AF%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%99%A8%E4%B8%AD%E8%84%B1%E7%A6%BB"><span class="toc-text">56. 将POD从副本控制器中脱离</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#57-Node%E7%8A%B6%E6%80%81%E5%8F%98%E4%B8%BANotReady%EF%BC%8C%E4%B8%94%E6%A3%80%E6%9F%A5%E7%8A%B6%E6%80%81%E4%B8%BAUnknown"><span class="toc-text">57. Node状态变为NotReady，且检查状态为Unknown.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#58-No-space-left-on-device%EF%BC%8C%E4%BD%86df-h%E6%9F%A5%E7%9C%8B%E7%A9%BA%E9%97%B4%E7%A9%BA%E7%A9%BA%E7%9A%84"><span class="toc-text">58. No space left on device，但df -h查看空间空空的</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/xhuaustc/images@main/80ad677abfc8210c0f9eb91a5e2465d9f40dd419ca0f2937a12ed348f15ef874.png')"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By Michael Pan</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'bd411f7fab0148676434',
      clientSecret: 'c428724cacf9b34ab17326dec6d6e8a2e23b6c15',
      repo: 'xhuaustc.github.io',
      owner: 'xhuaustc',
      admin: ['xhuaustc'],
      id: 'ffaba0a6598ae7a1af089793e547c6cc',
      updateCountCallback: commentCount
    },{"language":"zh-CN"}))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.textContent= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>