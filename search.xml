<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LiteLLM Proxy 使用指南：Docker 部署、vLLM 代理</title>
      <link href="/AI/LiteLLM-Proxy-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%EF%BC%9ADocker%E9%83%A8%E7%BD%B2%E3%80%81vLLM%E4%BB%A3%E7%90%86/"/>
      <url>/AI/LiteLLM-Proxy-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%EF%BC%9ADocker%E9%83%A8%E7%BD%B2%E3%80%81vLLM%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="背景与目标"><a href="#背景与目标" class="headerlink" title="背景与目标"></a>背景与目标</h2><p>LiteLLM Proxy 是一个 OpenAI API 兼容的模型网关，支持将来自 OpenAI、Azure OpenAI、Bedrock、Vertex AI 以及本地&#x2F;自建的 OpenAI 兼容推理服务（如 vLLM）统一到一套接口之下，并提供虚拟 API Key、用量与预算、速率限制、缓存、日志&#x2F;指标、路由、负载均衡与回退等能力。本文将演示：</p><ul><li>如何用 Docker 快速部署 LiteLLM Proxy（含最小可用与带数据库的完整模式）</li><li>如何把 vLLM 暴露的 OpenAI 兼容接口接入到 LiteLLM Proxy 进行统一代理</li><li>如何生成虚拟 Key、设置每分钟请求数（RPM）限速</li><li>如何查询模型列表等常用“免费”功能</li></ul><p>参考与更多细节请见官方文档：</p><ul><li><a href="https://docs.litellm.ai/docs/proxy/docker_quick_start">LiteLLM Proxy Docker 快速上手</a></li><li><a href="https://docs.litellm.ai/docs/providers/vllm">vLLM Provider 文档</a></li></ul><h2 id="你将学到什么"><a href="#你将学到什么" class="headerlink" title="你将学到什么"></a>你将学到什么</h2><ul><li>用 Docker 启动 LiteLLM Proxy，并验证 <code>/chat/completions</code></li><li>将本地 vLLM（OpenAI 兼容接口）纳入代理，统一用 OpenAI 协议调用</li><li>配置同名模型多后端负载均衡，实现流量分发与高可用</li><li>在不接数据库的前提下，如何给”不同团队”分发可控的 Key（网关方案）</li><li>接入数据库后，如何生成”虚拟 Key”、设置限速并进行用量治理</li><li>查询模型列表、排错以及生产级监控与高可用实践</li></ul><h2 id="核心功能速览"><a href="#核心功能速览" class="headerlink" title="核心功能速览"></a>核心功能速览</h2><ul><li><strong>OpenAI 兼容</strong>：统一 <code>/chat/completions</code>、<code>/embeddings</code> 等接口</li><li><strong>多模型路由</strong>：一个代理前面挂多家模型与自建 vLLM</li><li><strong>负载均衡</strong>：同名模型多后端分发，支持 simple-shuffle、usage-based-routing、latency-based-routing 等策略</li><li><strong>密钥治理</strong>：<ul><li>无数据库：用网关做静态 Key 白名单 + 限速 + 审计</li><li>带数据库：原生虚拟 Key、预算&#x2F;配额、团队&#x2F;用户可视化管理</li></ul></li><li><strong>可观测性</strong>：日志、指标、追踪，支持缓存与回退策略</li></ul><h2 id="如何阅读这篇文章"><a href="#如何阅读这篇文章" class="headerlink" title="如何阅读这篇文章"></a>如何阅读这篇文章</h2><ul><li>想快速跑通：直接看”快速开始”和”对接 vLLM”。</li><li>需要负载均衡：看”负载均衡：同名模型多后端分发”。</li><li>无数据库就要分发团队 Key：看”无数据库的密钥治理（最简部署）”。</li><li>需要 RPM&#x2F;预算&#x2F;面板：看”使用 Docker Compose（Proxy + Postgres）”与”生成虚拟 Key 并设置限速（RPM）”。</li><li>线上实践：看”生产部署实践（监控与高可用）”。</li></ul><h2 id="快速开始（最小可用）"><a href="#快速开始（最小可用）" class="headerlink" title="快速开始（最小可用）"></a>快速开始（最小可用）</h2><p>你可以直接拉取官方镜像并用一份 <code>config.yaml</code> 启动 Proxy。下面示例展示最小可用部署（未接数据库、仅用于功能验证）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pull image</span></span><br><span class="line">docker pull ghcr.io/berriai/litellm:main-latest</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start proxy with your config (created in next section)</span></span><br><span class="line">docker run \</span><br><span class="line">  -v $(<span class="built_in">pwd</span>)/litellm_config.yaml:/app/config.yaml \</span><br><span class="line">  -e AZURE_API_KEY=demo \</span><br><span class="line">  -e AZURE_API_BASE=https://example.openai.azure.com/ \</span><br><span class="line">  -p 4000:4000 \</span><br><span class="line">  ghcr.io/berriai/litellm:main-latest \</span><br><span class="line">  --config /app/config.yaml --detailed_debug</span><br><span class="line"><span class="comment"># Proxy up at http://0.0.0.0:4000</span></span><br></pre></td></tr></table></figure><p>最简单的 <code>litellm_config.yaml</code>（示例使用 Azure OpenAI，仅用于快速跑通 Proxy）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">model_list:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">gpt-4o</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">azure/my_azure_deployment</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">os.environ/AZURE_API_BASE</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">os.environ/AZURE_API_KEY</span></span><br><span class="line">      <span class="attr">api_version:</span> <span class="string">&quot;2025-01-01-preview&quot;</span> <span class="comment"># optional</span></span><br></pre></td></tr></table></figure><blockquote><p>提示：启动后可用 <code>POST /chat/completions</code> 进行测试，详见下文调用示例。</p></blockquote><h2 id="使用-Docker-Compose（Proxy-Postgres）"><a href="#使用-Docker-Compose（Proxy-Postgres）" class="headerlink" title="使用 Docker Compose（Proxy + Postgres）"></a>使用 Docker Compose（Proxy + Postgres）</h2><p>如果需要启用虚拟 Key、用户&#x2F;团队管理、预算与用量统计等高级功能，建议配合 Postgres 使用。官方提供了现成的 <code>docker-compose.yml</code> 与 <code>.env</code> 用法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get the compose file</span></span><br><span class="line">curl -O https://raw.githubusercontent.com/BerriAI/litellm/main/docker-compose.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set master key (admin) and salt key (for encrypting provider keys)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;LITELLM_MASTER_KEY=&quot;sk-1234&quot;&#x27;</span> &gt; .<span class="built_in">env</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;LITELLM_SALT_KEY=&quot;sk-1234&quot;&#x27;</span> &gt;&gt; .<span class="built_in">env</span></span><br><span class="line"><span class="built_in">source</span> .<span class="built_in">env</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start services</span></span><br><span class="line">docker-compose up</span><br></pre></td></tr></table></figure><p>将数据库接入到 <code>config.yaml</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">model_list:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">gpt-4o</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">azure/my_azure_deployment</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">os.environ/AZURE_API_BASE</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">os.environ/AZURE_API_KEY</span></span><br><span class="line">      <span class="attr">api_version:</span> <span class="string">&quot;2025-01-01-preview&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">general_settings:</span></span><br><span class="line">  <span class="attr">master_key:</span> <span class="string">sk-1234</span></span><br><span class="line">  <span class="attr">database_url:</span> <span class="string">&quot;postgresql://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;dbname&gt;&quot;</span></span><br></pre></td></tr></table></figure><blockquote><p>使用数据库后，默认提供 <code>/ui</code> 管理界面，可在浏览器访问。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f19054cd5a30c001351101907ad7e93623a3f950f9809518f1b795b6a80d9212.png" alt="UI">  </p><h2 id="对接-vLLM：把自建模型纳入统一代理"><a href="#对接-vLLM：把自建模型纳入统一代理" class="headerlink" title="对接 vLLM：把自建模型纳入统一代理"></a>对接 vLLM：把自建模型纳入统一代理</h2><p>vLLM 可以以 OpenAI 兼容方式暴露推理服务（<code>/v1</code> 路径）。我们先启动 vLLM，再在 LiteLLM 里将其注册为一个“模型”。</p><h3 id="1-启动-vLLM（OpenAI-兼容-API）"><a href="#1-启动-vLLM（OpenAI-兼容-API）" class="headerlink" title="1) 启动 vLLM（OpenAI 兼容 API）"></a>1) 启动 vLLM（OpenAI 兼容 API）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example: start vLLM OpenAI-compatible server</span></span><br><span class="line">python -m vllm.entrypoints.openai.api_server \</span><br><span class="line">  --model meta-llama/Llama-3.1-8B-Instruct \</span><br><span class="line">  --host 0.0.0.0 \</span><br><span class="line">  --port 8000</span><br><span class="line"><span class="comment"># vLLM OpenAI API at http://&lt;host&gt;:8000/v1</span></span><br></pre></td></tr></table></figure><blockquote><p>如果使用容器化 vLLM，请确保 LiteLLM Proxy 容器能够访问到 vLLM 的 <code>http://&lt;host&gt;:8000/v1</code>（可用 <code>host.docker.internal</code> 或桥接网络）。</p></blockquote><h3 id="2-在-LiteLLM-中注册-vLLM-模型"><a href="#2-在-LiteLLM-中注册-vLLM-模型" class="headerlink" title="2) 在 LiteLLM 中注册 vLLM 模型"></a>2) 在 LiteLLM 中注册 vLLM 模型</h3><p>LiteLLM 对“OpenAI 兼容端点”的使用建议前缀为 <code>hosted_vllm/</code>。将 <code>litellm_params.model</code> 设为 <code>hosted_vllm/&lt;model-identifier&gt;</code>，并把 <code>api_base</code> 指向你 vLLM 的 <code>/v1</code> 即可。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># file: litellm_config.yaml</span></span><br><span class="line"><span class="attr">model_list:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">llama-3.1-8b-instruct</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">hosted_vllm/llama-3.1-8b-instruct</span>  <span class="comment"># route to OpenAI-compatible vLLM</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">os.environ/HOSTED_VLLM_API_BASE</span> <span class="comment"># e.g. http://host.docker.internal:8000/v1</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">os.environ/HOSTED_VLLM_API_KEY</span>   <span class="comment"># optional if your vLLM server doesn&#x27;t require it</span></span><br><span class="line"></span><br><span class="line"><span class="attr">general_settings:</span></span><br><span class="line">  <span class="attr">master_key:</span> <span class="string">sk-1234</span>                           <span class="comment"># required if you want admin/virtual keys</span></span><br></pre></td></tr></table></figure><p>然后启动 LiteLLM Proxy：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">  -v $(<span class="built_in">pwd</span>)/litellm_config.yaml:/app/config.yaml \</span><br><span class="line">  -e HOSTED_VLLM_API_BASE=http://host.docker.internal:8000/v1 \</span><br><span class="line">  -e HOSTED_VLLM_API_KEY=EMPTY \</span><br><span class="line">  -p 4000:4000 \</span><br><span class="line">  ghcr.io/berriai/litellm:main-latest \</span><br><span class="line">  --config /app/config.yaml --detailed_debug</span><br></pre></td></tr></table></figure><p>现在，Proxy 会以 <code>model: &quot;llama-3.1-8b-instruct&quot;</code> 的名义，将请求转发到你本地&#x2F;私有的 vLLM 服务上。</p><h4 id="常见坑速查（vLLM-对接）"><a href="#常见坑速查（vLLM-对接）" class="headerlink" title="常见坑速查（vLLM 对接）"></a>常见坑速查（vLLM 对接）</h4><ul><li><code>404/connection error</code>：<code>api_base</code> 必须指向 vLLM 的 <code>/v1</code> 根，如 <code>http://host:8000/v1</code>。</li><li>容器网络：Proxy 与 vLLM 不在同一网络时，使用 <code>host.docker.internal</code> 或配置自定义 bridge 网络。</li><li>鉴权：若 vLLM 无鉴权，<code>api_key</code> 可留空；若自定义鉴权，请按 vLLM 的要求设置。</li><li>模型名不一致：<code>model_name</code>（对外名）可以自定义，但 <code>litellm_params.model</code> 需符合前缀与路由规则（<code>hosted_vllm/&lt;name&gt;</code>）。</li></ul><h2 id="负载均衡：同名模型多后端分发"><a href="#负载均衡：同名模型多后端分发" class="headerlink" title="负载均衡：同名模型多后端分发"></a>负载均衡：同名模型多后端分发</h2><p>在 <code>model_list</code> 中设置同名的 <code>model_name</code>，可实现流量负载到不同的后端。这种情况下 <code>master_key</code> 是必须的。同时路由策略默认为：<code>simple-shuffle</code>，其它策略可在 <a href="https://docs.litellm.ai/docs/proxy/load_balancing">LiteLLM 负载均衡文档</a> 中查看。</p><h3 id="负载均衡配置示例"><a href="#负载均衡配置示例" class="headerlink" title="负载均衡配置示例"></a>负载均衡配置示例</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># file: litellm_config.yaml</span></span><br><span class="line"><span class="attr">model_list:</span></span><br><span class="line">  <span class="comment"># 第一个后端实例</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">llama-3.1-8b-instruct</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">hosted_vllm/llama-3.1-8b-instruct</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">http://vllm-backend-1:8000/v1</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 第二个后端实例（同名模型）</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">llama-3.1-8b-instruct</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">hosted_vllm/llama-3.1-8b-instruct</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">http://vllm-backend-2:8000/v1</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 第三个后端实例（同名模型）</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">llama-3.1-8b-instruct</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">hosted_vllm/llama-3.1-8b-instruct</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">http://vllm-backend-3:8000/v1</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">general_settings:</span></span><br><span class="line">  <span class="attr">master_key:</span> <span class="string">sk-1234</span>  <span class="comment"># 负载均衡功能需要 master_key</span></span><br><span class="line"><span class="attr">router_settings:</span></span><br><span class="line">  <span class="attr">routing_strategy:</span> <span class="string">simple-shuffle</span>  <span class="comment"># 默认策略，可选：usage-based-routing, latency-based-routing</span></span><br></pre></td></tr></table></figure><h3 id="负载均衡测试"><a href="#负载均衡测试" class="headerlink" title="负载均衡测试"></a>负载均衡测试</h3><p>启动多个 vLLM 后端实例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动第一个 vLLM 实例</span></span><br><span class="line">python -m vllm.entrypoints.openai.api_server \</span><br><span class="line">  --model meta-llama/Llama-3.1-8B-Instruct \</span><br><span class="line">  --host 0.0.0.0 \</span><br><span class="line">  --port 8001</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动第二个 vLLM 实例</span></span><br><span class="line">python -m vllm.entrypoints.openai.api_server \</span><br><span class="line">  --model meta-llama/Llama-3.1-8B-Instruct \</span><br><span class="line">  --host 0.0.0.0 \</span><br><span class="line">  --port 8002</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动第三个 vLLM 实例</span></span><br><span class="line">python -m vllm.entrypoints.openai.api_server \</span><br><span class="line">  --model meta-llama/Llama-3.1-8B-Instruct \</span><br><span class="line">  --host 0.0.0.0 \</span><br><span class="line">  --port 8003</span><br></pre></td></tr></table></figure><p>启动 LiteLLM Proxy：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">  -v $(<span class="built_in">pwd</span>)/litellm_config.yaml:/app/config.yaml \</span><br><span class="line">  -p 4000:4000 \</span><br><span class="line">  ghcr.io/berriai/litellm:main-latest \</span><br><span class="line">  --config /app/config.yaml --detailed_debug</span><br></pre></td></tr></table></figure><h3 id="验证负载均衡效果"><a href="#验证负载均衡效果" class="headerlink" title="验证负载均衡效果"></a>验证负载均衡效果</h3><p>发送多个请求，观察流量分发：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发送 10 个请求，观察负载分发</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..10&#125;; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&quot;Request <span class="variable">$i</span>:&quot;</span></span><br><span class="line">  curl -X POST <span class="string">&#x27;http://0.0.0.0:4000/chat/completions&#x27;</span> \</span><br><span class="line">    -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">    -H <span class="string">&#x27;Authorization: Bearer sk-1234&#x27;</span> \</span><br><span class="line">    -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">      &quot;model&quot;: &quot;llama-3.1-8b-instruct&quot;,</span></span><br><span class="line"><span class="string">      &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">        &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, which backend am I talking to?&quot;&#125;</span></span><br><span class="line"><span class="string">      ],</span></span><br><span class="line"><span class="string">      &quot;max_tokens&quot;: 50</span></span><br><span class="line"><span class="string">    &#125;&#x27;</span> | jq <span class="string">&#x27;.choices[0].message.content&#x27;</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&quot;---&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h3 id="其他路由策略"><a href="#其他路由策略" class="headerlink" title="其他路由策略"></a>其他路由策略</h3><p>除了默认的 <code>simple-shuffle</code>，还可以使用以下策略：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">general_settings:</span></span><br><span class="line">  <span class="attr">master_key:</span> <span class="string">sk-1234</span></span><br><span class="line">  <span class="attr">routing_strategy:</span> <span class="string">usage-based-routing</span>  <span class="comment"># 基于使用量的路由</span></span><br><span class="line">  <span class="comment"># 或者</span></span><br><span class="line">  <span class="attr">routing_strategy:</span> <span class="string">latency-based-routing</span>  <span class="comment"># 基于延迟的路由</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>注意</strong>：负载均衡功能需要 <code>master_key</code> 支持，确保在 <code>general_settings</code> 中正确配置。</p></blockquote><h2 id="通过-Proxy-发起聊天请求"><a href="#通过-Proxy-发起聊天请求" class="headerlink" title="通过 Proxy 发起聊天请求"></a>通过 Proxy 发起聊天请求</h2><p>LiteLLM Proxy 兼容 OpenAI SDK&#x2F;接口。以下用 <code>curl</code> 演示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST <span class="string">&#x27;http://0.0.0.0:4000/chat/completions&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Authorization: Bearer sk-1234&#x27;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;llama-3.1-8b-instruct&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is LiteLLM Proxy?&quot;&#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>如果未使用数据库，你也可以把 <code>Authorization</code> 设置为你在 <code>general_settings.master_key</code> 中配置的主密钥；若启用了虚拟 Key（见下一节），则推荐使用虚拟 Key 访问。</p></blockquote><h2 id="生成虚拟-Key-并设置限速（RPM）"><a href="#生成虚拟-Key-并设置限速（RPM）" class="headerlink" title="生成虚拟 Key 并设置限速（RPM）"></a>生成虚拟 Key 并设置限速（RPM）</h2><p>启用了数据库后，可使用主密钥（<code>master_key</code>）来创建受控的虚拟 Key。例如限制每分钟 1 次请求：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -L -X POST <span class="string">&#x27;http://0.0.0.0:4000/key/generate&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Authorization: Bearer sk-1234&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;&quot;rpm_limit&quot;: 1&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>成功将返回：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span> <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sk-12...&quot;</span> <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>使用该虚拟 Key 调用模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1st call - should succeed</span></span><br><span class="line">curl -X POST <span class="string">&#x27;http://0.0.0.0:4000/chat/completions&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Authorization: Bearer sk-12...&#x27;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;llama-3.1-8b-instruct&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful math tutor.&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How to solve 8x + 7 = -23?&quot;&#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2nd call (within one minute) - should fail with 429</span></span><br><span class="line">curl -X POST <span class="string">&#x27;http://0.0.0.0:4000/chat/completions&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Authorization: Bearer sk-12...&#x27;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;llama-3.1-8b-instruct&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful math tutor.&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;How to solve 8x + 7 = -23?&quot;&#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="查询模型列表（-x2F-models）"><a href="#查询模型列表（-x2F-models）" class="headerlink" title="查询模型列表（&#x2F;models）"></a>查询模型列表（&#x2F;models）</h2><p>LiteLLM Proxy 暴露 OpenAI 兼容的模型列表接口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -s <span class="string">&#x27;http://0.0.0.0:4000/models&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Authorization: Bearer sk-1234&#x27;</span></span><br></pre></td></tr></table></figure><p>返回的列表中将包含你在 <code>model_list</code> 中注册的模型（例如 <code>llama-3.1-8b-instruct</code>）。</p><h2 id="常见问题与故障排除"><a href="#常见问题与故障排除" class="headerlink" title="常见问题与故障排除"></a>常见问题与故障排除</h2><ul><li><p>SSL 校验失败 &#x2F; 连接错误：可在 <code>config.yaml</code> 中关闭 SSL 校验（仅在受信环境调试时使用）。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">litellm_settings:</span></span><br><span class="line">  <span class="attr">ssl_verify:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></li><li><p>数据库连接失败 &#x2F; 权限不足：确认数据库用户有建库&#x2F;建表权限。必要时在数据库中执行授权（云厂商如 CloudSQL 语法略有差异）。</p></li><li><p>非 root 场景：官方提供了非 root 镜像使用说明，按需选择。</p></li><li><p>vLLM 访问不到：检查容器网络连通性，<code>api_base</code> 是否指向了可达的 <code>http://&lt;host&gt;:8000/v1</code>，以及是否通过 <code>host.docker.internal</code> 或自定义 bridge 网络打通。</p></li></ul><h2 id="安全与最佳实践"><a href="#安全与最佳实践" class="headerlink" title="安全与最佳实践"></a>安全与最佳实践</h2><ul><li>生产环境务必使用强随机的 <code>LITELLM_SALT_KEY</code> 与 <code>master_key</code>，切勿在版本库中明文提交。</li><li>对外暴露的 Proxy 建议置于零信任&#x2F;网关之后，搭配 WAF&#x2F;速率限制&#x2F;鉴权策略。</li><li>针对不同团队与应用使用不同的虚拟 Key，并配置预算、RPM&#x2F;TPM、可访问模型白名单。</li><li>定期审计访问日志与开销，启用缓存与模型路由策略以优化成本与稳定性。</li></ul><h2 id="生产部署实践（监控与高可用）"><a href="#生产部署实践（监控与高可用）" class="headerlink" title="生产部署实践（监控与高可用）"></a>生产部署实践（监控与高可用）</h2><h3 id="架构与高可用"><a href="#架构与高可用" class="headerlink" title="架构与高可用"></a>架构与高可用</h3><ul><li><strong>多副本部署</strong>：将 LiteLLM Proxy 以无状态方式水平扩展，多副本 + 负载均衡（Nginx&#x2F;Ingress&#x2F;Gateway）。</li><li><strong>数据库高可用</strong>：Postgres 采用主从&#x2F;托管服务（如 RDS&#x2F;CloudSQL&#x2F;Aurora），开启自动备份与只读副本；连接池建议使用 PgBouncer。</li><li><strong>缓存层</strong>：开启 Proxy 的缓存能力，或引入 Redis 作为响应缓存（对热门提示&#x2F;嵌入有效）。</li><li><strong>故障回退</strong>：在 <code>model_list</code> 中配置路由回退与多提供商冗余，优先同类开源模型或公有云模型作为备份。</li><li><strong>弹性伸缩</strong>：以 QPS&#x2F;RPM、CPU、延迟 P95&#x2F;P99 为指标触发 HPA（K8s 水平自动扩缩容）。</li></ul><h3 id="监控与日志"><a href="#监控与日志" class="headerlink" title="监控与日志"></a>监控与日志</h3><ul><li><strong>核心指标（Proxy）</strong>：<ul><li>请求量：<code>requests_total</code>（按模型、调用方、状态码分维度）</li><li>成功率：<code>success_rate</code>（2xx 比例）</li><li>延迟：<code>latency_ms_p50/p95/p99</code></li><li>速率限制触发：<code>rate_limit_hits</code></li><li>Token&#x2F;成本：<code>input_tokens_total</code>、<code>output_tokens_total</code>、<code>cost_total</code></li></ul></li><li><strong>核心指标（vLLM）</strong>：<ul><li>并发&#x2F;排队：<code>requests_in_flight</code>、<code>queue_depth</code></li><li>显存与负载：<code>gpu_memory_used</code>、<code>gpu_utilization</code>、<code>cpu_utilization</code></li><li>拒绝&#x2F;超时：<code>backend_errors</code>、<code>timeout_errors</code></li></ul></li><li><strong>日志与追踪</strong>：<ul><li>结构化访问日志（含 <code>request_id</code>、调用方、模型、用量、耗时、状态码）</li><li>结合 OpenTelemetry &#x2F; Jaeger 进行链路追踪，串联网关→Proxy→vLLM→存储</li></ul></li><li><strong>可观测性栈</strong>：Prometheus + Grafana（Dashboard：Proxy 指标 + vLLM&#x2F;GPU 指标），Loki&#x2F;ELK 做日志聚合。</li></ul><h4 id="告警阈值示例"><a href="#告警阈值示例" class="headerlink" title="告警阈值示例"></a>告警阈值示例</h4><ul><li>成功率低于 98%（5 分钟窗口）</li><li>P95 延迟高于 2s（连续 10 分钟）</li><li>429 速率限制命中率 &gt; 5%（提示需要扩容或调参）</li><li>vLLM <code>queue_depth</code> &gt; 100 且持续 5 分钟（推理拥塞）</li><li>GPU 显存利用率 &gt; 95% 且持续 10 分钟（需要缩短 max tokens&#x2F;增加副本）</li></ul><h3 id="安全与密钥治理"><a href="#安全与密钥治理" class="headerlink" title="安全与密钥治理"></a>安全与密钥治理</h3><ul><li><strong>密钥管理</strong>：<code>LITELLM_SALT_KEY</code> 与 <code>master_key</code> 存放于 KMS&#x2F;Secret Manager；定期轮换，最小权限访问。</li><li><strong>虚拟 Key 策略</strong>：为每个应用&#x2F;团队单独发放虚拟 Key，设置 <code>RPM/TPM/并发</code>、预算与模型白名单，超限自动告警。</li><li><strong>网络与访问控制</strong>：将 Proxy 置于私有网络内，通过 API 网关暴露；开启 WAF 与 IP 访问控制；对外只暴露必要端口。</li><li><strong>数据与合规</strong>：记录审计日志，敏感数据脱敏；对模型消息体避免长期持久化，仅保留元数据。</li></ul><h3 id="灰度与流量治理"><a href="#灰度与流量治理" class="headerlink" title="灰度与流量治理"></a>灰度与流量治理</h3><ul><li><strong>版本灰度</strong>：新模型&#x2F;新参数走 1%-5% 灰度；监控指标稳定后逐步扩大权重。</li><li><strong>路由策略</strong>：按租户&#x2F;区域&#x2F;延迟&#x2F;成本做智能路由与回退；对低优先级任务使用更低成本模型。</li><li><strong>缓存与重放</strong>：对可缓存请求开启缓存；对失败请求采用指数退避与幂等重试（结合 <code>request_id</code>）。</li></ul><h2 id="无数据库的密钥治理（最简部署）"><a href="#无数据库的密钥治理（最简部署）" class="headerlink" title="无数据库的密钥治理（最简部署）"></a>无数据库的密钥治理（最简部署）</h2><blockquote><p><strong>前提说明</strong>：官方 E2E 教程中，虚拟 Key（<code>/key/generate</code>）功能需要接入 Postgres 数据库方可启用与持久化管理（参考：<a href="https://docs.litellm.ai/docs/proxy/docker_quick_start">LiteLLM Proxy Docker 快速上手</a> 的“Generate a virtual key”章节）。在“最简部署（无数据库）”下，内建的虚拟 Key、预算、配额面板不可用。以下提供两种在无数据库前提下的可操作密钥治理方案。</p></blockquote><h3 id="方案-A：API-网关静态-Key-白名单（推荐）"><a href="#方案-A：API-网关静态-Key-白名单（推荐）" class="headerlink" title="方案 A：API 网关静态 Key 白名单（推荐）"></a>方案 A：API 网关静态 Key 白名单（推荐）</h3><p>思路：</p><ul><li>为每个团队生成一个“外发 Key”（例如 <code>sk-teamA-...</code>、<code>sk-teamB-...</code>），仅对团队公开。</li><li>在 API 网关（Nginx&#x2F;Kong&#x2F;Traefik 等）校验来访 Key；校验通过后，将请求头 <code>Authorization</code> 改写为 LiteLLM 的 <code>master_key</code>，并注入 <code>X-Team</code> 头标识团队，LiteLLM Proxy 端只需维护 <code>master_key</code> 即可。</li><li>限速与访问控制在网关实现（按团队维度），日志也在网关聚合，LiteLLM 只做推理转发。</li></ul><p>操作步骤：</p><ol><li><p>配置 LiteLLM 最简 <code>config.yaml</code>（仅 <code>master_key</code>）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">model_list:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">model_name:</span> <span class="string">llama-3.1-8b-instruct</span></span><br><span class="line">    <span class="attr">litellm_params:</span></span><br><span class="line">      <span class="attr">model:</span> <span class="string">hosted_vllm/llama-3.1-8b-instruct</span></span><br><span class="line">      <span class="attr">api_base:</span> <span class="string">http://vllm:8000/v1</span></span><br><span class="line">      <span class="attr">api_key:</span> <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="attr">general_settings:</span></span><br><span class="line">  <span class="attr">master_key:</span> <span class="string">sk-master-very-strong</span></span><br></pre></td></tr></table></figure></li><li><p>启动 LiteLLM Proxy（略，见前文）。</p></li><li><p>在 Nginx 上实现静态 Key 白名单 + 改写：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设放在 stream 或 http 反向代理前置，以下为 http 片段示例</span></span><br><span class="line"><span class="attribute">map</span> <span class="variable">$http_authorization</span> <span class="variable">$team_name</span> &#123;</span><br><span class="line">  <span class="attribute">default</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">  &quot;<span class="attribute">Bearer</span> sk-teamA-<span class="number">123</span><span class="string">&quot; teamA;</span></span><br><span class="line"><span class="string">  &quot;</span>Bearer sk-teamB-<span class="number">456</span><span class="string">&quot; teamB;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">map <span class="variable">$http_authorization</span> <span class="variable">$is_valid_key</span> &#123;</span></span><br><span class="line"><span class="string">  default 0;</span></span><br><span class="line"><span class="string">  &quot;</span>Bearer sk-teamA-<span class="number">123</span><span class="string">&quot; 1;</span></span><br><span class="line"><span class="string">  &quot;</span>Bearer sk-teamB-<span class="number">456</span><span class="string">&quot; 1;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 可选：每团队限速桶，1 分钟 60 次</span></span><br><span class="line"><span class="string">limit_req_zone <span class="variable">$team_name</span> zone=per_team:10m rate=60r/m;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">server &#123;</span></span><br><span class="line"><span class="string">  listen 80;</span></span><br><span class="line"><span class="string">  server_name litellm.example.com;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  location / &#123;</span></span><br><span class="line"><span class="string">    if (<span class="variable">$is_valid_key</span> = 0) &#123; return 401; &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # 限速（命中返回 429）</span></span><br><span class="line"><span class="string">    limit_req zone=per_team burst=30 nodelay;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    # 注入团队头，改写为 master_key 转发到 LiteLLM Proxy</span></span><br><span class="line"><span class="string">    proxy_set_header Authorization &quot;</span>Bearer sk-master-very-strong<span class="string">&quot;;</span></span><br><span class="line"><span class="string">    proxy_set_header X-Team <span class="variable">$team_name</span>;</span></span><br><span class="line"><span class="string">    proxy_pass http://litellm-proxy:4000;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>团队使用各自外发 Key 调用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Team A</span></span><br><span class="line">curl -X POST <span class="string">&#x27;https://litellm.example.com/chat/completions&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">  -H <span class="string">&#x27;Authorization: Bearer sk-teamA-123&#x27;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;llama-3.1-8b-instruct&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hi&quot;&#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure></li></ol><p>优点：</p><ul><li>无需数据库即可做到“多团队 Key、限速、隔离与审计”。</li><li>Key 轮换在网关层进行，LiteLLM 无感。</li></ul><p>注意：</p><ul><li>外发 Key 白名单应存放于 Secret 管理，启用审计与告警；网关日志中保留 <code>X-Team</code> 以便统计。</li><li>若需更精细的模型白名单、预算、用量统计面板，请切换到“带数据库”模式，使用虚拟 Key 原生能力。</li></ul><h3 id="方案-B：多实例多主密钥（隔离更强）"><a href="#方案-B：多实例多主密钥（隔离更强）" class="headerlink" title="方案 B：多实例多主密钥（隔离更强）"></a>方案 B：多实例多主密钥（隔离更强）</h3><p>思路：</p><ul><li>为每个团队部署一个 LiteLLM Proxy 实例，分别设置不同的 <code>master_key</code> 与域名（如 <code>teamA-llm.example.com</code>）。</li><li>通过上游 LB&#x2F;Ingress 做域名或路径路由，实例间资源独立，便于限速与版本隔离。</li></ul><p>优点：</p><ul><li>实例层面的强隔离，团队级资源&#x2F;风控策略互不影响。</li></ul><p>成本：</p><ul><li>需要多实例运维与配置同步（可用 IaC&#x2F;Helm 统一下发）。</li></ul><h3 id="无数据库下的常见诉求替代"><a href="#无数据库下的常见诉求替代" class="headerlink" title="无数据库下的常见诉求替代"></a>无数据库下的常见诉求替代</h3><ul><li><strong>限速</strong>：用网关 <code>limit_req</code>（Nginx）或 API 网关内置策略按团队维度限速。</li><li><strong>预算&#x2F;用量</strong>：解析网关日志与 LiteLLM 访问日志，按 <code>X-Team</code> 汇总请求数与 token 用量（可在边车或日志管道中解析响应 <code>usage</code> 字段）。</li><li><strong>模型白名单</strong>：按路由规则控制允许访问的路径和模型名（例如基于 <code>model</code> 字段的 WAF&#x2F;自定义网关插件）。</li></ul><blockquote><p>若后续需要虚拟 Key、预算、速率限制、团队&#x2F;用户&#x2F;密钥可视化管理，建议切换带数据库的部署方式；参考前文与官方教程：<a href="https://docs.litellm.ai/docs/proxy/docker_quick_start">LiteLLM Proxy Docker 快速上手</a>。</p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>官方教程：<code>LiteLLM Proxy</code> E2E 与 Docker 快速启动（包含虚拟 Key、速率限制、数据库接入等）<ul><li><a href="https://docs.litellm.ai/docs/proxy/docker_quick_start">https://docs.litellm.ai/docs/proxy/docker_quick_start</a></li></ul></li><li>vLLM Provider 集成说明（如何让 LiteLLM 代理 vLLM 暴露的 OpenAI 兼容服务）<ul><li><a href="https://docs.litellm.ai/docs/providers/vllm">https://docs.litellm.ai/docs/providers/vllm</a></li></ul></li></ul><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> LiteLLM </tag>
            
            <tag> vLLM </tag>
            
            <tag> LLM Proxy </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LightRAG：轻量级检索增强生成系统详解</title>
      <link href="/AI/LightRAG%EF%BC%9A%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F%E8%AF%A6%E8%A7%A3/"/>
      <url>/AI/LightRAG%EF%BC%9A%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90%E7%B3%BB%E7%BB%9F%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>随着大语言模型（LLM）的快速发展，如何让AI系统能够访问和处理大量外部知识成为了一个关键挑战。检索增强生成（Retrieval-Augmented Generation，RAG）技术应运而生，而LightRAG作为一个轻量级且高效的RAG系统，通过结合知识图谱和向量检索技术，为企业级知识管理和智能问答提供了优秀的解决方案。</p><h2 id="LightRAG-简介"><a href="#LightRAG-简介" class="headerlink" title="LightRAG 简介"></a>LightRAG 简介</h2><p>LightRAG是一个现代化的检索增强生成系统，专注于提供高质量的问答和知识管理功能。该系统最大的特点是将传统的向量检索与知识图谱技术相结合，实现了更精准和上下文相关的信息检索。</p><h3 id="核心特性"><a href="#核心特性" class="headerlink" title="核心特性"></a>核心特性</h3><ul><li><strong>轻量级设计</strong>：优化的架构设计，降低资源消耗</li><li><strong>多模态支持</strong>：同时支持向量检索和图谱检索</li><li><strong>多存储后端</strong>：兼容Neo4j、PostgreSQL、Faiss等多种存储系统</li><li><strong>多模型支持</strong>：支持OpenAI、Hugging Face、Ollama等主流LLM</li><li><strong>生产就绪</strong>：提供完整的API接口和Web UI界面</li><li><strong>高并发处理</strong>：支持并发索引和查询操作</li></ul><h2 id="系统架构设计"><a href="#系统架构设计" class="headerlink" title="系统架构设计"></a>系统架构设计</h2><p>LightRAG采用分层模块化架构，确保了系统的可扩展性和维护性。</p><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>LightRAG的架构分为索引（Index）和检索（Retrieve）两个核心流程，采用双重存储策略实现知识图谱和向量检索的完美结合。</p><h4 id="LightRAG索引架构流程图"><a href="#LightRAG索引架构流程图" class="headerlink" title="LightRAG索引架构流程图"></a>LightRAG索引架构流程图</h4><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f04e28e77765ecad406ef68858f68cd78fd3d66c980f520d3a4a06acb5921c31.png" alt="LightRAG索引流程">  </p><p>从索引流程图可以看到，LightRAG的索引过程包含以下关键步骤：</p><ol><li><p><strong>文档输入与分块</strong></p><ul><li>Input Documents → Text Chunks</li><li>使用嵌入模型进行文本分块处理</li></ul></li><li><p><strong>并行处理管道</strong></p><ul><li><strong>实体提取路径</strong>：Extract Entities &amp; Relations → Entities Data → Deduped Entities → Update Description → Embedding</li><li><strong>关系提取路径</strong>：Relations Data → Deduped Relations → Update Description → Embedding</li><li><strong>向量嵌入路径</strong>：Text Chunks → Embedding</li></ul></li><li><p><strong>双重存储</strong></p><ul><li><strong>知识图谱存储</strong>：Store in Knowledge Graph</li><li><strong>向量数据库存储</strong>：Store in Vector DB Storage (Naive Vector DB Storage)</li></ul></li></ol><h4 id="LightRAG检索与生成架构流程图"><a href="#LightRAG检索与生成架构流程图" class="headerlink" title="LightRAG检索与生成架构流程图"></a>LightRAG检索与生成架构流程图</h4><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f77b694ca53ed8247d484fe48fb8523ce1fe1a99462186dd2fb17646161df89c.png" alt="LightRAG检索生成流程">  </p><p>检索流程图展示了LightRAG如何处理查询并生成回答：</p><ol><li><p><strong>查询输入</strong></p><ul><li>Query → 进入检索系统</li></ul></li><li><p><strong>双路径检索</strong></p><ul><li><strong>左侧路径</strong>：Vector DB Storage → TopK Entities Results → Related text_units → Local Query Context</li><li><strong>右侧路径</strong>：Knowledge Graph → TopK Relations Results → Related Entities → Related text_units → Global Query Context</li></ul></li><li><p><strong>上下文融合与关键词提取</strong></p><ul><li>Local Query Context + Global Query Context → keywords_extraction</li><li>生成 low_level_keywords 和 high_level_keywords</li><li>使用嵌入模型进行关键词处理</li></ul></li><li><p><strong>最终生成</strong></p><ul><li>combined context → System Template Prompt → System Prompt</li><li>使用LLM生成最终响应（Response）</li></ul></li></ol><p>这种双重检索架构确保了：</p><ul><li><strong>精确性</strong>：通过实体和关系检索获得准确信息</li><li><strong>全面性</strong>：通过向量检索捕获语义相关内容</li><li><strong>智能性</strong>：自动融合本地和全局上下文</li></ul><h3 id="核心模块"><a href="#核心模块" class="headerlink" title="核心模块"></a>核心模块</h3><h4 id="1-核心后端（-lightrag）"><a href="#1-核心后端（-lightrag）" class="headerlink" title="1. 核心后端（/lightrag）"></a>1. 核心后端（<code>/lightrag</code>）</h4><p>包含LightRAG的核心逻辑，负责：</p><ul><li>文档处理和分块</li><li>实体和关系提取</li><li>向量嵌入生成</li><li>知识图谱构建</li><li>查询处理和响应生成</li></ul><h4 id="2-API层（-lightrag-api）"><a href="#2-API层（-lightrag-api）" class="headerlink" title="2. API层（/lightrag-api）"></a>2. API层（<code>/lightrag-api</code>）</h4><p>基于FastAPI构建的Web服务层，提供：</p><ul><li>RESTful API接口</li><li>文档上传和管理</li><li>查询接口</li><li>系统配置和监控</li></ul><h4 id="3-Web-UI（-lightrag-webui）"><a href="#3-Web-UI（-lightrag-webui）" class="headerlink" title="3. Web UI（/lightrag_webui）"></a>3. Web UI（<code>/lightrag_webui</code>）</h4><p>基于React的前端界面，支持：</p><ul><li>直观的文档管理界面</li><li>知识图谱可视化</li><li>交互式查询测试</li><li>系统状态监控</li></ul><h4 id="4-工具与插件（-tools）"><a href="#4-工具与插件（-tools）" class="headerlink" title="4. 工具与插件（/tools）"></a>4. 工具与插件（<code>/tools</code>）</h4><p>提供额外功能扩展：</p><ul><li>知识图谱可视化工具</li><li>数据导入导出工具</li><li>性能分析工具</li></ul><h2 id="索引与查询流程详解"><a href="#索引与查询流程详解" class="headerlink" title="索引与查询流程详解"></a>索引与查询流程详解</h2><h3 id="索引流程详解（Index-Pipeline）"><a href="#索引流程详解（Index-Pipeline）" class="headerlink" title="索引流程详解（Index Pipeline）"></a>索引流程详解（Index Pipeline）</h3><p>根据LightRAG索引架构图，索引流程采用高效的并行处理设计：</p><h4 id="核心索引流程"><a href="#核心索引流程" class="headerlink" title="核心索引流程"></a>核心索引流程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LightRAG索引流程实现</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lightrag_indexing_pipeline</span>(<span class="params">documents</span>):</span><br><span class="line">    <span class="comment"># 1. 文档预处理和分块</span></span><br><span class="line">    text_chunks = document_chunker.split(documents)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 三路并行处理</span></span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">        <span class="comment"># 路径1：向量嵌入处理</span></span><br><span class="line">        vector_future = executor.submit(generate_text_embeddings, text_chunks)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 路径2：实体提取和处理</span></span><br><span class="line">        entities_future = executor.submit(extract_and_process_entities, text_chunks)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 路径3：关系提取和处理</span></span><br><span class="line">        relations_future = executor.submit(extract_and_process_relations, text_chunks)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 双重存储策略</span></span><br><span class="line">    <span class="comment"># 向量存储：支持naive模式查询</span></span><br><span class="line">    store_to_vector_db_storage(vector_future.result())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 知识图谱存储：支持实体关系查询</span></span><br><span class="line">    store_to_knowledge_graph(</span><br><span class="line">        entities_future.result(), </span><br><span class="line">        relations_future.result()</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_and_process_entities</span>(<span class="params">text_chunks</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;实体提取和处理管道&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 使用LLM提取实体和关系</span></span><br><span class="line">    raw_entities = extract_entities_relations(text_chunks)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 实体数据处理</span></span><br><span class="line">    entities_data = process_entities_data(raw_entities)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 去重处理</span></span><br><span class="line">    deduped_entities = deduplicate_entities(entities_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新描述信息</span></span><br><span class="line">    updated_entities = update_entity_descriptions(deduped_entities)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成实体嵌入</span></span><br><span class="line">    entity_embeddings = generate_embeddings(updated_entities)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> entity_embeddings</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_and_process_relations</span>(<span class="params">text_chunks</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;关系提取和处理管道&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 提取关系数据</span></span><br><span class="line">    relations_data = extract_relations_data(text_chunks)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 去重处理</span></span><br><span class="line">    deduped_relations = deduplicate_relations(relations_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新描述信息</span></span><br><span class="line">    updated_relations = update_relation_descriptions(deduped_relations)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 生成关系嵌入</span></span><br><span class="line">    relation_embeddings = generate_embeddings(updated_relations)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> relation_embeddings</span><br></pre></td></tr></table></figure><h4 id="详细处理步骤"><a href="#详细处理步骤" class="headerlink" title="详细处理步骤"></a>详细处理步骤</h4><p><strong>阶段1：文档预处理</strong></p><ul><li><strong>Input Documents</strong> → <strong>Text Chunks</strong></li><li>智能文档分割，保持语义完整性</li><li>支持多种文档格式（PDF、Word、Markdown等）</li><li>可配置的分块大小和重叠策略</li></ul><p><strong>阶段2：三路并行提取</strong></p><ol><li><p><strong>实体提取路径</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Text Chunks → Extract Entities &amp; Relations </span><br><span class="line">→ Entities Data (name, type, description, chunk_id)</span><br><span class="line">→ Deduped Entities → Update Description → Embedding</span><br></pre></td></tr></table></figure></li><li><p><strong>关系提取路径</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Text Chunks → Extract Entities &amp; Relations</span><br><span class="line">→ Relations Data (source, target, description, strength, keywords, chunk_id)</span><br><span class="line">→ Deduped Relations → Update Description → Embedding</span><br></pre></td></tr></table></figure></li><li><p><strong>向量嵌入路径</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Text Chunks → Embedding → Store in Vector DB Storage</span><br></pre></td></tr></table></figure></li></ol><p><strong>阶段3：智能存储</strong></p><ul><li><strong>向量数据库</strong>：存储文本块嵌入，支持语义相似性检索</li><li><strong>知识图谱</strong>：存储实体关系网络，支持结构化查询</li><li><strong>KV存储</strong>：缓存中间结果，提高查询效率</li></ul><h3 id="查询流程详解（Query-Pipeline）"><a href="#查询流程详解（Query-Pipeline）" class="headerlink" title="查询流程详解（Query Pipeline）"></a>查询流程详解（Query Pipeline）</h3><p>根据LightRAG检索生成架构图，查询流程采用双路径检索和智能融合策略：</p><h4 id="核心查询流程"><a href="#核心查询流程" class="headerlink" title="核心查询流程"></a>核心查询流程</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LightRAG查询流程实现</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lightrag_query_pipeline</span>(<span class="params">query, mode=<span class="string">&quot;mix&quot;</span></span>):</span><br><span class="line">    <span class="comment"># 1. 查询预处理</span></span><br><span class="line">    processed_query = preprocess_query(query)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 双路径并行检索</span></span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">        <span class="comment"># 左侧路径：向量检索 → 实体检索</span></span><br><span class="line">        local_future = executor.submit(local_retrieval_path, processed_query)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 右侧路径：知识图谱检索 → 关系检索</span></span><br><span class="line">        global_future = executor.submit(global_retrieval_path, processed_query)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 上下文融合和关键词提取</span></span><br><span class="line">    local_context = local_future.result()</span><br><span class="line">    global_context = global_future.result()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 关键词提取和分层处理</span></span><br><span class="line">    keywords_data = extract_keywords(local_context, global_context)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 上下文组合和生成</span></span><br><span class="line">    combined_context = combine_contexts(</span><br><span class="line">        local_context, </span><br><span class="line">        global_context, </span><br><span class="line">        keywords_data</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. 系统提示词生成和LLM调用</span></span><br><span class="line">    system_prompt = generate_system_prompt(combined_context, query)</span><br><span class="line">    response = llm_generate(system_prompt)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">local_retrieval_path</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;本地检索路径：向量DB → TopK实体 → 相关文本单元&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 从向量数据库检索</span></span><br><span class="line">    vector_results = vector_db_search(query)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取TopK实体结果</span></span><br><span class="line">    topk_entities = get_topk_entities(vector_results)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取相关文本单元</span></span><br><span class="line">    related_text_units = get_related_text_units(topk_entities)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构建本地查询上下文</span></span><br><span class="line">    local_query_context = build_local_context(related_text_units)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> local_query_context</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">global_retrieval_path</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;全局检索路径：知识图谱 → TopK关系 → 相关实体和文本&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 从知识图谱检索</span></span><br><span class="line">    graph_results = knowledge_graph_search(query)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取TopK关系结果</span></span><br><span class="line">    topk_relations = get_topk_relations(graph_results)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取相关实体</span></span><br><span class="line">    related_entities = get_related_entities(topk_relations)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取相关文本单元</span></span><br><span class="line">    related_text_units = get_related_text_units(related_entities)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构建全局查询上下文</span></span><br><span class="line">    global_query_context = build_global_context(related_text_units)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> global_query_context</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_keywords</span>(<span class="params">local_context, global_context</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;关键词提取和分层处理&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 使用嵌入模型进行关键词提取</span></span><br><span class="line">    combined_text = local_context + global_context</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分层关键词提取</span></span><br><span class="line">    keywords_extraction_result = embedding_model.extract_keywords(combined_text)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;low_level_keywords&#x27;</span>: keywords_extraction_result[<span class="string">&#x27;low_level&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;high_level_keywords&#x27;</span>: keywords_extraction_result[<span class="string">&#x27;high_level&#x27;</span>]</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="详细检索步骤"><a href="#详细检索步骤" class="headerlink" title="详细检索步骤"></a>详细检索步骤</h4><p><strong>阶段1：查询输入处理</strong></p><ul><li><strong>Query</strong> → 查询预处理和意图分析</li></ul><p><strong>阶段2：双路径并行检索</strong></p><ol><li><p><strong>本地检索路径（左侧）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Vector DB Storage → TopK Entities Results </span><br><span class="line">→ Related text_units → Local Query Context</span><br></pre></td></tr></table></figure><ul><li>基于向量相似性检索最相关的实体</li><li>获取实体关联的文本单元</li><li>构建本地化的查询上下文</li></ul></li><li><p><strong>全局检索路径（右侧）</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Knowledge Graph → TopK Relations Results </span><br><span class="line">→ Related Entities → Related text_units → Global Query Context</span><br></pre></td></tr></table></figure><ul><li>基于图结构检索最相关的关系</li><li>获取关系涉及的实体和文本单元</li><li>构建全局化的查询上下文</li></ul></li></ol><p><strong>阶段3：智能上下文融合</strong></p><ul><li><strong>Local Query Context</strong> + <strong>Global Query Context</strong> → <strong>keywords_extraction</strong></li><li>生成 <strong>low_level_keywords</strong> 和 <strong>high_level_keywords</strong></li><li>使用嵌入模型进行语义理解和关键词提取</li></ul><p><strong>阶段4：生成与输出</strong></p><ul><li><strong>combined context</strong> → <strong>System Template Prompt</strong> → <strong>System Prompt</strong></li><li>使用LLM生成最终的智能回答（<strong>Response</strong>）</li></ul><h4 id="查询模式路由策略"><a href="#查询模式路由策略" class="headerlink" title="查询模式路由策略"></a>查询模式路由策略</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">route_query_mode</span>(<span class="params">query, user_mode=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;根据查询特征自动选择或验证查询模式&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> user_mode:</span><br><span class="line">        <span class="keyword">return</span> user_mode</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 自动模式选择逻辑</span></span><br><span class="line">    query_features = analyze_query_features(query)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> query_features[<span class="string">&#x27;entity_focused&#x27;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;local&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> query_features[<span class="string">&#x27;relationship_focused&#x27;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;global&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> query_features[<span class="string">&#x27;semantic_similarity&#x27;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;naive&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> query_features[<span class="string">&#x27;creative_task&#x27;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;bypass&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> query_features[<span class="string">&#x27;complex_reasoning&#x27;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;mix&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;hybrid&#x27;</span>  <span class="comment"># 默认模式</span></span><br></pre></td></tr></table></figure><h2 id="查询模式深度解析"><a href="#查询模式深度解析" class="headerlink" title="查询模式深度解析"></a>查询模式深度解析</h2><p>LightRAG提供了六种不同的查询模式，每种模式针对不同的使用场景进行了优化。下表展示了各种查询模式的特征对比：</p><h3 id="查询模式特征对比表"><a href="#查询模式特征对比表" class="headerlink" title="查询模式特征对比表"></a>查询模式特征对比表</h3><table><thead><tr><th>Query mode</th><th>entity</th><th>relationship</th><th>vector</th><th>Description</th></tr></thead><tbody><tr><td><strong>mix</strong></td><td>✅</td><td>✅</td><td>✅</td><td>Default mode - 默认模式，综合使用所有检索方式</td></tr><tr><td><strong>hybrid</strong></td><td>✅</td><td>✅</td><td>❌</td><td>graph - 图谱模式，结合实体和关系检索</td></tr><tr><td><strong>local</strong></td><td>✅</td><td>✅</td><td>❌</td><td>Focus on entity - 专注于实体检索</td></tr><tr><td><strong>global</strong></td><td>✅</td><td>✅</td><td>❌</td><td>Focus on relationship - 专注于关系检索</td></tr><tr><td><strong>naive</strong></td><td>❌</td><td>❌</td><td>✅</td><td>Vector only - 纯向量检索</td></tr><tr><td><strong>bypass</strong></td><td>❌</td><td>❌</td><td>❌</td><td>LLM only - 直接使用大语言模型，无检索</td></tr></tbody></table><h3 id="1-Mix模式（融合模式）"><a href="#1-Mix模式（融合模式）" class="headerlink" title="1. Mix模式（融合模式）"></a>1. Mix模式（融合模式）</h3><p><strong>适用场景</strong>：最复杂的查询，需要全面的信息检索</p><p><strong>工作原理</strong>：</p><ul><li>综合使用实体、关系和向量检索</li><li>深度融合图结构和语义表示</li><li>提供最全面的信息覆盖</li></ul><p><strong>技术实现</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mix_search</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="comment"># 实体检索</span></span><br><span class="line">    entity_results = entity_search(query)</span><br><span class="line">    <span class="comment"># 关系检索</span></span><br><span class="line">    relation_results = relationship_search(query)</span><br><span class="line">    <span class="comment"># 向量检索</span></span><br><span class="line">    vector_results = semantic_search(query)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 深度融合所有结果</span></span><br><span class="line">    fused_results = deep_fusion(entity_results, relation_results, vector_results)</span><br><span class="line">    <span class="keyword">return</span> fused_results</span><br></pre></td></tr></table></figure><h3 id="2-Hybrid模式（混合模式）"><a href="#2-Hybrid模式（混合模式）" class="headerlink" title="2. Hybrid模式（混合模式）"></a>2. Hybrid模式（混合模式）</h3><p><strong>适用场景</strong>：需要结构化知识和关系推理的查询</p><p><strong>工作原理</strong>：</p><ul><li>结合实体和关系检索</li><li>专注于图谱结构信息</li><li>适合复杂的知识推理</li></ul><p><strong>示例查询</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">问题：苹果公司与特斯拉公司有什么关联？</span><br><span class="line">检索策略：找到&quot;苹果&quot;和&quot;特斯拉&quot;实体 → 查询两者间的关系路径 → 分析关联性</span><br></pre></td></tr></table></figure><h3 id="3-Local模式（本地模式）"><a href="#3-Local模式（本地模式）" class="headerlink" title="3. Local模式（本地模式）"></a>3. Local模式（本地模式）</h3><p><strong>适用场景</strong>：需要精确信息的查询，如特定实体的属性查询</p><p><strong>工作原理</strong>：</p><ul><li>专注于检索特定实体及其直接关系</li><li>利用知识图谱的局部结构</li><li>提供高精度的事实性回答</li></ul><p><strong>示例查询</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">问题：张三的工作单位是什么？</span><br><span class="line">检索策略：找到&quot;张三&quot;实体 → 查询&quot;工作于&quot;关系 → 返回关联实体</span><br></pre></td></tr></table></figure><h3 id="4-Global模式（全局模式）"><a href="#4-Global模式（全局模式）" class="headerlink" title="4. Global模式（全局模式）"></a>4. Global模式（全局模式）</h3><p><strong>适用场景</strong>：需要综合理解的广泛主题查询</p><p><strong>工作原理</strong>：</p><ul><li>专注于关系检索和推理</li><li>处理更广泛的主题和概念</li><li>提供全面的背景信息</li></ul><p><strong>示例查询</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">问题：人工智能在医疗领域的应用趋势如何？</span><br><span class="line">检索策略：收集AI、医疗相关的关系网络 → 分析关系模式 → 生成趋势报告</span><br></pre></td></tr></table></figure><h3 id="5-Naive模式（纯向量检索）"><a href="#5-Naive模式（纯向量检索）" class="headerlink" title="5. Naive模式（纯向量检索）"></a>5. Naive模式（纯向量检索）</h3><p><strong>适用场景</strong>：简单的语义相似性查询</p><p><strong>工作原理</strong>：</p><ul><li>仅使用向量检索</li><li>基于语义相似性匹配</li><li>适合快速检索和模糊查询</li></ul><p><strong>技术实现</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">naive_search</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="comment"># 将查询转换为向量</span></span><br><span class="line">    query_vector = embed_query(query)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 在向量数据库中检索相似文档</span></span><br><span class="line">    similar_docs = vector_db.similarity_search(query_vector, k=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> similar_docs</span><br></pre></td></tr></table></figure><p><strong>示例查询</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">问题：什么是机器学习？</span><br><span class="line">检索策略：查询向量 → 匹配相似文档 → 返回语义相关内容</span><br></pre></td></tr></table></figure><h3 id="6-Bypass模式（直接LLM）"><a href="#6-Bypass模式（直接LLM）" class="headerlink" title="6. Bypass模式（直接LLM）"></a>6. Bypass模式（直接LLM）</h3><p><strong>适用场景</strong>：不需要外部知识的通用性查询</p><p><strong>工作原理</strong>：</p><ul><li>完全跳过检索步骤</li><li>直接使用LLM的内置知识</li><li>适合常识性问题和创意性任务</li></ul><p><strong>技术实现</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bypass_search</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="comment"># 直接使用LLM生成回答，不进行任何检索</span></span><br><span class="line">    response = llm.generate(query)</span><br><span class="line">    <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure><p><strong>示例查询</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">问题：请写一首关于春天的诗</span><br><span class="line">检索策略：无检索 → 直接LLM创作 → 返回原创内容</span><br></pre></td></tr></table></figure><h3 id="查询模式选择策略"><a href="#查询模式选择策略" class="headerlink" title="查询模式选择策略"></a>查询模式选择策略</h3><p>根据不同的查询类型，系统可以智能选择最适合的查询模式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">auto_select_mode</span>(<span class="params">query</span>):</span><br><span class="line">    query_type = analyze_query_type(query)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> query_type == <span class="string">&quot;factual_entity&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;local&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> query_type == <span class="string">&quot;relationship_analysis&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;global&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> query_type == <span class="string">&quot;complex_reasoning&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;mix&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> query_type == <span class="string">&quot;semantic_similarity&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;naive&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> query_type == <span class="string">&quot;creative_task&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;bypass&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;hybrid&quot;</span>  <span class="comment"># 默认选择</span></span><br></pre></td></tr></table></figure><h3 id="性能特征对比"><a href="#性能特征对比" class="headerlink" title="性能特征对比"></a>性能特征对比</h3><table><thead><tr><th>模式</th><th>检索复杂度</th><th>响应速度</th><th>准确性</th><th>资源消耗</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>mix</strong></td><td>最高</td><td>较慢</td><td>最高</td><td>最高</td><td>复杂推理查询</td></tr><tr><td><strong>hybrid</strong></td><td>高</td><td>中等</td><td>高</td><td>高</td><td>知识推理查询</td></tr><tr><td><strong>local</strong></td><td>中等</td><td>快</td><td>高</td><td>中等</td><td>实体属性查询</td></tr><tr><td><strong>global</strong></td><td>中等</td><td>中等</td><td>中高</td><td>中等</td><td>关系分析查询</td></tr><tr><td><strong>naive</strong></td><td>低</td><td>最快</td><td>中等</td><td>低</td><td>语义检索查询</td></tr><tr><td><strong>bypass</strong></td><td>无</td><td>快</td><td>中等</td><td>最低</td><td>通用知识查询</td></tr></tbody></table><h2 id="组件选项与配置"><a href="#组件选项与配置" class="headerlink" title="组件选项与配置"></a>组件选项与配置</h2><h3 id="存储后端选择"><a href="#存储后端选择" class="headerlink" title="存储后端选择"></a>存储后端选择</h3><h4 id="1-向量数据库选项"><a href="#1-向量数据库选项" class="headerlink" title="1. 向量数据库选项"></a>1. 向量数据库选项</h4><p><strong>Faiss</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 轻量级本地向量存储</span></span><br><span class="line">vector_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;faiss&quot;</span>,</span><br><span class="line">    <span class="string">&quot;dimension&quot;</span>: <span class="number">1536</span>,</span><br><span class="line">    <span class="string">&quot;index_type&quot;</span>: <span class="string">&quot;IVF&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nlist&quot;</span>: <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Chroma</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 易于使用的向量数据库</span></span><br><span class="line">vector_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;chroma&quot;</span>,</span><br><span class="line">    <span class="string">&quot;persist_directory&quot;</span>: <span class="string">&quot;./chroma_db&quot;</span>,</span><br><span class="line">    <span class="string">&quot;collection_name&quot;</span>: <span class="string">&quot;documents&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Milvus</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 企业级向量数据库</span></span><br><span class="line">vector_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;milvus&quot;</span>,</span><br><span class="line">    <span class="string">&quot;host&quot;</span>: <span class="string">&quot;localhost&quot;</span>,</span><br><span class="line">    <span class="string">&quot;port&quot;</span>: <span class="number">19530</span>,</span><br><span class="line">    <span class="string">&quot;collection_name&quot;</span>: <span class="string">&quot;lightrag_vectors&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-图数据库选项"><a href="#2-图数据库选项" class="headerlink" title="2. 图数据库选项"></a>2. 图数据库选项</h4><p><strong>Neo4j</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 功能最全面的图数据库</span></span><br><span class="line">graph_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;neo4j&quot;</span>,</span><br><span class="line">    <span class="string">&quot;uri&quot;</span>: <span class="string">&quot;bolt://localhost:7687&quot;</span>,</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;neo4j&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;password&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>NetworkX</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 轻量级图存储（适合开发测试）</span></span><br><span class="line">graph_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;networkx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;persist_path&quot;</span>: <span class="string">&quot;./graph_data.pkl&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="LLM模型选择"><a href="#LLM模型选择" class="headerlink" title="LLM模型选择"></a>LLM模型选择</h3><h4 id="OpenAI模型"><a href="#OpenAI模型" class="headerlink" title="OpenAI模型"></a>OpenAI模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">llm_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;openai&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;gpt-4-turbo&quot;</span>,</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;your-api-key&quot;</span>,</span><br><span class="line">    <span class="string">&quot;temperature&quot;</span>: <span class="number">0.1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="本地模型（Ollama）"><a href="#本地模型（Ollama）" class="headerlink" title="本地模型（Ollama）"></a>本地模型（Ollama）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">llm_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;ollama&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5:7b&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;http://localhost:11434&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Hugging-Face模型"><a href="#Hugging-Face模型" class="headerlink" title="Hugging Face模型"></a>Hugging Face模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">llm_config = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;huggingface&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;microsoft/DialoGPT-medium&quot;</span>,</span><br><span class="line">    <span class="string">&quot;device&quot;</span>: <span class="string">&quot;cuda:0&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="部署配置设置参考"><a href="#部署配置设置参考" class="headerlink" title="部署配置设置参考"></a>部署配置设置参考</h3><p>根据不同的硬件配置，以下是推荐的参数设置：</p><table><thead><tr><th>硬件配置</th><th>MAX_PARALLEL_INSERT</th><th>MAX_ASYNC</th><th>EMBEDDING_FUNC_MAX_ASYNC</th><th>CHUNK_SIZE</th></tr></thead><tbody><tr><td>4core 8GB</td><td>2</td><td>6</td><td>12</td><td>600</td></tr><tr><td>8core 16GB</td><td>4</td><td>12</td><td>24</td><td>800</td></tr><tr><td>16core 32GB</td><td>8</td><td>20</td><td>40</td><td>1000</td></tr><tr><td>32core 64GB</td><td>12</td><td>32</td><td>64</td><td>1200</td></tr></tbody></table><p><strong>配置说明</strong>：</p><ul><li><code>MAX_PARALLEL_INSERT</code>: 并行插入的最大数量，影响数据导入速度</li><li><code>MAX_ASYNC</code>: 异步操作的最大并发数，控制系统并发能力</li><li><code>EMBEDDING_FUNC_MAX_ASYNC</code>: 向量化函数的最大异步数，影响向量生成效率</li><li><code>CHUNK_SIZE</code>: 文本分块大小，影响检索精度和性能平衡</li></ul><p><strong>性能优化建议</strong>：</p><ol><li><strong>内存充足</strong>时可适当增加CHUNK_SIZE提高检索精度</li><li><strong>CPU核心多</strong>时可增加并行插入数量加速数据导入</li><li><strong>网络带宽充足</strong>时可增加异步并发数提升响应速度</li><li>建议根据实际业务场景进行性能测试和参数调优</li></ol><h2 id="使用场景与应用示例"><a href="#使用场景与应用示例" class="headerlink" title="使用场景与应用示例"></a>使用场景与应用示例</h2><h3 id="1-企业知识管理"><a href="#1-企业知识管理" class="headerlink" title="1. 企业知识管理"></a>1. 企业知识管理</h3><p><strong>场景描述</strong>：构建企业内部知识库，支持员工快速检索公司政策、技术文档、项目信息等。</p><p><strong>实现方案</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 企业知识库配置</span></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&quot;storage&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;vector_db&quot;</span>: <span class="string">&quot;milvus&quot;</span>,  <span class="comment"># 企业级向量存储</span></span><br><span class="line">        <span class="string">&quot;graph_db&quot;</span>: <span class="string">&quot;neo4j&quot;</span>     <span class="comment"># 复杂关系存储</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;llm&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;openai&quot;</span>,</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: <span class="string">&quot;gpt-4&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;query_modes&quot;</span>: [<span class="string">&quot;hybrid&quot;</span>, <span class="string">&quot;mix&quot;</span>]  <span class="comment"># 支持复杂查询</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line">rag = LightRAG(config)</span><br><span class="line">response = rag.query(<span class="string">&quot;公司的远程工作政策是什么？&quot;</span>, mode=<span class="string">&quot;hybrid&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="2-学术研究助手"><a href="#2-学术研究助手" class="headerlink" title="2. 学术研究助手"></a>2. 学术研究助手</h3><p><strong>场景描述</strong>：处理大量学术论文，帮助研究人员快速找到相关研究、理解技术脉络。</p><p><strong>技术特点</strong>：</p><ul><li>支持论文PDF解析</li><li>构建学术概念知识图谱</li><li>提供研究趋势分析</li></ul><h3 id="3-客户服务智能问答"><a href="#3-客户服务智能问答" class="headerlink" title="3. 客户服务智能问答"></a>3. 客户服务智能问答</h3><p><strong>场景描述</strong>：基于产品文档和FAQ构建智能客服系统。</p><p><strong>优势特点</strong>：</p><ul><li>多轮对话支持</li><li>上下文感知回答</li><li>实时知识更新</li></ul><h3 id="4-法律文档分析"><a href="#4-法律文档分析" class="headerlink" title="4. 法律文档分析"></a>4. 法律文档分析</h3><p><strong>场景描述</strong>：处理复杂的法律条文，提供法条查询和案例分析。</p><p><strong>实现要点</strong>：</p><ul><li>精确的实体识别（法条、案例、当事人）</li><li>复杂的法律关系建模</li><li>高精度的检索要求</li></ul><h2 id="部署与集成"><a href="#部署与集成" class="headerlink" title="部署与集成"></a>部署与集成</h2><h3 id="Docker部署"><a href="#Docker部署" class="headerlink" title="Docker部署"></a>Docker部署</h3><p>LightRAG提供了完整的Docker部署方案：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.10</span>-slim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> requirements.txt .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制应用代码</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> . /app</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;-m&quot;</span>, <span class="string">&quot;lightrag_api.main&quot;</span>]</span></span><br></pre></td></tr></table></figure><p><strong>部署命令</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建镜像</span></span><br><span class="line">docker build -t lightrag:latest .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">docker run -d \</span><br><span class="line">  --name lightrag \</span><br><span class="line">  -p 8000:8000 \</span><br><span class="line">  -v ./data:/app/data \</span><br><span class="line">  lightrag:latest</span><br></pre></td></tr></table></figure><h3 id="生产环境配置"><a href="#生产环境配置" class="headerlink" title="生产环境配置"></a>生产环境配置</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker-compose.yml</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.8&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">lightrag:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">lightrag:latest</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;8000:8000&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">NEO4J_URI=bolt://neo4j:7687</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">VECTOR_DB_TYPE=milvus</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">neo4j</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">milvus</span></span><br><span class="line">  </span><br><span class="line">  <span class="attr">neo4j:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">neo4j:5.0</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">NEO4J_AUTH=neo4j/password</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;7474:7474&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;7687:7687&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="attr">milvus:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">milvusdb/milvus:latest</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;19530:19530&quot;</span></span><br></pre></td></tr></table></figure><h2 id="性能优化与最佳实践"><a href="#性能优化与最佳实践" class="headerlink" title="性能优化与最佳实践"></a>性能优化与最佳实践</h2><h3 id="1-并发处理优化"><a href="#1-并发处理优化" class="headerlink" title="1. 并发处理优化"></a>1. 并发处理优化</h3><p>LightRAG支持并发索引和查询处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 并发索引配置</span></span><br><span class="line">indexing_config = &#123;</span><br><span class="line">    <span class="string">&quot;concurrent_workers&quot;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="string">&quot;batch_size&quot;</span>: <span class="number">100</span>,</span><br><span class="line">    <span class="string">&quot;chunk_overlap&quot;</span>: <span class="number">50</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询缓存配置</span></span><br><span class="line">cache_config = &#123;</span><br><span class="line">    <span class="string">&quot;enable_query_cache&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&quot;cache_size&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">    <span class="string">&quot;cache_ttl&quot;</span>: <span class="number">3600</span>  <span class="comment"># 1小时</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-重排序集成"><a href="#2-重排序集成" class="headerlink" title="2. 重排序集成"></a>2. 重排序集成</h3><p>通过集成重排序模型提高检索精度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重排序配置</span></span><br><span class="line">rerank_config = &#123;</span><br><span class="line">    <span class="string">&quot;enable_rerank&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&quot;rerank_model&quot;</span>: <span class="string">&quot;BAAI/bge-reranker-large&quot;</span>,</span><br><span class="line">    <span class="string">&quot;top_k&quot;</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="string">&quot;rerank_top_k&quot;</span>: <span class="number">3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-性能监控"><a href="#3-性能监控" class="headerlink" title="3. 性能监控"></a>3. 性能监控</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 性能监控指标</span></span><br><span class="line">metrics = &#123;</span><br><span class="line">    <span class="string">&quot;indexing_speed&quot;</span>: <span class="string">&quot;documents/second&quot;</span>,</span><br><span class="line">    <span class="string">&quot;query_latency&quot;</span>: <span class="string">&quot;milliseconds&quot;</span>,</span><br><span class="line">    <span class="string">&quot;memory_usage&quot;</span>: <span class="string">&quot;MB&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cache_hit_rate&quot;</span>: <span class="string">&quot;percentage&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="常见问题与解决方案"><a href="#常见问题与解决方案" class="headerlink" title="常见问题与解决方案"></a>常见问题与解决方案</h2><h3 id="1-内存使用优化"><a href="#1-内存使用优化" class="headerlink" title="1. 内存使用优化"></a>1. 内存使用优化</h3><p><strong>问题</strong>：大规模文档处理时内存占用过高</p><p><strong>解决方案</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用流式处理</span></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&quot;streaming_mode&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&quot;batch_processing&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&quot;max_memory_usage&quot;</span>: <span class="string">&quot;4GB&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-查询性能优化"><a href="#2-查询性能优化" class="headerlink" title="2. 查询性能优化"></a>2. 查询性能优化</h3><p><strong>问题</strong>：复杂查询响应时间过长</p><p><strong>解决方案</strong>：</p><ul><li>启用查询缓存</li><li>优化索引结构</li><li>使用更快的嵌入模型</li></ul><h3 id="3-多语言支持"><a href="#3-多语言支持" class="headerlink" title="3. 多语言支持"></a>3. 多语言支持</h3><p><strong>问题</strong>：处理中文等非英语文档</p><p><strong>解决方案</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多语言配置</span></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&quot;language&quot;</span>: <span class="string">&quot;zh-CN&quot;</span>,</span><br><span class="line">    <span class="string">&quot;embedding_model&quot;</span>: <span class="string">&quot;BAAI/bge-large-zh-v1.5&quot;</span>,</span><br><span class="line">    <span class="string">&quot;text_splitter&quot;</span>: <span class="string">&quot;chinese_text_splitter&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="LightRAG与其他RAG系统对比"><a href="#LightRAG与其他RAG系统对比" class="headerlink" title="LightRAG与其他RAG系统对比"></a>LightRAG与其他RAG系统对比</h2><p>在RAG技术生态中，除了LightRAG，还有多个优秀的解决方案。下面我们将LightRAG与两个主要竞品进行详细对比。</p><h3 id="与GraphRAG对比"><a href="#与GraphRAG对比" class="headerlink" title="与GraphRAG对比"></a>与GraphRAG对比</h3><p><strong>GraphRAG</strong> 是微软推出的基于知识图谱的RAG系统，专注于图结构化知识表示。</p><h4 id="架构对比"><a href="#架构对比" class="headerlink" title="架构对比"></a>架构对比</h4><table><thead><tr><th>对比维度</th><th>LightRAG</th><th>GraphRAG</th></tr></thead><tbody><tr><td><strong>核心理念</strong></td><td>图谱+向量双重检索</td><td>纯图谱检索</td></tr><tr><td><strong>存储架构</strong></td><td>向量DB + 图DB并行</td><td>主要依赖图数据库</td></tr><tr><td><strong>查询模式</strong></td><td>4种模式灵活切换</td><td>基于图遍历</td></tr><tr><td><strong>部署复杂度</strong></td><td>轻量级，易部署</td><td>相对复杂</td></tr></tbody></table><h4 id="技术特点对比"><a href="#技术特点对比" class="headerlink" title="技术特点对比"></a>技术特点对比</h4><p><strong>LightRAG优势</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LightRAG的混合检索</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hybrid_search</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="comment"># 同时利用向量相似性和图结构</span></span><br><span class="line">    vector_results = semantic_search(query)</span><br><span class="line">    graph_results = graph_traversal(query)</span><br><span class="line">    <span class="keyword">return</span> fuse_results(vector_results, graph_results)</span><br></pre></td></tr></table></figure><p><strong>GraphRAG优势</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GraphRAG的深度图推理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">graph_reasoning</span>(<span class="params">query</span>):</span><br><span class="line">    <span class="comment"># 多跳图推理，发现复杂关系</span></span><br><span class="line">    entities = extract_entities(query)</span><br><span class="line">    paths = multi_hop_traversal(entities, max_hops=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> synthesize_from_paths(paths)</span><br></pre></td></tr></table></figure><h4 id="适用场景对比"><a href="#适用场景对比" class="headerlink" title="适用场景对比"></a>适用场景对比</h4><p><strong>LightRAG更适合</strong>：</p><ul><li>需要快速语义检索的场景</li><li>混合查询需求（精确+模糊）</li><li>资源受限的环境</li><li>快速原型开发</li></ul><p><strong>GraphRAG更适合</strong>：</p><ul><li>复杂关系推理需求</li><li>多跳查询场景</li><li>结构化知识密集的领域</li><li>深度分析应用</li></ul><h3 id="与RAG-Everything对比"><a href="#与RAG-Everything对比" class="headerlink" title="与RAG Everything对比"></a>与RAG Everything对比</h3><p><strong>RAG Everything</strong> 是一个全功能的RAG平台，强调”everything”的理念，支持多种数据源和检索方式。</p><h4 id="功能覆盖对比"><a href="#功能覆盖对比" class="headerlink" title="功能覆盖对比"></a>功能覆盖对比</h4><table><thead><tr><th>功能模块</th><th>LightRAG</th><th>RAG Everything</th></tr></thead><tbody><tr><td><strong>数据源支持</strong></td><td>文档为主</td><td>全数据源（DB、API、文件等）</td></tr><tr><td><strong>检索方式</strong></td><td>向量+图谱</td><td>多种检索器组合</td></tr><tr><td><strong>系统复杂度</strong></td><td>专注核心功能</td><td>功能全面但复杂</td></tr><tr><td><strong>学习成本</strong></td><td>较低</td><td>较高</td></tr><tr><td><strong>定制能力</strong></td><td>高度可配置</td><td>极高的灵活性</td></tr></tbody></table><h4 id="技术架构对比"><a href="#技术架构对比" class="headerlink" title="技术架构对比"></a>技术架构对比</h4><p><strong>LightRAG架构</strong>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 精简但高效的架构</span></span><br><span class="line"><span class="attr">LightRAG:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Core</span> <span class="string">Engine</span> <span class="string">(轻量级)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Dual</span> <span class="string">Storage</span> <span class="string">(向量+图谱)</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Multi</span> <span class="string">Query</span> <span class="string">Modes</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Simple</span> <span class="string">API</span> <span class="string">Layer</span></span><br></pre></td></tr></table></figure><p><strong>RAG Everything架构</strong>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全功能平台架构</span></span><br><span class="line"><span class="attr">RAG_Everything:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Multiple</span> <span class="string">Data</span> <span class="string">Connectors</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Various</span> <span class="string">Retrieval</span> <span class="string">Engines</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Complex</span> <span class="string">Orchestration</span> <span class="string">Layer</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Extensive</span> <span class="string">Plugin</span> <span class="string">System</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Advanced</span> <span class="string">Analytics</span></span><br></pre></td></tr></table></figure><h4 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h4><p><strong>响应速度</strong>：</p><ul><li><strong>LightRAG</strong>：优化的双重检索，平均响应&lt;2秒</li><li><strong>RAG Everything</strong>：功能全面但响应时间较长，3-5秒</li><li><strong>GraphRAG</strong>：图遍历计算复杂，响应时间2-4秒</li></ul><p><strong>资源消耗</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 典型资源使用对比</span></span><br><span class="line">resource_usage = &#123;</span><br><span class="line">    <span class="string">&quot;LightRAG&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;memory&quot;</span>: <span class="string">&quot;2-4GB&quot;</span>,</span><br><span class="line">        <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;2-4 cores&quot;</span>,</span><br><span class="line">        <span class="string">&quot;storage&quot;</span>: <span class="string">&quot;适中&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;RAG_Everything&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;memory&quot;</span>: <span class="string">&quot;4-8GB&quot;</span>, </span><br><span class="line">        <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;4-8 cores&quot;</span>,</span><br><span class="line">        <span class="string">&quot;storage&quot;</span>: <span class="string">&quot;较大&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;GraphRAG&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;memory&quot;</span>: <span class="string">&quot;3-6GB&quot;</span>,</span><br><span class="line">        <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;2-6 cores&quot;</span>, </span><br><span class="line">        <span class="string">&quot;storage&quot;</span>: <span class="string">&quot;适中到大&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="开发体验对比"><a href="#开发体验对比" class="headerlink" title="开发体验对比"></a>开发体验对比</h4><p><strong>LightRAG开发体验</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单直接的使用方式</span></span><br><span class="line"><span class="keyword">from</span> lightrag <span class="keyword">import</span> LightRAG</span><br><span class="line"></span><br><span class="line">rag = LightRAG(config)</span><br><span class="line">rag.insert_documents(docs)</span><br><span class="line">response = rag.query(<span class="string">&quot;问题&quot;</span>, mode=<span class="string">&quot;hybrid&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>RAG Everything开发体验</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 功能丰富但配置复杂</span></span><br><span class="line"><span class="keyword">from</span> rag_everything <span class="keyword">import</span> RAGPlatform</span><br><span class="line"></span><br><span class="line">platform = RAGPlatform()</span><br><span class="line">platform.add_data_source(<span class="string">&quot;database&quot;</span>, db_config)</span><br><span class="line">platform.add_data_source(<span class="string">&quot;files&quot;</span>, file_config)</span><br><span class="line">platform.configure_retrievers(retriever_configs)</span><br><span class="line">platform.setup_pipeline(pipeline_config)</span><br><span class="line">response = platform.query(<span class="string">&quot;问题&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>GraphRAG开发体验</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 专注于图谱的使用方式</span></span><br><span class="line"><span class="keyword">from</span> graphrag <span class="keyword">import</span> GraphRAG</span><br><span class="line"></span><br><span class="line">graph_rag = GraphRAG(graph_config)</span><br><span class="line">graph_rag.build_knowledge_graph(documents)</span><br><span class="line">response = graph_rag.query(<span class="string">&quot;问题&quot;</span>, reasoning_depth=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h3 id="三者详细对比矩阵"><a href="#三者详细对比矩阵" class="headerlink" title="三者详细对比矩阵"></a>三者详细对比矩阵</h3><table><thead><tr><th>对比维度</th><th>LightRAG</th><th>GraphRAG</th><th>RAG Everything</th></tr></thead><tbody><tr><td><strong>技术门槛</strong></td><td>⭐⭐ 中等</td><td>⭐⭐⭐ 较高</td><td>⭐⭐⭐⭐ 高</td></tr><tr><td><strong>部署难度</strong></td><td>⭐⭐ 简单</td><td>⭐⭐⭐ 中等</td><td>⭐⭐⭐⭐ 复杂</td></tr><tr><td><strong>查询精度</strong></td><td>⭐⭐⭐⭐ 高</td><td>⭐⭐⭐⭐⭐ 很高</td><td>⭐⭐⭐ 中高</td></tr><tr><td><strong>查询速度</strong></td><td>⭐⭐⭐⭐ 快</td><td>⭐⭐⭐ 中等</td><td>⭐⭐ 较慢</td></tr><tr><td><strong>扩展性</strong></td><td>⭐⭐⭐ 良好</td><td>⭐⭐⭐ 良好</td><td>⭐⭐⭐⭐⭐ 优秀</td></tr><tr><td><strong>资源消耗</strong></td><td>⭐⭐⭐⭐ 低</td><td>⭐⭐⭐ 中等</td><td>⭐⭐ 较高</td></tr><tr><td><strong>社区生态</strong></td><td>⭐⭐⭐ 发展中</td><td>⭐⭐⭐⭐ 活跃</td><td>⭐⭐⭐ 中等</td></tr></tbody></table><h3 id="选择建议"><a href="#选择建议" class="headerlink" title="选择建议"></a>选择建议</h3><h4 id="选择LightRAG的情况"><a href="#选择LightRAG的情况" class="headerlink" title="选择LightRAG的情况"></a>选择LightRAG的情况</h4><ul><li>✅ 需要快速搭建RAG系统</li><li>✅ 兼顾语义检索和关系查询</li><li>✅ 资源受限的环境</li><li>✅ 注重系统稳定性和可维护性</li><li>✅ 中小型团队或项目</li></ul><h4 id="选择GraphRAG的情况"><a href="#选择GraphRAG的情况" class="headerlink" title="选择GraphRAG的情况"></a>选择GraphRAG的情况</h4><ul><li>✅ 复杂知识推理需求</li><li>✅ 深度关系分析场景</li><li>✅ 结构化数据为主</li><li>✅ 对查询精度要求极高</li><li>✅ 有足够的图数据库运维能力</li></ul><h4 id="选择RAG-Everything的情况"><a href="#选择RAG-Everything的情况" class="headerlink" title="选择RAG Everything的情况"></a>选择RAG Everything的情况</h4><ul><li>✅ 需要处理多种异构数据源</li><li>✅ 复杂的企业级集成需求</li><li>✅ 高度定制化要求</li><li>✅ 大型团队和充足资源</li><li>✅ 需要全方位的RAG能力</li></ul><h3 id="技术演进趋势"><a href="#技术演进趋势" class="headerlink" title="技术演进趋势"></a>技术演进趋势</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    A[传统RAG] --&gt; B[LightRAG&lt;br/&gt;轻量级+双重检索]</span><br><span class="line">    A --&gt; C[GraphRAG&lt;br/&gt;深度图推理] </span><br><span class="line">    A --&gt; D[RAG Everything&lt;br/&gt;全功能平台]</span><br><span class="line">    </span><br><span class="line">    B --&gt; E[未来融合&lt;br/&gt;最佳实践结合]</span><br><span class="line">    C --&gt; E</span><br><span class="line">    D --&gt; E</span><br></pre></td></tr></table></figure><p><strong>未来发展趋势</strong>：</p><ol><li><strong>技术融合</strong>：各系统优势互补，形成更完善的解决方案</li><li><strong>标准化</strong>：RAG接口和协议标准化</li><li><strong>智能化</strong>：自动选择最优检索策略</li><li><strong>边缘化</strong>：支持边缘计算和离线部署</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LightRAG作为一个现代化的检索增强生成系统，通过创新性地结合知识图谱和向量检索技术，为企业级AI应用提供了强大的知识管理能力。其轻量级的设计、灵活的架构和丰富的功能特性，使其成为构建智能问答系统的理想选择。</p><h3 id="核心优势"><a href="#核心优势" class="headerlink" title="核心优势"></a>核心优势</h3><ol><li><strong>技术先进性</strong>：融合多种检索模式，提供精准的知识获取</li><li><strong>架构灵活性</strong>：模块化设计，支持多种存储和模型选择</li><li><strong>生产就绪</strong>：完整的部署方案和监控能力</li><li><strong>易于集成</strong>：丰富的API接口和配置选项</li></ol><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>企业知识管理平台</li><li>智能客服系统</li><li>学术研究工具</li><li>法律文档分析</li><li>技术文档问答</li></ul><p>随着RAG技术的不断发展，LightRAG将继续演进，为更多场景提供高效的知识检索和生成能力。</p><h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><ul><li><a href="https://github.com/HKUDS/LightRAG">LightRAG GitHub仓库</a></li><li><a href="https://github.com/HKUDS/LightRAG/blob/main/docs/Algorithm.md">算法详解文档</a></li><li><a href="https://github.com/HKUDS/LightRAG/blob/main/docs/LightRAG_concurrent_explain.md">并发处理说明</a></li><li><a href="https://github.com/HKUDS/LightRAG/blob/main/docs/rerank_integration.md">重排序集成指南</a></li><li><a href="https://github.com/HKUDS/LightRAG/blob/main/docs/DockerDeployment.md">Docker部署文档</a></li></ul><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
            <tag> RAG </tag>
            
            <tag> AI </tag>
            
            <tag> 知识图谱 </tag>
            
            <tag> 向量检索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零构建RAG文档问答系统：技术栈与实现方案详解</title>
      <link href="/AI/%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BARAG%E6%96%87%E6%A1%A3%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%8A%80%E6%9C%AF%E6%A0%88%E4%B8%8E%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%E8%AF%A6%E8%A7%A3/"/>
      <url>/AI/%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BARAG%E6%96%87%E6%A1%A3%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F%EF%BC%9A%E6%8A%80%E6%9C%AF%E6%A0%88%E4%B8%8E%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="从零构建RAG文档问答系统：技术栈与实现方案详解"><a href="#从零构建RAG文档问答系统：技术栈与实现方案详解" class="headerlink" title="从零构建RAG文档问答系统：技术栈与实现方案详解"></a>从零构建RAG文档问答系统：技术栈与实现方案详解</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在人工智能快速发展的今天，如何让AI模型基于特定文档内容进行准确回答，成为了一个重要的技术挑战。传统的问答系统往往存在”幻觉”问题，即模型会生成看似合理但实际不准确的信息。为了解决这个问题，我们构建了一个基于RAG（Retrieval-Augmented Generation）技术的文档问答系统。</p><p>本文将详细介绍这个项目的技术栈选择、架构设计、实现方案以及开发过程中的关键决策。</p><h2 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h2><p>项目源代码: <a href="https://github.com/xhuaustc/rag-qa-system">https://github.com/xhuaustc/rag-qa-system</a></p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/0847c9aefba42b4a655c31c080a0218eff55f322451724d94dc86d1c5a36ce40.png" alt="rag 流程图">  </p><p>我们的RAG文档问答系统具有以下核心特性：</p><ul><li>🔍 <strong>多格式文档支持</strong>: PDF、DOCX、Markdown、TXT等</li><li>🤖 <strong>多LLM后端</strong>: Ollama、OpenAI、Azure OpenAI</li><li>📝 <strong>智能文档分块</strong>: 支持中英文混合文本的智能分块</li><li>🔗 <strong>向量检索</strong>: 基于ChromaDB的高效向量检索</li><li>💬 <strong>智能问答</strong>: 基于文档内容的智能问答</li><li>⚙️ <strong>灵活配置</strong>: 支持环境变量和代码配置</li><li>🛠️ <strong>模块化设计</strong>: 清晰的模块分离和扩展性</li></ul><h2 id="技术栈选择"><a href="#技术栈选择" class="headerlink" title="技术栈选择"></a>技术栈选择</h2><h3 id="核心框架"><a href="#核心框架" class="headerlink" title="核心框架"></a>核心框架</h3><p><strong>LangChain</strong>: 作为我们的核心框架，LangChain提供了丰富的LLM集成、文档处理和向量存储功能。它支持多种LLM提供商，并且有良好的扩展性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 核心依赖</span></span><br><span class="line">langchain&gt;=<span class="number">0.1</span><span class="number">.0</span></span><br><span class="line">langchain-community&gt;=<span class="number">0.0</span><span class="number">.10</span></span><br><span class="line">langchain-openai&gt;=<span class="number">0.0</span><span class="number">.5</span></span><br><span class="line">langchain-ollama&gt;=<span class="number">0.1</span><span class="number">.0</span></span><br></pre></td></tr></table></figure><p><strong>ChromaDB</strong>: 选择ChromaDB作为向量数据库，主要考虑其以下优势：</p><ul><li>轻量级，易于部署</li><li>支持本地存储，无需额外服务</li><li>良好的Python集成</li><li>支持元数据过滤</li></ul><h3 id="LLM提供商"><a href="#LLM提供商" class="headerlink" title="LLM提供商"></a>LLM提供商</h3><p>我们支持三种主要的LLM提供商：</p><ol><li><strong>Ollama</strong>: 本地部署，隐私保护，成本可控</li><li><strong>OpenAI</strong>: 云端服务，性能稳定，功能丰富</li><li><strong>Azure OpenAI</strong>: 企业级服务，合规性好</li></ol><h3 id="文档处理"><a href="#文档处理" class="headerlink" title="文档处理"></a>文档处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文档处理依赖</span></span><br><span class="line">markdown&gt;=<span class="number">3.5</span><span class="number">.0</span></span><br><span class="line">pypdf&gt;=<span class="number">3.17</span><span class="number">.0</span></span><br><span class="line">python-docx&gt;=<span class="number">1.1</span><span class="number">.0</span></span><br><span class="line">docx2txt&gt;=<span class="number">0.8</span></span><br><span class="line">unstructured&gt;=<span class="number">0.11</span><span class="number">.0</span></span><br></pre></td></tr></table></figure><h2 id="系统架构设计"><a href="#系统架构设计" class="headerlink" title="系统架构设计"></a>系统架构设计</h2><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p>我们的系统采用模块化设计，主要包含以下几个核心模块：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ollama/</span><br><span class="line">├── config/                 # 配置管理</span><br><span class="line">├── doc_proc/              # 文档处理</span><br><span class="line">├── embed/                  # 嵌入处理</span><br><span class="line">├── llm/                    # LLM客户端</span><br><span class="line">├── utils/                  # 工具模块</span><br><span class="line">└── main.py                 # 主程序</span><br></pre></td></tr></table></figure><h3 id="核心模块详解"><a href="#核心模块详解" class="headerlink" title="核心模块详解"></a>核心模块详解</h3><h4 id="1-配置管理模块-config"><a href="#1-配置管理模块-config" class="headerlink" title="1. 配置管理模块 (config/)"></a>1. 配置管理模块 (<code>config/</code>)</h4><p>使用Python的<code>dataclasses</code>模块构建了层次化的配置系统：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLMConfig</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;LLM客户端配置&quot;&quot;&quot;</span></span><br><span class="line">    provider: <span class="built_in">str</span> = field(default_factory=<span class="keyword">lambda</span>: os.getenv(<span class="string">&quot;LLM_PROVIDER&quot;</span>, <span class="string">&quot;ollama&quot;</span>))</span><br><span class="line">    model: <span class="built_in">str</span> = field(default_factory=<span class="keyword">lambda</span>: os.getenv(<span class="string">&quot;LLM_MODEL&quot;</span>, <span class="string">&quot;qwen3:8b&quot;</span>))</span><br><span class="line">    embedding_model: <span class="built_in">str</span> = field(default_factory=<span class="keyword">lambda</span>: os.getenv(<span class="string">&quot;LLM_EMBEDDING_MODEL&quot;</span>, <span class="string">&quot;shaw/dmeta-embedding-zh&quot;</span>))</span><br><span class="line">    api_key: <span class="type">Optional</span>[<span class="built_in">str</span>] = field(default_factory=<span class="keyword">lambda</span>: os.getenv(<span class="string">&quot;LLM_API_KEY&quot;</span>))</span><br><span class="line">    base_url: <span class="built_in">str</span> = field(default_factory=<span class="keyword">lambda</span>: os.getenv(<span class="string">&quot;LLM_BASE_URL&quot;</span>, <span class="string">&quot;http://localhost:11434&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AppSettings</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;应用程序设置&quot;&quot;&quot;</span></span><br><span class="line">    llm: LLMConfig = field(default_factory=LLMConfig)</span><br><span class="line">    storage: StorageConfig = field(default_factory=StorageConfig)</span><br><span class="line">    document_processing: DocumentProcessingConfig = field(default_factory=DocumentProcessingConfig)</span><br></pre></td></tr></table></figure><p>这种设计的优势：</p><ul><li><strong>类型安全</strong>: 使用dataclass提供类型检查</li><li><strong>环境变量集成</strong>: 自动从环境变量读取配置</li><li><strong>默认值</strong>: 提供合理的默认配置</li><li><strong>验证</strong>: 支持配置验证逻辑</li></ul><h4 id="2-LLM客户端模块-llm"><a href="#2-LLM客户端模块-llm" class="headerlink" title="2. LLM客户端模块 (llm/)"></a>2. LLM客户端模块 (<code>llm/</code>)</h4><p>采用工厂模式和策略模式设计LLM客户端：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseLLMClient</span>(<span class="title class_ inherited__">ABC</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;LLM客户端基类&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_text</span>(<span class="params">self, prompt: <span class="built_in">str</span>, **kwargs</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;生成文本&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_embeddings</span>(<span class="params">self, texts: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;生成嵌入向量&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OllamaLLMClient</span>(<span class="title class_ inherited__">BaseLLMClient</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Ollama LLM客户端&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config: LLMConfig</span>):</span><br><span class="line">        self.config = config</span><br><span class="line">        self._initialize_components()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_initialize_components</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;初始化Ollama组件&quot;&quot;&quot;</span></span><br><span class="line">        self.llm = OllamaLLM(model=self.config.model, base_url=self.config.base_url)</span><br><span class="line">        self.embeddings = OllamaEmbeddings(model=self.config.embedding_model, base_url=self.config.base_url)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLMClient</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;LLM客户端工厂&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, provider: <span class="built_in">str</span> = <span class="string">&quot;ollama&quot;</span>, **kwargs</span>):</span><br><span class="line">        self.provider = provider</span><br><span class="line">        self.config = LLMConfig(provider=provider, **kwargs)</span><br><span class="line">        self._client = self._create_client()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_client</span>(<span class="params">self</span>) -&gt; BaseLLMClient:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;创建具体的LLM客户端&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.provider == <span class="string">&quot;ollama&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> OllamaLLMClient(self.config)</span><br><span class="line">        <span class="keyword">elif</span> self.provider == <span class="string">&quot;openai&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> OpenAILLMClient(self.config)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;不支持的LLM提供商: <span class="subst">&#123;self.provider&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="3-文档处理模块-doc-proc"><a href="#3-文档处理模块-doc-proc" class="headerlink" title="3. 文档处理模块 (doc_proc/)"></a>3. 文档处理模块 (<code>doc_proc/</code>)</h4><p>文档处理模块负责文档的加载、分块和预处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultilingualChunker</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;多语言文档分块器&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, chunk_size: <span class="built_in">int</span> = <span class="number">1000</span>, chunk_overlap: <span class="built_in">int</span> = <span class="number">200</span></span>):</span><br><span class="line">        self.chunk_size = chunk_size</span><br><span class="line">        self.chunk_overlap = chunk_overlap</span><br><span class="line">        self.text_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">            chunk_size=chunk_size,</span><br><span class="line">            chunk_overlap=chunk_overlap,</span><br><span class="line">            separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot;。&quot;</span>, <span class="string">&quot;！&quot;</span>, <span class="string">&quot;？&quot;</span>, <span class="string">&quot;.&quot;</span>, <span class="string">&quot;!&quot;</span>, <span class="string">&quot;?&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>]</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clean_base64_data</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;清理文本中的Base64数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 移除Base64编码的图片数据</span></span><br><span class="line">        base64_patterns = [</span><br><span class="line">            <span class="string">r&#x27;data:image/[^;]+;base64,[A-Za-z0-9+/=]+&#x27;</span>,</span><br><span class="line">            <span class="string">r&#x27;[A-Za-z0-9+/]&#123;50,&#125;=&#123;0,2&#125;&#x27;</span>  <span class="comment"># 长Base64字符串</span></span><br><span class="line">        ]</span><br><span class="line">        </span><br><span class="line">        cleaned_text = text</span><br><span class="line">        <span class="keyword">for</span> pattern <span class="keyword">in</span> base64_patterns:</span><br><span class="line">            cleaned_text = re.sub(pattern, <span class="string">&#x27;[图片数据]&#x27;</span>, cleaned_text, flags=re.IGNORECASE)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> cleaned_text.strip()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">split_documents</span>(<span class="params">self, documents: <span class="type">List</span>[Document]</span>) -&gt; <span class="type">List</span>[Document]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;分割文档&quot;&quot;&quot;</span></span><br><span class="line">        processed_docs = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> doc <span class="keyword">in</span> documents:</span><br><span class="line">            <span class="comment"># 清理Base64数据</span></span><br><span class="line">            cleaned_content = self.clean_base64_data(doc.page_content)</span><br><span class="line">            doc.page_content = cleaned_content</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 分割文档</span></span><br><span class="line">            chunks = self.text_splitter.split_text(cleaned_content)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):</span><br><span class="line">                chunk_doc = Document(</span><br><span class="line">                    page_content=chunk,</span><br><span class="line">                    metadata=&#123;</span><br><span class="line">                        **doc.metadata,</span><br><span class="line">                        <span class="string">&quot;chunk_id&quot;</span>: i,</span><br><span class="line">                        <span class="string">&quot;total_chunks&quot;</span>: <span class="built_in">len</span>(chunks)</span><br><span class="line">                    &#125;</span><br><span class="line">                )</span><br><span class="line">                processed_docs.append(chunk_doc)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> processed_docs</span><br></pre></td></tr></table></figure><h4 id="4-嵌入处理模块-embed"><a href="#4-嵌入处理模块-embed" class="headerlink" title="4. 嵌入处理模块 (embed/)"></a>4. 嵌入处理模块 (<code>embed/</code>)</h4><p>嵌入处理模块负责文档的向量化和存储：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EmbeddingProcessor</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;嵌入处理器&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, collection_name: <span class="built_in">str</span>, llm_provider: <span class="built_in">str</span> = <span class="string">&quot;ollama&quot;</span>, **kwargs</span>):</span><br><span class="line">        self.collection_name = collection_name</span><br><span class="line">        self.llm_client = LLMClient(provider=llm_provider, **kwargs)</span><br><span class="line">        self.chroma_client = chromadb.PersistentClient(path=settings.storage.chroma_db_path)</span><br><span class="line">        self._setup_collection()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_setup_collection</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;设置ChromaDB集合&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 尝试获取现有集合</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                self.collection = self.chroma_client.get_collection(name=self.collection_name)</span><br><span class="line">                logger.info(<span class="string">f&quot;已获取现有集合: <span class="subst">&#123;self.collection_name&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="comment"># 如果集合不存在，创建新集合</span></span><br><span class="line">                self.collection = self.chroma_client.create_collection(name=self.collection_name)</span><br><span class="line">                logger.info(<span class="string">f&quot;已创建新集合: <span class="subst">&#123;self.collection_name&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            logger.error(<span class="string">f&quot;集合设置失败: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">raise</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_documents</span>(<span class="params">self, documents: <span class="type">List</span>[Document]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;处理文档并存储到向量数据库&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 生成嵌入向量</span></span><br><span class="line">        texts = [doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line">        embeddings = self.llm_client.generate_embeddings(texts)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 准备元数据</span></span><br><span class="line">        metadatas = []</span><br><span class="line">        ids = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(documents):</span><br><span class="line">            metadata = &#123;</span><br><span class="line">                **doc.metadata,</span><br><span class="line">                <span class="string">&quot;embedding_model&quot;</span>: self.llm_client.config.embedding_model,</span><br><span class="line">                <span class="string">&quot;processed_at&quot;</span>: datetime.now().isoformat()</span><br><span class="line">            &#125;</span><br><span class="line">            metadatas.append(metadata)</span><br><span class="line">            ids.append(<span class="string">f&quot;doc_<span class="subst">&#123;i&#125;</span>_<span class="subst">&#123;<span class="built_in">hash</span>(doc.page_content) % <span class="number">1000000</span>&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 存储到ChromaDB</span></span><br><span class="line">        self.collection.add(</span><br><span class="line">            embeddings=embeddings,</span><br><span class="line">            documents=texts,</span><br><span class="line">            metadatas=metadatas,</span><br><span class="line">            ids=ids</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        logger.info(<span class="string">f&quot;成功处理并存储 <span class="subst">&#123;<span class="built_in">len</span>(documents)&#125;</span> 个文档块&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">query_similar</span>(<span class="params">self, query: <span class="built_in">str</span>, n_results: <span class="built_in">int</span> = <span class="number">5</span></span>) -&gt; <span class="type">List</span>[<span class="type">Dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;查询相似文档&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 生成查询嵌入</span></span><br><span class="line">        query_embedding = self.llm_client.generate_embeddings([query])[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 向量检索</span></span><br><span class="line">        results = self.collection.query(</span><br><span class="line">            query_embeddings=[query_embedding],</span><br><span class="line">            n_results=n_results</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 格式化结果</span></span><br><span class="line">        formatted_results = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(results[<span class="string">&#x27;documents&#x27;</span>][<span class="number">0</span>])):</span><br><span class="line">            formatted_results.append(&#123;</span><br><span class="line">                <span class="string">&#x27;content&#x27;</span>: results[<span class="string">&#x27;documents&#x27;</span>][<span class="number">0</span>][i],</span><br><span class="line">                <span class="string">&#x27;metadata&#x27;</span>: results[<span class="string">&#x27;metadatas&#x27;</span>][<span class="number">0</span>][i],</span><br><span class="line">                <span class="string">&#x27;distance&#x27;</span>: results[<span class="string">&#x27;distances&#x27;</span>][<span class="number">0</span>][i] <span class="keyword">if</span> <span class="string">&#x27;distances&#x27;</span> <span class="keyword">in</span> results <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            &#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> formatted_results</span><br></pre></td></tr></table></figure><h2 id="关键技术实现"><a href="#关键技术实现" class="headerlink" title="关键技术实现"></a>关键技术实现</h2><h3 id="1-智能文档分块策略"><a href="#1-智能文档分块策略" class="headerlink" title="1. 智能文档分块策略"></a>1. 智能文档分块策略</h3><p>文档分块是RAG系统的关键环节。我们采用了以下策略：</p><ul><li><strong>递归字符分割</strong>: 使用<code>RecursiveCharacterTextSplitter</code>，支持多种分隔符</li><li><strong>多语言支持</strong>: 针对中英文混合文本优化分隔符</li><li><strong>元数据保持</strong>: 在分块过程中保持原始文档的元数据</li><li><strong>Base64清理</strong>: 自动清理文档中的Base64编码图片数据</li></ul><h3 id="2-向量检索优化"><a href="#2-向量检索优化" class="headerlink" title="2. 向量检索优化"></a>2. 向量检索优化</h3><ul><li><strong>相似度计算</strong>: 使用余弦相似度进行向量匹配</li><li><strong>元数据过滤</strong>: 支持基于文档类型、来源等元数据进行过滤</li><li><strong>结果排序</strong>: 按相似度降序排列检索结果</li></ul><h3 id="3-错误处理机制"><a href="#3-错误处理机制" class="headerlink" title="3. 错误处理机制"></a>3. 错误处理机制</h3><p>我们实现了分层的错误处理系统：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseError</span>(<span class="title class_ inherited__">Exception</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;基础异常类&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLMClientError</span>(<span class="title class_ inherited__">BaseError</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;LLM客户端错误&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DocumentProcessingError</span>(<span class="title class_ inherited__">BaseError</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;文档处理错误&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EmbeddingError</span>(<span class="title class_ inherited__">BaseError</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;嵌入处理错误&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><h3 id="4-配置管理"><a href="#4-配置管理" class="headerlink" title="4. 配置管理"></a>4. 配置管理</h3><p>支持多种配置方式：</p><ul><li>环境变量配置</li><li>代码配置</li><li>配置文件</li></ul><h2 id="开发过程中的关键决策"><a href="#开发过程中的关键决策" class="headerlink" title="开发过程中的关键决策"></a>开发过程中的关键决策</h2><h3 id="1-模块化设计"><a href="#1-模块化设计" class="headerlink" title="1. 模块化设计"></a>1. 模块化设计</h3><p><strong>决策</strong>: 将系统拆分为多个独立模块<br><strong>理由</strong>: </p><ul><li>提高代码可维护性</li><li>便于单元测试</li><li>支持功能扩展</li><li>降低模块间耦合</li></ul><h3 id="2-抽象基类设计"><a href="#2-抽象基类设计" class="headerlink" title="2. 抽象基类设计"></a>2. 抽象基类设计</h3><p><strong>决策</strong>: 为LLM客户端和文档加载器设计抽象基类<br><strong>理由</strong>:</p><ul><li>统一接口规范</li><li>便于添加新的提供商</li><li>提高代码复用性</li></ul><h3 id="3-配置验证"><a href="#3-配置验证" class="headerlink" title="3. 配置验证"></a>3. 配置验证</h3><p><strong>决策</strong>: 在配置类中添加验证逻辑<br><strong>理由</strong>:</p><ul><li>及早发现配置错误</li><li>提供清晰的错误信息</li><li>避免运行时错误</li></ul><h3 id="4-日志系统"><a href="#4-日志系统" class="headerlink" title="4. 日志系统"></a>4. 日志系统</h3><p><strong>决策</strong>: 实现统一的日志系统<br><strong>理由</strong>:</p><ul><li>便于调试和监控</li><li>记录关键操作</li><li>支持不同日志级别</li></ul><h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h3 id="1-批量处理"><a href="#1-批量处理" class="headerlink" title="1. 批量处理"></a>1. 批量处理</h3><p>文档处理和嵌入生成采用批量处理方式，减少API调用次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">process_documents</span>(<span class="params">self, documents: <span class="type">List</span>[Document]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># 批量生成嵌入向量</span></span><br><span class="line">    texts = [doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line">    embeddings = self.llm_client.generate_embeddings(texts)</span><br></pre></td></tr></table></figure><h3 id="2-向量数据库优化"><a href="#2-向量数据库优化" class="headerlink" title="2. 向量数据库优化"></a>2. 向量数据库优化</h3><ul><li>使用持久化存储，避免重复计算</li><li>支持增量更新</li><li>元数据索引优化</li></ul><h3 id="3-内存管理"><a href="#3-内存管理" class="headerlink" title="3. 内存管理"></a>3. 内存管理</h3><ul><li>流式处理大文档</li><li>及时释放不需要的对象</li><li>控制批处理大小</li></ul><h2 id="部署和使用"><a href="#部署和使用" class="headerlink" title="部署和使用"></a>部署和使用</h2><h3 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python 3.8+</span></span><br><span class="line"><span class="comment"># 内存: 至少4GB</span></span><br><span class="line"><span class="comment"># 存储: 根据文档数量确定</span></span><br></pre></td></tr></table></figure><h3 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 安装依赖</span></span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 配置环境变量</span></span><br><span class="line"><span class="built_in">export</span> LLM_PROVIDER=ollama</span><br><span class="line"><span class="built_in">export</span> LLM_MODEL=qwen3:8b</span><br><span class="line"><span class="built_in">export</span> LLM_BASE_URL=http://localhost:11434</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 运行系统</span></span><br><span class="line">python main.py</span><br></pre></td></tr></table></figure><h3 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> embed.embedding <span class="keyword">import</span> EmbeddingProcessor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化处理器</span></span><br><span class="line">processor = EmbeddingProcessor(</span><br><span class="line">    collection_name=<span class="string">&quot;my_docs&quot;</span>,</span><br><span class="line">    llm_provider=<span class="string">&quot;ollama&quot;</span>,</span><br><span class="line">    llm_model=<span class="string">&quot;qwen3:8b&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理文档</span></span><br><span class="line">processor.process_directory(<span class="string">&quot;docs/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 问答</span></span><br><span class="line">query = <span class="string">&quot;如何配置系统？&quot;</span></span><br><span class="line">results = processor.query_similar(query, n_results=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="未来扩展方向"><a href="#未来扩展方向" class="headerlink" title="未来扩展方向"></a>未来扩展方向</h2><h3 id="1-功能扩展"><a href="#1-功能扩展" class="headerlink" title="1. 功能扩展"></a>1. 功能扩展</h3><ul><li><strong>多模态支持</strong>: 支持图片、音频等多媒体文档</li><li><strong>实时更新</strong>: 支持文档的实时更新和增量处理</li><li><strong>用户界面</strong>: 开发Web界面，提升用户体验</li><li><strong>API服务</strong>: 提供RESTful API接口</li></ul><h3 id="2-性能优化"><a href="#2-性能优化" class="headerlink" title="2. 性能优化"></a>2. 性能优化</h3><ul><li><strong>分布式处理</strong>: 支持大规模文档的分布式处理</li><li><strong>缓存机制</strong>: 实现智能缓存，提高查询速度</li><li><strong>索引优化</strong>: 优化向量索引结构</li></ul><h3 id="3-智能化提升"><a href="#3-智能化提升" class="headerlink" title="3. 智能化提升"></a>3. 智能化提升</h3><ul><li><strong>自动分块优化</strong>: 基于内容语义的智能分块</li><li><strong>查询理解</strong>: 改进查询理解和重写</li><li><strong>答案生成</strong>: 优化答案生成的质量和准确性</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过这个RAG文档问答系统的开发，我们深入理解了RAG技术的核心原理和实现细节。项目的成功关键在于：</p><ol><li><strong>合理的架构设计</strong>: 模块化、可扩展的架构</li><li><strong>技术栈选择</strong>: 成熟稳定的技术栈</li><li><strong>错误处理</strong>: 完善的错误处理和日志系统</li><li><strong>性能优化</strong>: 针对性的性能优化措施</li><li><strong>用户体验</strong>: 简单易用的接口设计</li></ol><p>这个项目不仅解决了实际的文档问答需求，也为后续的AI应用开发提供了良好的基础架构。通过持续优化和扩展，我们可以构建更加智能和强大的AI应用系统。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://python.langchain.com/">LangChain官方文档</a></li><li><a href="https://docs.trychroma.com/">ChromaDB文档</a></li><li><a href="https://ollama.ai/docs">Ollama文档</a></li><li><a href="https://arxiv.org/abs/2005.11401">RAG技术论文</a></li></ul><hr><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LangChain </tag>
            
            <tag> RAG </tag>
            
            <tag> AI </tag>
            
            <tag> ChromaDB </tag>
            
            <tag> Ollama </tag>
            
            <tag> 文档问答 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LangChain框架入门与实践：组件详解、使用场景与示例</title>
      <link href="/AI/LangChain%E6%A1%86%E6%9E%B6%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9A%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3%E3%80%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8E%E7%A4%BA%E4%BE%8B/"/>
      <url>/AI/LangChain%E6%A1%86%E6%9E%B6%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%9A%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3%E3%80%81%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8E%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="背景与目标读者"><a href="#背景与目标读者" class="headerlink" title="背景与目标读者"></a>背景与目标读者</h3><p>LangChain 是一个面向大型语言模型（Large Language Models, LLM）应用开发的开源框架，由 Harrison Chase 于 2022 年发布，并在 2023 年成立公司后快速发展。它通过统一的抽象与模块化组件，帮助开发者高效构建复杂的 AI 应用，如聊天机器人、文档问答（RAG）、智能代理（Agent）与自动摘要等。</p><p>本文面向有一定 Python 基础、希望系统了解并快速上手 LangChain 的工程师与技术爱好者，覆盖核心组件、常见应用场景与可运行示例代码。</p><hr><h3 id="LangChain-是什么，为什么需要它？"><a href="#LangChain-是什么，为什么需要它？" class="headerlink" title="LangChain 是什么，为什么需要它？"></a>LangChain 是什么，为什么需要它？</h3><ul><li>统一接口：屏蔽不同模型与服务的差异（如 OpenAI、Hugging Face、本地模型等），提供一致的调用方式。</li><li>组件化设计：围绕模型、提示（Prompt）、链（Chain）、代理（Agent）、记忆（Memory）、索引（Indexes&#x2F;Retriever）等模块化组合，便于扩展与维护。</li><li>工程化能力：提供可观测（Callbacks）、持久化（Checkpointers&#x2F;Message History）、工具接入（Tools）、生态集成（VectorStore&#x2F;Embeddings&#x2F;Loaders）等工程能力。</li></ul><hr><h3 id="核心组件与用法速览"><a href="#核心组件与用法速览" class="headerlink" title="核心组件与用法速览"></a>核心组件与用法速览</h3><h4 id="1-模型（Models）"><a href="#1-模型（Models）" class="headerlink" title="1) 模型（Models）"></a>1) 模型（Models）</h4><p>对接各类聊天&#x2F;补全模型，常见通过 <code>langchain-openai</code>、<code>langchain-community</code>、<code>langchain-anthropic</code> 等包集成。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Python</span></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0.2</span>)</span><br><span class="line">resp = model.invoke(<span class="string">&quot;用一句话解释什么是RAG？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(resp.content)</span><br></pre></td></tr></table></figure><h4 id="2-提示（Prompts）"><a href="#2-提示（Prompts）" class="headerlink" title="2) 提示（Prompts）"></a>2) 提示（Prompts）</h4><p>将系统指令、示例与用户输入组织为模板，支持变量插值与角色化消息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一名资深AI助教，输出要简洁准确。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;请用要点列举回答：&#123;question&#125;&quot;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h4 id="3-链（Chains-x2F-LCEL）"><a href="#3-链（Chains-x2F-LCEL）" class="headerlink" title="3) 链（Chains &#x2F; LCEL）"></a>3) 链（Chains &#x2F; LCEL）</h4><p>使用 LangChain Expression Language（LCEL）以“管道”方式组合组件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">chain = prompt | model | StrOutputParser()</span><br><span class="line"><span class="built_in">print</span>(chain.invoke(&#123;<span class="string">&quot;question&quot;</span>: <span class="string">&quot;LangChain 的核心组件有哪些？&quot;</span>&#125;))</span><br></pre></td></tr></table></figure><h4 id="4-代理（Agents）"><a href="#4-代理（Agents）" class="headerlink" title="4) 代理（Agents）"></a>4) 代理（Agents）</h4><p>让 LLM 作为决策引擎，基于工具（Tools）动态选择行动，如搜索、计算或代码执行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_react_agent, AgentExecutor</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="built_in">float</span>, b: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return a + b&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">tools = [add]</span><br><span class="line">agent = create_react_agent(model, tools)</span><br><span class="line">executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;请计算 12.5 与 7.5 的和，然后用一句中文描述结果。&quot;</span>&#125;)[<span class="string">&quot;output&quot;</span>])</span><br></pre></td></tr></table></figure><h4 id="5-记忆（Memory）"><a href="#5-记忆（Memory）" class="headerlink" title="5) 记忆（Memory）"></a>5) 记忆（Memory）</h4><p>存储会话历史，使多轮对话更连贯。推荐以 <code>RunnableWithMessageHistory</code> 使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.chat_history <span class="keyword">import</span> InMemoryChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables.history <span class="keyword">import</span> RunnableWithMessageHistory</span><br><span class="line"></span><br><span class="line">history_store = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_history</span>(<span class="params">session_id: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">return</span> history_store.setdefault(session_id, InMemoryChatMessageHistory())</span><br><span class="line"></span><br><span class="line">conversational_chain = RunnableWithMessageHistory(</span><br><span class="line">    chain,</span><br><span class="line">    get_history,</span><br><span class="line">    input_messages_key=<span class="string">&quot;question&quot;</span>,</span><br><span class="line">    history_messages_key=<span class="string">&quot;history&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(conversational_chain.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;question&quot;</span>: <span class="string">&quot;记住我喜欢Python。&quot;</span>&#125;,</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: <span class="string">&quot;u1&quot;</span>&#125;&#125;</span><br><span class="line">))</span><br><span class="line"><span class="built_in">print</span>(conversational_chain.invoke(</span><br><span class="line">    &#123;<span class="string">&quot;question&quot;</span>: <span class="string">&quot;我刚才说我喜欢哪种语言？&quot;</span>&#125;,</span><br><span class="line">    config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: <span class="string">&quot;u1&quot;</span>&#125;&#125;</span><br><span class="line">))</span><br></pre></td></tr></table></figure><h4 id="6-索引-x2F-检索（Indexes-x2F-VectorStores-x2F-Retrievers）"><a href="#6-索引-x2F-检索（Indexes-x2F-VectorStores-x2F-Retrievers）" class="headerlink" title="6) 索引 &#x2F; 检索（Indexes &#x2F; VectorStores &#x2F; Retrievers）"></a>6) 索引 &#x2F; 检索（Indexes &#x2F; VectorStores &#x2F; Retrievers）</h4><p>将文档切分、向量化并索引，供模型检索以提升事实性（RAG）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">docs = [</span><br><span class="line">    <span class="string">&quot;LangChain 提供统一的模型接口与组件化能力。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;RAG 将检索与生成结合，提升回答的准确性。&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">100</span>, chunk_overlap=<span class="number">20</span>)</span><br><span class="line">splits = splitter.create_documents(docs)</span><br><span class="line"></span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line">vectordb = FAISS.from_documents(splits, embeddings)</span><br><span class="line">retriever = vectordb.as_retriever(k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">context_docs = retriever.invoke(<span class="string">&quot;什么是RAG？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>([d.page_content <span class="keyword">for</span> d <span class="keyword">in</span> context_docs])</span><br></pre></td></tr></table></figure><hr><h3 id="快速开始：环境与第一个程序"><a href="#快速开始：环境与第一个程序" class="headerlink" title="快速开始：环境与第一个程序"></a>快速开始：环境与第一个程序</h3><h4 id="安装与准备"><a href="#安装与准备" class="headerlink" title="安装与准备"></a>安装与准备</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U <span class="string">&quot;langchain&gt;=0.2&quot;</span> langchain-openai langchain-community langchain-text-splitters faiss-cpu python-dotenv</span><br></pre></td></tr></table></figure><p>配置密钥（以 OpenAI 为例），建议使用环境变量或 <code>.env</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setx OPENAI_API_KEY <span class="string">&quot;sk-xxxxxxxx&quot;</span>   <span class="comment"># Windows PowerShell 可使用 $env:OPENAI_API_KEY=&quot;...&quot;</span></span><br></pre></td></tr></table></figure><h4 id="Hello-LangChain（LCEL-版）"><a href="#Hello-LangChain（LCEL-版）" class="headerlink" title="Hello, LangChain（LCEL 版）"></a>Hello, LangChain（LCEL 版）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;OPENAI_API_KEY&quot;</span>] = os.getenv(<span class="string">&quot;OPENAI_API_KEY&quot;</span>, <span class="string">&quot;&lt;YOUR_KEY&gt;&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0.2</span>)</span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是专业的技术助理，回答务必准确且简洁。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;question&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">chain = prompt | model | StrOutputParser()</span><br><span class="line"><span class="built_in">print</span>(chain.invoke(&#123;<span class="string">&quot;question&quot;</span>: <span class="string">&quot;一句话介绍LangChain。&quot;</span>&#125;))</span><br></pre></td></tr></table></figure><hr><h3 id="常见使用场景与示例"><a href="#常见使用场景与示例" class="headerlink" title="常见使用场景与示例"></a>常见使用场景与示例</h3><h4 id="场景一：知识库问答（RAG）"><a href="#场景一：知识库问答（RAG）" class="headerlink" title="场景一：知识库问答（RAG）"></a>场景一：知识库问答（RAG）</h4><p>将企业文档做切分与向量化，检索相关片段并与提示拼接后交给模型生成答案。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI, OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">docs = [</span><br><span class="line">    <span class="string">&quot;LangChain 是用于构建由大型语言模型驱动应用的框架。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;它包含模型、提示、链、代理、记忆与索引等组件。&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">120</span>, chunk_overlap=<span class="number">20</span>)</span><br><span class="line">splits = splitter.create_documents(docs)</span><br><span class="line"></span><br><span class="line">emb = OpenAIEmbeddings()</span><br><span class="line">vectordb = FAISS.from_documents(splits, emb)</span><br><span class="line">retriever = vectordb.as_retriever(k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;请基于给定上下文回答用户问题，若无法从上下文得到答案，请明确说明。上下文：\n&#123;context&#125;&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;问题：&#123;question&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">parser = StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rag_answer</span>(<span class="params">question: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    context_docs = retriever.invoke(question)</span><br><span class="line">    context = <span class="string">&quot;\n\n&quot;</span>.join(d.page_content <span class="keyword">for</span> d <span class="keyword">in</span> context_docs)</span><br><span class="line">    chain = prompt | model | parser</span><br><span class="line">    <span class="keyword">return</span> chain.invoke(&#123;<span class="string">&quot;context&quot;</span>: context, <span class="string">&quot;question&quot;</span>: question&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(rag_answer(<span class="string">&quot;LangChain 的核心组件是什么？&quot;</span>))</span><br></pre></td></tr></table></figure><h4 id="场景二：多轮聊天机器人（会话记忆）"><a href="#场景二：多轮聊天机器人（会话记忆）" class="headerlink" title="场景二：多轮聊天机器人（会话记忆）"></a>场景二：多轮聊天机器人（会话记忆）</h4><p>使用 <code>RunnableWithMessageHistory</code> 追踪对话上下文，使回答更连贯。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.chat_history <span class="keyword">import</span> InMemoryChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables.history <span class="keyword">import</span> RunnableWithMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是友好的中文助理，记住用户偏好。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;placeholder&quot;</span>, <span class="string">&quot;&#123;history&#125;&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;question&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">chain = prompt | ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0.3</span>) | StrOutputParser()</span><br><span class="line">store = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_history</span>(<span class="params">sid</span>):</span><br><span class="line">    <span class="keyword">return</span> store.setdefault(sid, InMemoryChatMessageHistory())</span><br><span class="line"></span><br><span class="line">conv = RunnableWithMessageHistory(chain, get_history, input_messages_key=<span class="string">&quot;question&quot;</span>, history_messages_key=<span class="string">&quot;history&quot;</span>)</span><br><span class="line"></span><br><span class="line">sid = <span class="string">&quot;user-42&quot;</span></span><br><span class="line"><span class="built_in">print</span>(conv.invoke(&#123;<span class="string">&quot;question&quot;</span>: <span class="string">&quot;我喜欢Go语言，请记住。&quot;</span>&#125;, config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: sid&#125;&#125;))</span><br><span class="line"><span class="built_in">print</span>(conv.invoke(&#123;<span class="string">&quot;question&quot;</span>: <span class="string">&quot;我喜欢哪种语言？&quot;</span>&#125;, config=&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;session_id&quot;</span>: sid&#125;&#125;))</span><br></pre></td></tr></table></figure><h4 id="场景三：长文档摘要"><a href="#场景三：长文档摘要" class="headerlink" title="场景三：长文档摘要"></a>场景三：长文档摘要</h4><p>将长文切分后分别摘要，再做聚合（Map-Reduce 思路）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">LangChain 通过统一抽象与模块化组件，帮助开发者构建LLM应用……（长文略）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">splits = RecursiveCharacterTextSplitter(chunk_size=<span class="number">300</span>, chunk_overlap=<span class="number">50</span>).split_text(text)</span><br><span class="line">model = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">parser = StrOutputParser()</span><br><span class="line"></span><br><span class="line">map_prompt = ChatPromptTemplate.from_template(<span class="string">&quot;请用中文简洁总结：&#123;chunk&#125;&quot;</span>)</span><br><span class="line">map_chain = map_prompt | model | parser</span><br><span class="line"></span><br><span class="line">summaries = [map_chain.invoke(&#123;<span class="string">&quot;chunk&quot;</span>: c&#125;) <span class="keyword">for</span> c <span class="keyword">in</span> splits]</span><br><span class="line"></span><br><span class="line">reduce_prompt = ChatPromptTemplate.from_template(<span class="string">&quot;将以下摘要合并为一段清晰总结：\n&#123;points&#125;&quot;</span>)</span><br><span class="line">reduce_chain = reduce_prompt | model | parser</span><br><span class="line"></span><br><span class="line">final_summary = reduce_chain.invoke(&#123;<span class="string">&quot;points&quot;</span>: <span class="string">&quot;\n&quot;</span>.join(summaries)&#125;)</span><br><span class="line"><span class="built_in">print</span>(final_summary)</span><br></pre></td></tr></table></figure><h4 id="场景四：工具调用-x2F-数据分析代理"><a href="#场景四：工具调用-x2F-数据分析代理" class="headerlink" title="场景四：工具调用&#x2F;数据分析代理"></a>场景四：工具调用&#x2F;数据分析代理</h4><p>通过 Agent 使用工具（如计算、搜索、数据库查询）来完成复杂任务。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_react_agent, AgentExecutor</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multiply</span>(<span class="params">a: <span class="built_in">float</span>, b: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multiply two numbers&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a * b</span><br><span class="line"></span><br><span class="line">tools = [multiply]</span><br><span class="line">agent = create_react_agent(ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>), tools)</span><br><span class="line">executor = AgentExecutor(agent=agent, tools=tools)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;请计算 3.2 乘以 8，并给出中文说明。&quot;</span>&#125;)[<span class="string">&quot;output&quot;</span>])</span><br></pre></td></tr></table></figure><hr><h3 id="进阶与工程化建议"><a href="#进阶与工程化建议" class="headerlink" title="进阶与工程化建议"></a>进阶与工程化建议</h3><ul><li>版本与依赖：<ul><li>推荐使用 <code>langchain&gt;=0.2</code> 与分包（<code>langchain-openai</code>、<code>langchain-community</code> 等）；不同版本 API 可能有变更。</li><li>向量库可选 Lancedb、FAISS、Chroma、Milvus、PGVector 等；生产建议持久化与备份策略。</li></ul></li><li>可观测与调试：<ul><li>使用 Callbacks 记录 Token 成本与时延；保留提示与上下文以便复现。</li></ul></li><li>安全与隐私：<ul><li>使用环境变量存储 API Key，不要硬编码；</li><li>对数据做脱敏，遵守隐私合规；</li><li>明确第三方服务的数据保留政策。</li></ul></li><li>部署建议：<ul><li>后端服务化（FastAPI 等），前后端分离；</li><li>缓存热点向量检索与响应；</li><li>结合队列与异步提高吞吐。</li></ul></li></ul><hr><h3 id="常见问题（FAQ）"><a href="#常见问题（FAQ）" class="headerlink" title="常见问题（FAQ）"></a>常见问题（FAQ）</h3><ul><li>输出偶尔不稳定？<ul><li>降低 <code>temperature</code>，并在提示中明确约束输出格式；</li><li>为 RAG 增强检索质量（更好的切分、合适的 <code>k</code> 值与重排序）。</li></ul></li><li>检索不相关？<ul><li>优化切分策略与嵌入模型；尝试添加领域示例与更明确的系统指令。</li></ul></li><li>Agent 行为“走偏”？<ul><li>限制可用工具、添加防护指令与超时；在日志中审计推理轨迹。</li></ul></li></ul><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li>LangChain 官方文档（入门&#x2F;指南&#x2F;组件）：<code>https://python.langchain.com/docs/</code></li><li>OpenAI 接入（langchain-openai）：<code>https://python.langchain.com/docs/integrations/chat/openai</code></li><li>向量数据库（FAISS&#x2F;Chroma&#x2F;Milvus）：<code>https://python.langchain.com/docs/integrations/vectorstores/</code></li></ul><hr><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LangChain </tag>
            
            <tag> LLM </tag>
            
            <tag> RAG </tag>
            
            <tag> Agent </tag>
            
            <tag> Prompt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vLLM高性能大模型推理引擎使用指南</title>
      <link href="/AI/vLLM%E9%AB%98%E6%80%A7%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/AI/vLLM%E9%AB%98%E6%80%A7%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>在当今AI快速发展的时代，大模型推理性能直接影响着应用的用户体验和成本效益。vLLM作为一个高性能的大模型推理引擎，为开发者提供了快速、高效的模型服务解决方案。本文将详细介绍如何使用vLLM进行离线推理和在线服务部署，特别是如何利用uv工具进行快速环境管理，以及如何部署兼容OpenAI API的模型服务。</p><h2 id="什么是vLLM"><a href="#什么是vLLM" class="headerlink" title="什么是vLLM"></a>什么是vLLM</h2><p>vLLM（Very Large Language Model）是由UC Berkeley开发的高性能大语言模型推理和服务引擎。它具有以下特点：</p><ul><li><strong>高吞吐量</strong>：通过PagedAttention等技术优化，显著提升推理速度</li><li><strong>内存效率</strong>：动态内存管理，减少显存占用</li><li><strong>易于使用</strong>：提供简洁的Python API和OpenAI兼容接口</li><li><strong>灵活部署</strong>：支持批量推理和在线服务两种模式</li></ul><h2 id="环境准备与安装"><a href="#环境准备与安装" class="headerlink" title="环境准备与安装"></a>环境准备与安装</h2><h3 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h3><ul><li><strong>操作系统</strong>：Linux</li><li><strong>Python版本</strong>：3.9 - 3.12</li><li><strong>硬件</strong>：NVIDIA GPU（推荐）</li></ul><h3 id="使用uv工具快速安装"><a href="#使用uv工具快速安装" class="headerlink" title="使用uv工具快速安装"></a>使用uv工具快速安装</h3><p><a href="https://github.com/astral-sh/uv">uv</a>是一个超快的Python环境管理器，可以显著加速环境创建和包安装过程。</p><h4 id="1-安装uv工具"><a href="#1-安装uv工具" class="headerlink" title="1. 安装uv工具"></a>1. 安装uv工具</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Linux/macOS上安装uv</span></span><br><span class="line">curl -LsSf https://astral.sh/uv/install.sh | sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或使用pip安装</span></span><br><span class="line">pip install uv</span><br></pre></td></tr></table></figure><h4 id="2-创建Python环境并安装vLLM"><a href="#2-创建Python环境并安装vLLM" class="headerlink" title="2. 创建Python环境并安装vLLM"></a>2. 创建Python环境并安装vLLM</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">uv python list <span class="comment">#查看 python 可用版本</span></span><br><span class="line"><span class="comment"># 创建Python 3.12环境并安装vLLM</span></span><br><span class="line">uv venv myenv --python 3.12 --seed</span><br><span class="line"><span class="built_in">source</span> myenv/bin/activate</span><br><span class="line">uv pip install vllm</span><br></pre></td></tr></table></figure><h4 id="3-一键运行方式（推荐）"><a href="#3-一键运行方式（推荐）" class="headerlink" title="3. 一键运行方式（推荐）"></a>3. 一键运行方式（推荐）</h4><p>如果您只是想快速测试vLLM，可以使用uv的<code>--with</code>选项直接运行，无需创建虚拟环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接运行vLLM命令</span></span><br><span class="line">uv run --with vllm vllm --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动vLLM服务</span></span><br><span class="line">uv run --with vllm vllm serve Qwen/Qwen2.5-1.5B-Instruct</span><br></pre></td></tr></table></figure><h3 id="传统conda安装方式"><a href="#传统conda安装方式" class="headerlink" title="传统conda安装方式"></a>传统conda安装方式</h3><p>如果您更习惯使用conda管理环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create -n vllm-env python=3.12 -y</span><br><span class="line">conda activate vllm-env</span><br><span class="line">pip install vllm</span><br></pre></td></tr></table></figure><h2 id="常用模型下载与本地存放位置说明"><a href="#常用模型下载与本地存放位置说明" class="headerlink" title="常用模型下载与本地存放位置说明"></a>常用模型下载与本地存放位置说明</h2><p>在使用vLLM进行推理或服务部署前，需先准备好大模型权重文件。vLLM支持直接加载<a href="https://huggingface.co/models">HuggingFace Hub</a>上的主流模型，常见模型包括：</p><ul><li>Qwen&#x2F;Qwen2.5-1.5B-Instruct</li><li>meta-llama&#x2F;Llama-2-7b-chat-hf</li><li>baichuan-inc&#x2F;Baichuan2-7B-Chat</li><li>internlm&#x2F;internlm2-chat-1_8b</li><li>deepseek-ai&#x2F;deepseek-llm-7b-chat</li></ul><h3 id="下载模型命令示例"><a href="#下载模型命令示例" class="headerlink" title="下载模型命令示例"></a>下载模型命令示例</h3><p>以Qwen2.5-1.5B-Instruct为例，可使用如下命令提前下载模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用huggingface-cli下载模型</span></span><br><span class="line">pip install huggingface_hub</span><br><span class="line">huggingface-cli download Qwen/Qwen2.5-1.5B-Instruct --local-dir ./models/Qwen2.5-1.5B-Instruct</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除模型</span></span><br><span class="line">huggingface-cli delete-cache</span><br></pre></td></tr></table></figure><p>或直接在vLLM加载时自动下载：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vllm serve Qwen/Qwen2.5-1.5B-Instruct</span><br></pre></td></tr></table></figure><h3 id="模型本地存放路径"><a href="#模型本地存放路径" class="headerlink" title="模型本地存放路径"></a>模型本地存放路径</h3><ul><li>默认情况下，HuggingFace Hub会将模型文件缓存到 <code>~/.cache/huggingface/hub</code> 目录。</li><li>你也可以通过 <code>HUGGINGFACE_HUB_CACHE</code> 环境变量自定义缓存路径，例如：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HUGGINGFACE_HUB_CACHE=/data/models/hf_cache</span><br></pre></td></tr></table></figure><ul><li>若使用<code>huggingface-cli download</code>，可通过<code>--local-dir</code>参数指定下载目录。</li></ul><h3 id="使用ModelScope下载模型"><a href="#使用ModelScope下载模型" class="headerlink" title="使用ModelScope下载模型"></a>使用ModelScope下载模型</h3><p>ModelScope: <a href="https://www.modelscope.cn/models">https://www.modelscope.cn/models</a><br>设置环境变量，优先使用 ModelScope 下载：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export VLLM_USE_MODELSCOPE=True</span><br></pre></td></tr></table></figure><p>安装ModelScope </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uv pip install modelscope</span><br></pre></td></tr></table></figure><p>下载模型</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelscope download qwen/Qwen2.5-1.5B-Instruct</span><br></pre></td></tr></table></figure><p>ModelScope 默认缓存在 ~&#x2F;.cache&#x2F;modelscope&#x2F;hub<br>可通过环境变量 TRANSFORMERS_CACHE&#x2F;MODELSCOPE_CACHE自定义目录。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><blockquote><p><strong>注意</strong>：首次加载大模型时需保证磁盘空间充足，部分模型体积较大（数GB至数十GB不等）。</p><p><strong>安全建议</strong>：请从官方或权威渠道下载模型，避免使用来历不明的第三方模型文件。</p></blockquote><h2 id="离线批量推理"><a href="#离线批量推理" class="headerlink" title="离线批量推理"></a>离线批量推理</h2><p>vLLM的离线推理功能适用于批量处理大量文本的场景，如数据分析、内容生成等。</p><h3 id="基础使用示例"><a href="#基础使用示例" class="headerlink" title="基础使用示例"></a>基础使用示例</h3><p>创建一个Python脚本<code>offline_inference.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入提示列表</span></span><br><span class="line">prompts = [</span><br><span class="line">    <span class="string">&quot;你好，我的名字是&quot;</span>,</span><br><span class="line">    <span class="string">&quot;人工智能的未来是&quot;</span>,</span><br><span class="line">    <span class="string">&quot;深度学习最重要的突破是&quot;</span>,</span><br><span class="line">    <span class="string">&quot;请解释一下什么是Transformer架构&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置采样参数</span></span><br><span class="line"><span class="comment"># temperature: 控制生成文本的随机性，值越高越随机</span></span><br><span class="line"><span class="comment"># top_p: 核采样参数，控制候选词汇的范围</span></span><br><span class="line"><span class="comment"># max_tokens: 生成文本的最大长度</span></span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=<span class="number">0.8</span>, </span><br><span class="line">    top_p=<span class="number">0.95</span>,</span><br><span class="line">    max_tokens=<span class="number">256</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化vLLM引擎</span></span><br><span class="line"><span class="comment"># 这里使用较小的模型作为示例，您可以替换为其他支持的模型</span></span><br><span class="line">llm = LLM(model=<span class="string">&quot;facebook/opt-125m&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行批量推理</span></span><br><span class="line">outputs = llm.generate(prompts, sampling_params)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理并显示结果</span></span><br><span class="line"><span class="keyword">for</span> output <span class="keyword">in</span> outputs:</span><br><span class="line">    prompt = output.prompt</span><br><span class="line">    generated_text = output.outputs[<span class="number">0</span>].text</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;输入: <span class="subst">&#123;prompt&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;输出: <span class="subst">&#123;generated_text&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">50</span>)</span><br></pre></td></tr></table></figure><h3 id="高级配置选项"><a href="#高级配置选项" class="headerlink" title="高级配置选项"></a>高级配置选项</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建更详细的采样配置</span></span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=<span class="number">0.7</span>,           <span class="comment"># 生成温度</span></span><br><span class="line">    top_p=<span class="number">0.9</span>,                <span class="comment"># 核采样</span></span><br><span class="line">    top_k=<span class="number">40</span>,                 <span class="comment"># Top-K采样</span></span><br><span class="line">    repetition_penalty=<span class="number">1.1</span>,    <span class="comment"># 重复惩罚</span></span><br><span class="line">    max_tokens=<span class="number">512</span>,           <span class="comment"># 最大生成长度</span></span><br><span class="line">    stop=[<span class="string">&quot;&lt;/s&gt;&quot;</span>, <span class="string">&quot;\n\n&quot;</span>]     <span class="comment"># 停止符号</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置模型加载参数</span></span><br><span class="line">llm = LLM(</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,</span><br><span class="line">    tensor_parallel_size=<span class="number">1</span>,    <span class="comment"># 张量并行大小</span></span><br><span class="line">    dtype=<span class="string">&quot;float16&quot;</span>,           <span class="comment"># 数据类型</span></span><br><span class="line">    max_model_len=<span class="number">4096</span>,       <span class="comment"># 最大模型长度</span></span><br><span class="line">    gpu_memory_utilization=<span class="number">0.8</span> <span class="comment"># GPU内存使用率</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="部署OpenAI兼容API服务"><a href="#部署OpenAI兼容API服务" class="headerlink" title="部署OpenAI兼容API服务"></a>部署OpenAI兼容API服务</h2><p>vLLM最强大的功能之一是能够部署为兼容OpenAI API的服务，让您可以无缝替换OpenAI的API端点。</p><h3 id="启动vLLM服务"><a href="#启动vLLM服务" class="headerlink" title="启动vLLM服务"></a>启动vLLM服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动基础服务</span></span><br><span class="line">vllm serve Qwen/Qwen2.5-1.5B-Instruct</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动带自定义配置的服务</span></span><br><span class="line">vllm serve Qwen/Qwen2.5-1.5B-Instruct \</span><br><span class="line">    --host 0.0.0.0 \</span><br><span class="line">    --port 8000 \</span><br><span class="line">    --api-key your-api-key \</span><br><span class="line">    --max-model-len 4096 \</span><br><span class="line">    --tensor-parallel-size 1</span><br></pre></td></tr></table></figure><h3 id="使用curl测试API"><a href="#使用curl测试API" class="headerlink" title="使用curl测试API"></a>使用curl测试API</h3><h4 id="1-测试模型列表"><a href="#1-测试模型列表" class="headerlink" title="1. 测试模型列表"></a>1. 测试模型列表</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/models</span><br></pre></td></tr></table></figure><h4 id="2-文本补全API"><a href="#2-文本补全API" class="headerlink" title="2. 文本补全API"></a>2. 文本补全API</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/completions \</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">    -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">        &quot;model&quot;: &quot;Qwen/Qwen2.5-1.5B-Instruct&quot;,</span></span><br><span class="line"><span class="string">        &quot;prompt&quot;: &quot;人工智能的发展趋势是&quot;,</span></span><br><span class="line"><span class="string">        &quot;max_tokens&quot;: 100,</span></span><br><span class="line"><span class="string">        &quot;temperature&quot;: 0.7</span></span><br><span class="line"><span class="string">    &#125;&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="3-聊天补全API"><a href="#3-聊天补全API" class="headerlink" title="3. 聊天补全API"></a>3. 聊天补全API</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions \</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">    -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">        &quot;model&quot;: &quot;Qwen/Qwen2.5-1.5B-Instruct&quot;,</span></span><br><span class="line"><span class="string">        &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">            &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个有用的AI助手。&quot;&#125;,</span></span><br><span class="line"><span class="string">            &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请解释一下什么是机器学习？&quot;&#125;</span></span><br><span class="line"><span class="string">        ],</span></span><br><span class="line"><span class="string">        &quot;max_tokens&quot;: 200,</span></span><br><span class="line"><span class="string">        &quot;temperature&quot;: 0.7</span></span><br><span class="line"><span class="string">    &#125;&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="Python客户端使用"><a href="#Python客户端使用" class="headerlink" title="Python客户端使用"></a>Python客户端使用</h3><h4 id="1-使用OpenAI-Python库"><a href="#1-使用OpenAI-Python库" class="headerlink" title="1. 使用OpenAI Python库"></a>1. 使用OpenAI Python库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置客户端连接到vLLM服务</span></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;your-api-key&quot;</span>,  <span class="comment"># 如果设置了API密钥</span></span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:8000/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本补全</span></span><br><span class="line">completion = client.completions.create(</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,</span><br><span class="line">    prompt=<span class="string">&quot;深度学习的核心概念包括&quot;</span>,</span><br><span class="line">    max_tokens=<span class="number">150</span>,</span><br><span class="line">    temperature=<span class="number">0.7</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;补全结果:&quot;</span>, completion.choices[<span class="number">0</span>].text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聊天补全</span></span><br><span class="line">chat_response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个专业的技术顾问。&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;请推荐一个适合初学者的机器学习框架。&quot;</span>&#125;</span><br><span class="line">    ],</span><br><span class="line">    max_tokens=<span class="number">200</span>,</span><br><span class="line">    temperature=<span class="number">0.7</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;聊天回复:&quot;</span>, chat_response.choices[<span class="number">0</span>].message.content)</span><br></pre></td></tr></table></figure><h4 id="2-流式响应处理"><a href="#2-流式响应处理" class="headerlink" title="2. 流式响应处理"></a>2. 流式响应处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;your-api-key&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:8000/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 流式聊天补全</span></span><br><span class="line">stream = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;请详细介绍一下Transformer架构的工作原理。&quot;</span>&#125;</span><br><span class="line">    ],</span><br><span class="line">    stream=<span class="literal">True</span>,</span><br><span class="line">    max_tokens=<span class="number">500</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;流式响应:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> stream:</span><br><span class="line">    <span class="keyword">if</span> chunk.choices[<span class="number">0</span>].delta.content <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(chunk.choices[<span class="number">0</span>].delta.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><h2 id="生产环境部署建议"><a href="#生产环境部署建议" class="headerlink" title="生产环境部署建议"></a>生产环境部署建议</h2><h3 id="1-服务配置优化"><a href="#1-服务配置优化" class="headerlink" title="1. 服务配置优化"></a>1. 服务配置优化</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生产环境启动脚本</span></span><br><span class="line">vllm serve Qwen/Qwen2.5-7B-Instruct \</span><br><span class="line">    --host 0.0.0.0 \</span><br><span class="line">    --port 8000 \</span><br><span class="line">    --api-key $(<span class="built_in">cat</span> /path/to/api-key) \</span><br><span class="line">    --tensor-parallel-size 2 \</span><br><span class="line">    --max-model-len 8192 \</span><br><span class="line">    --gpu-memory-utilization 0.85 \</span><br><span class="line">    --disable-log-requests \</span><br><span class="line">    --max-num-seqs 64</span><br></pre></td></tr></table></figure><h3 id="2-Docker部署"><a href="#2-Docker部署" class="headerlink" title="2. Docker部署"></a>2. Docker部署</h3><p>创建<code>Dockerfile</code>：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> nvidia/cuda:<span class="number">12.1</span>-devel-ubuntu20.<span class="number">04</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装系统依赖</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y \</span></span><br><span class="line"><span class="language-bash">    python3 python3-pip curl \</span></span><br><span class="line"><span class="language-bash">    &amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装uv和vLLM</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> curl -LsSf https://astral.sh/uv/install.sh | sh</span></span><br><span class="line"><span class="keyword">ENV</span> PATH=<span class="string">&quot;/root/.cargo/bin:$PATH&quot;</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> uv pip install --system vllm</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置工作目录</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /app</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 暴露端口</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动命令</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;vllm&quot;</span>, <span class="string">&quot;serve&quot;</span>, <span class="string">&quot;Qwen/Qwen2.5-1.5B-Instruct&quot;</span>, <span class="string">&quot;--host&quot;</span>, <span class="string">&quot;0.0.0.0&quot;</span>, <span class="string">&quot;--port&quot;</span>, <span class="string">&quot;8000&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>构建并运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建镜像</span></span><br><span class="line">docker build -t vllm-server .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行容器</span></span><br><span class="line">docker run --gpus all -p 8000:8000 vllm-server</span><br></pre></td></tr></table></figure><h3 id="3-负载均衡和监控"><a href="#3-负载均衡和监控" class="headerlink" title="3. 负载均衡和监控"></a>3. 负载均衡和监控</h3><p>使用Nginx进行负载均衡：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">upstream</span> vllm_backend &#123;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.1:8000</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.1:8001</span>;</span><br><span class="line">    <span class="attribute">server</span> <span class="number">127.0.0.1:8002</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> your-domain.com;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://vllm_backend;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_read_timeout</span> <span class="number">300s</span>;</span><br><span class="line">        <span class="attribute">proxy_connect_timeout</span> <span class="number">30s</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="性能优化技巧"><a href="#性能优化技巧" class="headerlink" title="性能优化技巧"></a>性能优化技巧</h2><h3 id="1-显存优化"><a href="#1-显存优化" class="headerlink" title="1. 显存优化"></a>1. 显存优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用KV缓存量化</span></span><br><span class="line">llm = LLM(</span><br><span class="line">    model=<span class="string">&quot;your-model&quot;</span>,</span><br><span class="line">    kv_cache_dtype=<span class="string">&quot;fp8&quot;</span>,  <span class="comment"># 使用FP8量化KV缓存</span></span><br><span class="line">    quantization=<span class="string">&quot;awq&quot;</span>      <span class="comment"># 使用AWQ量化</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="2-并行策略"><a href="#2-并行策略" class="headerlink" title="2. 并行策略"></a>2. 并行策略</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多GPU张量并行</span></span><br><span class="line">vllm serve your-model --tensor-parallel-size 4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 流水线并行（适用于超大模型）</span></span><br><span class="line">vllm serve your-model --pipeline-parallel-size 2</span><br></pre></td></tr></table></figure><h3 id="3-批处理优化"><a href="#3-批处理优化" class="headerlink" title="3. 批处理优化"></a>3. 批处理优化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 动态批处理配置</span></span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=<span class="number">0.7</span>,</span><br><span class="line">    max_tokens=<span class="number">256</span>,</span><br><span class="line">    <span class="comment"># 启用连续批处理</span></span><br><span class="line">    use_beam_search=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="常见问题和解决方案"><a href="#常见问题和解决方案" class="headerlink" title="常见问题和解决方案"></a>常见问题和解决方案</h2><h3 id="1-内存不足错误"><a href="#1-内存不足错误" class="headerlink" title="1. 内存不足错误"></a>1. 内存不足错误</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 降低GPU内存使用率</span></span><br><span class="line">vllm serve your-model --gpu-memory-utilization 0.7</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用CPU卸载</span></span><br><span class="line">vllm serve your-model --cpu-offload-gb 4</span><br></pre></td></tr></table></figure><h3 id="2-模型加载失败"><a href="#2-模型加载失败" class="headerlink" title="2. 模型加载失败"></a>2. 模型加载失败</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用ModelScope镜像（国内用户）</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;VLLM_USE_MODELSCOPE&quot;</span>] = <span class="string">&quot;true&quot;</span></span><br><span class="line"></span><br><span class="line">llm = LLM(model=<span class="string">&quot;qwen/Qwen2.5-1.5B-Instruct&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="3-API响应超时"><a href="#3-API响应超时" class="headerlink" title="3. API响应超时"></a>3. API响应超时</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加超时时间</span></span><br><span class="line">curl -X POST http://localhost:8000/v1/chat/completions \</span><br><span class="line">    --max-time 300 \</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">    -d <span class="string">&#x27;&#123;&quot;model&quot;: &quot;your-model&quot;, &quot;messages&quot;: [...]&#125;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="Windows-下安装vllm"><a href="#Windows-下安装vllm" class="headerlink" title="Windows 下安装vllm"></a>Windows 下安装vllm</h2><h3 id="安装WSL2及NVIDIA驱动"><a href="#安装WSL2及NVIDIA驱动" class="headerlink" title="安装WSL2及NVIDIA驱动"></a>安装WSL2及NVIDIA驱动</h3><ul><li><p>启动wsl2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">打开“控制面板”，进入“程序和功能”→“启用或关闭 Windows 功能”。</span><br><span class="line">勾选“适用于Linux的Windows子系统”和“虚拟机平台”。</span><br><span class="line">点击“确定”后重启电脑</span><br></pre></td></tr></table></figure></li><li><p>安装Ubuntu系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wsl.exe --list --online</span><br><span class="line">wsl --install Ubuntu --location E:/WSL2/Ubuntu</span><br><span class="line">wsl -s Ubuntu # 将Ubuntu设置为默认的系统</span><br></pre></td></tr></table></figure></li><li><p>安装nvidia 驱动： <a href="https://www.nvidia.cn/drivers/lookup/">https://www.nvidia.cn/drivers/lookup/</a></p></li></ul><h3 id="安装编译器"><a href="#安装编译器" class="headerlink" title="安装编译器"></a>安装编译器</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wsl --cd ~</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y build-essential # 安装编译器工具</span><br><span class="line">sudo apt install -y python3-dev</span><br></pre></td></tr></table></figure><h3 id="安装vllm"><a href="#安装vllm" class="headerlink" title="安装vllm"></a>安装vllm</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -LsSf https://astral.sh/uv/install.sh | sh</span><br><span class="line">mkdir vllm &amp;&amp; cd vllm</span><br><span class="line">uv venv myenv --python 3.12 --seed</span><br><span class="line">source myenv/bin/activate</span><br><span class="line">uv pip install vllm</span><br></pre></td></tr></table></figure><h3 id="运行模型"><a href="#运行模型" class="headerlink" title="运行模型"></a>运行模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 uv run --with vllm vllm serve Qwen/Qwen2.5-1.5B-Instruct</span><br><span class="line"># 或</span><br><span class="line">CUDA_VISIBLE_DEVICES=0 vllm serve Qwen/Qwen2.5-1.5B-Instruct</span><br></pre></td></tr></table></figure><p>如果有两张显卡，可设置 CUDA_VISIBLE_DEVICES&#x3D;0,1 并加上–tensor-parallel-size 2 开启并行运算<br>–port 指定端口， 默认为8000</p><h3 id="CUDA-OOM"><a href="#CUDA-OOM" class="headerlink" title="CUDA OOM"></a>CUDA OOM</h3><p>如果遇到 CUDA OOM错误，则设置DGX参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=0 uv run --with vllm vllm serve Qwen/Qwen2.5-1.5B-Instruct \</span><br><span class="line">    --gpu-memory-utilization 0.4</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>vLLM作为一个高性能的大模型推理引擎，为开发者提供了强大的工具来部署和使用大语言模型。通过本文的介绍，您应该能够：</p><ol><li><strong>快速环境搭建</strong>：使用uv工具高效管理Python环境和依赖</li><li><strong>离线批量推理</strong>：处理大规模文本生成任务</li><li><strong>在线API服务</strong>：部署兼容OpenAI API的模型服务</li><li><strong>生产环境优化</strong>：通过各种配置提升性能和稳定性</li></ol><p>vLLM的优势在于其出色的性能表现和易用性，特别是在需要高吞吐量推理的场景下。随着大模型技术的不断发展，vLLM将继续是一个值得关注和使用的重要工具。</p><h2 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h2><ul><li><a href="https://vllm.hyper.ai/docs/getting-started/quickstart/">vLLM官方文档</a></li><li><a href="https://github.com/vllm-project/vllm">vLLM GitHub仓库</a></li><li><a href="https://github.com/astral-sh/uv">uv工具官方文档</a></li><li><a href="https://platform.openai.com/docs/api-reference">OpenAI API文档</a></li><li><a href="https://vllm.hyper.ai/docs/">vLLM中文站</a></li></ul><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> vLLM </tag>
            
            <tag> 大模型推理 </tag>
            
            <tag> OpenAI API </tag>
            
            <tag> uv </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cursor创建一个python项目的所有交互</title>
      <link href="/AI/Cursor%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AApython%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%89%80%E6%9C%89%E4%BA%A4%E4%BA%92/"/>
      <url>/AI/Cursor%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AApython%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%89%80%E6%9C%89%E4%BA%A4%E4%BA%92/</url>
      
        <content type="html"><![CDATA[<p>本文内容主要参考自《用cursor玩转AI辅助编程》，将详细记录如何借助 Cursor AI 高效开发一个基于 FastAPI 和 Vue.js 的销售数据分析系统。适合希望了解 AI 辅助编程实践的 Python 全栈开发者。文章涵盖了从项目初始化、依赖配置、数据库设计、后端与前端开发、数据处理、API 实现、测试到前后端联调的完整流程。通过真实的对话与操作示例，帮助读者掌握在实际开发场景下如何高效利用 Cursor 进行协作，显著提升开发效率与代码质量。</p><h1 id="后端开发"><a href="#后端开发" class="headerlink" title="后端开发"></a>后端开发</h1><h2 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h2><ol><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">我需要开发一个销售数据分析系统，主要功能包括数据处理、统计分析和API。 </span><br><span class="line">请推荐合适的Python框架和技术栈，并帮助我搭建基础项目结构。 </span><br><span class="line">系统需要处理CSV格式的销售数据，进行数据清洗和分析，最后通过Web API框架提供查询API。 </span><br><span class="line">请帮我细化开发步骤，以便后续和你沟通时，能够一步一步实现。</span><br></pre></td></tr></table></figure></li><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">感谢你的建议！不过我想做一些调整： </span><br><span class="line">1. 我希望使用MySQL而不是PostgreSQL，因为我在本地电脑已经安装了MySQL </span><br><span class="line">2. 暂时不需要Docker，我们先在本地开发运行即可 </span><br><span class="line">3. 其他的技术选型都很好，我们继续使用FastAPI和Pandas </span><br><span class="line">请帮我调整项目结构和依赖配置来适配这些变更内容。</span><br></pre></td></tr></table></figure></li><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">现在的技术选型我很满意。 </span><br><span class="line">请帮我把实现细节细化一下，并生成COMPOSER 可以理解的提示词，以便后续项目实现 </span><br></pre></td></tr></table></figure>生成结果如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">我来帮你把项目实现细节拆分成更具体的步骤，并按照实现顺序组织。 </span><br><span class="line">1. 基础框架搭建 </span><br><span class="line">步骤1.1：创建项目结构 </span><br><span class="line">mkdir sales_analysis </span><br><span class="line">cd sales_analysis </span><br><span class="line"># 创建所需目录 </span><br><span class="line">mkdir -p app/api/endpoints app/core app/models app/schemas app/services tests data </span><br><span class="line">步骤1.2：创建虚拟环境和安装依赖 </span><br><span class="line">python -m venv venv </span><br><span class="line">source venv/bin/activate  # Linux/Mac </span><br><span class="line">pip install -r requirements.txt </span><br><span class="line">2. 数据模型设计 </span><br><span class="line">步骤2.1：创建基础数据模型 </span><br><span class="line">from sqlalchemy import Column, Integer, String, Float, DateTime, ForeignKey </span><br><span class="line">from sqlalchemy.orm import relationship </span><br><span class="line">from app.core.database import Base </span><br><span class="line">class Product(Base): </span><br><span class="line">    __tablename__ = &quot;products&quot; </span><br><span class="line">    id </span><br><span class="line">= Column(Integer, primary_key=True, index=True) </span><br><span class="line">    name = Column(String(100), nullable=False) </span><br><span class="line">    category = Column(String(50)) </span><br><span class="line">    price = Column(Float, nullable=False) </span><br><span class="line">class Sale(Base): </span><br><span class="line">    __tablename__ = &quot;sales&quot; </span><br><span class="line"> </span><br><span class="line">    id = Column(Integer, primary_key=True, index=True) </span><br><span class="line">    product_id = Column(Integer, ForeignKey(&quot;products.id&quot;)) </span><br><span class="line">    quantity = Column(Integer, nullable=False) </span><br><span class="line">    sale_date = Column(DateTime, nullable=False) </span><br><span class="line">    total_amount = Column(Float, nullable=False) </span><br><span class="line">3. 数据处理服务 </span><br><span class="line">步骤3.1：CSV数据处理服务 </span><br><span class="line">import pandas as pd </span><br><span class="line">from sqlalchemy.orm import Session </span><br><span class="line">from app.models.sales import Product, Sale </span><br><span class="line">from datetime import datetime </span><br><span class="line"> </span><br><span class="line">class DataProcessor: </span><br><span class="line">    @staticmethod </span><br><span class="line">    def process_csv(file_path: str, db: Session): </span><br><span class="line">        df = pd.read_csv(file_path) </span><br><span class="line">        # 数据清洗和转换逻辑 </span><br><span class="line">        # 将处理后的数据保存到数据库 </span><br><span class="line">4.  API开发 </span><br><span class="line">步骤4.1：创建API路由 </span><br><span class="line">from fastapi import APIRouter, Depends, HTTPException </span><br><span class="line">from sqlalchemy.orm import Session </span><br><span class="line">from app.core.database import get_db </span><br><span class="line">from app.services.data_processor import DataProcessor </span><br><span class="line"> </span><br><span class="line">router = APIRouter() </span><br><span class="line"> </span><br><span class="line">@router.get(&quot;/sales/summary&quot;) </span><br><span class="line">def get_sales_summary(db: Session = Depends(get_db)): </span><br><span class="line">    # 实现销售汇总统计 </span><br><span class="line">    pass </span><br><span class="line"> </span><br><span class="line">@router.get(&quot;/sales/trend&quot;) </span><br><span class="line">def get_sales_trend(start_date: str, end_date: str, db: Session = Depends(get_db)): </span><br><span class="line">    # 实现销售趋势分析 </span><br><span class="line">    pass </span><br><span class="line">5. 数据分析服务 </span><br><span class="line">步骤5.1：创建分析服务 </span><br><span class="line">import pandas as pd </span><br><span class="line">from sqlalchemy.orm import Session </span><br><span class="line">from app.models.sales import Sale, Product </span><br><span class="line"> </span><br><span class="line">class SalesAnalytics: </span><br><span class="line">    @staticmethod </span><br><span class="line">    def calculate_summary(db: Session): </span><br><span class="line">        # 实现销售汇总统计逻辑 </span><br><span class="line">        pass </span><br><span class="line"> </span><br><span class="line">    @staticmethod </span><br><span class="line">    def analyze_trends(db: Session, start_date: str, end_date: str): </span><br><span class="line">        # 实现销售趋势分析逻辑 </span><br><span class="line">        pass </span><br><span class="line">实现顺序和提示词 </span><br><span class="line">1. 设置项目基础结构 </span><br><span class="line">请帮我创建sales_analysis项目的基础目录结构，包括所有必要的空文件。 </span><br><span class="line">2. 创建数据库配置 </span><br><span class="line">请帮我实现MySQL数据库配置文件，包括database.py和config.py，需要支持环境变量配置。 </span><br><span class="line">3. 实现数据模型 </span><br><span class="line">请帮我实现销售数据分析系统的SQLAlchemy数据模型，包括产品表和销售记录表。 </span><br><span class="line">4. 实现数据处理服务 </span><br><span class="line">请帮我实现CSV数据处理服务，包括数据清洗和导入数据库的功能。 </span><br><span class="line">5. 实现API路由 </span><br><span class="line">请帮我实现销售数据分析系统的FastAPI路由，包括数据导入、查询和分析API。 </span><br><span class="line">6. 实现数据分析服务 </span><br><span class="line">请帮我实现销售数据分析服务，包括销售汇总、趋势分析等功能。 </span><br><span class="line">测试数据示例 </span><br><span class="line">创建示例CSV文件 `data/sample_sales.csv`: </span><br><span class="line">product_id,product_name,category,price,quantity,sale_date </span><br><span class="line">1,产品A,电子,99.9,2,2024-01-01 </span><br><span class="line">2,产品B,服装,199.9,1,2024-01-02 </span><br><span class="line">下一步建议 </span><br><span class="line">1. 我们可以从创建项目基础结构开始 </span><br><span class="line">2. 然后实现数据库配置 </span><br><span class="line">3. 接着是数据模型的实现 </span><br><span class="line">你想从哪个部分开始？每个步骤我都可以提供详细的代码实现。</span><br></pre></td></tr></table></figure></li><li>将返回结果保存在notepads中</li></ol><h2 id="基础配置-x2F-环境搭建"><a href="#基础配置-x2F-环境搭建" class="headerlink" title="基础配置&#x2F;环境搭建"></a>基础配置&#x2F;环境搭建</h2><ol><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">请帮我创建sales_analysis项目的基础目录结构，包括所有必要的空文件。 </span><br><span class="line">目录是这样的： </span><br><span class="line">sales_analysis/ </span><br><span class="line">├── app/ </span><br><span class="line">第5章  Cursor项目进阶：销售数据分析（后端Python部分）  |  97 </span><br><span class="line"> </span><br><span class="line">│   ├── __init__.py </span><br><span class="line">│   ├── main.py           # FastAPI应用入口 </span><br><span class="line">│   ├── api/ </span><br><span class="line">│   │   ├── __init__.py </span><br><span class="line">│   │   └── endpoints/ </span><br><span class="line">│   ├── core/ </span><br><span class="line">│   │   ├── config.py </span><br><span class="line">│   │   └── database.py </span><br><span class="line">│   ├── models/ </span><br><span class="line">│   ├── schemas/ </span><br><span class="line">│   └── services/ </span><br><span class="line">├── tests/ </span><br><span class="line">├── data/ </span><br><span class="line">└── requirements.txt </span><br><span class="line">其中 requirements.txt 内部的依赖是这样的： </span><br><span class="line">fastapi&gt;=0.104.0 </span><br><span class="line">uvicorn&gt;=0.24.0 </span><br><span class="line">pandas&gt;=2.1.0 </span><br><span class="line">numpy&gt;=1.24.0 </span><br><span class="line">sqlalchemy&gt;=2.0.0 </span><br><span class="line">mysqlclient&gt;=2.2.0 </span><br><span class="line">python-dotenv&gt;=1.0.0 </span><br><span class="line">pydantic&gt;=2.4.0 </span><br><span class="line">pytest&gt;=7.4.0 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">以下是我的真实的MySQL连接信息，请帮我做对应文件的修改 </span><br><span class="line">localhost:3306 </span><br><span class="line">用户名：root </span><br><span class="line">密码：root </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">帮我创建虚拟环境和安装依赖 </span><br></pre></td></tr></table></figure></li></ol><h2 id="功能实现"><a href="#功能实现" class="headerlink" title="功能实现"></a>功能实现</h2><ol><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 请帮我实现销售数据分析系统的SQLAlchemy数据模型，包括产品表和销售记录表。 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@Codebase 请帮我在database.py中添加创建表的代码</span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">我现在想用运行方法的形式启动整个项目，这样后续我做代码调试时会更方便。 </span><br><span class="line">请你帮我修改必要的代码 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 请帮我实现CSV文件的数据处理服务，包括数据清洗和导入数据库的功能。</span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 请帮我实现销售数据分析系统的FastAPI路由，包括数据导入、查询和分析API。 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 请帮我实现销售数据分析服务，包括销售汇总、趋势分析等功能。</span><br></pre></td></tr></table></figure></li></ol><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ol><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@notepads @Codebase  </span><br><span class="line">我现在已经写完代码了，需要测试，请你帮我生成一份测试计划 </span><br></pre></td></tr></table></figure></li><li>将生成内容保存到 notepads中</li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 帮我生成单元测试的部分</span><br></pre></td></tr></table></figure></li><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">我需要在cursor中对这个文件做Debug，请告诉我如何配置</span><br></pre></td></tr></table></figure></li><li>在notepads中添加以下内容<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 异常处理 </span><br><span class="line">在写代码时，如果你捕获了异常，就需要打印异常堆栈信息和当时请求的参数，方便我后续排查问题。</span><br></pre></td></tr></table></figure></li></ol><h1 id="前端开发"><a href="#前端开发" class="headerlink" title="前端开发"></a>前端开发</h1><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ol><li>启动后端项目，获取API文档</li><li>添加doc 索引, <a href="https://vuejs.**g/guide/introduction.html,%E5%90%8D%E5%AD%97%E4%B8%BA">https://vuejs.**g/guide/introduction.html,名字为</a> Vue.js</li><li>复制<a href="http://localhost:8000/openapi.json%EF%BC%8C%E5%86%85%E5%AE%B9%E4%BF%9D%E5%AD%98%E5%88%B0%E6%96%87%E4%BB%B6api.md">http://localhost:8000/openapi.json，内容保存到文件api.md</a><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 文档</span><br><span class="line">以下是 API 文档的JSON 定义</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="需求分析-1"><a href="#需求分析-1" class="headerlink" title="需求分析"></a>需求分析</h2><ol><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@api.md @Vue.js</span><br><span class="line">我希望你基于api.md中的API内容，开发一个前端项目。 </span><br><span class="line">项目需要用到Vue.js和其他一些配套的前端组件。 </span><br><span class="line">整体页面风格希望可以做得简洁、大方。 </span><br><span class="line">对于一些数据展示的业务模块，希望可以增加图表组件的支持，看上去更加直观。 </span><br><span class="line">我希望你可以清晰罗列每个步骤，方便我后续在“COMPOSER”面板中与Cursor进行沟通 </span><br></pre></td></tr></table></figure></li><li>复制输出到新的nodepads 中</li><li>chat<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">需要运行前端项目，在电脑上需要安装哪些软件？</span><br></pre></td></tr></table></figure></li></ol><h2 id="后端开发-1"><a href="#后端开发-1" class="headerlink" title="后端开发"></a>后端开发</h2><ol><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 现在帮我创建Vue项目 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">帮我生成一份测试CSV文件，数据尽可能多一些，方便我后续在前端用图表展示。 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@notepads @Codebase 在前端单击“点击上传”选项时，希望可以加一个进度条，上传成功后希望可以有一个</span><br><span class="line">提示消息，而且现在上传文件没有请求后端接口，你来修复一下 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@Codebase 我在数据库中查看sale_records表数据时，发现有一些数据的total_amount算得不对，</span><br><span class="line">大部分是对的。请你分析可能的原因并给出解决方案。 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 帮我实现销售数据管理模块的其他功能 </span><br></pre></td></tr></table></figure></li><li>后端更新了接口后，前端需要对应适配<br>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads @Codebase 请基于最新的API对现有的代码做出修改与适配</span><br></pre></td></tr></table></figure></li><li>数据分析模块 agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads 帮我生成数据分析模块的代码 </span><br></pre></td></tr></table></figure></li><li>agent<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@Codebase 我希望光标悬浮在品类分析图表上可以显示数字</span><br></pre></td></tr></table></figure></li></ol><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="提示词参考"><a href="#提示词参考" class="headerlink" title="提示词参考"></a>提示词参考</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">@note @Codebase </span><br><span class="line">我需要实现一个文章管理模块，要求如下： </span><br><span class="line">1. 功能需求： </span><br><span class="line">   - </span><br><span class="line">文章的增删改查操作 </span><br><span class="line">   - </span><br><span class="line">支持分页列表展示 </span><br><span class="line">   - </span><br><span class="line">包含标题、内容、发布时间等字段 </span><br><span class="line">2. 技术要求： </span><br><span class="line">   - </span><br><span class="line">使用SpringBoot框架 </span><br><span class="line">   - </span><br><span class="line">MyBatis 作为ORM框架 </span><br><span class="line">   - </span><br><span class="line">遵循RESTful API设计规范 </span><br><span class="line">3. 预期输出： </span><br><span class="line">   - </span><br><span class="line">后端API代码 </span><br><span class="line">   - </span><br><span class="line">数据库表设计 </span><br><span class="line">   - </span><br><span class="line">前端页面代码（Vue.js） </span><br><span class="line">4. 质量规范： </span><br><span class="line">   - </span><br><span class="line">需要添加适当的注释 </span><br><span class="line">   - </span><br><span class="line">包含异常处理 </span><br><span class="line">   - </span><br><span class="line">遵循项目现有的代码风格 </span><br></pre></td></tr></table></figure><h2 id="使用上下文，"><a href="#使用上下文，" class="headerlink" title="使用上下文，"></a>使用上下文，</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@notepads @Codebase @docs @file @git @cursor rules @Folders @Chat @Link @Web @Recent changes  @Code</span><br></pre></td></tr></table></figure><blockquote><p>本文由AI生成，内容仅供参考。在实际部署前，请根据具体环境进行测试和验证。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cursor </tag>
            
            <tag> Python </tag>
            
            <tag> FastAPI </tag>
            
            <tag> Vue.js </tag>
            
            <tag> 全栈开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT-4.1 提示指南（翻译）</title>
      <link href="/AI/GPT-4.1%E6%8F%90%E7%A4%BA%E6%8C%87%E5%8D%97%EF%BC%88%E7%BF%BB%E8%AF%91%EF%BC%89/"/>
      <url>/AI/GPT-4.1%E6%8F%90%E7%A4%BA%E6%8C%87%E5%8D%97%EF%BC%88%E7%BF%BB%E8%AF%91%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>原文 <a href="https://cookbook.openai.com/examples/gpt4-1_prompting_guide#4-instruction-following">GPT-4.1 Prompting Guide</a></p><p>GPT-4.1 模型系列在编码、指令遵循和长上下文处理能力方面相比 GPT-4o 有了显著提升。在本提示指南中，我们整理了从大量内部测试中得出的重要提示技巧，以帮助开发者充分利用这个新模型系列的改进能力。</p><p>许多典型的最佳实践仍然适用于 GPT-4.1，例如提供上下文示例、使指令尽可能具体和清晰，以及通过提示诱导规划以最大化模型智能。然而，我们预计充分利用这个模型需要一些提示迁移。GPT-4.1 经过训练，比其前身更严格、更字面地遵循指令，而前身倾向于更自由地从用户和系统提示中推断意图。这也意味着，GPT-4.1 具有高度的可引导性，对明确指定的提示反应灵敏——如果模型行为与您期望的不同，一个坚定且明确澄清您期望行为的单句几乎总是足以引导模型回到正轨。</p><p>请继续阅读可用作参考的提示示例，并记住虽然这些指导广泛适用，但没有建议是万能的。AI 工程本质上是一门经验性学科，大型语言模型本质上是非确定性的；除了遵循本指南外，我们建议构建信息丰富的评估并经常迭代，以确保您的提示工程变更为您的用例带来好处。</p><h2 id="1-代理工作流"><a href="#1-代理工作流" class="headerlink" title="1. 代理工作流"></a>1. 代理工作流</h2><p>GPT-4.1 是构建代理工作流的绝佳选择。在模型训练中，我们强调提供多样化的代理问题解决轨迹，我们的模型代理框架在 SWE-bench Verified 上实现了非推理模型的最先进性能，解决了 55% 的问题。</p><h3 id="系统提示提醒"><a href="#系统提示提醒" class="headerlink" title="系统提示提醒"></a>系统提示提醒</h3><p>为了充分利用 GPT-4.1 的代理能力，我们建议在所有代理提示中包含三种关键类型的提醒。以下提示专门针对代理编码工作流进行了优化，但可以轻松修改用于一般代理用例。</p><ol><li><strong>持久性</strong>：这确保模型理解它正在进入多消息轮次，并防止它过早地将控制权交还给用户。我们的示例如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你是一个代理 - 请继续直到用户的查询完全解决，然后结束你的轮次并交还给用户。只有在确定问题已解决时才终止你的轮次。</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>工具调用</strong>：这鼓励模型充分利用其工具，并减少其产生幻觉或猜测答案的可能性。我们的示例如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果你不确定与用户请求相关的文件内容或代码库结构，请使用你的工具读取文件并收集相关信息：不要猜测或编造答案。</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>规划</strong>（可选）：如果需要，这确保模型在文本中明确规划和反思每个工具调用，而不是仅通过链接一系列工具调用来完成任务。我们的示例如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">你必须在每个函数调用之前广泛规划，并广泛反思之前函数调用的结果。不要仅通过函数调用来完成整个过程，因为这可能会损害你解决问题和深入思考的能力。</span><br></pre></td></tr></table></figure><p>GPT-4.1 经过训练，在代理环境中对用户指令和系统提示都非常严格地响应。模型严格遵循这三个简单指令，我们的内部 SWE-bench Verified 分数提高了近 20%——因此我们强烈建议从涵盖上述三个类别的明确提醒开始任何代理提示。总的来说，我们发现这三个指令将模型从类似聊天机器人的状态转变为更加”渴望”的代理，自主且独立地推动交互向前发展。</p><h3 id="工具调用"><a href="#工具调用" class="headerlink" title="工具调用"></a>工具调用</h3><p>与之前的模型相比，GPT-4.1 在有效利用作为 OpenAI API 请求参数传递的工具方面接受了更多训练。我们鼓励开发者专门使用 tools 字段来传递工具，而不是手动将工具描述注入到提示中并为工具调用编写单独的解析器，正如一些人过去报告的那样。这是最小化错误并确保模型在工具调用轨迹期间保持分布的最佳方式——在我们自己的实验中，我们观察到使用 API 解析的工具描述与手动将模式注入系统提示相比，SWE-bench Verified 通过率提高了 2%。</p><p>开发者应该清楚地命名工具以表明其目的，并在工具的”description”字段中添加清晰、详细的描述。同样，对于每个工具参数，依靠良好的命名和描述来确保适当的使用。如果你的工具特别复杂，你想提供工具使用示例，我们建议你在系统提示中创建一个 <code># Examples</code> 部分并将示例放在那里，而不是将它们添加到”description”字段中，该字段应该保持全面但相对简洁。提供示例有助于指示何时使用工具、是否在工具调用中包含用户文本，以及哪些参数适合不同的输入。记住，你可以在 <a href="https://platform.openai.com/playground">Prompt Playground</a> 中使用”Generate Anything”来为新工具定义获得良好的起点。</p><h3 id="提示诱导规划和思维链"><a href="#提示诱导规划和思维链" class="headerlink" title="提示诱导规划和思维链"></a>提示诱导规划和思维链</h3><p>如前所述，开发者可以选择性地提示使用 GPT-4.1 构建的代理在工具调用之间进行规划和反思，而不是在无间断序列中静默调用工具。GPT-4.1 不是一个推理模型——意味着它在回答之前不会产生内部思维链——但在提示中，开发者可以通过使用上面显示的规划提示组件的任何变体来诱导模型产生明确的、逐步的计划。这可以被认为是模型”大声思考”。在我们对 SWE-bench Verified 代理任务的实验中，诱导明确规划使通过率提高了 4%。</p><h3 id="示例提示：SWE-bench-Verified"><a href="#示例提示：SWE-bench-Verified" class="headerlink" title="示例提示：SWE-bench Verified"></a>示例提示：SWE-bench Verified</h3><p>下面，我们分享用于在 SWE-bench Verified 上获得最高分数的代理提示，该提示包含关于工作流和问题解决策略的详细指令。这种通用模式可用于任何代理任务。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=os.environ.get(</span><br><span class="line">        <span class="string">&quot;OPENAI_API_KEY&quot;</span>, <span class="string">&quot;&lt;your OpenAI API key if not set as env var&gt;&quot;</span></span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">SYS_PROMPT_SWEBENCH = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你将被要求修复开源仓库中的问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你的思考应该彻底，所以如果很长也没关系。你可以在决定采取每个行动之前和之后逐步思考。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你必须迭代并继续直到问题解决。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你已经在 /testbed 文件夹中拥有解决这个问题所需的一切，即使没有互联网连接。我希望你在回到我之前完全自主地解决这个问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只有在确定问题已解决时才终止你的轮次。逐步解决问题，并确保验证你的更改是正确的。永远不要在没有解决问题的情况下结束你的轮次，当你说你要进行工具调用时，确保你实际上进行了工具调用，而不是结束你的轮次。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">问题绝对可以在没有互联网的情况下解决。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">花时间思考每一步 - 记住严格检查你的解决方案并注意边界情况，特别是你做的更改。你的解决方案必须是完美的。如果不是，继续努力。最后，你必须使用提供的工具严格测试你的代码，并多次测试，以捕获所有边界情况。如果它不够健壮，继续迭代并使其完美。未能充分严格地测试代码是这类任务的头号失败模式；确保你处理所有边界情况，如果提供了现有测试则运行它们。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你必须在每个函数调用之前广泛规划，并广泛反思之前函数调用的结果。不要仅通过函数调用来完成整个过程，因为这可能会损害你解决问题和深入思考的能力。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 工作流</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 高级问题解决策略</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. 深入理解问题。仔细阅读问题并批判性地思考需要什么。</span></span><br><span class="line"><span class="string">2. 调查代码库。探索相关文件，搜索关键函数，并收集上下文。</span></span><br><span class="line"><span class="string">3. 制定清晰、逐步的计划。将修复分解为可管理的、增量步骤。</span></span><br><span class="line"><span class="string">4. 增量实施修复。进行小的、可测试的代码更改。</span></span><br><span class="line"><span class="string">5. 根据需要调试。使用调试技术隔离和解决问题。</span></span><br><span class="line"><span class="string">6. 频繁测试。每次更改后运行测试以验证正确性。</span></span><br><span class="line"><span class="string">7. 迭代直到根本原因修复且所有测试通过。</span></span><br><span class="line"><span class="string">8. 全面反思和验证。测试通过后，思考原始意图，编写额外测试以确保正确性，并记住还有隐藏测试也必须通过，解决方案才真正完成。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">请参考下面的详细部分以获取每个步骤的更多信息。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 1. 深入理解问题</span></span><br><span class="line"><span class="string">仔细阅读问题并在编码前认真思考解决计划。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 2. 代码库调查</span></span><br><span class="line"><span class="string">- 探索相关文件和目录。</span></span><br><span class="line"><span class="string">- 搜索与问题相关的关键函数、类或变量。</span></span><br><span class="line"><span class="string">- 阅读和理解相关代码片段。</span></span><br><span class="line"><span class="string">- 识别问题的根本原因。</span></span><br><span class="line"><span class="string">- 在收集更多上下文时持续验证和更新你的理解。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 3. 制定详细计划</span></span><br><span class="line"><span class="string">- 概述修复问题的具体、简单和可验证的步骤序列。</span></span><br><span class="line"><span class="string">- 将修复分解为小的、增量更改。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 4. 进行代码更改</span></span><br><span class="line"><span class="string">- 在编辑之前，始终读取相关文件内容或部分以确保完整上下文。</span></span><br><span class="line"><span class="string">- 如果补丁未正确应用，尝试重新应用。</span></span><br><span class="line"><span class="string">- 进行小的、可测试的、增量更改，这些更改逻辑上来自你的调查和计划。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 5. 调试</span></span><br><span class="line"><span class="string">- 仅在你高度确信它们可以解决问题时进行代码更改</span></span><br><span class="line"><span class="string">- 调试时，尝试确定根本原因而不是解决症状</span></span><br><span class="line"><span class="string">- 调试所需时间以识别根本原因并确定修复</span></span><br><span class="line"><span class="string">- 使用打印语句、日志或临时代码检查程序状态，包括描述性语句或错误消息以了解发生了什么</span></span><br><span class="line"><span class="string">- 为了测试假设，你还可以添加测试语句或函数</span></span><br><span class="line"><span class="string">- 如果发生意外行为，重新审视你的假设。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 6. 测试</span></span><br><span class="line"><span class="string">- 使用 `!python3 run_tests.py`（或等效）频繁运行测试。</span></span><br><span class="line"><span class="string">- 每次更改后，通过运行相关测试验证正确性。</span></span><br><span class="line"><span class="string">- 如果测试失败，分析失败并修改你的补丁。</span></span><br><span class="line"><span class="string">- 如果需要，编写额外测试以捕获重要行为或边界情况。</span></span><br><span class="line"><span class="string">- 在最终确定之前确保所有测试通过。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 7. 最终验证</span></span><br><span class="line"><span class="string">- 确认根本原因已修复。</span></span><br><span class="line"><span class="string">- 审查你的解决方案的逻辑正确性和健壮性。</span></span><br><span class="line"><span class="string">- 迭代直到你极其确信修复完成且所有测试通过。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 8. 最终反思和额外测试</span></span><br><span class="line"><span class="string">- 仔细反思用户的原始意图和问题陈述。</span></span><br><span class="line"><span class="string">- 考虑可能未被现有测试覆盖的潜在边界情况或场景。</span></span><br><span class="line"><span class="string">- 编写需要通过的额外测试以完全验证你的解决方案的正确性。</span></span><br><span class="line"><span class="string">- 运行这些新测试并确保它们都通过。</span></span><br><span class="line"><span class="string">- 注意还有额外的隐藏测试也必须通过，解决方案才能成功。</span></span><br><span class="line"><span class="string">- 不要仅仅因为可见测试通过就假设任务完成；继续完善直到你确信修复是健壮和全面的。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">PYTHON_TOOL_DESCRIPTION = <span class="string">&quot;&quot;&quot;此函数用于在有状态的 Jupyter notebook 环境中执行 Python 代码或终端命令。python 将响应执行输出或在 60.0 秒后超时。此会话的互联网访问已禁用。不要进行外部网络请求或 API 调用，因为它们会失败。就像在 Jupyter notebook 中一样，你也可以通过调用此函数并带有以感叹号开头的终端命令来执行终端命令。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">此外，出于此任务的目的，你可以使用 `apply_patch` 命令作为输入调用此函数。`apply_patch` 有效地允许你对文件执行 diff/patch，但 diff 规范的格式对此任务是唯一的，所以请仔细注意这些指令。要使用 `apply_patch` 命令，你应该将以下结构的消息作为&quot;input&quot;传递：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%%bash</span></span><br><span class="line"><span class="string">apply_patch &lt;&lt;&quot;EOF&quot;</span></span><br><span class="line"><span class="string">*** Begin Patch</span></span><br><span class="line"><span class="string">[YOUR_PATCH]</span></span><br><span class="line"><span class="string">*** End Patch</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其中 [YOUR_PATCH] 是你的补丁的实际内容，以以下 V4A diff 格式指定。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">*** [ACTION] File: [path/to/file] -&gt; ACTION 可以是 Add、Update 或 Delete 之一。</span></span><br><span class="line"><span class="string">对于需要更改的每个代码片段，重复以下内容：</span></span><br><span class="line"><span class="string">[context_before] -&gt; 参见下面关于上下文的进一步说明。</span></span><br><span class="line"><span class="string">- [old_code] -&gt; 在旧代码前加减号。</span></span><br><span class="line"><span class="string">+ [new_code] -&gt; 在新替换代码前加加号。</span></span><br><span class="line"><span class="string">[context_after] -&gt; 参见下面关于上下文的进一步说明。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">关于 [context_before] 和 [context_after] 的说明：</span></span><br><span class="line"><span class="string">- 默认情况下，显示每个更改上方和下方的 3 行代码。如果一个更改在另一个更改的 3 行内，不要在第二个更改的 [context_before] 行中重复第一个更改的 [context_after] 行。</span></span><br><span class="line"><span class="string">- 如果 3 行上下文不足以唯一标识文件中的代码片段，使用 @@ 操作符指示代码片段所属的类或函数。例如，我们可能有：</span></span><br><span class="line"><span class="string">@@ class BaseClass</span></span><br><span class="line"><span class="string">[3 行预上下文]</span></span><br><span class="line"><span class="string">- [old_code]</span></span><br><span class="line"><span class="string">+ [new_code]</span></span><br><span class="line"><span class="string">[3 行后上下文]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- 如果一个代码块在类或函数中重复如此多次，以至于即使单个 @@ 语句和 3 行上下文也无法唯一标识代码片段，你可以使用多个 `@@` 语句跳转到正确的上下文。例如：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@@ class BaseClass</span></span><br><span class="line"><span class="string">@@ def method():</span></span><br><span class="line"><span class="string">[3 行预上下文]</span></span><br><span class="line"><span class="string">- [old_code]</span></span><br><span class="line"><span class="string">+ [new_code]</span></span><br><span class="line"><span class="string">[3 行后上下文]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">注意，我们不在此 diff 格式中使用行号，因为上下文足以唯一标识代码。你可能作为&quot;input&quot;传递给此函数以应用补丁的消息示例如下所示。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%%bash</span></span><br><span class="line"><span class="string">apply_patch &lt;&lt;&quot;EOF&quot;</span></span><br><span class="line"><span class="string">*** Begin Patch</span></span><br><span class="line"><span class="string">*** Update File: pygorithm/searching/binary_search.py</span></span><br><span class="line"><span class="string">@@ class BaseClass</span></span><br><span class="line"><span class="string">@@     def search():</span></span><br><span class="line"><span class="string">-        pass</span></span><br><span class="line"><span class="string">+        raise NotImplementedError()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@@ class Subclass</span></span><br><span class="line"><span class="string">@@     def search():</span></span><br><span class="line"><span class="string">-        pass</span></span><br><span class="line"><span class="string">+        raise NotImplementedError()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">*** End Patch</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">文件引用只能是相对的，永远不要是绝对的。运行 apply_patch 命令后，python 总是会说&quot;Done!&quot;，无论补丁是否成功应用。但是，你可以通过查看在&quot;Done!&quot;输出之前打印的任何警告或日志行来确定是否有问题和错误。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">python_bash_patch_tool = &#123;</span><br><span class="line">  <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;python&quot;</span>,</span><br><span class="line">  <span class="string">&quot;description&quot;</span>: PYTHON_TOOL_DESCRIPTION,</span><br><span class="line">  <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;strict&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">      <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">      <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">          <span class="string">&quot;input&quot;</span>: &#123;</span><br><span class="line">              <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">              <span class="string">&quot;description&quot;</span>: <span class="string">&quot; 你希望执行的 Python 代码、终端命令（以感叹号开头）或 apply_patch 命令。&quot;</span>,</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;input&quot;</span>],</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 额外的框架设置：</span></span><br><span class="line"><span class="comment"># - 将你的仓库添加到 /testbed</span></span><br><span class="line"><span class="comment"># - 将你的问题添加到第一个用户消息</span></span><br><span class="line"><span class="comment"># - 注意：尽管我们为 python、bash 和 apply_patch 使用了单个工具，但我们通常建议定义更细粒度的工具，专注于单个功能</span></span><br><span class="line"></span><br><span class="line">response = client.responses.create(</span><br><span class="line">    instructions=SYS_PROMPT_SWEBENCH,</span><br><span class="line">    model=<span class="string">&quot;gpt-4.1-2025-04-14&quot;</span>,</span><br><span class="line">    tools=[python_bash_patch_tool],</span><br><span class="line">    <span class="built_in">input</span>=<span class="string">f&quot;请回答以下问题：\nBug: Typerror...&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response.to_dict()[<span class="string">&quot;output&quot;</span>]</span><br></pre></td></tr></table></figure><h2 id="2-长上下文"><a href="#2-长上下文" class="headerlink" title="2. 长上下文"></a>2. 长上下文</h2><p>GPT-4.1 具有高性能的 100 万 token 输入上下文窗口，适用于各种长上下文任务，包括结构化文档解析、重新排序、在忽略无关上下文的同时选择相关信息，以及使用上下文执行多跳推理。</p><h3 id="最佳上下文大小"><a href="#最佳上下文大小" class="headerlink" title="最佳上下文大小"></a>最佳上下文大小</h3><p>我们观察到在针在干草堆评估中，直到我们完整的 100 万 token 上下文都有很好的性能，我们观察到在具有相关和无关代码以及其他文档混合的复杂任务中有很强的性能。然而，长上下文性能可能会随着需要检索更多项目或执行需要了解整个上下文状态的复杂推理（例如执行图搜索）而降低。</p><h3 id="调整上下文依赖"><a href="#调整上下文依赖" class="headerlink" title="调整上下文依赖"></a>调整上下文依赖</h3><p>考虑回答你的问题可能需要的内部与外部世界知识的混合。有时模型使用一些自己的知识来连接概念或进行逻辑跳跃很重要，而在其他情况下，只使用提供的上下文是可取的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 指令</span><br><span class="line">// 用于内部知识</span><br><span class="line">- 仅使用提供的外部上下文中的文档来回答用户查询。如果你基于此上下文不知道答案，你必须回应&quot;我没有回答该问题所需的信息&quot;，即使用户坚持要你回答问题。</span><br><span class="line">// 用于内部和外部知识</span><br><span class="line">- 默认情况下，使用提供的外部上下文来回答用户查询，但如果需要其他基本知识来回答，并且你对答案有信心，你可以使用一些自己的知识来帮助回答问题。</span><br></pre></td></tr></table></figure><h3 id="提示组织"><a href="#提示组织" class="headerlink" title="提示组织"></a>提示组织</h3><p>特别是在长上下文使用中，指令和上下文的放置会影响性能。如果你的提示中有长上下文，理想情况下将你的指令放在提供上下文的开始和结束，因为我们发现这比仅在上下或下方表现更好。如果你希望只将指令放在一次，那么在提供的上下文上方比下方效果更好。</p><h2 id="3-思维链"><a href="#3-思维链" class="headerlink" title="3. 思维链"></a>3. 思维链</h2><p>如上所述，GPT-4.1 不是一个推理模型，但提示模型逐步思考（称为”思维链”）可以是模型将问题分解为更易管理的部分、解决它们并提高整体输出质量的有效方式，但代价是使用更多输出 token 的更高成本和延迟。该模型经过训练，在代理推理和现实世界问题解决方面表现良好，因此它不应该需要太多提示就能表现良好。</p><p>我们建议从提示末尾的这个基本思维链指令开始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">首先，仔细逐步思考回答查询需要哪些文档。然后，打印出每个文档的标题和 ID。然后，将 ID 格式化为列表。</span><br></pre></td></tr></table></figure><p>从那里，你应该通过审计你特定示例和评估中的失败，并用更明确的指令解决系统性规划和推理错误来改进你的思维链（CoT）提示。在无约束的 CoT 提示中，它尝试的策略可能有差异，如果你观察到一种效果很好的方法，你可以在提示中编码该策略。一般来说，错误往往来自误解用户意图、上下文收集或分析不足，或逐步思考不足或不正确，所以注意这些并尝试用更有主见的指令解决它们。</p><p>这是一个示例提示，指示模型更系统地专注于分析用户意图并在继续回答之前考虑相关上下文。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 推理策略</span><br><span class="line">1. 查询分析：分解和分析查询，直到你对其可能询问的内容有信心。考虑提供的上下文以帮助澄清任何模糊或令人困惑的信息。</span><br><span class="line">2. 上下文分析：仔细选择和分析大量潜在相关文档。优化召回 - 如果有些无关紧要也没关系，但正确的文档必须在此列表中，否则你的最终答案将是错误的。每个的分析步骤：</span><br><span class="line">a. 分析：分析它可能与回答查询相关或不相关的分析。</span><br><span class="line">b. 相关性评级：[高、中、低、无]</span><br><span class="line">3. 综合：总结哪些文档最相关以及原因，包括相关性评级为中等或更高的所有文档。</span><br><span class="line"></span><br><span class="line"># 用户问题</span><br><span class="line">&#123;user_question&#125;</span><br><span class="line"></span><br><span class="line"># 外部上下文</span><br><span class="line">&#123;external_context&#125;</span><br><span class="line"></span><br><span class="line">首先，仔细逐步思考回答查询需要哪些文档，严格遵循提供的推理策略。然后，打印出每个文档的标题和 ID。然后，将 ID 格式化为列表。</span><br></pre></td></tr></table></figure><h2 id="4-指令遵循"><a href="#4-指令遵循" class="headerlink" title="4. 指令遵循"></a>4. 指令遵循</h2><p>GPT-4.1 表现出出色的指令遵循性能，开发者可以利用这一点来精确塑造和控制其特定用例的输出。开发者经常广泛提示代理推理步骤、响应语气和声音、工具调用信息、输出格式、要避免的主题等。然而，由于模型更字面地遵循指令，开发者可能需要包含关于做什么或不做什么的明确规范。此外，为其他模型优化的现有提示可能不会立即与此模型一起工作，因为现有指令被更严格地遵循。</p><p>这演示了虚构客户服务代理的最佳实践。观察规则的多样性、具体性、使用额外部分获得更多细节，以及一个示例来演示整合所有先前规则的精确行为。</p><p>尝试运行以下 notebook 单元格 - 你应该看到用户消息和工具调用，用户消息应该以问候开始，然后回显他们的答案，然后提到他们即将调用工具。尝试更改指令来塑造模型行为，或尝试其他用户消息，以测试指令遵循性能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">SYS_PROMPT_CUSTOMER_SERVICE = <span class="string">&quot;&quot;&quot;你是 NewTelco 的有用客户服务代理，帮助用户高效地满足他们的请求，同时严格遵守提供的指导方针。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 指令</span></span><br><span class="line"><span class="string">- 始终用&quot;你好，你已联系到 NewTelco，我能帮你什么？&quot;问候用户</span></span><br><span class="line"><span class="string">- 在回答关于公司、其产品或服务或用户账户的事实性问题之前，始终调用工具。仅使用检索的上下文，永远不要依赖你自己的知识来回答这些问题。</span></span><br><span class="line"><span class="string">    - 但是，如果你没有足够的信息来正确调用工具，请向用户询问你需要的信息。</span></span><br><span class="line"><span class="string">- 如果用户请求，升级到人工。</span></span><br><span class="line"><span class="string">- 不要讨论禁止的主题（政治、宗教、有争议的时事、医疗、法律或财务建议、个人对话、内部公司运营，或对任何人员或公司的批评）。</span></span><br><span class="line"><span class="string">- 在适当时依赖示例短语，但永远不要在同一对话中重复示例短语。随意变化示例短语以避免听起来重复，并使其更适合用户。</span></span><br><span class="line"><span class="string">- 始终遵循新消息的提供输出格式，包括对检索的政策文档中任何事实陈述的引用。</span></span><br><span class="line"><span class="string">- 如果你要调用工具，始终在调用工具之前和之后向用户发送适当的消息。</span></span><br><span class="line"><span class="string">- 在所有回复中保持专业和简洁的语气，并在句子之间使用表情符号。</span></span><br><span class="line"><span class="string">- 如果你已解决用户的请求，询问是否还有其他可以帮忙的</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 精确响应步骤（每次响应）</span></span><br><span class="line"><span class="string">1. 如有必要，调用工具来满足用户期望的行动。始终在调用工具之前和之后向用户发送消息，让他们了解情况。</span></span><br><span class="line"><span class="string">2. 在你的用户回复中</span></span><br><span class="line"><span class="string">    a. 使用积极倾听并回显你听到用户要求的内容。</span></span><br><span class="line"><span class="string">    b. 根据上述指导方针适当回应。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 示例短语</span></span><br><span class="line"><span class="string">## 转移禁止主题</span></span><br><span class="line"><span class="string">- &quot;对不起，但我无法讨论该主题。还有其他我可以帮助你的吗？&quot;</span></span><br><span class="line"><span class="string">- &quot;这不是我能够提供信息的内容，但我很乐意帮助你解决其他问题。&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 调用工具前</span></span><br><span class="line"><span class="string">- &quot;为了帮助你，我只需要验证你的信息。&quot;</span></span><br><span class="line"><span class="string">- &quot;让我为你检查一下——请稍等。&quot;</span></span><br><span class="line"><span class="string">- &quot;我现在为你检索最新详情。&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 调用工具后</span></span><br><span class="line"><span class="string">- &quot;好的，这是我找到的：[回复]&quot;</span></span><br><span class="line"><span class="string">- &quot;所以我找到的是：[回复]&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 输出格式</span></span><br><span class="line"><span class="string">- 始终包含你对用户的最终回复。</span></span><br><span class="line"><span class="string">- 在提供来自检索上下文的事实信息时，始终在相关陈述后立即包含引用。使用以下引用格式：</span></span><br><span class="line"><span class="string">    - 对于单个来源：[NAME](ID)</span></span><br><span class="line"><span class="string">    - 对于多个来源：[NAME](ID), [NAME](ID)</span></span><br><span class="line"><span class="string">- 仅提供关于此公司、其政策、其产品或客户账户的信息，并且仅基于上下文中提供的信息。不要回答此范围之外的问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 示例</span></span><br><span class="line"><span class="string">## 用户</span></span><br><span class="line"><span class="string">你能告诉我你们的家庭计划选项吗？</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 助手回复 1</span></span><br><span class="line"><span class="string">### 消息</span></span><br><span class="line"><span class="string">&quot;你好，你已联系到 NewTelco，我能帮你什么？ 😊🎉</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">你想了解我们的家庭计划选项。 🤝 让我为你检查一下——请稍等。 🚀&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 工具调用</span></span><br><span class="line"><span class="string">lookup_policy_document(topic=&quot;family plan options&quot;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 工具调用后，助手会跟进：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## 助手回复 2（工具调用后）</span></span><br><span class="line"><span class="string">### 消息</span></span><br><span class="line"><span class="string">&quot;好的，这是我找到的： 🎉 我们的家庭计划允许最多 5 条线路共享数据，每条额外线路享受 10% 折扣 [家庭计划政策](ID-010)。 📱 今天还有其他我可以帮助你的吗？ 😊&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">get_policy_doc = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;lookup_policy_document&quot;</span>,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;按主题或关键词查找内部文档和政策的工具。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;strict&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">        <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;topic&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: <span class="string">&quot;在公司政策或文档中搜索的主题或关键词。&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;topic&quot;</span>],</span><br><span class="line">        <span class="string">&quot;additionalProperties&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">get_user_acct = &#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_user_account_info&quot;</span>,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;获取用户账户信息的工具&quot;</span>,</span><br><span class="line">    <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;strict&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">        <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;phone_number&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: <span class="string">&quot;格式为 &#x27;(xxx) xxx-xxxx&#x27;&quot;</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;phone_number&quot;</span>],</span><br><span class="line">        <span class="string">&quot;additionalProperties&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = client.responses.create(</span><br><span class="line">    instructions=SYS_PROMPT_CUSTOMER_SERVICE,</span><br><span class="line">    model=<span class="string">&quot;gpt-4.1-2025-04-14&quot;</span>,</span><br><span class="line">    tools=[get_policy_doc, get_user_acct],</span><br><span class="line">    <span class="built_in">input</span>=<span class="string">&quot;国际服务要多少钱？我要去法国。&quot;</span>,</span><br><span class="line">    <span class="comment"># input=&quot;为什么我上个月的账单这么高？&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response.to_dict()[<span class="string">&quot;output&quot;</span>]</span><br></pre></td></tr></table></figure><h2 id="5-一般建议"><a href="#5-一般建议" class="headerlink" title="5. 一般建议"></a>5. 一般建议</h2><h3 id="提示结构"><a href="#提示结构" class="headerlink" title="提示结构"></a>提示结构</h3><p>作为参考，这是构建提示的良好起点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 角色和目标</span><br><span class="line"></span><br><span class="line"># 指令</span><br><span class="line"></span><br><span class="line">## 更详细指令的子类别</span><br><span class="line"></span><br><span class="line"># 推理步骤</span><br><span class="line"></span><br><span class="line"># 输出格式</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">## 示例 1</span><br><span class="line"></span><br><span class="line"># 上下文</span><br><span class="line"></span><br><span class="line"># 最终指令和逐步思考的提示</span><br></pre></td></tr></table></figure><p>添加或删除部分以满足你的需求，并进行实验以确定对你的使用最优的内容。</p><h3 id="分隔符"><a href="#分隔符" class="headerlink" title="分隔符"></a>分隔符</h3><p>以下是为提示选择最佳分隔符的一些一般指导原则。请参考长上下文部分以获取该上下文类型的特殊考虑。</p><ol><li><p><strong>Markdown</strong>：我们建议从这里开始，使用 markdown 标题作为主要部分和子部分（包括更深的层次结构，到 H4+）。使用内联反引号或反引号块来精确包装代码，并根据需要使用标准编号或项目符号列表。</p></li><li><p><strong>XML</strong>：这些也表现良好，我们改进了此模型对 XML 中信息的遵循。XML 便于精确包装包括开始和结束的部分，为标签添加元数据以获得额外上下文，并启用嵌套。以下是使用 XML 标签在示例部分中嵌套示例的示例，每个都有输入和输出：</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;examples&gt;</span><br><span class="line">&lt;example1 type=&quot;Abbreviate&quot;&gt;</span><br><span class="line">&lt;input&gt;San Francisco&lt;/input&gt;</span><br><span class="line">&lt;output&gt;- SF&lt;/output&gt;</span><br><span class="line">&lt;/example1&gt;</span><br><span class="line">&lt;/examples&gt;</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>JSON</strong> 高度结构化，模型在编码上下文中特别理解良好。但它可能更冗长，并且需要字符转义，这会增加开销。</li></ol><p>专门用于向输入上下文添加大量文档或文件的指导：</p><ul><li>XML 在我们的长上下文测试中表现良好。<ul><li>示例：<code>&lt;doc id=&#39;1&#39; title=&#39;The Fox&#39;&gt;The quick brown fox jumps over the lazy dog&lt;/doc&gt;</code></li></ul></li><li>这种格式由 Lee 等人提出（<a href="https://arxiv.org/pdf/2406.13121">ref</a>），在我们的长上下文测试中也表现良好。<ul><li>示例：<code>ID: 1 | TITLE: The Fox | CONTENT: The quick brown fox jumps over the lazy dog</code></li></ul></li><li>JSON 表现特别差。<ul><li>示例：<code>[&#123;&#39;id&#39;: 1, &#39;title&#39;: &#39;The Fox&#39;, &#39;content&#39;: &#39;The quick brown fox jumped over the lazy dog&#39;&#125;]</code></li></ul></li></ul><p>模型经过训练，能够稳健地理解各种格式的结构。一般来说，使用你的判断并思考什么将提供清晰的信息并”突出”给模型。例如，如果你检索的文档包含大量 XML，基于 XML 的分隔符可能效果较差。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>在一些孤立的情况下，我们观察到模型抵制产生很长、重复的输出，例如，逐个分析数百个项目。如果这对你的用例是必要的，强烈指示模型完整输出此信息，并考虑分解问题或使用更简洁的方法。</li><li>我们看到一些罕见的并行工具调用不正确的情况。我们建议测试这个，并考虑将 <a href="https://platform.openai.com/docs/api-reference/responses/create#responses-create-parallel_tool_calls">parallel_tool_calls</a> 参数设置为 false，如果你看到问题。</li></ul><h2 id="附录：生成和应用文件差异"><a href="#附录：生成和应用文件差异" class="headerlink" title="附录：生成和应用文件差异"></a>附录：生成和应用文件差异</h2><p>开发者向我们提供反馈，准确和格式良好的差异生成是为编码相关任务提供动力的关键能力。为此，GPT-4.1 系列相对于之前的 GPT 模型具有显著改进的差异功能。此外，虽然 GPT-4.1 在给定清晰指令和示例的情况下在生成任何格式的差异方面都有很强的性能，但我们在这里开源一个推荐的差异格式，模型在这方面接受了大量训练。我们特别希望对于刚开始的开发者，这将消除你自己创建差异的大部分猜测工作。</p><h3 id="应用补丁"><a href="#应用补丁" class="headerlink" title="应用补丁"></a>应用补丁</h3><p>请参阅下面的示例，了解正确应用我们推荐的工具调用的提示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">APPLY_PATCH_TOOL_DESC = <span class="string">&quot;&quot;&quot;这是一个自定义实用程序，使添加、删除、移动或编辑代码文件更加方便。`apply_patch` 有效地允许你对文件执行 diff/patch，但 diff 规范的格式对此任务是唯一的，所以请仔细注意这些指令。要使用 `apply_patch` 命令，你应该将以下结构的消息作为&quot;input&quot;传递：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%%bash</span></span><br><span class="line"><span class="string">apply_patch &lt;&lt;&quot;EOF&quot;</span></span><br><span class="line"><span class="string">*** Begin Patch</span></span><br><span class="line"><span class="string">[YOUR_PATCH]</span></span><br><span class="line"><span class="string">*** End Patch</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其中 [YOUR_PATCH] 是你的补丁的实际内容，以以下 V4A diff 格式指定。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">*** [ACTION] File: [path/to/file] -&gt; ACTION 可以是 Add、Update 或 Delete 之一。</span></span><br><span class="line"><span class="string">对于需要更改的每个代码片段，重复以下内容：</span></span><br><span class="line"><span class="string">[context_before] -&gt; 参见下面关于上下文的进一步说明。</span></span><br><span class="line"><span class="string">- [old_code] -&gt; 在旧代码前加减号。</span></span><br><span class="line"><span class="string">+ [new_code] -&gt; 在新替换代码前加加号。</span></span><br><span class="line"><span class="string">[context_after] -&gt; 参见下面关于上下文的进一步说明。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">关于 [context_before] 和 [context_after] 的说明：</span></span><br><span class="line"><span class="string">- 默认情况下，显示每个更改上方和下方的 3 行代码。如果一个更改在另一个更改的 3 行内，不要在第二个更改的 [context_before] 行中重复第一个更改的 [context_after] 行。</span></span><br><span class="line"><span class="string">- 如果 3 行上下文不足以唯一标识文件中的代码片段，使用 @@ 操作符指示代码片段所属的类或函数。例如，我们可能有：</span></span><br><span class="line"><span class="string">@@ class BaseClass</span></span><br><span class="line"><span class="string">[3 行预上下文]</span></span><br><span class="line"><span class="string">- [old_code]</span></span><br><span class="line"><span class="string">+ [new_code]</span></span><br><span class="line"><span class="string">[3 行后上下文]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- 如果一个代码块在类或函数中重复如此多次，以至于即使单个 @@ 语句和 3 行上下文也无法唯一标识代码片段，你可以使用多个 `@@` 语句跳转到正确的上下文。例如：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@@ class BaseClass</span></span><br><span class="line"><span class="string">@@ def method():</span></span><br><span class="line"><span class="string">[3 行预上下文]</span></span><br><span class="line"><span class="string">- [old_code]</span></span><br><span class="line"><span class="string">+ [new_code]</span></span><br><span class="line"><span class="string">[3 行后上下文]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">注意，我们不在此 diff 格式中使用行号，因为上下文足以唯一标识代码。你可能作为&quot;input&quot;传递给此函数以应用补丁的消息示例如下所示。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%%bash</span></span><br><span class="line"><span class="string">apply_patch &lt;&lt;&quot;EOF&quot;</span></span><br><span class="line"><span class="string">*** Begin Patch</span></span><br><span class="line"><span class="string">*** Update File: pygorithm/searching/binary_search.py</span></span><br><span class="line"><span class="string">@@ class BaseClass</span></span><br><span class="line"><span class="string">@@     def search():</span></span><br><span class="line"><span class="string">-        pass</span></span><br><span class="line"><span class="string">+        raise NotImplementedError()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@@ class Subclass</span></span><br><span class="line"><span class="string">@@     def search():</span></span><br><span class="line"><span class="string">-        pass</span></span><br><span class="line"><span class="string">+        raise NotImplementedError()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">*** End Patch</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">文件引用只能是相对的，永远不要是绝对的。运行 apply_patch 命令后，python 总是会说&quot;Done!&quot;，无论补丁是否成功应用。但是，你可以通过查看在&quot;Done!&quot;输出之前打印的任何警告或日志行来确定是否有问题和错误。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">APPLY_PATCH_TOOL = &#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;apply_patch&quot;</span>,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: APPLY_PATCH_TOOL_DESC,</span><br><span class="line">    <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">        <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: <span class="string">&quot; 你希望执行的 apply_patch 命令。&quot;</span>,</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考实现：apply-patch-py"><a href="#参考实现：apply-patch-py" class="headerlink" title="参考实现：apply_patch.py"></a>参考实现：apply_patch.py</h3><p>这是我们作为模型训练一部分使用的 apply_patch 工具的参考实现。你需要使其可执行并作为 <code>apply_patch</code> 从模型将执行命令的 shell 中可用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">A self-contained **pure-Python 3.9+** utility for applying human-readable</span></span><br><span class="line"><span class="string">“pseudo-diff” patch files to a collection of text files.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> annotations</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass, field</span><br><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> (</span><br><span class="line">    <span class="type">Callable</span>,</span><br><span class="line">    <span class="type">Dict</span>,</span><br><span class="line">    <span class="type">List</span>,</span><br><span class="line">    <span class="type">Optional</span>,</span><br><span class="line">    <span class="type">Tuple</span>,</span><br><span class="line">    <span class="type">Union</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Domain objects</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ActionType</span>(<span class="built_in">str</span>, Enum):</span><br><span class="line">    ADD = <span class="string">&quot;add&quot;</span></span><br><span class="line">    DELETE = <span class="string">&quot;delete&quot;</span></span><br><span class="line">    UPDATE = <span class="string">&quot;update&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FileChange</span>:</span><br><span class="line">    <span class="built_in">type</span>: ActionType</span><br><span class="line">    old_content: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line">    new_content: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line">    move_path: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Commit</span>:</span><br><span class="line">    changes: <span class="type">Dict</span>[<span class="built_in">str</span>, FileChange] = field(default_factory=<span class="built_in">dict</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Exceptions</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiffError</span>(<span class="title class_ inherited__">ValueError</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Any problem detected while parsing or applying a patch.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Helper dataclasses used while parsing patches</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Chunk</span>:</span><br><span class="line">    orig_index: <span class="built_in">int</span> = -<span class="number">1</span></span><br><span class="line">    del_lines: <span class="type">List</span>[<span class="built_in">str</span>] = field(default_factory=<span class="built_in">list</span>)</span><br><span class="line">    ins_lines: <span class="type">List</span>[<span class="built_in">str</span>] = field(default_factory=<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PatchAction</span>:</span><br><span class="line">    <span class="built_in">type</span>: ActionType</span><br><span class="line">    new_file: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line">    chunks: <span class="type">List</span>[Chunk] = field(default_factory=<span class="built_in">list</span>)</span><br><span class="line">    move_path: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Patch</span>:</span><br><span class="line">    actions: <span class="type">Dict</span>[<span class="built_in">str</span>, PatchAction] = field(default_factory=<span class="built_in">dict</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Patch text parser</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Parser</span>:</span><br><span class="line">    current_files: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span><br><span class="line">    lines: <span class="type">List</span>[<span class="built_in">str</span>]</span><br><span class="line">    index: <span class="built_in">int</span> = <span class="number">0</span></span><br><span class="line">    patch: Patch = field(default_factory=Patch)</span><br><span class="line">    fuzz: <span class="built_in">int</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------------- low-level helpers -------------------------------------- #</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_cur_line</span>(<span class="params">self</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">if</span> self.index &gt;= <span class="built_in">len</span>(self.lines):</span><br><span class="line">            <span class="keyword">raise</span> DiffError(<span class="string">&quot;Unexpected end of input while parsing patch&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> self.lines[self.index]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_norm</span>(<span class="params">line: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Strip CR so comparisons work for both LF and CRLF input.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> line.rstrip(<span class="string">&quot;\r&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------------- scanning convenience ----------------------------------- #</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_done</span>(<span class="params">self, prefixes: <span class="type">Optional</span>[<span class="type">Tuple</span>[<span class="built_in">str</span>, ...]] = <span class="literal">None</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> self.index &gt;= <span class="built_in">len</span>(self.lines):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> (</span><br><span class="line">            prefixes</span><br><span class="line">            <span class="keyword">and</span> <span class="built_in">len</span>(prefixes) &gt; <span class="number">0</span></span><br><span class="line">            <span class="keyword">and</span> self._norm(self._cur_line()).startswith(prefixes)</span><br><span class="line">        ):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">startswith</span>(<span class="params">self, prefix: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="type">Tuple</span>[<span class="built_in">str</span>, ...]]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">return</span> self._norm(self._cur_line()).startswith(prefix)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_str</span>(<span class="params">self, prefix: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Consume the current line if it starts with *prefix* and return the text</span></span><br><span class="line"><span class="string">        **after** the prefix.  Raises if prefix is empty.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> prefix == <span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;read_str() requires a non-empty prefix&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> self._norm(self._cur_line()).startswith(prefix):</span><br><span class="line">            text = self._cur_line()[<span class="built_in">len</span>(prefix) :]</span><br><span class="line">            self.index += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> text</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_line</span>(<span class="params">self</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Return the current raw line and advance.&quot;&quot;&quot;</span></span><br><span class="line">        line = self._cur_line()</span><br><span class="line">        self.index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> line</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------------- public entry point -------------------------------------- #</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.is_done((<span class="string">&quot;*** End Patch&quot;</span>,)):</span><br><span class="line">            <span class="comment"># ---------- UPDATE ---------- #</span></span><br><span class="line">            path = self.read_str(<span class="string">&quot;*** Update File: &quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> path:</span><br><span class="line">                <span class="keyword">if</span> path <span class="keyword">in</span> self.patch.actions:</span><br><span class="line">                    <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Duplicate update for file: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">                move_to = self.read_str(<span class="string">&quot;*** Move to: &quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> path <span class="keyword">not</span> <span class="keyword">in</span> self.current_files:</span><br><span class="line">                    <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Update File Error - missing file: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">                text = self.current_files[path]</span><br><span class="line">                action = self._parse_update_file(text)</span><br><span class="line">                action.move_path = move_to <span class="keyword">or</span> <span class="literal">None</span></span><br><span class="line">                self.patch.actions[path] = action</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ---------- DELETE ---------- #</span></span><br><span class="line">            path = self.read_str(<span class="string">&quot;*** Delete File: &quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> path:</span><br><span class="line">                <span class="keyword">if</span> path <span class="keyword">in</span> self.patch.actions:</span><br><span class="line">                    <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Duplicate delete for file: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> path <span class="keyword">not</span> <span class="keyword">in</span> self.current_files:</span><br><span class="line">                    <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Delete File Error - missing file: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">                self.patch.actions[path] = PatchAction(<span class="built_in">type</span>=ActionType.DELETE)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ---------- ADD ---------- #</span></span><br><span class="line">            path = self.read_str(<span class="string">&quot;*** Add File: &quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> path:</span><br><span class="line">                <span class="keyword">if</span> path <span class="keyword">in</span> self.patch.actions:</span><br><span class="line">                    <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Duplicate add for file: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> path <span class="keyword">in</span> self.current_files:</span><br><span class="line">                    <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Add File Error - file already exists: <span class="subst">&#123;path&#125;</span>&quot;</span>)</span><br><span class="line">                self.patch.actions[path] = self._parse_add_file()</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Unknown line while parsing: <span class="subst">&#123;self._cur_line()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.startswith(<span class="string">&quot;*** End Patch&quot;</span>):</span><br><span class="line">            <span class="keyword">raise</span> DiffError(<span class="string">&quot;Missing *** End Patch sentinel&quot;</span>)</span><br><span class="line">        self.index += <span class="number">1</span>  <span class="comment"># consume sentinel</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ------------- section parsers ---------------------------------------- #</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_parse_update_file</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; PatchAction:</span><br><span class="line">        action = PatchAction(<span class="built_in">type</span>=ActionType.UPDATE)</span><br><span class="line">        lines = text.split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.is_done(</span><br><span class="line">            (</span><br><span class="line">                <span class="string">&quot;*** End Patch&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** Update File:&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** Delete File:&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** Add File:&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** End of File&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ):</span><br><span class="line">            def_str = self.read_str(<span class="string">&quot;@@ &quot;</span>)</span><br><span class="line">            section_str = <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> def_str <span class="keyword">and</span> self._norm(self._cur_line()) == <span class="string">&quot;@@&quot;</span>:</span><br><span class="line">                section_str = self.read_line()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (def_str <span class="keyword">or</span> section_str <span class="keyword">or</span> index == <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Invalid line in update section:\n<span class="subst">&#123;self._cur_line()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> def_str.strip():</span><br><span class="line">                found = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">if</span> def_str <span class="keyword">not</span> <span class="keyword">in</span> lines[:index]:</span><br><span class="line">                    <span class="keyword">for</span> i, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines[index:], index):</span><br><span class="line">                        <span class="keyword">if</span> s == def_str:</span><br><span class="line">                            index = i + <span class="number">1</span></span><br><span class="line">                            found = <span class="literal">True</span></span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> found <span class="keyword">and</span> def_str.strip() <span class="keyword">not</span> <span class="keyword">in</span> [</span><br><span class="line">                    s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> lines[:index]</span><br><span class="line">                ]:</span><br><span class="line">                    <span class="keyword">for</span> i, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines[index:], index):</span><br><span class="line">                        <span class="keyword">if</span> s.strip() == def_str.strip():</span><br><span class="line">                            index = i + <span class="number">1</span></span><br><span class="line">                            self.fuzz += <span class="number">1</span></span><br><span class="line">                            found = <span class="literal">True</span></span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            next_ctx, chunks, end_idx, eof = peek_next_section(self.lines, self.index)</span><br><span class="line">            new_index, fuzz = find_context(lines, next_ctx, index, eof)</span><br><span class="line">            <span class="keyword">if</span> new_index == -<span class="number">1</span>:</span><br><span class="line">                ctx_txt = <span class="string">&quot;\n&quot;</span>.join(next_ctx)</span><br><span class="line">                <span class="keyword">raise</span> DiffError(</span><br><span class="line">                    <span class="string">f&quot;Invalid <span class="subst">&#123;<span class="string">&#x27;EOF &#x27;</span> <span class="keyword">if</span> eof <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span>&#125;</span>context at <span class="subst">&#123;index&#125;</span>:\n<span class="subst">&#123;ctx_txt&#125;</span>&quot;</span></span><br><span class="line">                )</span><br><span class="line">            self.fuzz += fuzz</span><br><span class="line">            <span class="keyword">for</span> ch <span class="keyword">in</span> chunks:</span><br><span class="line">                ch.orig_index += new_index</span><br><span class="line">                action.chunks.append(ch)</span><br><span class="line">            index = new_index + <span class="built_in">len</span>(next_ctx)</span><br><span class="line">            self.index = end_idx</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_parse_add_file</span>(<span class="params">self</span>) -&gt; PatchAction:</span><br><span class="line">        lines: <span class="type">List</span>[<span class="built_in">str</span>] = []</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.is_done(</span><br><span class="line">            (<span class="string">&quot;*** End Patch&quot;</span>, <span class="string">&quot;*** Update File:&quot;</span>, <span class="string">&quot;*** Delete File:&quot;</span>, <span class="string">&quot;*** Add File:&quot;</span>)</span><br><span class="line">        ):</span><br><span class="line">            s = self.read_line()</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> s.startswith(<span class="string">&quot;+&quot;</span>):</span><br><span class="line">                <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Invalid Add File line (missing &#x27;+&#x27;): <span class="subst">&#123;s&#125;</span>&quot;</span>)</span><br><span class="line">            lines.append(s[<span class="number">1</span>:])  <span class="comment"># strip leading &#x27;+&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> PatchAction(<span class="built_in">type</span>=ActionType.ADD, new_file=<span class="string">&quot;\n&quot;</span>.join(lines))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Helper functions</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_context_core</span>(<span class="params"></span></span><br><span class="line"><span class="params">    lines: <span class="type">List</span>[<span class="built_in">str</span>], context: <span class="type">List</span>[<span class="built_in">str</span>], start: <span class="built_in">int</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> context:</span><br><span class="line">        <span class="keyword">return</span> start, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, <span class="built_in">len</span>(lines)):</span><br><span class="line">        <span class="keyword">if</span> lines[i : i + <span class="built_in">len</span>(context)] == context:</span><br><span class="line">            <span class="keyword">return</span> i, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, <span class="built_in">len</span>(lines)):</span><br><span class="line">        <span class="keyword">if</span> [s.rstrip() <span class="keyword">for</span> s <span class="keyword">in</span> lines[i : i + <span class="built_in">len</span>(context)]] == [</span><br><span class="line">            s.rstrip() <span class="keyword">for</span> s <span class="keyword">in</span> context</span><br><span class="line">        ]:</span><br><span class="line">            <span class="keyword">return</span> i, <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, <span class="built_in">len</span>(lines)):</span><br><span class="line">        <span class="keyword">if</span> [s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> lines[i : i + <span class="built_in">len</span>(context)]] == [</span><br><span class="line">            s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> context</span><br><span class="line">        ]:</span><br><span class="line">            <span class="keyword">return</span> i, <span class="number">100</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_context</span>(<span class="params"></span></span><br><span class="line"><span class="params">    lines: <span class="type">List</span>[<span class="built_in">str</span>], context: <span class="type">List</span>[<span class="built_in">str</span>], start: <span class="built_in">int</span>, eof: <span class="built_in">bool</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]:</span><br><span class="line">    <span class="keyword">if</span> eof:</span><br><span class="line">        new_index, fuzz = find_context_core(lines, context, <span class="built_in">len</span>(lines) - <span class="built_in">len</span>(context))</span><br><span class="line">        <span class="keyword">if</span> new_index != -<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> new_index, fuzz</span><br><span class="line">        new_index, fuzz = find_context_core(lines, context, start)</span><br><span class="line">        <span class="keyword">return</span> new_index, fuzz + <span class="number">10_000</span></span><br><span class="line">    <span class="keyword">return</span> find_context_core(lines, context, start)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">peek_next_section</span>(<span class="params"></span></span><br><span class="line"><span class="params">    lines: <span class="type">List</span>[<span class="built_in">str</span>], index: <span class="built_in">int</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>[<span class="built_in">str</span>], <span class="type">List</span>[Chunk], <span class="built_in">int</span>, <span class="built_in">bool</span>]:</span><br><span class="line">    old: <span class="type">List</span>[<span class="built_in">str</span>] = []</span><br><span class="line">    del_lines: <span class="type">List</span>[<span class="built_in">str</span>] = []</span><br><span class="line">    ins_lines: <span class="type">List</span>[<span class="built_in">str</span>] = []</span><br><span class="line">    chunks: <span class="type">List</span>[Chunk] = []</span><br><span class="line">    mode = <span class="string">&quot;keep&quot;</span></span><br><span class="line">    orig_index = index</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> index &lt; <span class="built_in">len</span>(lines):</span><br><span class="line">        s = lines[index]</span><br><span class="line">        <span class="keyword">if</span> s.startswith(</span><br><span class="line">            (</span><br><span class="line">                <span class="string">&quot;@@&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** End Patch&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** Update File:&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** Delete File:&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** Add File:&quot;</span>,</span><br><span class="line">                <span class="string">&quot;*** End of File&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">        ):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> s == <span class="string">&quot;***&quot;</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> s.startswith(<span class="string">&quot;***&quot;</span>):</span><br><span class="line">            <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Invalid Line: <span class="subst">&#123;s&#125;</span>&quot;</span>)</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        last_mode = mode</span><br><span class="line">        <span class="keyword">if</span> s == <span class="string">&quot;&quot;</span>:</span><br><span class="line">            s = <span class="string">&quot; &quot;</span></span><br><span class="line">        <span class="keyword">if</span> s[<span class="number">0</span>] == <span class="string">&quot;+&quot;</span>:</span><br><span class="line">            mode = <span class="string">&quot;add&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> s[<span class="number">0</span>] == <span class="string">&quot;-&quot;</span>:</span><br><span class="line">            mode = <span class="string">&quot;delete&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> s[<span class="number">0</span>] == <span class="string">&quot; &quot;</span>:</span><br><span class="line">            mode = <span class="string">&quot;keep&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> DiffError(<span class="string">f&quot;Invalid Line: <span class="subst">&#123;s&#125;</span>&quot;</span>)</span><br><span class="line">        s = s[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&quot;keep&quot;</span> <span class="keyword">and</span> last_mode != mode:</span><br><span class="line">            <span class="keyword">if</span> ins_lines <span class="keyword">or</span> del_lines:</span><br><span class="line">                chunks.append(</span><br><span class="line">                    Chunk(</span><br><span class="line">                        orig_index=<span class="built_in">len</span>(old) - <span class="built_in">len</span>(del_lines),</span><br><span class="line">                        del_lines=del_lines,</span><br><span class="line">                        ins_lines=ins_lines,</span><br><span class="line">                    )</span><br><span class="line">                )</span><br><span class="line">            del_lines, ins_lines = [], []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&quot;delete&quot;</span>:</span><br><span class="line">            del_lines.append(s)</span><br><span class="line">            old.append(s)</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&quot;add&quot;</span>:</span><br><span class="line">            ins_lines.append(s)</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&quot;keep&quot;</span>:</span><br><span class="line">            old.append(s)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ins_lines <span class="keyword">or</span> del_lines:</span><br><span class="line">        chunks.append(</span><br><span class="line">            Chunk(</span><br><span class="line">                orig_index=<span class="built_in">len</span>(old) - <span class="built_in">len</span>(del_lines),</span><br><span class="line">                del_lines=del_lines,</span><br><span class="line">                ins_lines=ins_lines,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> index &lt; <span class="built_in">len</span>(lines) <span class="keyword">and</span> lines[index] == <span class="string">&quot;*** End of File&quot;</span>:</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> old, chunks, index, <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> index == orig_index:</span><br><span class="line">        <span class="keyword">raise</span> DiffError(<span class="string">&quot;Nothing in this section&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> old, chunks, index, <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Patch → Commit and Commit application</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_get_updated_file</span>(<span class="params">text: <span class="built_in">str</span>, action: PatchAction, path: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">if</span> action.<span class="built_in">type</span> <span class="keyword">is</span> <span class="keyword">not</span> ActionType.UPDATE:</span><br><span class="line">        <span class="keyword">raise</span> DiffError(<span class="string">&quot;_get_updated_file called with non-update action&quot;</span>)</span><br><span class="line">    orig_lines = text.split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    dest_lines: <span class="type">List</span>[<span class="built_in">str</span>] = []</span><br><span class="line">    orig_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> action.chunks:</span><br><span class="line">        <span class="keyword">if</span> chunk.orig_index &gt; <span class="built_in">len</span>(orig_lines):</span><br><span class="line">            <span class="keyword">raise</span> DiffError(</span><br><span class="line">                <span class="string">f&quot;<span class="subst">&#123;path&#125;</span>: chunk.orig_index <span class="subst">&#123;chunk.orig_index&#125;</span> exceeds file length&quot;</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">if</span> orig_index &gt; chunk.orig_index:</span><br><span class="line">            <span class="keyword">raise</span> DiffError(</span><br><span class="line">                <span class="string">f&quot;<span class="subst">&#123;path&#125;</span>: overlapping chunks at <span class="subst">&#123;orig_index&#125;</span> &gt; <span class="subst">&#123;chunk.orig_index&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        dest_lines.extend(orig_lines[orig_index : chunk.orig_index])</span><br><span class="line">        orig_index = chunk.orig_index</span><br><span class="line"></span><br><span class="line">        dest_lines.extend(chunk.ins_lines)</span><br><span class="line">        orig_index += <span class="built_in">len</span>(chunk.del_lines)</span><br><span class="line"></span><br><span class="line">    dest_lines.extend(orig_lines[orig_index:])</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n&quot;</span>.join(dest_lines)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">patch_to_commit</span>(<span class="params">patch: Patch, orig: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; Commit:</span><br><span class="line">    commit = Commit()</span><br><span class="line">    <span class="keyword">for</span> path, action <span class="keyword">in</span> patch.actions.items():</span><br><span class="line">        <span class="keyword">if</span> action.<span class="built_in">type</span> <span class="keyword">is</span> ActionType.DELETE:</span><br><span class="line">            commit.changes[path] = FileChange(</span><br><span class="line">                <span class="built_in">type</span>=ActionType.DELETE, old_content=orig[path]</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> action.<span class="built_in">type</span> <span class="keyword">is</span> ActionType.ADD:</span><br><span class="line">            <span class="keyword">if</span> action.new_file <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> DiffError(<span class="string">&quot;ADD action without file content&quot;</span>)</span><br><span class="line">            commit.changes[path] = FileChange(</span><br><span class="line">                <span class="built_in">type</span>=ActionType.ADD, new_content=action.new_file</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> action.<span class="built_in">type</span> <span class="keyword">is</span> ActionType.UPDATE:</span><br><span class="line">            new_content = _get_updated_file(orig[path], action, path)</span><br><span class="line">            commit.changes[path] = FileChange(</span><br><span class="line">                <span class="built_in">type</span>=ActionType.UPDATE,</span><br><span class="line">                old_content=orig[path],</span><br><span class="line">                new_content=new_content,</span><br><span class="line">                move_path=action.move_path,</span><br><span class="line">            )</span><br><span class="line">    <span class="keyword">return</span> commit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  User-facing helpers</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">text_to_patch</span>(<span class="params">text: <span class="built_in">str</span>, orig: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="type">Tuple</span>[Patch, <span class="built_in">int</span>]:</span><br><span class="line">    lines = text.splitlines()  <span class="comment"># preserves blank lines, no strip()</span></span><br><span class="line">    <span class="keyword">if</span> (</span><br><span class="line">        <span class="built_in">len</span>(lines) &lt; <span class="number">2</span></span><br><span class="line">        <span class="keyword">or</span> <span class="keyword">not</span> Parser._norm(lines[<span class="number">0</span>]).startswith(<span class="string">&quot;*** Begin Patch&quot;</span>)</span><br><span class="line">        <span class="keyword">or</span> Parser._norm(lines[-<span class="number">1</span>]) != <span class="string">&quot;*** End Patch&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">raise</span> DiffError(<span class="string">&quot;Invalid patch text - missing sentinels&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parser = Parser(current_files=orig, lines=lines, index=<span class="number">1</span>)</span><br><span class="line">    parser.parse()</span><br><span class="line">    <span class="keyword">return</span> parser.patch, parser.fuzz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">identify_files_needed</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">    lines = text.splitlines()</span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        line[<span class="built_in">len</span>(<span class="string">&quot;*** Update File: &quot;</span>) :]</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">&quot;*** Update File: &quot;</span>)</span><br><span class="line">    ] + [</span><br><span class="line">        line[<span class="built_in">len</span>(<span class="string">&quot;*** Delete File: &quot;</span>) :]</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">&quot;*** Delete File: &quot;</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">identify_files_added</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">    lines = text.splitlines()</span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        line[<span class="built_in">len</span>(<span class="string">&quot;*** Add File: &quot;</span>) :]</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> lines</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">&quot;*** Add File: &quot;</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  File-system helpers</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_files</span>(<span class="params">paths: <span class="type">List</span>[<span class="built_in">str</span>], open_fn: <span class="type">Callable</span>[[<span class="built_in">str</span>], <span class="built_in">str</span>]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]:</span><br><span class="line">    <span class="keyword">return</span> &#123;path: open_fn(path) <span class="keyword">for</span> path <span class="keyword">in</span> paths&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_commit</span>(<span class="params"></span></span><br><span class="line"><span class="params">    commit: Commit,</span></span><br><span class="line"><span class="params">    write_fn: <span class="type">Callable</span>[[<span class="built_in">str</span>, <span class="built_in">str</span>], <span class="literal">None</span>],</span></span><br><span class="line"><span class="params">    remove_fn: <span class="type">Callable</span>[[<span class="built_in">str</span>], <span class="literal">None</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">for</span> path, change <span class="keyword">in</span> commit.changes.items():</span><br><span class="line">        <span class="keyword">if</span> change.<span class="built_in">type</span> <span class="keyword">is</span> ActionType.DELETE:</span><br><span class="line">            remove_fn(path)</span><br><span class="line">        <span class="keyword">elif</span> change.<span class="built_in">type</span> <span class="keyword">is</span> ActionType.ADD:</span><br><span class="line">            <span class="keyword">if</span> change.new_content <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> DiffError(<span class="string">f&quot;ADD change for <span class="subst">&#123;path&#125;</span> has no content&quot;</span>)</span><br><span class="line">            write_fn(path, change.new_content)</span><br><span class="line">        <span class="keyword">elif</span> change.<span class="built_in">type</span> <span class="keyword">is</span> ActionType.UPDATE:</span><br><span class="line">            <span class="keyword">if</span> change.new_content <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> DiffError(<span class="string">f&quot;UPDATE change for <span class="subst">&#123;path&#125;</span> has no new content&quot;</span>)</span><br><span class="line">            target = change.move_path <span class="keyword">or</span> path</span><br><span class="line">            write_fn(target, change.new_content)</span><br><span class="line">            <span class="keyword">if</span> change.move_path:</span><br><span class="line">                remove_fn(path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_patch</span>(<span class="params"></span></span><br><span class="line"><span class="params">    text: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">    open_fn: <span class="type">Callable</span>[[<span class="built_in">str</span>], <span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">    write_fn: <span class="type">Callable</span>[[<span class="built_in">str</span>, <span class="built_in">str</span>], <span class="literal">None</span>],</span></span><br><span class="line"><span class="params">    remove_fn: <span class="type">Callable</span>[[<span class="built_in">str</span>], <span class="literal">None</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> text.startswith(<span class="string">&quot;*** Begin Patch&quot;</span>):</span><br><span class="line">        <span class="keyword">raise</span> DiffError(<span class="string">&quot;Patch text must start with *** Begin Patch&quot;</span>)</span><br><span class="line">    paths = identify_files_needed(text)</span><br><span class="line">    orig = load_files(paths, open_fn)</span><br><span class="line">    patch, _fuzz = text_to_patch(text, orig)</span><br><span class="line">    commit = patch_to_commit(patch, orig)</span><br><span class="line">    apply_commit(commit, write_fn, remove_fn)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Done!&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  Default FS helpers</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">open_file</span>(<span class="params">path: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;rt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> fh:</span><br><span class="line">        <span class="keyword">return</span> fh.read()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_file</span>(<span class="params">path: <span class="built_in">str</span>, content: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    target = pathlib.Path(path)</span><br><span class="line">    target.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">with</span> target.<span class="built_in">open</span>(<span class="string">&quot;wt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> fh:</span><br><span class="line">        fh.write(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">remove_file</span>(<span class="params">path: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    pathlib.Path(path).unlink(missing_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="comment">#  CLI entry-point</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------------------------- #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">    patch_text = sys.stdin.read()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> patch_text:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Please pass patch text through stdin&quot;</span>, file=sys.stderr)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = process_patch(patch_text, open_file, write_file, remove_file)</span><br><span class="line">    <span class="keyword">except</span> DiffError <span class="keyword">as</span> exc:</span><br><span class="line">        <span class="built_in">print</span>(exc, file=sys.stderr)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h3 id="其他有效的-Diff-格式"><a href="#其他有效的-Diff-格式" class="headerlink" title="其他有效的 Diff 格式"></a>其他有效的 Diff 格式</h3><p>如果你想尝试使用不同的 diff 格式，我们在测试中发现，Aider 的 polyglot 基准测试中使用的 SEARCH&#x2F;REPLACE（查找&#x2F;替换）diff 格式，以及一种没有内部转义的伪 XML 格式，都有很高的成功率。</p><p>这些 diff 格式有两个关键共同点：（1）它们不使用行号；（2）它们都明确提供了需要被替换的精确代码和用于替换的新代码，并且两者之间有清晰的分隔符。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">SEARCH_REPLACE_DIFF_EXAMPLE = &quot;&quot;&quot;</span><br><span class="line">path/to/file.py</span><br><span class="line">```</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; SEARCH</span><br><span class="line">def search():</span><br><span class="line">    pass</span><br><span class="line">=======</span><br><span class="line">def search():</span><br><span class="line">   raise NotImplementedError()</span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; REPLACE</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">PSEUDO_XML_DIFF_EXAMPLE = &quot;&quot;&quot;</span><br><span class="line">&lt;edit&gt;</span><br><span class="line">&lt;file&gt;</span><br><span class="line">path/to/file.py</span><br><span class="line">&lt;/file&gt;</span><br><span class="line">&lt;old_code&gt;</span><br><span class="line">def search():</span><br><span class="line">    pass</span><br><span class="line">&lt;/old_code&gt;</span><br><span class="line">&lt;new_code&gt;</span><br><span class="line">def search():</span><br><span class="line">   raise NotImplementedError()</span><br><span class="line">&lt;/new_code&gt;</span><br><span class="line">&lt;/edit&gt;</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure><blockquote><p>本文由AI生成，内容仅供参考。在实际部署前，请根据具体环境进行测试和验证。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Argo Rollouts使用指南：Kubernetes高级部署策略详解</title>
      <link href="/openshift/Argo-Rollouts%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%EF%BC%9AKubernetes%E9%AB%98%E7%BA%A7%E9%83%A8%E7%BD%B2%E7%AD%96%E7%95%A5%E8%AF%A6%E8%A7%A3/"/>
      <url>/openshift/Argo-Rollouts%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%EF%BC%9AKubernetes%E9%AB%98%E7%BA%A7%E9%83%A8%E7%BD%B2%E7%AD%96%E7%95%A5%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在现代云原生应用部署中，传统的Kubernetes Deployment虽然简单易用，但在生产环境中往往需要更精细的部署控制和更安全的发布策略。Argo Rollouts作为Kubernetes的高级部署控制器，提供了蓝绿部署、金丝雀部署、渐进式发布等多种高级部署策略，让应用发布变得更加安全、可控和自动化。</p><p>本文将为初次接触Argo Rollouts的读者提供全面的使用指南，包括核心概念、功能特性、实际案例和最佳实践，帮助您快速掌握这一强大的部署工具。</p><h2 id="Argo-Rollouts简介"><a href="#Argo-Rollouts简介" class="headerlink" title="Argo Rollouts简介"></a>Argo Rollouts简介</h2><h3 id="什么是Argo-Rollouts"><a href="#什么是Argo-Rollouts" class="headerlink" title="什么是Argo Rollouts"></a>什么是Argo Rollouts</h3><p>Argo Rollouts是Argo项目的一部分，它是一个Kubernetes控制器，用于提供更高级的部署策略。与标准的Kubernetes Deployment不同，Argo Rollouts支持：</p><ul><li><strong>蓝绿部署（Blue-Green Deployment）</strong>：零停机时间部署</li><li><strong>金丝雀部署（Canary Deployment）</strong>：渐进式流量切换</li><li><strong>渐进式发布（Progressive Delivery）</strong>：基于指标的自动发布</li><li><strong>回滚策略</strong>：快速回滚到之前的版本</li><li><strong>暂停和恢复</strong>：手动控制发布过程</li></ul><h3 id="核心优势"><a href="#核心优势" class="headerlink" title="核心优势"></a>核心优势</h3><ol><li><strong>零停机部署</strong>：通过蓝绿部署策略实现真正的零停机时间</li><li><strong>风险控制</strong>：金丝雀部署可以逐步验证新版本</li><li><strong>自动化</strong>：基于Prometheus指标的自动发布决策</li><li><strong>可视化</strong>：提供Web UI和CLI工具进行部署管理</li><li><strong>与现有生态集成</strong>：与Istio、Linkerd、NGINX Ingress等无缝集成</li></ol><h2 id="安装和配置"><a href="#安装和配置" class="headerlink" title="安装和配置"></a>安装和配置</h2><h3 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h3><ul><li>Kubernetes集群（1.16+）</li><li>kubectl已配置</li><li>可选：Prometheus（用于指标分析）</li></ul><h3 id="安装Argo-Rollouts"><a href="#安装Argo-Rollouts" class="headerlink" title="安装Argo Rollouts"></a>安装Argo Rollouts</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装Argo Rollouts控制器</span></span><br><span class="line">kubectl create namespace argo-rollouts</span><br><span class="line">kubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证安装</span></span><br><span class="line">kubectl get pods -n argo-rollouts</span><br></pre></td></tr></table></figure><h3 id="安装Argo-Rollouts-CLI工具"><a href="#安装Argo-Rollouts-CLI工具" class="headerlink" title="安装Argo Rollouts CLI工具"></a>安装Argo Rollouts CLI工具</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载kubectl-argo-rollouts插件</span></span><br><span class="line">curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64</span><br><span class="line"><span class="built_in">chmod</span> +x kubectl-argo-rollouts-linux-amd64</span><br><span class="line">sudo <span class="built_in">mv</span> kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证安装</span></span><br><span class="line">kubectl argo rollouts version</span><br></pre></td></tr></table></figure><h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Rollout资源"><a href="#Rollout资源" class="headerlink" title="Rollout资源"></a>Rollout资源</h3><p>Argo Rollout使用自定义资源<code>Rollout</code>来替代标准的<code>Deployment</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Rollout</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-rollout</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">blueGreen:</span></span><br><span class="line">      <span class="attr">activeService:</span> <span class="string">active-service</span></span><br><span class="line">      <span class="attr">previewService:</span> <span class="string">preview-service</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.19</span></span><br></pre></td></tr></table></figure><h3 id="部署策略类型"><a href="#部署策略类型" class="headerlink" title="部署策略类型"></a>部署策略类型</h3><ol><li><strong>BlueGreen策略</strong>：创建两个完全相同的环境，快速切换</li><li><strong>Canary策略</strong>：逐步将流量从旧版本转移到新版本</li><li><strong>Mixed策略</strong>：结合蓝绿和金丝雀的混合策略</li></ol><h2 id="蓝绿部署实战"><a href="#蓝绿部署实战" class="headerlink" title="蓝绿部署实战"></a>蓝绿部署实战</h2><h3 id="场景介绍"><a href="#场景介绍" class="headerlink" title="场景介绍"></a>场景介绍</h3><p>蓝绿部署是最安全的部署策略之一，特别适合对可用性要求极高的生产环境。它通过创建两个完全相同的环境（蓝色和绿色），在新版本部署完成后快速切换流量。</p><h3 id="完整示例"><a href="#完整示例" class="headerlink" title="完整示例"></a>完整示例</h3><h4 id="1-创建Service资源"><a href="#1-创建Service资源" class="headerlink" title="1. 创建Service资源"></a>1. 创建Service资源</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># active-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">active-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">preview-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">example-app</span></span><br></pre></td></tr></table></figure><h4 id="2-创建Rollout资源"><a href="#2-创建Rollout资源" class="headerlink" title="2. 创建Rollout资源"></a>2. 创建Rollout资源</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rollout-bluegreen.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Rollout</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-rollout</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">blueGreen:</span></span><br><span class="line">      <span class="attr">activeService:</span> <span class="string">active-service</span></span><br><span class="line">      <span class="attr">previewService:</span> <span class="string">preview-service</span></span><br><span class="line">      <span class="attr">autoPromotionEnabled:</span> <span class="literal">false</span>  <span class="comment"># 禁用自动提升</span></span><br><span class="line">      <span class="attr">scaleDownDelaySeconds:</span> <span class="number">30</span>    <span class="comment"># 延迟删除旧版本</span></span><br><span class="line">      <span class="attr">prePromotionAnalysis:</span></span><br><span class="line">        <span class="attr">templates:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">success-rate</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service-name</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">preview-service.default.svc.cluster.local:80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.19</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">        <span class="attr">readinessProbe:</span></span><br><span class="line">          <span class="attr">httpGet:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">          <span class="attr">initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line">          <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br></pre></td></tr></table></figure><h4 id="3-部署应用"><a href="#3-部署应用" class="headerlink" title="3. 部署应用"></a>3. 部署应用</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 应用配置</span></span><br><span class="line">kubectl apply -f active-service.yaml</span><br><span class="line">kubectl apply -f rollout-bluegreen.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看部署状态</span></span><br><span class="line">kubectl argo rollouts get rollout example-rollout</span><br></pre></td></tr></table></figure><h4 id="4-更新镜像版本"><a href="#4-更新镜像版本" class="headerlink" title="4. 更新镜像版本"></a>4. 更新镜像版本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新到新版本</span></span><br><span class="line">kubectl argo rollouts <span class="built_in">set</span> image example-rollout example-app=nginx:1.20</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看部署进度</span></span><br><span class="line">kubectl argo rollouts get rollout example-rollout</span><br></pre></td></tr></table></figure><h4 id="5-手动提升到生产环境"><a href="#5-手动提升到生产环境" class="headerlink" title="5. 手动提升到生产环境"></a>5. 手动提升到生产环境</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 手动提升（将流量切换到新版本）</span></span><br><span class="line">kubectl argo rollouts promote example-rollout</span><br></pre></td></tr></table></figure><h3 id="蓝绿部署的优势"><a href="#蓝绿部署的优势" class="headerlink" title="蓝绿部署的优势"></a>蓝绿部署的优势</h3><ul><li><strong>零停机时间</strong>：新版本完全部署后才切换流量</li><li><strong>快速回滚</strong>：只需切换Service选择器即可回滚</li><li><strong>完全隔离</strong>：新旧版本完全隔离，互不影响</li><li><strong>易于验证</strong>：可以在切换前对新版本进行充分测试</li></ul><h2 id="金丝雀部署实战"><a href="#金丝雀部署实战" class="headerlink" title="金丝雀部署实战"></a>金丝雀部署实战</h2><h3 id="场景介绍-1"><a href="#场景介绍-1" class="headerlink" title="场景介绍"></a>场景介绍</h3><p>金丝雀部署适合需要逐步验证新版本的场景，通过逐步增加新版本的流量比例，可以及时发现和解决问题。</p><h3 id="完整示例-1"><a href="#完整示例-1" class="headerlink" title="完整示例"></a>完整示例</h3><h4 id="1-创建Ingress资源（使用NGINX-Ingress）"><a href="#1-创建Ingress资源（使用NGINX-Ingress）" class="headerlink" title="1. 创建Ingress资源（使用NGINX Ingress）"></a>1. 创建Ingress资源（使用NGINX Ingress）</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ingress.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-ingress</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/canary-weight:</span> <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">example.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">example-service</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><h4 id="2-创建Rollout资源-1"><a href="#2-创建Rollout资源-1" class="headerlink" title="2. 创建Rollout资源"></a>2. 创建Rollout资源</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rollout-canary.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Rollout</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-rollout</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">canary:</span></span><br><span class="line">      <span class="attr">canaryService:</span> <span class="string">canary-service</span>  <span class="comment"># required</span></span><br><span class="line">      <span class="attr">stableService:</span> <span class="string">stable-service</span>  <span class="comment"># required</span></span><br><span class="line">      <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">20</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">40</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">60</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">80</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">100</span></span><br><span class="line">      <span class="attr">trafficRouting:</span></span><br><span class="line">        <span class="attr">nginx:</span></span><br><span class="line">          <span class="attr">stableIngress:</span> <span class="string">example-ingress</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.19</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure><h4 id="3-部署和更新"><a href="#3-部署和更新" class="headerlink" title="3. 部署和更新"></a>3. 部署和更新</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 应用配置</span></span><br><span class="line">kubectl apply -f ingress.yaml</span><br><span class="line">kubectl apply -f rollout-canary.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新镜像</span></span><br><span class="line">kubectl argo rollouts <span class="built_in">set</span> image example-rollout example-app=nginx:1.20</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看部署状态</span></span><br><span class="line">kubectl argo rollouts get rollout example-rollout</span><br></pre></td></tr></table></figure><h4 id="4-手动控制部署过程"><a href="#4-手动控制部署过程" class="headerlink" title="4. 手动控制部署过程"></a>4. 手动控制部署过程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暂停部署</span></span><br><span class="line">kubectl argo rollouts pause example-rollout</span><br><span class="line"></span><br><span class="line"><span class="comment"># 继续部署</span></span><br><span class="line">kubectl argo rollouts resume example-rollout</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回滚到上一个版本</span></span><br><span class="line">kubectl argo rollouts undo example-rollout</span><br></pre></td></tr></table></figure><h2 id="基于指标的渐进式发布"><a href="#基于指标的渐进式发布" class="headerlink" title="基于指标的渐进式发布"></a>基于指标的渐进式发布</h2><h3 id="场景介绍-2"><a href="#场景介绍-2" class="headerlink" title="场景介绍"></a>场景介绍</h3><p>基于指标的渐进式发布是Argo Rollout的高级功能，它可以根据Prometheus指标自动决定是否继续发布或回滚。</p><h3 id="配置示例"><a href="#配置示例" class="headerlink" title="配置示例"></a>配置示例</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rollout-with-analysis.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Rollout</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-rollout</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">canary:</span></span><br><span class="line">      <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">20</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">analysis:</span></span><br><span class="line">          <span class="attr">templates:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">success-rate</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service-name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">example-service.default.svc.cluster.local:80</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">40</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">analysis:</span></span><br><span class="line">          <span class="attr">templates:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">success-rate</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service-name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">example-service.default.svc.cluster.local:80</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">100</span></span><br><span class="line">      <span class="attr">trafficRouting:</span></span><br><span class="line">        <span class="attr">nginx:</span></span><br><span class="line">          <span class="attr">stableIngress:</span> <span class="string">example-ingress</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.19</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">AnalysisTemplate</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">success-rate</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">args:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service-name</span></span><br><span class="line">  <span class="attr">metrics:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">success-rate</span></span><br><span class="line">    <span class="attr">interval:</span> <span class="string">60s</span></span><br><span class="line">    <span class="attr">count:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">successCondition:</span> <span class="string">result[0]</span> <span class="string">&gt;=</span> <span class="number">0.95</span></span><br><span class="line">    <span class="attr">provider:</span></span><br><span class="line">      <span class="attr">prometheus:</span></span><br><span class="line">        <span class="attr">address:</span> <span class="string">http://prometheus.monitoring.svc.cluster.local:9090</span></span><br><span class="line">        <span class="attr">query:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          sum(rate(http_requests_total&#123;service=&quot;&#123;&#123;args.service-name&#125;&#125;&quot;,status!~&quot;5..&quot;&#125;[5m])) /</span></span><br><span class="line"><span class="string">          sum(rate(http_requests_total&#123;service=&quot;&#123;&#123;args.service-name&#125;&#125;&quot;&#125;[5m]))</span></span><br></pre></td></tr></table></figure><h2 id="高级功能"><a href="#高级功能" class="headerlink" title="高级功能"></a>高级功能</h2><h3 id="1-自动回滚"><a href="#1-自动回滚" class="headerlink" title="1. 自动回滚"></a>1. 自动回滚</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置自动回滚</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">canary:</span></span><br><span class="line">      <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">analysis:</span></span><br><span class="line">          <span class="attr">templates:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">success-rate</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service-name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">example-service.default.svc.cluster.local:80</span></span><br><span class="line">          <span class="attr">rollbackOnFailure:</span> <span class="literal">true</span>  <span class="comment"># 分析失败时自动回滚</span></span><br></pre></td></tr></table></figure><h3 id="2-资源限制和HPA集成"><a href="#2-资源限制和HPA集成" class="headerlink" title="2. 资源限制和HPA集成"></a>2. 资源限制和HPA集成</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 与HPA集成的Rollout</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Rollout</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hpa-rollout</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">canary:</span></span><br><span class="line">      <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">20</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pause:</span> &#123;<span class="attr">duration:</span> <span class="string">60s</span>&#125;</span><br><span class="line">      <span class="bullet">-</span> <span class="attr">setWeight:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">example-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">example-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.19</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;64Mi&quot;</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;250m&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;128Mi&quot;</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-hpa</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scaleTargetRef:</span></span><br><span class="line">    <span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Rollout</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">hpa-rollout</span></span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">metrics:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">Resource</span></span><br><span class="line">    <span class="attr">resource:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">cpu</span></span><br><span class="line">      <span class="attr">target:</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">Utilization</span></span><br><span class="line">        <span class="attr">averageUtilization:</span> <span class="number">70</span></span><br></pre></td></tr></table></figure><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="1-部署策略选择"><a href="#1-部署策略选择" class="headerlink" title="1. 部署策略选择"></a>1. 部署策略选择</h3><ul><li><strong>蓝绿部署</strong>：适合对可用性要求极高的生产环境</li><li><strong>金丝雀部署</strong>：适合需要逐步验证的场景</li><li><strong>基于指标的发布</strong>：适合有完善监控体系的环境</li></ul><h3 id="2-监控和告警"><a href="#2-监控和告警" class="headerlink" title="2. 监控和告警"></a>2. 监控和告警</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置监控指标</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">canary:</span></span><br><span class="line">      <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">analysis:</span></span><br><span class="line">          <span class="attr">templates:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">error-rate</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">response-time</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service-name</span></span><br><span class="line">            <span class="attr">value:</span> <span class="string">example-service.default.svc.cluster.local:80</span></span><br></pre></td></tr></table></figure><h3 id="3-回滚策略"><a href="#3-回滚策略" class="headerlink" title="3. 回滚策略"></a>3. 回滚策略</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置回滚策略</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">canary:</span></span><br><span class="line">      <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">analysis:</span></span><br><span class="line">          <span class="attr">templates:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">templateName:</span> <span class="string">success-rate</span></span><br><span class="line">          <span class="attr">rollbackOnFailure:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">rollbackOnError:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="4-资源管理"><a href="#4-资源管理" class="headerlink" title="4. 资源管理"></a>4. 资源管理</h3><ul><li>合理设置副本数，避免资源浪费</li><li>使用资源限制确保应用稳定性</li><li>配置HPA实现自动扩缩容</li></ul><h3 id="5-安全考虑"><a href="#5-安全考虑" class="headerlink" title="5. 安全考虑"></a>5. 安全考虑</h3><ul><li>使用RBAC控制访问权限</li><li>配置网络策略限制Pod间通信</li><li>定期更新镜像版本修复安全漏洞</li></ul><h2 id="故障排除"><a href="#故障排除" class="headerlink" title="故障排除"></a>故障排除</h2><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ol><li><p><strong>部署卡住</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查Pod状态</span></span><br><span class="line">kubectl get pods -l app=example-app</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Rollout状态</span></span><br><span class="line">kubectl argo rollouts get rollout example-rollout</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看事件</span></span><br><span class="line">kubectl describe rollout example-rollout</span><br></pre></td></tr></table></figure></li><li><p><strong>流量路由问题</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查Service配置</span></span><br><span class="line">kubectl get svc -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Ingress配置</span></span><br><span class="line">kubectl describe ingress example-ingress</span><br></pre></td></tr></table></figure></li><li><p><strong>指标分析失败</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查Prometheus连接</span></span><br><span class="line">kubectl get pods -n monitoring</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看分析模板</span></span><br><span class="line">kubectl get analysistemplate</span><br></pre></td></tr></table></figure></li></ol><h3 id="调试技巧"><a href="#调试技巧" class="headerlink" title="调试技巧"></a>调试技巧</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用详细日志</span></span><br><span class="line">kubectl logs -n argo-rollouts deployment/argo-rollouts-controller -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看Rollout详细状态</span></span><br><span class="line">kubectl argo rollouts get rollout example-rollout --watch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出Rollout配置</span></span><br><span class="line">kubectl argo rollouts get rollout example-rollout -o yaml</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Argo Rollouts为Kubernetes提供了强大的高级部署策略，通过蓝绿部署、金丝雀部署和基于指标的渐进式发布，可以显著提高应用部署的安全性和可靠性。</p><h3 id="关键要点"><a href="#关键要点" class="headerlink" title="关键要点"></a>关键要点</h3><ol><li><strong>选择合适的部署策略</strong>：根据业务需求选择蓝绿、金丝雀或混合策略</li><li><strong>配置完善的监控</strong>：使用Prometheus指标进行自动化决策</li><li><strong>实施最佳实践</strong>：合理配置资源、设置回滚策略、管理权限</li><li><strong>持续优化</strong>：根据实际运行情况调整部署参数</li></ol><h3 id="相关资源"><a href="#相关资源" class="headerlink" title="相关资源"></a>相关资源</h3><ul><li><a href="https://argoproj.github.io/argo-rollouts/">Argo Rollouts官方文档</a></li><li><a href="https://github.com/argoproj/argo-rollouts">Argo Rollouts GitHub仓库</a></li><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Kubernetes部署策略最佳实践</a></li><li><a href="https://prometheus.io/docs/introduction/overview/">Prometheus监控指南</a></li></ul><p>通过本文的学习，您应该能够熟练使用Argo Rollouts进行高级部署管理，为您的Kubernetes应用提供更安全、更可靠的发布策略。</p><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> openshift </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> Argo Rollouts </tag>
            
            <tag> DevOps </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRE MCP Tools：运维工程师的AI助手工具箱</title>
      <link href="/AI/SRE%20MCP%20Tools%EF%BC%9A%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84AI%E5%8A%A9%E6%89%8B%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
      <url>/AI/SRE%20MCP%20Tools%EF%BC%9A%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84AI%E5%8A%A9%E6%89%8B%E5%B7%A5%E5%85%B7%E7%AE%B1/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在现代互联网时代，站点可靠性工程（SRE）已成为确保服务稳定运行的核心实践。随着系统复杂性的不断增加，运维工程师需要管理的工具和平台也越来越多。从监控告警到事件响应，从部署管理到成本优化，每个环节都需要专业的工具支持。</p><p>但是，在面对海量的监控数据、复杂的告警规则、频繁的部署需求时，传统的手工操作已经无法满足现代运维的需求。这时，MCP（Model Context Protocol）工具的出现，为SRE工程师提供了全新的解决方案。</p><p>今天，我将为大家介绍一套完整的SRE MCP Tools工具箱，涵盖监控可观测性、部署编排、事件响应、数据库管理等多个方面，帮助运维工程师构建智能化的运维体系。</p><h2 id="什么是SRE-MCP-Tools？"><a href="#什么是SRE-MCP-Tools？" class="headerlink" title="什么是SRE MCP Tools？"></a>什么是SRE MCP Tools？</h2><p>SRE MCP Tools是一套基于模型上下文协议（MCP）的运维工具集合，它允许AI助手直接与各种运维工具和平台进行集成，实现自动化的运维操作。通过这些工具，运维工程师可以使用自然语言与AI助手交互，让AI帮助完成复杂的运维任务。</p><h3 id="核心优势"><a href="#核心优势" class="headerlink" title="核心优势"></a>核心优势</h3><ul><li><strong>🚨 快速发现问题</strong>：自动化监控和告警，第一时间发现系统异常</li><li><strong>🔧 快速解决问题</strong>：自动化故障响应和修复，减少人工干预</li><li><strong>📈 预防问题</strong>：趋势分析和容量规划，防患于未然</li><li><strong>💼 提高效率</strong>：减少手动操作，标准化运维流程</li><li><strong>💰 降低成本</strong>：优化资源使用，避免过度配置</li></ul><h2 id="🔍-监控与可观测性-MCP"><a href="#🔍-监控与可观测性-MCP" class="headerlink" title="🔍 监控与可观测性 MCP"></a>🔍 监控与可观测性 MCP</h2><h3 id="Prometheus-x2F-Grafana-MCP"><a href="#Prometheus-x2F-Grafana-MCP" class="headerlink" title="Prometheus&#x2F;Grafana MCP"></a>Prometheus&#x2F;Grafana MCP</h3><p>作为现代监控体系的核心，Prometheus&#x2F;Grafana MCP提供了强大的监控数据访问和可视化能力。</p><p><strong>主要功能：</strong></p><ul><li><strong>自动化指标查询</strong>：通过自然语言查询Prometheus指标</li><li><strong>告警规则管理</strong>：智能创建和管理告警规则</li><li><strong>仪表板创建</strong>：自动生成Grafana仪表板</li></ul><p><strong>使用场景：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例：查询CPU使用率</span></span><br><span class="line">query_cpu_usage = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">请帮我查询过去1小时内CPU使用率超过80%的服务器，</span></span><br><span class="line"><span class="string">并创建一个告警规则当CPU使用率连续5分钟超过90%时发送告警。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Datadog-x2F-New-Relic-MCP"><a href="#Datadog-x2F-New-Relic-MCP" class="headerlink" title="Datadog&#x2F;New Relic MCP"></a>Datadog&#x2F;New Relic MCP</h3><p>商业化监控平台的强大功能，提供统一的监控数据访问接口。</p><p><strong>主要功能：</strong></p><ul><li><strong>统一监控数据访问</strong>：跨平台监控数据查询</li><li><strong>异常检测</strong>：基于机器学习的异常检测</li><li><strong>性能分析</strong>：应用性能监控和分析</li></ul><h3 id="Jaeger-x2F-Zipkin-MCP"><a href="#Jaeger-x2F-Zipkin-MCP" class="headerlink" title="Jaeger&#x2F;Zipkin MCP"></a>Jaeger&#x2F;Zipkin MCP</h3><p>分布式系统的链路追踪分析工具，帮助快速定位性能瓶颈。</p><p><strong>主要功能：</strong></p><ul><li><strong>分布式链路追踪分析</strong>：可视化请求在系统中的传播路径</li><li><strong>性能瓶颈定位</strong>：识别慢查询和性能热点</li><li><strong>依赖关系映射</strong>：生成服务依赖图</li></ul><h3 id="ELK-Stack-MCP"><a href="#ELK-Stack-MCP" class="headerlink" title="ELK Stack MCP"></a>ELK Stack MCP</h3><p>强大的日志分析平台，提供智能化的日志处理能力。</p><p><strong>主要功能：</strong></p><ul><li><strong>日志聚合查询</strong>：跨多个数据源的日志查询</li><li><strong>错误模式识别</strong>：自动识别错误模式和异常</li><li><strong>日志分析自动化</strong>：智能化的日志分析和报告</li></ul><h2 id="🚀-部署与编排-MCP"><a href="#🚀-部署与编排-MCP" class="headerlink" title="🚀 部署与编排 MCP"></a>🚀 部署与编排 MCP</h2><h3 id="ArgoCD-MCP"><a href="#ArgoCD-MCP" class="headerlink" title="ArgoCD MCP"></a>ArgoCD MCP</h3><p>GitOps部署管理的最佳实践，实现声明式的应用部署。</p><p><strong>主要功能：</strong></p><ul><li><strong>GitOps部署管理</strong>：基于Git的自动化部署</li><li><strong>应用状态监控</strong>：实时监控应用部署状态</li><li><strong>回滚操作</strong>：快速回滚到上一个稳定版本</li></ul><h3 id="Kubernetes-MCP"><a href="#Kubernetes-MCP" class="headerlink" title="Kubernetes MCP"></a>Kubernetes MCP</h3><p>容器编排平台的核心管理工具，提供集群资源的全面管理。</p><p><strong>主要功能：</strong></p><ul><li><strong>集群资源管理</strong>：Pod、Service、ConfigMap等资源管理</li><li><strong>Pod状态检查</strong>：实时监控Pod健康状态</li><li><strong>自动扩缩容</strong>：基于指标的自动扩缩容</li></ul><p><strong>使用示例：</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例：检查集群状态</span></span><br><span class="line"><span class="string">kubectl_status</span> <span class="string">=</span> <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">请帮我检查生产环境k8s集群的状态，</span></span><br><span class="line"><span class="string">包括：</span></span><br><span class="line"><span class="string">- 节点资源使用情况</span></span><br><span class="line"><span class="string">- 异常Pod列表</span></span><br><span class="line"><span class="string">- 最近的事件日志</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Helm-MCP"><a href="#Helm-MCP" class="headerlink" title="Helm MCP"></a>Helm MCP</h3><p>Kubernetes应用包管理工具，简化应用部署和管理。</p><p><strong>主要功能：</strong></p><ul><li><strong>Chart管理</strong>：Helm Chart的创建和管理</li><li><strong>版本控制</strong>：应用版本的管理和回滚</li><li><strong>批量部署</strong>：多环境的批量部署</li></ul><h3 id="Terraform-MCP"><a href="#Terraform-MCP" class="headerlink" title="Terraform MCP"></a>Terraform MCP</h3><p>基础设施即代码的实践工具，管理云基础设施。</p><p><strong>主要功能：</strong></p><ul><li><strong>基础设施即代码</strong>：声明式的基础设施管理</li><li><strong>资源变更管理</strong>：安全的基础设施变更</li><li><strong>多云支持</strong>：支持多个云平台</li></ul><h2 id="🔧-事件响应与自动化-MCP"><a href="#🔧-事件响应与自动化-MCP" class="headerlink" title="🔧 事件响应与自动化 MCP"></a>🔧 事件响应与自动化 MCP</h2><h3 id="PagerDuty-MCP"><a href="#PagerDuty-MCP" class="headerlink" title="PagerDuty MCP"></a>PagerDuty MCP</h3><p>专业的事件响应管理平台，提供完整的事件响应流程。</p><p><strong>主要功能：</strong></p><ul><li><strong>告警管理</strong>：智能告警聚合和去重</li><li><strong>事件响应自动化</strong>：自动化的事件响应流程</li><li><strong>值班调度</strong>：智能的值班人员调度</li></ul><h3 id="Slack-x2F-Teams-MCP"><a href="#Slack-x2F-Teams-MCP" class="headerlink" title="Slack&#x2F;Teams MCP"></a>Slack&#x2F;Teams MCP</h3><p>团队协作平台的集成，实现ChatOps的最佳实践。</p><p><strong>主要功能：</strong></p><ul><li><strong>自动化通知</strong>：重要事件的自动通知</li><li><strong>ChatOps集成</strong>：在聊天中执行运维命令</li><li><strong>团队协作</strong>：团队间的协作和信息共享</li></ul><h3 id="Jira-x2F-ServiceNow-MCP"><a href="#Jira-x2F-ServiceNow-MCP" class="headerlink" title="Jira&#x2F;ServiceNow MCP"></a>Jira&#x2F;ServiceNow MCP</h3><p>事件管理和工作流自动化平台。</p><p><strong>主要功能：</strong></p><ul><li><strong>事件单管理</strong>：故障单的创建和跟踪</li><li><strong>工作流自动化</strong>：自动化的工作流程</li><li><strong>问题跟踪</strong>：问题的全生命周期管理</li></ul><h2 id="📊-数据库与存储-MCP"><a href="#📊-数据库与存储-MCP" class="headerlink" title="📊 数据库与存储 MCP"></a>📊 数据库与存储 MCP</h2><h3 id="Trino-x2F-Presto-MCP"><a href="#Trino-x2F-Presto-MCP" class="headerlink" title="Trino&#x2F;Presto MCP"></a>Trino&#x2F;Presto MCP</h3><p>大数据查询引擎，提供跨数据源的统一查询能力。</p><p><strong>主要功能：</strong></p><ul><li><strong>大数据查询</strong>：跨多个数据源的统一查询</li><li><strong>性能分析</strong>：查询性能的分析和优化</li><li><strong>数据洞察</strong>：业务数据的深度分析</li></ul><h3 id="Redis-x2F-MongoDB-MCP"><a href="#Redis-x2F-MongoDB-MCP" class="headerlink" title="Redis&#x2F;MongoDB MCP"></a>Redis&#x2F;MongoDB MCP</h3><p>NoSQL数据库的管理工具，提供缓存和数据库的健康监控。</p><p><strong>主要功能：</strong></p><ul><li><strong>缓存管理</strong>：Redis缓存的管理和监控</li><li><strong>数据库健康检查</strong>：数据库性能和健康状态监控</li><li><strong>数据备份</strong>：自动化的数据备份和恢复</li></ul><h3 id="S3-x2F-对象存储-MCP"><a href="#S3-x2F-对象存储-MCP" class="headerlink" title="S3&#x2F;对象存储 MCP"></a>S3&#x2F;对象存储 MCP</h3><p>云存储服务的管理工具，提供存储监控和成本优化。</p><p><strong>主要功能：</strong></p><ul><li><strong>存储监控</strong>：存储使用情况和性能监控</li><li><strong>成本优化</strong>：存储成本的分析和优化建议</li><li><strong>数据备份验证</strong>：备份数据的完整性验证</li></ul><h2 id="🛡️-安全与合规-MCP"><a href="#🛡️-安全与合规-MCP" class="headerlink" title="🛡️ 安全与合规 MCP"></a>🛡️ 安全与合规 MCP</h2><h3 id="Vault-MCP"><a href="#Vault-MCP" class="headerlink" title="Vault MCP"></a>Vault MCP</h3><p>企业级密钥管理解决方案，提供安全的密钥管理。</p><p><strong>主要功能：</strong></p><ul><li><strong>密钥管理</strong>：集中化的密钥管理</li><li><strong>证书轮换</strong>：自动化的证书轮换</li><li><strong>安全策略</strong>：细粒度的安全策略管理</li></ul><h3 id="Falco-MCP"><a href="#Falco-MCP" class="headerlink" title="Falco MCP"></a>Falco MCP</h3><p>运行时安全监控工具，提供容器和云原生的安全监控。</p><p><strong>主要功能：</strong></p><ul><li><strong>运行时安全监控</strong>：实时的安全事件监控</li><li><strong>异常行为检测</strong>：基于规则的异常行为检测</li><li><strong>威胁响应</strong>：自动化的威胁响应</li></ul><h3 id="Compliance-MCP"><a href="#Compliance-MCP" class="headerlink" title="Compliance MCP"></a>Compliance MCP</h3><p>合规性管理工具，确保系统符合各种合规要求。</p><p><strong>主要功能：</strong></p><ul><li><strong>合规性检查</strong>：自动化的合规性检查</li><li><strong>审计日志分析</strong>：审计日志的分析和报告</li><li><strong>合规报告</strong>：自动生成合规报告</li></ul><h2 id="🔄-CI-x2F-CD与版本管理-MCP"><a href="#🔄-CI-x2F-CD与版本管理-MCP" class="headerlink" title="🔄 CI&#x2F;CD与版本管理 MCP"></a>🔄 CI&#x2F;CD与版本管理 MCP</h2><h3 id="Jenkins-x2F-GitHub-Actions-MCP"><a href="#Jenkins-x2F-GitHub-Actions-MCP" class="headerlink" title="Jenkins&#x2F;GitHub Actions MCP"></a>Jenkins&#x2F;GitHub Actions MCP</h3><p>持续集成和持续部署平台的管理工具。</p><p><strong>主要功能：</strong></p><ul><li><strong>构建管道管理</strong>：CI&#x2F;CD管道的创建和管理</li><li><strong>部署自动化</strong>：自动化的部署流程</li><li><strong>构建监控</strong>：构建状态的监控和告警</li></ul><h3 id="Git-MCP"><a href="#Git-MCP" class="headerlink" title="Git MCP"></a>Git MCP</h3><p>版本控制系统的管理工具，提供代码管理的自动化。</p><p><strong>主要功能：</strong></p><ul><li><strong>代码变更分析</strong>：代码变更的影响分析</li><li><strong>发布管理</strong>：版本发布的管理和跟踪</li><li><strong>回滚操作</strong>：快速的代码回滚</li></ul><h3 id="Docker-Registry-MCP"><a href="#Docker-Registry-MCP" class="headerlink" title="Docker Registry MCP"></a>Docker Registry MCP</h3><p>容器镜像管理工具，提供镜像的全生命周期管理。</p><p><strong>主要功能：</strong></p><ul><li><strong>镜像管理</strong>：容器镜像的管理和分发</li><li><strong>漏洞扫描</strong>：镜像安全漏洞扫描</li><li><strong>清理策略</strong>：自动化的镜像清理</li></ul><h2 id="💰-成本优化-MCP"><a href="#💰-成本优化-MCP" class="headerlink" title="💰 成本优化 MCP"></a>💰 成本优化 MCP</h2><h3 id="AWS-x2F-GCP-x2F-Azure-Cost-MCP"><a href="#AWS-x2F-GCP-x2F-Azure-Cost-MCP" class="headerlink" title="AWS&#x2F;GCP&#x2F;Azure Cost MCP"></a>AWS&#x2F;GCP&#x2F;Azure Cost MCP</h3><p>云服务成本管理工具，提供成本分析和优化建议。</p><p><strong>主要功能：</strong></p><ul><li><strong>成本分析</strong>：云服务成本的详细分析</li><li><strong>资源优化建议</strong>：基于使用情况的优化建议</li><li><strong>预算管理</strong>：成本预算的管理和告警</li></ul><h3 id="Kubernetes-Cost-MCP"><a href="#Kubernetes-Cost-MCP" class="headerlink" title="Kubernetes Cost MCP"></a>Kubernetes Cost MCP</h3><p>Kubernetes集群成本管理工具。</p><p><strong>主要功能：</strong></p><ul><li><strong>集群成本分配</strong>：应用和团队的成本分配</li><li><strong>资源使用优化</strong>：资源使用效率的优化</li><li><strong>成本预测</strong>：基于历史数据的成本预测</li></ul><h2 id="🎯-实施建议与最佳实践"><a href="#🎯-实施建议与最佳实践" class="headerlink" title="🎯 实施建议与最佳实践"></a>🎯 实施建议与最佳实践</h2><h3 id="优先级实施顺序"><a href="#优先级实施顺序" class="headerlink" title="优先级实施顺序"></a>优先级实施顺序</h3><ol><li><p><strong>监控可观测性</strong> - 建立完整的监控体系</p><ul><li>首先部署Prometheus&#x2F;Grafana MCP</li><li>配置基础的系统监控指标</li><li>建立告警规则和通知机制</li></ul></li><li><p><strong>事件响应自动化</strong> - 减少MTTR，提高响应速度</p><ul><li>集成PagerDuty MCP或类似工具</li><li>建立自动化的事件响应流程</li><li>配置ChatOps集成</li></ul></li><li><p><strong>部署自动化</strong> - 标准化部署流程，减少人为错误</p><ul><li>实施GitOps部署管理</li><li>建立CI&#x2F;CD管道</li><li>配置自动化测试</li></ul></li><li><p><strong>数据库监控</strong> - 确保数据层稳定性</p><ul><li>监控数据库性能指标</li><li>建立数据备份和恢复机制</li><li>配置数据库健康检查</li></ul></li><li><p><strong>成本优化</strong> - 持续优化资源使用效率</p><ul><li>分析云服务成本</li><li>优化资源配置</li><li>建立成本控制机制</li></ul></li></ol><h3 id="配置示例"><a href="#配置示例" class="headerlink" title="配置示例"></a>配置示例</h3><p>以下是一个完整的SRE MCP配置示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;prometheus&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mcp-prometheus-server&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;--url&quot;</span><span class="punctuation">,</span> <span class="string">&quot;http://prometheus:9090&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;PROMETHEUS_URL&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://prometheus:9090&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;kubernetes&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mcp-kubernetes-server&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;--kubeconfig&quot;</span><span class="punctuation">,</span> <span class="string">&quot;/path/to/kubeconfig&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;KUBECONFIG&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/path/to/kubeconfig&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;pagerduty&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mcp-pagerduty-server&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;PAGERDUTY_API_KEY&quot;</span><span class="punctuation">:</span> <span class="string">&quot;your-api-key&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;slack&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mcp-slack-server&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;SLACK_BOT_TOKEN&quot;</span><span class="punctuation">:</span> <span class="string">&quot;your-bot-token&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;SLACK_CHANNEL&quot;</span><span class="punctuation">:</span> <span class="string">&quot;#ops&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><ol><li><strong>渐进式实施</strong>：不要一次性部署所有工具，建议分阶段实施</li><li><strong>团队培训</strong>：确保团队成员了解MCP工具的使用方法</li><li><strong>监控覆盖</strong>：确保关键服务都有相应的监控和告警</li><li><strong>文档维护</strong>：维护详细的运维文档和操作手册</li><li><strong>安全考虑</strong>：确保API密钥和敏感信息的安全管理</li></ol><h2 id="实际应用场景"><a href="#实际应用场景" class="headerlink" title="实际应用场景"></a>实际应用场景</h2><h3 id="故障响应场景"><a href="#故障响应场景" class="headerlink" title="故障响应场景"></a>故障响应场景</h3><p>当生产环境出现故障时，SRE工程师可以通过AI助手快速响应：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">用户：生产环境API响应时间异常，请帮我排查问题</span><br><span class="line"></span><br><span class="line">AI助手：</span><br><span class="line">1. 正在查询Prometheus监控数据...</span><br><span class="line">2. 发现API响应时间在15:30开始异常增长</span><br><span class="line">3. 检查Kubernetes集群状态...</span><br><span class="line">4. 发现数据库连接池使用率达到95%</span><br><span class="line">5. 建议：增加数据库连接池大小或扩容数据库实例</span><br><span class="line">6. 已创建PagerDuty事件并通知相关人员</span><br><span class="line">7. 是否需要我执行自动扩容？</span><br></pre></td></tr></table></figure><h3 id="日常运维场景"><a href="#日常运维场景" class="headerlink" title="日常运维场景"></a>日常运维场景</h3><p>在日常运维中，AI助手可以帮助完成各种例行任务：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">用户：请帮我检查今天的系统健康状态</span><br><span class="line"></span><br><span class="line">AI助手：</span><br><span class="line">📊 系统健康状态报告 (2025-01-14)</span><br><span class="line"></span><br><span class="line">🔍 监控指标：</span><br><span class="line">- CPU使用率：平均65%，峰值82%</span><br><span class="line">- 内存使用率：平均71%，峰值89%</span><br><span class="line">- 磁盘使用率：平均45%，峰值67%</span><br><span class="line">- 网络流量：入流量2.3GB/s，出流量1.8GB/s</span><br><span class="line"></span><br><span class="line">🚨 告警情况：</span><br><span class="line">- 当前活跃告警：3个</span><br><span class="line">- 最近24小时告警：15个</span><br><span class="line">- 已解决告警：12个</span><br><span class="line"></span><br><span class="line">📈 应用性能：</span><br><span class="line">- 平均响应时间：245ms</span><br><span class="line">- 错误率：0.02%</span><br><span class="line">- 吞吐量：1200 req/s</span><br><span class="line"></span><br><span class="line">💰 成本分析：</span><br><span class="line">- 今日成本：$1,234</span><br><span class="line">- 较昨日变化：+2.3%</span><br><span class="line">- 本月预计：$35,678</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>SRE MCP Tools代表了运维自动化的新趋势，它将AI技术与传统运维工具完美结合，为运维工程师提供了智能化的解决方案。通过这套工具箱，运维团队可以：</p><ul><li><strong>提升效率</strong>：自动化重复性任务，释放人力资源</li><li><strong>降低风险</strong>：标准化操作流程，减少人为错误</li><li><strong>快速响应</strong>：智能化的故障检测和响应</li><li><strong>持续优化</strong>：基于数据的持续改进</li></ul><p>作为互联网工程师，掌握这些工具不仅能提升个人技能，更能为团队和企业创造价值。建议大家根据自己的实际需求，选择合适的工具进行试用和部署。</p><p>未来，随着AI技术的不断发展，我们相信SRE MCP Tools将会变得更加智能和强大，为运维工程师带来更多的可能性。让我们一起拥抱这个充满机遇的时代！</p><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://modelcontextprotocol.io/">MCP官方文档</a></li><li><a href="https://prometheus.io/docs/practices/">Prometheus监控最佳实践</a></li><li><a href="https://kubernetes.io/docs/concepts/">Kubernetes运维指南</a></li><li><a href="https://sre.google/sre-book/">SRE工程实践</a></li><li><a href="https://www.gitops.tech/">GitOps最佳实践</a></li><li><a href="https://github.com/rohitg00/awesome-devops-mcp-servers">Awesome DevOps MCP Servers</a></li></ul><blockquote><p>本文由AI生成，内容仅供参考。在实际部署前，请根据具体环境进行测试和验证。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> SRE </category>
          
          <category> DevOps </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MCP </tag>
            
            <tag> SRE </tag>
            
            <tag> 运维 </tag>
            
            <tag> 可观测性 </tag>
            
            <tag> 自动化 </tag>
            
            <tag> 监控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac配置Windows键盘与鼠标：让你的Mac体验更像Windows</title>
      <link href="/DevOps/Mac%E9%85%8D%E7%BD%AEwindows%E9%95%9C%E5%83%8F%E4%B8%8E%E9%BC%A0%E6%A0%87/"/>
      <url>/DevOps/Mac%E9%85%8D%E7%BD%AEwindows%E9%95%9C%E5%83%8F%E4%B8%8E%E9%BC%A0%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="为什么需要这样的配置？"><a href="#为什么需要这样的配置？" class="headerlink" title="为什么需要这样的配置？"></a>为什么需要这样的配置？</h3><p>Mac 电脑的鼠标滚轮方向、键盘快捷键以及操作逻辑与Windows系统存在显著差异。对于长期使用Windows系统的用户来说，突然转换到Mac可能会遇到以下问题：</p><ul><li><strong>鼠标滚轮方向相反</strong>：Mac的”自然滚动”与Windows相反</li><li><strong>Alt+Tab切换逻辑不同</strong>：Mac的Command+Tab与Windows的Alt+Tab行为差异很大</li><li><strong>剪贴板功能缺失</strong>：Mac缺少类似Windows的剪贴板历史功能</li><li><strong>修饰键位置不同</strong>：Command、Option、Control键的位置和功能与Windows的Ctrl、Alt键不同</li></ul><p>通过合理的软件配置和系统设置，我们可以让Mac的使用体验更接近Windows，减少学习成本，提高工作效率。</p><h2 id="核心软件解决方案"><a href="#核心软件解决方案" class="headerlink" title="核心软件解决方案"></a>核心软件解决方案</h2><h3 id="1-Scroll-Reverser-解决鼠标滚轮方向问题"><a href="#1-Scroll-Reverser-解决鼠标滚轮方向问题" class="headerlink" title="1. Scroll Reverser - 解决鼠标滚轮方向问题"></a>1. Scroll Reverser - 解决鼠标滚轮方向问题</h3><h4 id="软件介绍"><a href="#软件介绍" class="headerlink" title="软件介绍"></a>软件介绍</h4><p><a href="https://pilotmoon.com/scrollreverser/">Scroll Reverser</a> 是一款免费的开源软件，专门用于调整Mac的滚轮滚动方向。</p><h4 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h4><ul><li>独立控制鼠标和触控板的滚动方向</li><li>支持水平和垂直滚动的独立设置</li><li>可以针对不同应用程序设置不同的滚动行为</li><li>菜单栏快速切换功能</li></ul><h4 id="详细配置步骤"><a href="#详细配置步骤" class="headerlink" title="详细配置步骤"></a>详细配置步骤</h4><ol><li><strong>下载安装</strong>：访问官网下载最新版本</li><li><strong>启动设置</strong>：<ul><li>打开Scroll Reverser</li><li>在”Scrolling”选项卡中勾选”Reverse Vertical”</li><li>如果需要，也可以勾选”Reverse Horizontal”<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/6cf0c7b0e8dda7e9c2595640f1afe014c991f35e177e4958afcc7a4b23d9c92d.png" alt="Scroll Reverser"></li></ul></li></ol><h3 id="2-AltTab-实现Windows式窗口切换"><a href="#2-AltTab-实现Windows式窗口切换" class="headerlink" title="2. AltTab - 实现Windows式窗口切换"></a>2. AltTab - 实现Windows式窗口切换</h3><h4 id="软件介绍-1"><a href="#软件介绍-1" class="headerlink" title="软件介绍"></a>软件介绍</h4><p><a href="https://alt-tab-macos.netlify.app/">AltTab</a> 让Mac的窗口切换体验更接近Windows系统。</p><h4 id="核心优势"><a href="#核心优势" class="headerlink" title="核心优势"></a>核心优势</h4><ul><li><strong>显示所有窗口</strong>：不只是应用程序图标，而是实际窗口预览</li><li><strong>包含最小化窗口</strong>：可以直接切换到最小化的窗口</li><li><strong>更快的响应速度</strong>：相比系统自带的切换更流畅</li><li><strong>高度可自定义</strong>：支持多种显示样式和快捷键组合</li></ul><h4 id="详细配置指南"><a href="#详细配置指南" class="headerlink" title="详细配置指南"></a>详细配置指南</h4><ol><li><strong>基础设置</strong>：<ul><li>下载安装AltTab</li><li>在系统偏好设置中禁用原生的Command+Tab</li><li>启动AltTab并设置开机自启</li></ul></li><li><strong>快捷键配置</strong>：<ul><li>将主快捷键设置为Option+Tab（更接近Windows的Alt+Tab）</li><li>或保持Command+Tab但享受增强功能</li></ul></li><li><strong>外观定制</strong>：<ul><li>选择窗口显示大小</li><li>设置背景透明度</li><li>调整窗口间距和布局</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f712bfdaed0eee7ab9fd37e7abc0a3a90eabae8b7fc31e39b4917bd0ef93708f.png" alt="AltTab">  </p><h3 id="3-Maccy-强大的剪贴板管理器"><a href="#3-Maccy-强大的剪贴板管理器" class="headerlink" title="3. Maccy - 强大的剪贴板管理器"></a>3. Maccy - 强大的剪贴板管理器</h3><h4 id="软件特色"><a href="#软件特色" class="headerlink" title="软件特色"></a>软件特色</h4><p><a href="https://maccy.app/">Maccy</a> 是一款轻量级的剪贴板历史管理器，类似Windows的剪贴板功能。</p><h4 id="主要功能-1"><a href="#主要功能-1" class="headerlink" title="主要功能"></a>主要功能</h4><ul><li><strong>历史记录</strong>：自动保存复制的文本、图片等内容</li><li><strong>快速搜索</strong>：支持模糊搜索历史剪贴内容</li><li><strong>智能分类</strong>：自动识别文本、图片、文件等不同类型</li><li><strong>隐私安全</strong>：支持忽略敏感应用（如密码管理器）</li></ul><h4 id="使用技巧"><a href="#使用技巧" class="headerlink" title="使用技巧"></a>使用技巧</h4><ol><li><strong>快捷键设置</strong>：<ul><li>默认快捷键：Shift+Command+C</li><li>可自定义为更符合个人习惯的组合</li></ul></li><li><strong>高级功能</strong>：<ul><li>设置历史记录数量限制</li><li>配置忽略列表（银行、密码等敏感应用）</li><li>启用&#x2F;禁用图片和文件的历史记录</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8ec9bfbd875a19825e2c1185c8b69fe26aa61c8a038fadd4315e22e9b87a18f3.png" alt="maccy">  </p><h3 id="4-系统修饰键配置"><a href="#4-系统修饰键配置" class="headerlink" title="4. 系统修饰键配置"></a>4. 系统修饰键配置</h3><h4 id="修改键盘映射-Modifier-Keys"><a href="#修改键盘映射-Modifier-Keys" class="headerlink" title="修改键盘映射 Modifier Keys"></a>修改键盘映射 Modifier Keys</h4><p>通过Mac的系统偏好设置，我们可以重新映射修饰键：</p><ol><li><strong>进入设置</strong>：<ul><li>打开”系统偏好设置” → “键盘”</li><li>点击右下角的”修饰键…”按钮</li></ul></li><li><strong>推荐配置</strong>：<ul><li><strong>Command键</strong> → 映射为Control</li><li><strong>Control键</strong> → 映射为Command</li><li><strong>Option键</strong> → 保持不变（作为Alt键使用）</li></ul></li><li><strong>针对外接键盘</strong>：<ul><li>如果使用Windows键盘，需要单独为外接键盘设置映射</li><li>Windows键 → Command键</li><li>Alt键 → Option键</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c1f13f0b721780f4454fe3a007bd71a697c87bbc0ef1fa8fa4a5af78717c219f.png" alt="Modifier Keys">  </p><h2 id="进阶配置与替代方案"><a href="#进阶配置与替代方案" class="headerlink" title="进阶配置与替代方案"></a>进阶配置与替代方案</h2><h3 id="其他实用工具推荐"><a href="#其他实用工具推荐" class="headerlink" title="其他实用工具推荐"></a>其他实用工具推荐</h3><h4 id="Karabiner-Elements-高级键盘定制"><a href="#Karabiner-Elements-高级键盘定制" class="headerlink" title="Karabiner-Elements - 高级键盘定制"></a>Karabiner-Elements - 高级键盘定制</h4><ul><li>更精细的键盘映射控制</li><li>支持复杂的快捷键组合</li><li>可以创建自定义的键盘行为</li></ul><h4 id="BetterTouchTool-触控板和鼠标增强"><a href="#BetterTouchTool-触控板和鼠标增强" class="headerlink" title="BetterTouchTool - 触控板和鼠标增强"></a>BetterTouchTool - 触控板和鼠标增强</h4><ul><li>自定义触控板手势</li><li>鼠标按键重新映射</li><li>窗口管理快捷操作</li></ul><h4 id="Magnet-窗口管理"><a href="#Magnet-窗口管理" class="headerlink" title="Magnet - 窗口管理"></a>Magnet - 窗口管理</h4><ul><li>类似Windows的窗口贴边功能</li><li>快捷键快速调整窗口大小和位置</li></ul><h3 id="常见问题与解决方案"><a href="#常见问题与解决方案" class="headerlink" title="常见问题与解决方案"></a>常见问题与解决方案</h3><h4 id="问题1：软件冲突"><a href="#问题1：软件冲突" class="headerlink" title="问题1：软件冲突"></a>问题1：软件冲突</h4><p><strong>现象</strong>：多个键盘工具同时运行导致快捷键失效<br><strong>解决方案</strong>：</p><ul><li>优先使用系统原生设置</li><li>按需启用第三方工具</li><li>避免功能重复的软件同时运行</li></ul><h4 id="问题2：外接设备兼容性"><a href="#问题2：外接设备兼容性" class="headerlink" title="问题2：外接设备兼容性"></a>问题2：外接设备兼容性</h4><p><strong>现象</strong>：某些Windows键鼠在Mac上功能异常<br><strong>解决方案</strong>：</p><ul><li>检查设备驱动是否支持Mac</li><li>使用USB Overdrive等通用驱动</li><li>考虑购买Mac兼容的设备</li></ul><h4 id="问题3：系统更新后配置丢失"><a href="#问题3：系统更新后配置丢失" class="headerlink" title="问题3：系统更新后配置丢失"></a>问题3：系统更新后配置丢失</h4><p><strong>现象</strong>：macOS更新后需要重新配置<br><strong>解决方案</strong>：</p><ul><li>定期备份配置文件</li><li>使用支持配置同步的工具</li><li>记录个人配置清单</li></ul><h2 id="性能优化建议"><a href="#性能优化建议" class="headerlink" title="性能优化建议"></a>性能优化建议</h2><h3 id="系统资源管理"><a href="#系统资源管理" class="headerlink" title="系统资源管理"></a>系统资源管理</h3><ol><li><strong>开机启动项管理</strong>：只保留必要的工具自启</li><li><strong>内存占用监控</strong>：定期检查各工具的资源占用</li><li><strong>定期清理</strong>：清除不需要的历史数据和缓存</li></ol><h3 id="工作流程优化"><a href="#工作流程优化" class="headerlink" title="工作流程优化"></a>工作流程优化</h3><ol><li><strong>快捷键标准化</strong>：在不同设备间保持一致的快捷键设置</li><li><strong>场景化配置</strong>：为不同工作场景创建配置文件</li><li><strong>定期评估</strong>：根据使用习惯调整配置</li></ol><h2 id="总结与建议"><a href="#总结与建议" class="headerlink" title="总结与建议"></a>总结与建议</h2><h3 id="核心要点"><a href="#核心要点" class="headerlink" title="核心要点"></a>核心要点</h3><p>通过合理配置上述工具，可以显著改善Mac的Windows用户体验：</p><ul><li><strong>Scroll Reverser</strong> 解决滚轮方向问题</li><li><strong>AltTab</strong> 提供熟悉的窗口切换体验  </li><li><strong>Maccy</strong> 增强剪贴板功能</li><li><strong>系统修饰键配置</strong> 让键盘操作更符合Windows习惯</li></ul><h3 id="实施建议"><a href="#实施建议" class="headerlink" title="实施建议"></a>实施建议</h3><ol><li><strong>循序渐进</strong>：不要一次性安装所有工具，先从最需要的开始</li><li><strong>个性化调整</strong>：根据个人使用习惯微调各项设置</li><li><strong>保持更新</strong>：定期检查软件更新，确保兼容性和安全性</li><li><strong>备份配置</strong>：重要的配置文件要做好备份</li></ol><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>某些软件可能需要系统权限，请谨慎授权</li><li>部分功能可能影响系统性能，请根据实际需求启用</li><li>定期检查软件的安全性和隐私政策</li></ul><p>通过这些配置，Mac用户可以在保持系统稳定性的同时，享受到更符合Windows使用习惯的操作体验，从而提高日常工作效率。</p><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> mac </tag>
            
            <tag> windows </tag>
            
            <tag> 键鼠配置 </tag>
            
            <tag> 效率工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>rclone使用教程</title>
      <link href="/DevOps/rclone%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
      <url>/DevOps/rclone%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>rclone 是一款强大的命令行工具，支持在本地与多种云存储之间进行高效的数据同步和迁移。本文将介绍 rclone 的安装、配置及常用操作方法，帮助你快速上手。</p><h1 id="一、安装-rclone"><a href="#一、安装-rclone" class="headerlink" title="一、安装 rclone"></a>一、安装 rclone</h1><h2 id="1-公网环境安装（以-Ubuntu-为例）"><a href="#1-公网环境安装（以-Ubuntu-为例）" class="headerlink" title="1. 公网环境安装（以 Ubuntu 为例）"></a>1. 公网环境安装（以 Ubuntu 为例）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl https://downloads.rclone.org/v1.67.0/rclone-v1.67.0-linux-amd64.deb -o rclone-v1.67.0-linux-amd64.deb</span><br><span class="line">sudo dpkg -i rclone-v1.67.0-linux-amd64.deb</span><br></pre></td></tr></table></figure><h2 id="2-Mac-安装"><a href="#2-Mac-安装" class="headerlink" title="2. Mac 安装"></a>2. Mac 安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install rclone</span><br></pre></td></tr></table></figure><p>更多平台和安装方式可参考 <a href="https://rclone.org/downloads/">rclone 官方下载页面</a>。</p><h1 id="二、配置-rclone"><a href="#二、配置-rclone" class="headerlink" title="二、配置 rclone"></a>二、配置 rclone</h1><p>rclone 的配置文件默认位于 <code>~/.config/rclone/rclone.conf</code>。你可以手动创建和编辑该文件，或通过 <code>rclone config</code> 命令进行交互式配置。</p><h2 id="1-创建配置目录"><a href="#1-创建配置目录" class="headerlink" title="1. 创建配置目录"></a>1. 创建配置目录</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p ~/.config/rclone</span><br></pre></td></tr></table></figure><h2 id="2-编辑配置文件"><a href="#2-编辑配置文件" class="headerlink" title="2. 编辑配置文件"></a>2. 编辑配置文件</h2><p>以下是一个典型的配置示例，支持 swift 和 s3 两种后端：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; ~/.config/rclone/rclone.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[ss-data]</span></span><br><span class="line"><span class="string">type = swift</span></span><br><span class="line"><span class="string">env_auth = false</span></span><br><span class="line"><span class="string">user = $&#123;STORAGE_USER&#125;</span></span><br><span class="line"><span class="string">key = $&#123;STORAGE_PASSWORD&#125;</span></span><br><span class="line"><span class="string">auth = https://&#123;SS_ENDPOINT&#125;/auth/v1.0</span></span><br><span class="line"><span class="string">auth_version = 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[s3-data]</span></span><br><span class="line"><span class="string">type = s3</span></span><br><span class="line"><span class="string">env_auth = true</span></span><br><span class="line"><span class="string">access_key_id = $&#123;S3_ACCESS_ID&#125;</span></span><br><span class="line"><span class="string">secret_access_key = $&#123;S3_SECRET_KEY&#125;</span></span><br><span class="line"><span class="string">region = us-east-1</span></span><br><span class="line"><span class="string">endpoint = https://$&#123;S3_ENDPOINT&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>请根据实际账号和密钥替换 <code>$&#123;STORAGE_USER&#125;</code>, <code>$&#123;STORAGE_PASSWORD&#125;</code>,<code>$&#123;S3_ACCESS_ID&#125;</code>,<code>$&#123;S3_SECRET_KEY&#125;</code> 等变量。</p><h1 id="三、常用命令"><a href="#三、常用命令" class="headerlink" title="三、常用命令"></a>三、常用命令</h1><h2 id="1-查看目录"><a href="#1-查看目录" class="headerlink" title="1. 查看目录"></a>1. 查看目录</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone lsd ss-data:bucketname</span><br></pre></td></tr></table></figure><h2 id="2-查看文件"><a href="#2-查看文件" class="headerlink" title="2. 查看文件"></a>2. 查看文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone <span class="built_in">ls</span> ss-data:bucketname/path/file.txt</span><br></pre></td></tr></table></figure><h2 id="3-拷贝文件"><a href="#3-拷贝文件" class="headerlink" title="3. 拷贝文件"></a>3. 拷贝文件</h2><p>将文件从一个存储拷贝到另一个存储：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone copy ss-data:bucketname/path/file.txt s3-data:bucketname2/path/ -P</span><br></pre></td></tr></table></figure><h2 id="4-目录同步"><a href="#4-目录同步" class="headerlink" title="4. 目录同步"></a>4. 目录同步</h2><h3 id="rclone-copy-拷贝文件"><a href="#rclone-copy-拷贝文件" class="headerlink" title="rclone copy 拷贝文件"></a>rclone copy 拷贝文件</h3><p>rclone copy 只会把源目录的内容复制到目标目录，不会删除目标目录中多余的文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone copy ./local_dir ss-data:bucketname/remote_dir -P --transfers=32 --checkers=32 --retries=8 --log-level INFO</span><br></pre></td></tr></table></figure><ul><li><p>-P<br>显示进度条（progress），包括传输速度、已完成&#x2F;剩余数据量、预计剩余时间等信息，便于实时观察任务进度。</p></li><li><p>–transfers&#x3D;32<br>同时进行的文件传输任务数，默认值通常为4。设置为32可以大幅提升并发传输能力，适合大量小文件或高带宽场景，但过高可能导致资源争用或被服务端限流。官方认为最大不要超过128。</p></li><li><p>–multi-thread-streams&#x3D;16<br>启用单个大文件的多线程分块并发传输，N 表示每个大文件使用的并发线程数（如 4、8、16 等）。</p></li><li><p>–buffer-size&#x3D;128M<br>主要作用于单个文件的流式传输，即每个并发传输任务分配的内存缓冲区。对于大文件，较大的 buffer 可以减少磁盘 I&#x2F;O 等待、提升吞吐量。对于小文件，单个文件本身很小，往往一次就能读&#x2F;写完，缓冲区很难被充分利用。</p></li><li><p>–checkers&#x3D;32<br>并发校验文件（如比对源和目标文件是否一致）的线程数。默认值通常为8。提高该值可以加快大批量文件的校验速度，适合大规模同步。官方认为最大不要超过64.</p><table><thead><tr><th>场景</th><th>关键参数</th><th>说明</th></tr></thead><tbody><tr><td>大文件</td><td>–multi-thread-streams&#x3D;8</td><td>单文件多线程分块传输</td></tr><tr><td></td><td>–buffer-size&#x3D;128M</td><td>提高单线程缓冲区</td></tr><tr><td></td><td>–transfers&#x3D;4</td><td>并发文件数适中</td></tr><tr><td>小文件</td><td>–transfers&#x3D;32 –checkers&#x3D;32</td><td>提高并发数</td></tr><tr><td></td><td>–buffer-size&#x3D;默认</td><td>无需调大缓冲区</td></tr><tr><td></td><td>–multi-thread-streams&#x3D;0（默认）</td><td>无需多线程分块</td></tr></tbody></table></li><li><p>–retries&#x3D;8<br>单个文件传输失败时的重试次数。默认值为3。设置为8可以增强在网络不稳定或偶发错误情况下的容错能力，减少因偶发错误导致的整体失败。</p></li><li><p>–log-level INFO<br>设置日志输出级别为 INFO，显示一般性的信息、进度和警告。常用级别有 DEBUG、INFO、NOTICE、ERROR。INFO 适合日常使用，既能看到关键日志，又不会太冗杂。</p></li><li><p>–bwlimit 参数用于限制 rclone 的传输带宽速率，例如 –bwlimit&#x3D;20M 表示将传输速度限制为每秒 20MB。<br>该参数的作用：<br>控制网络使用率：防止 rclone 占用全部可用带宽，确保其他网络应用仍能正常工作<br>避免被服务商限流：某些云存储提供商会对高速持续传输进行限流，设置合理的带宽限制可以避免这种情况<br>适应网络环境：在网络不稳定的情况下，适当限制带宽可能会提高整体传输的可靠性<br>支持的单位：<br>K 或 k：KB&#x2F;s (千字节&#x2F;秒)<br>M 或 m：MB&#x2F;s (兆字节&#x2F;秒)<br>G 或 g：GB&#x2F;s (吉字节&#x2F;秒)<br>也可以设置时间段带宽限制，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--bwlimit &quot;08:00,10M 12:00,1M 18:00,5M 23:00,off&quot;</span><br></pre></td></tr></table></figure><p>这会在不同时间段自动应用不同的带宽限制。</p></li><li><p>–s3-chunk-size：设置 S3 分片上传时每个分块的大小（默认通常为 5MB）</p></li><li><p>–s3-upload-concurrency：控制单个文件上传时并发上传的分块数量（默认通常为 4）<br>当上传大文件到 S3 时，rclone 会：<br>将文件分割成多个大小为 –s3-chunk-size 的块<br>同时上传 –s3-upload-concurrency 个块<br>增大 –s3-chunk-size 减少了分块数量，但每个块需要更多内存<br>增大 –s3-upload-concurrency 提高并行度，但会增加内存和网络资源消耗</p><table><thead><tr><th>场景</th><th>关键参数</th><th>说明</th></tr></thead><tbody><tr><td>快速网络环境</td><td>–s3-chunk-size&#x3D;64M –s3-upload-concurrency&#x3D;8</td><td>增大两个值可提高吞吐量</td></tr><tr><td>内存受限环境</td><td>–s3-chunk-size&#x3D;16M –s3-upload-concurrency&#x3D;6</td><td>保持适中的块大小，适当增加并发数</td></tr><tr><td>不稳定网络</td><td>–s3-chunk-size&#x3D;8M –s3-upload-concurrency&#x3D;4</td><td>较小的块大小和适中的并发数有助于错误恢复</td></tr></tbody></table></li></ul><h3 id="rclone-rsync-同步目录"><a href="#rclone-rsync-同步目录" class="headerlink" title="rclone rsync 同步目录"></a>rclone rsync 同步目录</h3><p>rclone rsync 会让目标目录和源目录完全一致，即：目标中有但源中没有的文件会被删除，行为更接近 rsync 的 –delete。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone <span class="built_in">sync</span> ./local_dir ss-data:bucketname/remote_dir -P</span><br></pre></td></tr></table></figure><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>rclone copy 适合做备份，不会误删目标端已有文件。</li><li>rclone sync 适合做镜像同步，但要小心目标端数据被删除。</li><li>文件特别多的场景，应该将需要上传的文件切分成多个任务进行</li></ul><ol><li>获取需要上传的所有文件列表<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone lsf --files-only -R src:path | sort &gt; all_files.txt</span><br></pre></td></tr></table></figure></li><li>将文件进行切分，每份不超过10w个文件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">split -l 100000 --numeric-suffixes all_files.txt chunk_</span><br></pre></td></tr></table></figure>以上是将源文件每100000个文件拆成一份</li><li>指定切分的文件列表，进行上传<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rclone copy src:path dst:path --files-from chunk_00 --no-traverse --transfers=64 --checkers=32 --retries=8 --progress</span><br></pre></td></tr></table></figure>这里是上传chunk_00 列表。<br>–no-traverse: rclone在复制文件时是不先列出目标目录下的所有文件，适用于目标目录文件数特别多的场景</li></ol><h1 id="四、更多参考"><a href="#四、更多参考" class="headerlink" title="四、更多参考"></a>四、更多参考</h1><ul><li><a href="https://rclone.org/docs/">rclone 官方文档</a></li><li><a href="https://hcc.unl.edu/docs/handling_data/data_transfer/using_rclone_with_hcc/">HCC: Using Rclone for File Transfer</a></li></ul><p>rclone 支持丰富的云存储后端和灵活的参数配置，适合多种数据迁移和备份场景。建议结合实际需求，查阅官方文档，发挥其最大效能。</p><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> rclone </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes云原生存储解决方案 - Longhorn安装指南</title>
      <link href="/DevOps/Kubernetes%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AD%98%E5%82%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%20-%20Longhorn%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"/>
      <url>/DevOps/Kubernetes%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AD%98%E5%82%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%20-%20Longhorn%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Longhorn 是一个轻量级、可靠且功能强大的分布式块存储系统，专为 Kubernetes 而设计。它实现了可靠的持久化存储，支持快照、备份和跨集群灾难恢复等企业级功能。</p><h3 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h3><ul><li>企业级分布式块存储</li><li>跨节点数据复制和自动重建</li><li>无中心化架构</li><li>非侵入式架构</li><li>图形化管理界面</li><li>快照和备份支持</li><li>跨集群灾备能力</li></ul><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><p>在安装 Longhorn 之前，请确保您的环境满足以下要求：</p><h3 id="环境检查"><a href="#环境检查" class="headerlink" title="环境检查"></a>环境检查</h3><p>在部署 Longhorn 之前，强烈建议运行环境检查脚本来验证您的环境是否满足所有必要条件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载环境检查脚本</span></span><br><span class="line">curl -sSfL https://raw.githubusercontent.com/longhorn/longhorn/v1.8.1/scripts/environment_check.sh | bash</span><br></pre></td></tr></table></figure><p>这个脚本会检查：</p><ul><li>操作系统依赖</li><li>内核模块</li><li>挂载点</li><li>系统工具</li><li>网络配置</li><li>SELinux 状态</li><li>iscsi 服务状态</li></ul><h3 id="硬件要求"><a href="#硬件要求" class="headerlink" title="硬件要求"></a>硬件要求</h3><ul><li>CPU: 最低 1 核</li><li>内存: 最低 1GB</li><li>磁盘: 每个节点至少 20GB 可用空间</li></ul><h3 id="软件要求"><a href="#软件要求" class="headerlink" title="软件要求"></a>软件要求</h3><ul><li>Kubernetes v1.21+</li><li>所有节点已安装 open-iscsi</li><li>所有节点已安装 curl、findmnt、grep、awk、blkid、lsblk 等工具</li></ul><h3 id="节点要求"><a href="#节点要求" class="headerlink" title="节点要求"></a>节点要求</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在所有节点执行以下命令安装必要组件</span></span><br><span class="line">apt-get install open-iscsi curl util-linux grep awk -y</span><br><span class="line">systemctl <span class="built_in">enable</span> iscsid</span><br><span class="line">systemctl start iscsid</span><br></pre></td></tr></table></figure><h2 id="安装方法"><a href="#安装方法" class="headerlink" title="安装方法"></a>安装方法</h2><h3 id="方法一：使用-Helm-安装（推荐）"><a href="#方法一：使用-Helm-安装（推荐）" class="headerlink" title="方法一：使用 Helm 安装（推荐）"></a>方法一：使用 Helm 安装（推荐）</h3><ol><li>添加 Longhorn 的 Helm 仓库：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add longhorn https://charts.longhorn.io</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><ol start="2"><li>创建 longhorn-system 命名空间：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace longhorn-system</span><br></pre></td></tr></table></figure><ol start="3"><li>安装 Longhorn：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install longhorn longhorn/longhorn --namespace longhorn-system --create-namespace --version 1.8.1</span><br></pre></td></tr></table></figure><p>默认数据目录是&#x2F;var&#x2F;lib&#x2F;longhorn, 可以通过配置values.yaml按照自己的存储规划要求设置自定义的目录。 如: –set defaultSettings.defaultDataPath&#x3D;”&#x2F;data&#x2F;longhorn”</p><h3 id="方法二：使用-kubectl-安装"><a href="#方法二：使用-kubectl-安装" class="headerlink" title="方法二：使用 kubectl 安装"></a>方法二：使用 kubectl 安装</h3><ol><li>直接应用官方的安装清单：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/v1.5.3/deploy/longhorn.yaml</span><br></pre></td></tr></table></figure><h3 id="方法三：使用-ArgoCD-安装"><a href="#方法三：使用-ArgoCD-安装" class="headerlink" title="方法三：使用 ArgoCD 安装"></a>方法三：使用 ArgoCD 安装</h3><p>如果您的集群使用 ArgoCD 进行 GitOps 管理，可以通过以下方式部署 Longhorn：</p><ol><li>创建 Application 配置文件 <code>longhorn-application.yaml</code>：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">argoproj.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Application</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">longhorn</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">argocd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">project:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">source:</span></span><br><span class="line">    <span class="attr">chart:</span> <span class="string">longhorn</span></span><br><span class="line">    <span class="attr">repoURL:</span> <span class="string">https://charts.longhorn.io</span></span><br><span class="line">    <span class="attr">targetRevision:</span> <span class="number">1.8</span><span class="number">.1</span></span><br><span class="line">    <span class="attr">helm:</span></span><br><span class="line">      <span class="attr">values:</span> <span class="string">|</span></span><br><span class="line"><span class="string">        defaultSettings:</span></span><br><span class="line"><span class="string">          defaultDataPath: /data/longhorn</span></span><br><span class="line"><span class="string">          # 可选：配置备份存储位置</span></span><br><span class="line"><span class="string">          backupTarget: s3://backups@us-east-1/</span></span><br><span class="line"><span class="string">          backupTargetCredentialSecret: longhorn-backup-secret</span></span><br><span class="line"><span class="string">        persistence:</span></span><br><span class="line"><span class="string">          defaultClass: true</span></span><br><span class="line"><span class="string">          defaultClassReplicaCount: 3</span></span><br><span class="line"><span class="string"></span>  <span class="attr">destination:</span></span><br><span class="line">    <span class="attr">server:</span> <span class="string">https://kubernetes.default.svc</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">longhorn-system</span></span><br><span class="line">  <span class="attr">syncPolicy:</span></span><br><span class="line">    <span class="attr">automated:</span></span><br><span class="line">      <span class="attr">prune:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">selfHeal:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">syncOptions:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">CreateNamespace=true</span></span><br></pre></td></tr></table></figure><ol start="2"><li>如果需要配置备份到 S3，创建密钥文件 <code>backup-secret.yaml</code>：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">longhorn-backup-secret</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">longhorn-system</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">stringData:</span></span><br><span class="line">  <span class="attr">AWS_ACCESS_KEY_ID:</span> <span class="string">your-access-key</span></span><br><span class="line">  <span class="attr">AWS_SECRET_ACCESS_KEY:</span> <span class="string">your-secret-key</span></span><br><span class="line">  <span class="attr">AWS_ENDPOINTS:</span> <span class="string">https://s3.us-east-1.amazonaws.com/</span></span><br></pre></td></tr></table></figure><ol start="3"><li>应用配置：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 namespace（如果不存在）</span></span><br><span class="line">kubectl create namespace longhorn-system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果配置了备份，先创建 secret</span></span><br><span class="line">kubectl apply -f backup-secret.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 ArgoCD Application</span></span><br><span class="line">kubectl apply -f longhorn-application.yaml</span><br></pre></td></tr></table></figure><ol start="4"><li>验证部署状态：<ul><li>在 ArgoCD UI 中查看应用同步状态</li><li>等待所有资源创建完成</li><li>检查 Pod 状态：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n longhorn-system</span><br></pre></td></tr></table></figure></li></ul></li></ol><h2 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h2><ol><li>检查所有 Pod 是否正常运行：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n longhorn-system</span><br></pre></td></tr></table></figure><p>预期输出应该显示所有 Pod 都处于 Running 状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">longhorn-manager-pzqsp                     1/1     Running   0          5m</span><br><span class="line">longhorn-driver-deployer-7fd7f8b5c-shpkj   1/1     Running   0          5m</span><br><span class="line">longhorn-ui-78f64844b9-mb7t2              1/1     Running   0          5m</span><br><span class="line">csi-attacher-7bf4b7f996-df8v6             1/1     Running   0          4m</span><br><span class="line">csi-provisioner-869bdc4b79-mzrwf          1/1     Running   0          4m</span><br><span class="line">csi-resizer-6d8cf5f99f-fd2ck              1/1     Running   0          4m</span><br><span class="line">csi-snapshotter-588457fcdf-22bqp          1/1     Running   0          4m</span><br></pre></td></tr></table></figure><ol start="2"><li>验证 StorageClass 是否创建：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get sc</span><br></pre></td></tr></table></figure><p>应该能看到 longhorn StorageClass：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                 PROVISIONER          RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">longhorn (default)   driver.longhorn.io   Delete          Immediate           true                   5m</span><br></pre></td></tr></table></figure><h2 id="访问-Longhorn-UI"><a href="#访问-Longhorn-UI" class="headerlink" title="访问 Longhorn UI"></a>访问 Longhorn UI</h2><ol><li>创建 Ingress（可选）：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">longhorn-ingress</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">longhorn-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">longhorn.example.com</span>  <span class="comment"># 替换为您的域名</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">longhorn-frontend</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><ol start="2"><li>或者使用端口转发：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl port-forward service/longhorn-frontend 8000:80 -n longhorn-system</span><br></pre></td></tr></table></figure><p>然后访问 <code>http://localhost:8000</code></p><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p>创建一个使用 Longhorn 存储的示例 Pod：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">longhorn-test-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">longhorn</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">2Gi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:stable-alpine</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">longhorn-test-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">longhorn-test-volume</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">longhorn-test-pvc</span></span><br></pre></td></tr></table></figure><h2 id="常见问题处理"><a href="#常见问题处理" class="headerlink" title="常见问题处理"></a>常见问题处理</h2><ol><li>Pod 无法调度到节点</li></ol><ul><li>检查节点是否满足 Longhorn 的系统要求</li><li>确认 iscsid 服务是否正常运行</li><li>查看 Longhorn Manager 日志</li></ul><ol start="2"><li>存储卷创建失败</li></ol><ul><li>检查存储空间是否充足</li><li>确认网络连接是否正常</li><li>查看 Longhorn UI 中的事件日志</li></ul><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ol><li>存储配置</li></ol><ul><li>建议使用 SSD 作为存储介质</li><li>为不同类型的工作负载创建不同的 StorageClass</li><li>根据实际需求配置副本数量</li></ul><ol start="2"><li>备份策略</li></ol><ul><li>定期创建数据快照</li><li>配置远程备份到对象存储</li><li>制定灾难恢复计划</li></ul><h2 id="存储配置"><a href="#存储配置" class="headerlink" title="存储配置"></a>存储配置</h2><h3 id="指定节点参与-Longhorn-存储"><a href="#指定节点参与-Longhorn-存储" class="headerlink" title="指定节点参与 Longhorn 存储"></a>指定节点参与 Longhorn 存储</h3><ol><li>将需要作为存储的节点添加 label, storage&#x3D;longhorn<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node &lt;node-1&gt; storage=longhorn</span><br></pre></td></tr></table></figure></li><li>在1步中的节点对应的位置创建好目录<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/longhorn</span><br></pre></td></tr></table></figure></li><li>通过 Helm 安装时指定node<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">helm install longhorn longhorn/longhorn \</span><br><span class="line">    --namespace longhorn-system \</span><br><span class="line">    --set longhornManager.nodeSelector.storage=longhorn \</span><br><span class="line">    --set longhornDriver.nodeSelector.storage=longhorn \</span><br><span class="line">    --set longhornUI.nodeSelector.storage=longhorn \</span><br><span class="line">    --set defaultSettings.defaultDataPath=&quot;/data/longhorn&quot;</span><br></pre></td></tr></table></figure></li></ol><h3 id="配置节点默认存储路径"><a href="#配置节点默认存储路径" class="headerlink" title="配置节点默认存储路径"></a>配置节点默认存储路径</h3><p>Longhorn 默认使用 <code>/var/lib/longhorn</code> 作为存储路径。您可以通过以下方式修改默认存储路径：</p><ol><li><p>在 Longhorn UI 中修改：</p><ul><li>访问 Longhorn UI</li><li>点击 “Setting” -&gt; “General” -&gt; “Default Data Path”</li><li>修改为您想要的路径，如 <code>/data/longhorn</code></li></ul></li><li><p>通过 Helm 安装时指定：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">helm install longhorn longhorn/longhorn \</span><br><span class="line">  --namespace longhorn-system \</span><br><span class="line">  --create-namespace \</span><br><span class="line">  --version 1.8.1 \</span><br><span class="line">  --<span class="built_in">set</span> defaultSettings.defaultDataPath=<span class="string">&quot;/data/longhorn&quot;</span></span><br></pre></td></tr></table></figure><h3 id="配置额外的存储目录"><a href="#配置额外的存储目录" class="headerlink" title="配置额外的存储目录"></a>配置额外的存储目录</h3><p>您可以为节点添加多个存储目录或磁盘：</p><ol><li><p>准备存储目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在节点上创建目录</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /data/longhorn-1</span><br><span class="line"><span class="built_in">mkdir</span> -p /data/longhorn-2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保目录权限正确</span></span><br><span class="line"><span class="built_in">chmod</span> 700 /data/longhorn-*</span><br><span class="line"><span class="built_in">chown</span> root:root /data/longhorn-*</span><br></pre></td></tr></table></figure></li><li><p>在 Longhorn UI 中添加磁盘：</p><ul><li>进入 “Node” 页面</li><li>选择要配置的节点</li><li>点击 “Edit Node and Disks”</li><li>在 “Add Disk” 部分：<ul><li>输入磁盘路径（如 <code>/data/longhorn-1</code>）</li><li>设置磁盘调度选项</li><li>设置存储预留空间</li><li>点击 “Save” 保存配置</li></ul></li></ul></li></ol><h3 id="使用原始磁盘设备"><a href="#使用原始磁盘设备" class="headerlink" title="使用原始磁盘设备"></a>使用原始磁盘设备</h3><p>如果要使用原始磁盘设备作为存储：</p><ol><li><p>准备磁盘：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看可用磁盘</span></span><br><span class="line">lsblk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 格式化磁盘（假设使用 /dev/sdb）</span></span><br><span class="line">mkfs.ext4 /dev/sdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建挂载点</span></span><br><span class="line"><span class="built_in">mkdir</span> -p /data/longhorn-disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载磁盘</span></span><br><span class="line">mount /dev/sdb /data/longhorn-disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到 fstab 以确保重启后自动挂载</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;/dev/sdb /data/longhorn-disk ext4 defaults 0 0&quot;</span> &gt;&gt; /etc/fstab</span><br></pre></td></tr></table></figure></li><li><p>在 Longhorn UI 中添加磁盘：</p><ul><li>路径填写磁盘的挂载点（如 <code>/data/longhorn-disk</code>）</li><li>其他步骤同上</li></ul></li></ol><h3 id="存储标签（Storage-Tags）"><a href="#存储标签（Storage-Tags）" class="headerlink" title="存储标签（Storage Tags）"></a>存储标签（Storage Tags）</h3><p>您可以使用存储标签来管理不同性能的存储：</p><ol><li><p>添加标签：</p><ul><li>在 Longhorn UI 中选择节点和磁盘</li><li>添加标签，如：<ul><li><code>ssd=true</code> 用于 SSD 存储</li><li><code>hdd=true</code> 用于 HDD 存储</li></ul></li></ul></li><li><p>在创建卷时使用标签：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">longhorn-ssd</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">driver.longhorn.io</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">numberOfReplicas:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">  <span class="attr">diskSelector:</span> <span class="string">&quot;ssd&quot;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">high-perf-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">longhorn-ssd</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gi</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="存储最佳实践"><a href="#存储最佳实践" class="headerlink" title="存储最佳实践"></a>存储最佳实践</h3><ol><li><p>容量规划</p><ul><li>为系统预留足够空间（建议 30% 以上）</li><li>考虑副本数量对存储空间的影响</li><li>定期监控存储使用情况</li></ul></li><li><p>性能优化</p><ul><li>使用 SSD 作为主存储</li><li>合理设置副本数量（通常为 3）</li><li>避免在系统盘上存储数据</li></ul></li><li><p>可靠性保障</p><ul><li>使用 RAID 配置提高可靠性</li><li>配置定期备份</li><li>启用磁盘健康检查</li></ul></li><li><p>监控告警</p><ul><li>配置存储空间告警阈值</li><li>监控磁盘 I&#x2F;O 性能</li><li>设置节点状态监控</li></ul></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://longhorn.io/docs/">Longhorn 官方文档</a></li><li><a href="https://github.com/longhorn/longhorn">Longhorn GitHub</a></li><li><a href="https://kubernetes.io/docs/concepts/storage/">Kubernetes 存储文档</a></li></ul><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> DevOps </category>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 存储 </tag>
            
            <tag> Longhorn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Python开发自己的MCP服务：AI能力扩展入门指南</title>
      <link href="/AI/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84MCP/"/>
      <url>/AI/%E4%BD%BF%E7%94%A8python%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84MCP/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>随着人工智能技术的快速发展，大语言模型（LLM）如ChatGPT、Claude等已经成为了改变我们工作和生活方式的强大工具。但你是否想过，如何让这些AI模型具备访问外部工具和数据的能力，从而解决更复杂的问题？今天，我将向大家介绍一项令人兴奋的技术——模型上下文协议（Model Context Protocol，简称MCP），并教你如何使用Python开发自己的MCP服务，为AI模型赋予更强大的能力。</p><h2 id="什么是MCP？"><a href="#什么是MCP？" class="headerlink" title="什么是MCP？"></a>什么是MCP？</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>模型上下文协议（MCP）是一个开放标准，用于AI应用程序与大型语言模型之间的通信。它定义了一套标准接口，使应用程序能够向模型提供上下文信息，并允许模型调用应用程序暴露的工具。</p><p>简单来说，MCP就像是AI模型和外部世界之间的一座桥梁，让模型能够”看见”和”操作”外部的数据和功能。</p><h3 id="为什么需要MCP？"><a href="#为什么需要MCP？" class="headerlink" title="为什么需要MCP？"></a>为什么需要MCP？</h3><p>想象一下，如果你正在与ChatGPT聊天，希望它能够：</p><ul><li>查询你的个人日历</li><li>分析你的Excel数据</li><li>控制你的智能家居设备</li><li>从你的私有数据库中获取信息</li></ul><p>这些功能都需要AI模型能够访问外部系统和数据，而MCP正是为解决这一需求而生的。</p><h2 id="MCP的核心组件"><a href="#MCP的核心组件" class="headerlink" title="MCP的核心组件"></a>MCP的核心组件</h2><p>MCP协议定义了三个核心原语，每一个都扮演着重要的角色：</p><table><thead><tr><th>原语</th><th>控制权</th><th>描述</th><th>示例应用</th></tr></thead><tbody><tr><td>Prompts（提示）</td><td>用户控制</td><td>用户可以选择调用的交互式模板</td><td>快捷命令、应用菜单</td></tr><tr><td>Resources（资源）</td><td>应用程序控制</td><td>应用程序管理的上下文数据</td><td>文件内容、数据库记录</td></tr><tr><td>Tools（工具）</td><td>模型控制</td><td>AI模型可调用的函数</td><td>API请求、数据处理</td></tr></tbody></table><p>这三种原语共同构成了MCP的基础，使模型能够以结构化的方式与外部世界交互。</p><h2 id="准备工作：安装MCP-Python-SDK"><a href="#准备工作：安装MCP-Python-SDK" class="headerlink" title="准备工作：安装MCP Python SDK"></a>准备工作：安装MCP Python SDK</h2><p>在开始开发MCP服务之前，我们需要安装MCP的Python SDK。打开你的终端并运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mcp</span><br></pre></td></tr></table></figure><p>这个简单的命令将安装所有必要的依赖，让你能够立即开始开发。</p><h2 id="创建你的第一个MCP服务"><a href="#创建你的第一个MCP服务" class="headerlink" title="创建你的第一个MCP服务"></a>创建你的第一个MCP服务</h2><p>让我们从一个简单的例子开始，创建一个能够执行基本数学运算的MCP服务。</p><h3 id="基本加法计算器"><a href="#基本加法计算器" class="headerlink" title="基本加法计算器"></a>基本加法计算器</h3><p>创建一个名为<code>calculator.py</code>的文件，并添加以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个名为&quot;简易计算器&quot;的MCP服务器</span></span><br><span class="line">mcp = FastMCP(<span class="string">&quot;简易计算器&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个加法工具</span></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a: <span class="built_in">int</span>, b: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add two numbers together&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务器</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    mcp.run()</span><br></pre></td></tr></table></figure><p>这段代码创建了一个简单的MCP服务，它提供了一个<code>add</code>工具，可以将两个数字相加。</p><h3 id="运行你的MCP服务"><a href="#运行你的MCP服务" class="headerlink" title="运行你的MCP服务"></a>运行你的MCP服务</h3><p>现在，你可以在终端中运行这个服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python calculator.py</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">mcp run calculator.py</span><br></pre></td></tr></table></figure><p>一旦服务启动，它就可以被支持MCP的AI模型或应用程序使用了。</p><h2 id="进阶：创建功能丰富的MCP服务"><a href="#进阶：创建功能丰富的MCP服务" class="headerlink" title="进阶：创建功能丰富的MCP服务"></a>进阶：创建功能丰富的MCP服务</h2><p>在了解了基础知识后，让我们创建一个更复杂的MCP服务，它包含了所有三种核心原语：提示、资源和工具。</p><h3 id="多功能助手服务"><a href="#多功能助手服务" class="headerlink" title="多功能助手服务"></a>多功能助手服务</h3><p>创建一个名为<code>assistant.py</code>的文件，并添加以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个名为&quot;多功能助手&quot;的MCP服务器</span></span><br><span class="line">mcp = FastMCP(<span class="string">&quot;多功能助手&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个资源：当前时间</span></span><br><span class="line"><span class="meta">@mcp.resource(<span class="params"><span class="string">&quot;time://current&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">current_time</span>() -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return the current time as a resource&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> datetime.datetime.now().strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个工具：掷骰子</span></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">roll_dice</span>(<span class="params">sides: <span class="built_in">int</span> = <span class="number">6</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Roll a dice with the specified number of sides&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> random.randint(<span class="number">1</span>, sides)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个工具：计算BMI</span></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_bmi</span>(<span class="params">weight_kg: <span class="built_in">float</span>, height_m: <span class="built_in">float</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Calculate BMI given weight in kg and height in meters&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> weight_kg / (height_m * height_m)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个提示：创建健康建议</span></span><br><span class="line"><span class="meta">@mcp.prompt()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">health_advice</span>(<span class="params">user_name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate a prompt for health advice&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;请为<span class="subst">&#123;user_name&#125;</span>提供一些基于科学的健康生活方式建议。考虑饮食、运动和睡眠方面的建议。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务器</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    mcp.run()</span><br></pre></td></tr></table></figure><p>这个多功能助手服务提供了:</p><ul><li>一个资源：获取当前时间</li><li>两个工具：掷骰子和计算BMI</li><li>一个提示模板：生成健康建议</li></ul><h2 id="高级功能：整合外部API"><a href="#高级功能：整合外部API" class="headerlink" title="高级功能：整合外部API"></a>高级功能：整合外部API</h2><p>MCP服务的真正力量在于它能够将AI模型与外部系统和API集成。下面是一个示例，展示如何创建一个能够获取天气信息的MCP服务：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个名为&quot;天气助手&quot;的MCP服务器</span></span><br><span class="line">mcp = FastMCP(<span class="string">&quot;天气助手&quot;</span>)</span><br><span class="line"></span><br><span class="line">API_KEY = <span class="string">&quot;your_api_key_here&quot;</span>  <span class="comment"># 替换为你的API密钥</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_weather</span>(<span class="params">city: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get current weather for a specified city&quot;&quot;&quot;</span></span><br><span class="line">    url = <span class="string">f&quot;https://api.weatherapi.com/v1/current.json?key=<span class="subst">&#123;API_KEY&#125;</span>&amp;q=<span class="subst">&#123;city&#125;</span>&quot;</span></span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        data = response.json()</span><br><span class="line">        temp_c = data[<span class="string">&quot;current&quot;</span>][<span class="string">&quot;temp_c&quot;</span>]</span><br><span class="line">        condition = data[<span class="string">&quot;current&quot;</span>][<span class="string">&quot;condition&quot;</span>][<span class="string">&quot;text&quot;</span>]</span><br><span class="line">        humidity = data[<span class="string">&quot;current&quot;</span>][<span class="string">&quot;humidity&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;City: <span class="subst">&#123;city&#125;</span>, Temperature: <span class="subst">&#123;temp_c&#125;</span>°C, Condition: <span class="subst">&#123;condition&#125;</span>, Humidity: <span class="subst">&#123;humidity&#125;</span>%&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Error fetching weather data: <span class="subst">&#123;response.status_code&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务器</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    mcp.run()</span><br></pre></td></tr></table></figure><p>这个服务通过调用外部的天气API，为模型提供了获取实时天气信息的能力。</p><h2 id="将MCP服务与现有应用集成"><a href="#将MCP服务与现有应用集成" class="headerlink" title="将MCP服务与现有应用集成"></a>将MCP服务与现有应用集成</h2><p>如果你已经有一个现有的Web应用程序，你可以将MCP服务集成到其中。以下是如何将MCP服务与Starlette（一个轻量级的ASGI框架）集成的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> starlette.applications <span class="keyword">import</span> Starlette</span><br><span class="line"><span class="keyword">from</span> starlette.routing <span class="keyword">import</span> Mount</span><br><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建MCP服务</span></span><br><span class="line">mcp = FastMCP(<span class="string">&quot;集成服务&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate a greeting message&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Hello, <span class="subst">&#123;name&#125;</span>! Welcome to our integrated service.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将MCP服务挂载到Starlette应用</span></span><br><span class="line">app = Starlette(</span><br><span class="line">    routes=[</span><br><span class="line">        Mount(<span class="string">&#x27;/mcp&#x27;</span>, app=mcp.sse_app()),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务器</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure><p>通过这种方式，你可以在不改变现有应用架构的情况下，为它添加AI能力。</p><h2 id="高级概念：状态管理"><a href="#高级概念：状态管理" class="headerlink" title="高级概念：状态管理"></a>高级概念：状态管理</h2><p>有时，你需要在不同的请求之间保持状态。下面是一个简单的待办事项管理器，它展示了如何在MCP服务中管理状态：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个名为&quot;待办事项管理器&quot;的MCP服务器</span></span><br><span class="line">mcp = FastMCP(<span class="string">&quot;待办事项管理器&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用一个简单的列表来存储待办事项</span></span><br><span class="line">todos = []</span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_todo</span>(<span class="params">task: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Add a new task to the todo list&quot;&quot;&quot;</span></span><br><span class="line">    todos.append(task)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Task added: <span class="subst">&#123;task&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">list_todos</span>() -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;List all tasks in the todo list&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> todos:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;No tasks in the todo list.&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n&quot;</span>.join([<span class="string">f&quot;<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>. <span class="subst">&#123;task&#125;</span>&quot;</span> <span class="keyword">for</span> i, task <span class="keyword">in</span> <span class="built_in">enumerate</span>(todos)])</span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">complete_todo</span>(<span class="params">task_number: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Mark a task as completed and remove it from the list&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> todos <span class="keyword">or</span> task_number &lt;= <span class="number">0</span> <span class="keyword">or</span> task_number &gt; <span class="built_in">len</span>(todos):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Invalid task number.&quot;</span></span><br><span class="line">    task = todos.pop(task_number - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Completed task: <span class="subst">&#123;task&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务器</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    mcp.run()</span><br></pre></td></tr></table></figure><p>这个示例展示了如何使用全局变量来保存状态。在实际应用中，你可能需要使用数据库或其他持久化存储方案。</p><h2 id="客户端与MCP服务的交互"><a href="#客户端与MCP服务的交互" class="headerlink" title="客户端与MCP服务的交互"></a>客户端与MCP服务的交互</h2><p>MCP不仅定义了服务器端的接口，还定义了客户端如何与这些服务交互。下面是一个简单的客户端示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mcp <span class="keyword">import</span> ClientSession, StdioServerParameters</span><br><span class="line"><span class="keyword">from</span> mcp.client.stdio <span class="keyword">import</span> stdio_client</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建服务器参数</span></span><br><span class="line">server_params = StdioServerParameters(</span><br><span class="line">    command=<span class="string">&quot;python&quot;</span>,</span><br><span class="line">    args=[<span class="string">&quot;calculator.py&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> stdio_client(server_params) <span class="keyword">as</span> (read, write):</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> ClientSession(read, write) <span class="keyword">as</span> session:</span><br><span class="line">            <span class="comment"># 初始化连接</span></span><br><span class="line">            <span class="keyword">await</span> session.initialize()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 列出可用的工具</span></span><br><span class="line">            tools = <span class="keyword">await</span> session.list_tools()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Available tools: <span class="subst">&#123;tools&#125;</span>&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 调用add工具</span></span><br><span class="line">            result = <span class="keyword">await</span> session.call_tool(<span class="string">&quot;add&quot;</span>, arguments=&#123;<span class="string">&quot;a&quot;</span>: <span class="number">5</span>, <span class="string">&quot;b&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;5 + 3 = <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> asyncio</span><br><span class="line">    asyncio.run(run())</span><br></pre></td></tr></table></figure><p>这个客户端脚本连接到我们之前创建的计算器服务，列出可用的工具，然后调用<code>add</code>工具计算5+3的结果。</p><h2 id="cursor中配置自己开发的MCP"><a href="#cursor中配置自己开发的MCP" class="headerlink" title="cursor中配置自己开发的MCP"></a>cursor中配置自己开发的MCP</h2><p>在mcp.json中添加mcp server</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;mcpServers&quot;: &#123;</span><br><span class="line">        &quot;server&quot;: &#123;</span><br><span class="line">            &quot;command&quot;: &quot;python&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;/User/admin/workspace/mcp-server/main.py&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e2a4744b18a4848844e6beb59757aab4357b5fd724a1902d19c4af7ac386a349.png" alt="customize mcp">  </p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/639a2155efa3163c6849d401ffdbd926cb45322509f9801dd8f5672bf3c6d3de.png" alt="mcp 示例">  </p><h2 id="实际应用场景"><a href="#实际应用场景" class="headerlink" title="实际应用场景"></a>实际应用场景</h2><p>MCP服务的应用场景非常广泛，以下是一些可能的使用案例：</p><ol><li><p><strong>个人助手</strong>：创建一个能够访问你的日历、邮件和文档的个人助手</p></li><li><p><strong>数据分析工具</strong>：开发一个能够处理和分析数据集的服务，让AI模型可以直接操作数据</p></li><li><p><strong>内容管理系统</strong>：构建一个服务，允许AI模型创建、编辑和发布内容到你的网站或博客</p></li><li><p><strong>企业知识库</strong>：开发一个能够安全访问企业内部文档和知识库的服务</p></li><li><p><strong>智能家居控制</strong>：创建一个服务，让AI能够控制你的智能家居设备</p></li></ol><h2 id="调试技巧"><a href="#调试技巧" class="headerlink" title="调试技巧"></a>调试技巧</h2><p>在开发MCP服务时，调试是一个重要的环节。以下是一些有用的调试技巧：</p><ol><li><strong>启用详细日志</strong>：在创建FastMCP实例时，可以启用详细日志：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mcp = FastMCP(<span class="string">&quot;调试服务&quot;</span>, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>添加自定义日志</strong>：在工具和资源处理函数中，添加打印语句：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_tool</span>(<span class="params">param: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;my_tool called with param: <span class="subst">&#123;param&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 处理逻辑</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>使用调试客户端</strong>：创建一个简单的客户端脚本，专门用于测试你的服务</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MCP为开发者提供了一种强大的方式，让AI模型能够与外部世界交互，从而扩展其能力范围。通过使用Python和MCP SDK，即使是初学者也能轻松地开发出功能丰富的MCP服务，为AI模型赋予更强大的能力。</p><p>无论你是想创建个人助手、企业工具，还是创新的AI应用，MCP都为你提供了所需的基础设施。随着对MCP的深入学习和实践，你将能够构建出更加复杂和强大的系统，充分发挥AI技术的潜力。</p><h2 id="学习资源"><a href="#学习资源" class="headerlink" title="学习资源"></a>学习资源</h2><ul><li><a href="https://github.com/modelcontextprotocol/python-sdk">MCP Python SDK GitHub 仓库</a></li><li><a href="https://modelcontextprotocol.io/docs/">Model Context Protocol 官方文档</a></li><li><a href="https://docs.python.org/zh-cn/3/">Python 官方文档</a></li><li><a href="https://docs.anthropic.com/claude/">Anthropic Claude 开发者文档</a></li></ul><p>开始你的MCP开发之旅吧，相信不久的将来，你将能够创建出令人惊叹的AI驱动应用！</p><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> 开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> MCP </tag>
            
            <tag> AI开发 </tag>
            
            <tag> 大语言模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用NSSM将程序注册为Windows服务</title>
      <link href="/DevOps/%E4%BD%BF%E7%94%A8NSSM%E5%B0%86%E7%A8%8B%E5%BA%8F%E6%B3%A8%E5%86%8C%E4%B8%BAWindows%E6%9C%8D%E5%8A%A1/"/>
      <url>/DevOps/%E4%BD%BF%E7%94%A8NSSM%E5%B0%86%E7%A8%8B%E5%BA%8F%E6%B3%A8%E5%86%8C%E4%B8%BAWindows%E6%9C%8D%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p><a href="https://nssm.cc/">NSSM (Non-Sucking Service Manager)</a> 是一个非常实用的Windows服务管理工具，它可以将任何应用程序注册为Windows服务，支持开机自启动、失败自动重启等功能，本文将介绍如何使用NSSM，并以Nginx为例进行实践。</p><h2 id="NSSM简介"><a href="#NSSM简介" class="headerlink" title="NSSM简介"></a>NSSM简介</h2><p>NSSM的主要特点：</p><ul><li>可以将任何可执行程序注册为Windows服务</li><li>支持服务失败自动重启</li><li>支持开机自动启动</li><li>可以捕获程序的标准输出和错误输出到日志文件</li><li>提供图形界面和命令行两种操作方式</li><li>完全免费开源</li></ul><h2 id="安装NSSM"><a href="#安装NSSM" class="headerlink" title="安装NSSM"></a>安装NSSM</h2><ol><li><p>下载NSSM<br>访问 <a href="https://nssm.cc/download">NSSM官网</a> 下载最新版本<br>或使用 <a href="https://chocolatey.org/">Chocolatey</a> 包管理器安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">choco install nssm</span><br></pre></td></tr></table></figure></li><li><p>解压下载的zip文件（如果是手动下载）<br>将win64目录下的nssm.exe复制到一个固定目录，比如：<code>C:\Program Files\nssm</code></p></li><li><p>添加环境变量（可选）<br>将nssm.exe所在目录添加到系统PATH环境变量中</p></li></ol><h2 id="使用NSSM注册Nginx服务"><a href="#使用NSSM注册Nginx服务" class="headerlink" title="使用NSSM注册Nginx服务"></a>使用NSSM注册Nginx服务</h2><h3 id="图形界面方式"><a href="#图形界面方式" class="headerlink" title="图形界面方式"></a>图形界面方式</h3><ol><li><p>打开命令提示符，输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nssm install nginx</span><br></pre></td></tr></table></figure></li><li><p>在弹出的图形界面中配置：</p></li></ol><ul><li>Path：填写nginx.exe的完整路径，如：<code>C:\nginx\nginx.exe</code></li><li>Startup directory：填写nginx的安装目录，如：<code>C:\nginx</code></li><li>Service name：服务名称，默认为”nginx”</li></ul><ol start="3"><li>切换到”Details”标签：</li></ol><ul><li>Display name：显示名称，如：”Nginx Web Server”</li><li>Description：描述信息，如：”Nginx HTTP and reverse proxy server”</li></ul><ol start="4"><li>切换到”Log on”标签：</li></ol><ul><li>选择”Local System account”（推荐）</li></ul><ol start="5"><li>切换到”I&#x2F;O”标签：</li></ol><ul><li>Output (stdout)：设置标准输出日志路径，如：<code>C:\nginx\logs\service-stdout.log</code></li><li>Error (stderr)：设置错误输出日志路径，如：<code>C:\nginx\logs\service-error.log</code></li></ul><ol start="6"><li>切换到”Exit actions”标签：</li></ol><ul><li>Restart：选择”Restart application”</li><li>Delay：设置重启延迟，如：30000（30秒）</li></ul><h3 id="命令行方式"><a href="#命令行方式" class="headerlink" title="命令行方式"></a>命令行方式</h3><p>也可以使用命令行一次性完成配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">nssm install nginx <span class="string">&quot;C:\nginx\nginx.exe&quot;</span></span><br><span class="line">nssm <span class="built_in">set</span> nginx AppDirectory <span class="string">&quot;C:\nginx&quot;</span></span><br><span class="line">nssm <span class="built_in">set</span> nginx DisplayName <span class="string">&quot;Nginx Web Server&quot;</span></span><br><span class="line">nssm <span class="built_in">set</span> nginx Description <span class="string">&quot;Nginx HTTP and reverse proxy server&quot;</span></span><br><span class="line">nssm <span class="built_in">set</span> nginx AppStdout <span class="string">&quot;C:\nginx\logs\service-stdout.log&quot;</span></span><br><span class="line">nssm <span class="built_in">set</span> nginx AppStderr <span class="string">&quot;C:\nginx\logs\service-error.log&quot;</span></span><br><span class="line">nssm <span class="built_in">set</span> nginx AppRestartDelay 30000</span><br></pre></td></tr></table></figure><h2 id="服务管理命令"><a href="#服务管理命令" class="headerlink" title="服务管理命令"></a>服务管理命令</h2><ol><li><p>启动服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nssm start nginx</span><br></pre></td></tr></table></figure></li><li><p>停止服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nssm stop nginx</span><br></pre></td></tr></table></figure></li><li><p>重启服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nssm restart nginx</span><br></pre></td></tr></table></figure></li><li><p>查看服务状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nssm status nginx</span><br></pre></td></tr></table></figure></li><li><p>移除服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nssm remove nginx</span><br></pre></td></tr></table></figure></li></ol><h2 id="常见问题处理"><a href="#常见问题处理" class="headerlink" title="常见问题处理"></a>常见问题处理</h2><ol><li>服务启动失败</li></ol><ul><li>检查程序路径是否正确</li><li>检查程序所需的依赖文件是否完整</li><li>查看Windows事件查看器中的错误日志</li><li>检查服务账户是否有足够权限</li></ul><ol start="2"><li>日志文件无法创建</li></ol><ul><li>确保日志目录存在</li><li>确保服务账户对日志目录有写入权限</li></ul><ol start="3"><li>程序异常退出不重启</li></ol><ul><li>检查Exit actions标签中的重启设置</li><li>适当调整重启延迟时间</li></ul><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><ol><li>路径设置</li></ol><ul><li>使用绝对路径</li><li>避免路径中包含空格，如果无法避免，请使用引号包围</li><li>建议将程序安装在系统盘之外的分区</li></ul><ol start="2"><li>日志管理</li></ol><ul><li>设置日志轮转，避免日志文件过大</li><li>定期清理旧日志</li><li>建议使用专门的日志目录</li></ul><ol start="3"><li>权限控制</li></ol><ul><li>使用最小权限原则</li><li>必要时创建专门的服务账户</li><li>定期检查和更新权限设置</li></ul><ol start="4"><li>监控告警</li></ol><ul><li>配置服务监控</li><li>设置异常重启告警</li><li>定期检查服务状态</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>NSSM是一个强大的Windows服务管理工具，通过它可以轻松地将普通程序转换为Windows服务，实现自动化运维。本文以Nginx为例介绍了NSSM的基本使用方法，希望对大家有所帮助。在实际应用中，还可以根据具体需求进行更多个性化配置。</p><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> windows </tag>
            
            <tag> nssm </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在Cursor中配置MCP</title>
      <link href="/AI/%E5%9C%A8Cursor%E4%B8%AD%E9%85%8D%E7%BD%AEMCP/"/>
      <url>/AI/%E5%9C%A8Cursor%E4%B8%AD%E9%85%8D%E7%BD%AEMCP/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是Cursor-MCP"><a href="#什么是Cursor-MCP" class="headerlink" title="什么是Cursor MCP"></a>什么是Cursor MCP</h2><p>MCP (Model Context Protocol) 是由Anthropic公司开发的协议，旨在让大型语言模型(LLM)能够安全地与外部工具和服务交互。Cursor作为先进的AI编程工具，集成了MCP功能，允许Cursor连接自定义AI模型服务器，扩展AI助手能力，连接第三方服务（GitHub、Jira等）。通过MCP，AI助手能够获取实时数据、执行特定操作，大大增强了其实用性和功能范围。</p><h2 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h2><h3 id="1-打开MCP配置界面"><a href="#1-打开MCP配置界面" class="headerlink" title="1. 打开MCP配置界面"></a>1. 打开MCP配置界面</h3><ol><li>打开Cursor</li><li>点击左下角设置图标或使用快捷键 <code>Ctrl+Shift+P</code>（Windows）&#x2F;<code>Cmd+Shift+P</code>（Mac）</li><li>搜索并选择”Cursor Settings”</li><li>在左侧边栏选择”MCP”</li></ol><h3 id="2-添加MCP服务器"><a href="#2-添加MCP服务器" class="headerlink" title="2. 添加MCP服务器"></a>2. 添加MCP服务器</h3><p>在MCP Servers部分，点击”Add new MCP server”，推荐配置以下三个服务器：</p><h4 id="2-1-GitHub-MCP-Server"><a href="#2-1-GitHub-MCP-Server" class="headerlink" title="2.1 GitHub MCP Server"></a>2.1 GitHub MCP Server</h4><ul><li><strong>Name</strong>: GitHub</li><li><strong>Type</strong>: command</li><li><strong>Command</strong>: <code>npx -y @modelcontextprotocol/server-github</code></li></ul><p><strong>主要功能</strong>：</p><ul><li>文件操作：创建、更新文件，提交多个文件</li><li>仓库管理：搜索、创建仓库，管理分支</li><li>Issue和PR：创建、更新、评论Issue，管理PR</li><li>代码搜索：按语言、路径、文件类型搜索代码</li></ul><p><strong>配置GitHub令牌</strong>：</p><ul><li>在GitHub创建个人访问令牌（需要<code>repo</code>权限）</li><li>使用环境变量： <code>GITHUB_PERSONAL_ACCESS_TOKEN=你的令牌</code></li></ul><h4 id="2-2-Atlassian-MCP-Server"><a href="#2-2-Atlassian-MCP-Server" class="headerlink" title="2.2 Atlassian MCP Server"></a>2.2 Atlassian MCP Server</h4><ul><li><strong>Name</strong>: Atlassian</li><li><strong>Type</strong>: command</li><li><strong>Command</strong>: <code>uvx mcp-atlassian --confluence-url=https://your-domain.atlassian.net/wiki --confluence-username=你的邮箱 --confluence-token=你的令牌 --jira-url=https://your-domain.atlassian.net --jira-username=你的邮箱 --jira-token=你的令牌</code></li></ul><p>先安装uvx：<code>pip install uv</code></p><p><strong>主要功能</strong>：</p><ul><li>Confluence：搜索内容，获取&#x2F;创建&#x2F;更新&#x2F;删除页面</li><li>Jira：查询issue，创建&#x2F;更新任务，状态转换，添加工作日志</li><li>项目管理：链接issue到Epic，获取项目的所有issue</li></ul><p><strong>配置Atlassian令牌</strong>：</p><ul><li>在 <a href="https://id.atlassian.com/manage/api-tokens">https://id.atlassian.com/manage/api-tokens</a> 创建API令牌</li></ul><h4 id="2-3-Time-MCP-Server"><a href="#2-3-Time-MCP-Server" class="headerlink" title="2.3 Time MCP Server"></a>2.3 Time MCP Server</h4><ul><li><strong>Name</strong>: Time</li><li><strong>Type</strong>: command</li><li><strong>Command</strong>: <code>npx -y @modelcontextprotocol/server-time</code></li></ul><p>也可使用：<code>uvx mcp-server-time</code></p><p><strong>主要功能</strong>：</p><ul><li>获取当前时间：获取特定时区或系统时区的当前时间</li><li>时区转换：在不同时区之间转换时间</li><li>自定义时区：支持设置默认时区（如<code>--local-timezone=Asia/Shanghai</code>）</li></ul><h3 id="3-完整配置示例"><a href="#3-完整配置示例" class="headerlink" title="3. 完整配置示例"></a>3. 完整配置示例</h3><p>以下是三个MCP服务器的完整配置示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;github&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;npx&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;-y&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;@modelcontextprotocol/server-github&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;</span><span class="punctuation">:</span> <span class="string">&quot;github token&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;GITHUB_USERNAME&quot;</span><span class="punctuation">:</span> <span class="string">&quot;github username&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;atlassian&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;uvx&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;mcp-atlassian&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;JIRA_URL&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://&lt;jira url&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;JIRA_USERNAME&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jira username&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;JIRA_PERSONAL_TOKEN&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jira token&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;time&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;uvx&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;mcp-server-time&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;--local-timezone=Asia/Shanghai&quot;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>windows下配置需要特别注意command需要全路径，如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;mcpServers&quot;: &#123;</span><br><span class="line">        &quot;github&quot;: &#123;</span><br><span class="line">            &quot;command&quot;: &quot;cmd&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;/c&quot;,</span><br><span class="line">                &quot;npx -y @modelcontextprotocol/server-github&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;env&quot;: &#123;</span><br><span class="line">                &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;github token&quot;,</span><br><span class="line">                &quot;GITHUB_USERNAME&quot;: &quot;github username&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;filesystem&quot;: &#123;</span><br><span class="line">            &quot;command&quot;: &quot;C:\\nodejs\\node.exe&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;C:\\Users\\admin\\AppData\\Roaming\\npm\\node_modules\\@modelcontextprotocol\\server-filesystem\\dist\\index.js&quot;,</span><br><span class="line">                &quot;D:\\&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;time&quot;: &#123;</span><br><span class="line">            &quot;command&quot;: &quot;C:\\Users\\admin\\.local\\bin\\uvx.exe&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;mcp-server-time&quot;,</span><br><span class="line">                &quot;--local-timezone=Asia/Shanghai&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-验证配置"><a href="#4-验证配置" class="headerlink" title="4. 验证配置"></a>4. 验证配置</h3><p>添加服务器后，服务器状态应显示为绿色，表示连接成功。黄色状态时，尝试刷新或重启Cursor。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/52d02b689a8968ac22c98627a4a5d9d47c63601300a0fd7040d5848a7bd29fb1.png" alt="MCP Status">  </p><h3 id="5-使用MCP功能"><a href="#5-使用MCP功能" class="headerlink" title="5. 使用MCP功能"></a>5. 使用MCP功能</h3><p>配置完成后：</p><ol><li>在Agent模式下使用MCP功能</li><li>在聊天窗口指示AI使用MCP工具，例如”使用GitHub创建一个新仓库”</li><li>在提示时选择接受</li></ol><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><ol><li><strong>服务器显示黄色状态</strong>：尝试刷新或重启Cursor</li><li><strong>命令执行失败</strong>：确认已安装Node.js，检查网络连接</li><li><strong>工具未显示</strong>：确认使用Agent模式，重启Cursor</li><li><strong>权限问题</strong>：确保API令牌正确且有足够权限</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过配置MCP，可以显著扩展Cursor功能，提高开发效率。推荐的三个服务器（GitHub、Atlassian和Time）满足开发者日常多种需求。</p><p>参考资料：</p><ul><li><a href="https://www.pulsemcp.com/clients/cursor-ide">Cursor MCP官方文档</a></li><li><a href="https://github.com/modelcontextprotocol/servers/tree/main/src/github">GitHub MCP Server文档</a></li><li><a href="https://github.com/sooperset/mcp-atlassian">sooperset&#x2F;mcp-atlassian</a></li><li><a href="https://github.com/modelcontextprotocol/servers/tree/main/src/time">Time MCP Server文档</a></li></ul><hr><blockquote><p>本文由 AI 辅助生成，如有错误或建议，欢迎指出。 </p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> ai </tag>
            
            <tag> cursor </tag>
            
            <tag> mcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在本地电脑部署AI大模型</title>
      <link href="/AI/%E5%9C%A8%E6%9C%AC%E5%9C%B0%E7%94%B5%E8%84%91%E9%83%A8%E7%BD%B2AI%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/AI/%E5%9C%A8%E6%9C%AC%E5%9C%B0%E7%94%B5%E8%84%91%E9%83%A8%E7%BD%B2AI%E5%A4%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>软件：</p><ul><li>ollama: <a href="https://ollama.com/">https://ollama.com/</a></li><li>docker: <a href="https://www.docker.com/">https://www.docker.com/</a></li><li>open-webui: <a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a></li></ul><h2 id="1-下载安装ollama-https-ollama-com-download"><a href="#1-下载安装ollama-https-ollama-com-download" class="headerlink" title="1. 下载安装ollama. https://ollama.com/download"></a>1. 下载安装ollama. <a href="https://ollama.com/download">https://ollama.com/download</a></h2><p>安装时，ollama默认安装在C盘，如果希望安装在其它盘，安装时可指定安装路径</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\OllamaSetup.exe /DIR=&#x27;D:\Program Files\Ollama&#x27;</span><br></pre></td></tr></table></figure><p>ollama 使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># ollama -h</span><br><span class="line">Large language model runner</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  ollama [flags]</span><br><span class="line">  ollama [command]</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  serve       Start ollama</span><br><span class="line">  create      Create a model from a Modelfile</span><br><span class="line">  show        Show information for a model</span><br><span class="line">  run         Run a model</span><br><span class="line">  stop        Stop a running model</span><br><span class="line">  pull        Pull a model from a registry</span><br><span class="line">  push        Push a model to a registry</span><br><span class="line">  list        List models</span><br><span class="line">  ps          List running models</span><br><span class="line">  cp          Copy a model</span><br><span class="line">  rm          Remove a model</span><br><span class="line">  help        Help about any command</span><br></pre></td></tr></table></figure><p>ollama 也支持 <a href="https://huggingface.co/models">Hugging Face</a> 模型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ollama run hf.co/&#123;用户名&#125;/&#123;模型仓库&#125;:&#123;标签&#125;</span><br><span class="line"># #如</span><br><span class="line"># ollama run hf.co/inclusionAI/Ming-Lite-Omni:latest</span><br></pre></td></tr></table></figure><p>Ming-lite-omni 是 Ming-omni 的轻量版本，源自 Ling-lite，具有 28 亿个激活参数。它是一个统一的多模态模型，能够处理图像、文本、音频和视频，并在语音和图像生成方面表现出色。</p><h2 id="2-安装本地模型-https-ollama-com-search"><a href="#2-安装本地模型-https-ollama-com-search" class="headerlink" title="2. 安装本地模型. https://ollama.com/search"></a>2. 安装本地模型. <a href="https://ollama.com/search">https://ollama.com/search</a></h2><ul><li><p><a href="https://ollama.com/PetrosStav/gemma3-tools">PetrosStav&#x2F;gemma3-tools</a>: 基于google gemma3模型，同时支持图片识别与tools。</p></li><li><p><a href="https://ollama.com/library/deepseek-r1">deepseek-r1</a>: 一个开放式推理模型家族，其性能接近O3和Gemini 2.5 Pro等领先模型。</p></li><li><p><a href="https://ollama.com/library/qwen3">qwen3</a>: 来自Alibaba的千问模型，对中文支持比较好,支持tools, thinking。</p></li><li><p><a href="https://ollama.com/library/qwen2.5-coder">qwen2.5-coder</a>: 用于代码生成，代码推理及代码修复。</p></li><li><p><a href="https://ollama.com/library/llama4">llama4</a>: Meta公司最新推出的大型语言模型, 擅长文本摘要、情感分析、代码生成等任务，但有限支持中文。</p></li><li><p><a href="https://ollama.com/library/gemma3">gemma3</a>: google开源的大语言模型，当前单卡最强的模型<br>根据需求下载特定模型，及参数版本。参数量越大对电脑配置要求越好，也越聪明。普通7B参数量即可。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/b9d87fdd8fc714f6c94619750dae56195757ddc2b263218f3e60cb38148a546b.png" alt="qwen2.5"></p></li></ul><p>本地终端运行命令下载及运行大模型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># ollama run qwen2.5</span><br><span class="line">pulling manifest</span><br><span class="line">pulling 2bada8a74506... 100% ▕████████████████████████████████████████████████████████▏ 4.7 GB</span><br><span class="line">pulling 66b9ea09bd5b... 100% ▕████████████████████████████████████████████████████████▏   68 B</span><br><span class="line">pulling eb4402837c78... 100% ▕████████████████████████████████████████████████████████▏ 1.5 KB</span><br><span class="line">pulling 832dd9e00a68... 100% ▕████████████████████████████████████████████████████████▏  11 KB</span><br><span class="line">pulling 2f15b3218f05... 100% ▕████████████████████████████████████████████████████████▏  487 B</span><br><span class="line">verifying sha256 digest</span><br><span class="line">writing manifest</span><br><span class="line">success</span><br><span class="line">&gt;&gt;&gt; 中国有几个省</span><br><span class="line">截至2023年，中国的省级行政区划包括34个省份。具体划分如下：</span><br><span class="line"></span><br><span class="line">- 23个省：如广东、江苏、山东等；</span><br><span class="line">- 5个自治区：内蒙古自治区、广西壮族自治区、西藏自治区、宁夏回族自治区和新疆维吾尔自治区；</span><br><span class="line">- 4个直辖市：北京、天津、上海、重庆；</span><br><span class="line">- 2个特别行政区：香港特别行政区、澳门特别行政区；</span><br><span class="line">- 1个省级行政单位：海南省，其中三沙市为地级市。</span><br><span class="line"></span><br><span class="line">这种划分是中华人民共和国现行的省份及行政区划形式。</span><br></pre></td></tr></table></figure><p>运行完成后，即可与模型对话。<br><strong>模型本地位置</strong>：默认保存在用户Home目录&#x2F;.ollama&#x2F;models(windows 为C:\Users&lt;用户名&gt;.ollama\models)，可通过设置环境变量 <code>OLLAMA_MODELS</code>更改模型的保存路径。</p><h2 id="3-docker部署open-web-ui提供聊天界面，体验类似chat-gpt"><a href="#3-docker部署open-web-ui提供聊天界面，体验类似chat-gpt" class="headerlink" title="3. docker部署open web ui提供聊天界面，体验类似chat gpt."></a>3. docker部署open web ui提供聊天界面，体验类似chat gpt.</h2><p><a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a></p><h3 id="3-1-如果ollama-运行在本机："><a href="#3-1-如果ollama-运行在本机：" class="headerlink" title="3.1 如果ollama 运行在本机："></a>3.1 如果ollama 运行在本机：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure><h3 id="3-2-如果ollama-运行在不同机器："><a href="#3-2-如果ollama-运行在不同机器：" class="headerlink" title="3.2 如果ollama 运行在不同机器："></a>3.2 如果ollama 运行在不同机器：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=http://&lt;remote-server-ip&gt;:11434 -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure><p>其中OLLAMA_BASE_URL为ollama server地址，本地默认为：127.0.0.1:11434</p><h3 id="3-3-访问open-webui，通过浏览器与模型对话"><a href="#3-3-访问open-webui，通过浏览器与模型对话" class="headerlink" title="3.3 访问open-webui，通过浏览器与模型对话"></a>3.3 访问open-webui，通过浏览器与模型对话</h3><p>访问地址： <a href="http://localhost:3000/">http://localhost:3000</a> </p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/be75719f6939652191faca51ab79d03f9689c978312722a8c0ca8365b1d6d6df.png" alt="open webui">  </p><ul><li>open-webui中可以管理用户，同时注意将更新模型的可见性，默认是不可见的，即只有管理员可以看到。</li></ul><h2 id="4-补充：open-webui库中支持一键运行ollama和open-webui"><a href="#4-补充：open-webui库中支持一键运行ollama和open-webui" class="headerlink" title="4. 补充：open-webui库中支持一键运行ollama和open-webui"></a>4. 补充：open-webui库中支持一键运行ollama和open-webui</h2><p><a href="https://raw.githubusercontent.com/open-webui/open-webui/refs/heads/main/docker-compose.yaml">https://raw.githubusercontent.com/open-webui/open-webui/refs/heads/main/docker-compose.yaml</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama</span><br></pre></td></tr></table></figure><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>MiGPT: 将小爱同学接入ollama本地大模型（也支持接入线上模型ChatGPT,豆包等），变得更智能。<br><a href="https://github.com/idootop/mi-gpt?tab=readme-ov-file">https://github.com/idootop/mi-gpt?tab=readme-ov-file</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> ai </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sunshine &amp; Moonlight实现串流传输</title>
      <link href="/infra/Moonlight-Sunshine/"/>
      <url>/infra/Moonlight-Sunshine/</url>
      
        <content type="html"><![CDATA[<p>有时希望将家里的投影仪作为电脑显示器及音响，但是重新布线却很麻烦，这时使用串流传输就可以轻松解决。开源方案就是：Sunshine &amp; Moonlight，它可以实现低延迟、高画质的跨平台串流体验。</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="Sunshine简介"><a href="#Sunshine简介" class="headerlink" title="Sunshine简介"></a>Sunshine简介</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/24c4d86f2d4256d943313f65394ab91d1eedd02ca9cd721a700bac70bf26433f.png" alt="Sunshine"><br>Sunshine是一个开源的串流服务器软件,可以安装在Windows、Linux等系统上。它的主要功能包括:</p><ul><li>捕获屏幕画面和音频</li><li>对画面进行编码压缩</li><li>通过网络传输给客户端</li><li>Sunshine支持多种编码格式,如H.264、HEVC等,可以根据网络状况自动调整画质。</li></ul><h2 id="Moonlight客户端"><a href="#Moonlight客户端" class="headerlink" title="Moonlight客户端"></a>Moonlight客户端</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/25fc0a9922ef293a4766301aebee746049daa6798c5436bd9c87f96931c4e66f.png" alt="Moonlight客户端"><br>Moonlight是与Sunshine配套的客户端软件,支持Windows、Android、iOS等多个平台。它可以接收Sunshine传输的画面,并进行解码显示。<br>Moonlight的主要特点包括:</p><ul><li>低延迟:延迟可低至20ms</li><li>高画质:支持4K 120FPS串流</li><li>跨平台:支持PC、手机、平板等设备</li><li>手柄支持:可使用手柄控制远程设备</li></ul><h1 id="部署与配置"><a href="#部署与配置" class="headerlink" title="部署与配置"></a>部署与配置</h1><h2 id="SunShine"><a href="#SunShine" class="headerlink" title="SunShine"></a>SunShine</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>SunShine部署在远程被控制电脑上，下载对应系统的安装包，直接安装运行即可。<br>Sunshine下载：<a href="https://github.com/LizardByte/Sunshine/releases">https://github.com/LizardByte/Sunshine/releases</a><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c2e59ea731019442a64d626df389a644f9e57b98ed9735c3405ad81568207c6f.png" alt="SunShine">  </p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol><li><p>Configuration中可进行配置：如同时连接client数， 性能设置等。一般默认配置即可。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/51aa07df64f244130ac6c5e4b06f21df5f4bc442ddf70a348f090b16af63549a.png" alt="Configuration">  </p></li><li><p>Application中设置进入控制电脑后执行的命令，如设置Ryujinx.exe启动Switch模拟器。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/30f123db06b45e2ac759427dbe963560ea1452649e3117356e4aea2c8e0a0a83.png" alt="Application">  </p></li><li><p>Pin页面，在控制端首次连接时进行认证校验。</p></li></ol><h2 id="Moonlight"><a href="#Moonlight" class="headerlink" title="Moonlight"></a>Moonlight</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>在控制端安装Moonlight App. 支持多种系统，ios&#x2F;Android&#x2F;Windows&#x2F;Linux&#x2F;Mac.<br>Moonlight下载：<a href="https://moonlight-stream.org/">https://moonlight-stream.org</a></p><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><ol><li>确保设备与被控制端在同一个局域网下（这是SunShine的默认配置，也可以将SunShine配置为公网可访问，需要先开通相关网络）。</li><li>打开Moonlight App，主机列表中会默认搜索到相关的主机，如果没有可通过输入IP添加。</li><li>第一次点击主机后，提示PIN码，进行SunShine管理界面，输入PIN码，匹配完成后，完成配对连接。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/63120db5b598740b481824621979ef1e3e24a4ca80ab2fd1f80777c309547d95.png" alt="PIN 码">  </li><li>点击主机，进入远程桌面。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/635bff2cbf7f77ea71ab0f18ddaf3b494cf645a403f78a3d0df66d38a5a46d48.png" alt="演示"></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> infra </tag>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vault常见操作</title>
      <link href="/DevOps/vault%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/"/>
      <url>/DevOps/vault%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.vaultproject.io/">Hashicorp Vault</a> 是一个基于身份的秘密和加密管理系统，用于严格控制访问各种机密数据，如 API 加密密钥、密码和证书。以下是 Vault 的一些常见使用操作。</p><h2 id="Login"><a href="#Login" class="headerlink" title="Login"></a>Login</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ export VAULT_ADDR=&#x27;http://your-vault-address:8200&#x27;</span><br><span class="line">$ export VAULT_TOKEN=&#x27;your-vault-token&#x27;</span><br></pre></td></tr></table></figure><h2 id="Secret操作"><a href="#Secret操作" class="headerlink" title="Secret操作"></a>Secret操作</h2><ul><li>secret引擎<br>KV</li><li>Path<br>region&#x2F;cluster&#x2F;project&#x2F;application</li><li>Key<br>devops-api</li><li>field<br>k-name</li><li>value<br>k-value</li></ul><ol><li><p>查看权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault token lookup</span><br></pre></td></tr></table></figure></li><li><p>新建kv</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vault secrets enable \</span><br><span class="line">    -path=/git-av \</span><br><span class="line">    -description &quot;k/v engine for the quickstart guide&quot; \</span><br><span class="line">    -version=1 \</span><br><span class="line">    kv</span><br></pre></td></tr></table></figure></li><li><p>查看所有secrets</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault secrets list</span><br></pre></td></tr></table></figure></li><li><p>创建或者更新key</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv put git-av/devops-api/k8s-test/test a=b</span><br></pre></td></tr></table></figure></li><li><p>list</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv list git-av/devops-api/k8s-test/</span><br></pre></td></tr></table></figure></li><li><p>添加字段 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv patch git-av/devops-api/k8s-test/test d=b</span><br></pre></td></tr></table></figure></li><li><p>删除字段</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv patch git-av/devops-api/k8s-test/test d=null</span><br></pre></td></tr></table></figure></li><li><p>查看key的内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv get git-av/devops-api/k8s-test/test</span><br></pre></td></tr></table></figure></li><li><p>删除key</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv delete git-av/devops-api/k8s-test/test</span><br><span class="line">$ vault kv metadata delete git-av/kratos-api/k8s-test/test</span><br></pre></td></tr></table></figure></li><li><p>删除kv secret</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault secrets disable git-av</span><br></pre></td></tr></table></figure></li><li><p>查看版本列表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv metadata get  git-av/devops-api/k8s-test/test</span><br></pre></td></tr></table></figure></li><li><p>回滚到指定版本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault kv rollback -version 6 git-av/devops-api/k8s-test/test</span><br></pre></td></tr></table></figure></li></ol><h2 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h2><ol><li><p>创建policy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vault policy write jenkins-policy - &lt;&lt;EOF</span><br><span class="line">path &quot;global/services/app/prod/kv/*&quot; &#123;</span><br><span class="line">  capabilities = [&quot;read&quot;]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">path &quot;global/services/app/stage/kv/*&quot; &#123;</span><br><span class="line">  capabilities = [&quot;read&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>policy中的path指的是key路径</p></li><li><p>查看 policy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault policy read jenkins-policy</span><br></pre></td></tr></table></figure></li><li><p>查看role</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vault auth list</span><br><span class="line">$ vault list auth/approle/role</span><br><span class="line">$ vault read auth/approle/role/jenkins</span><br><span class="line">$ vault read auth/approle/role/jenkins/role-id</span><br></pre></td></tr></table></figure></li><li><p>更新role key</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault write -f auth/approle/role/devops-readonly/secret-id</span><br></pre></td></tr></table></figure></li><li><p>创建app role for jenkins<br>5.1 enable approle</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault auth enable approle</span><br></pre></td></tr></table></figure></li></ol><p>5.2 policy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vault policy write jenkins-policy - &lt;&lt;EOF</span><br><span class="line">path &quot;devops/data/jenkins/*&quot; &#123;</span><br><span class="line">  capabilities = [&quot;read&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>5.3 add approle</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$vault write auth/approle/role/jenkins \</span><br><span class="line">    secret_id_ttl=0s \</span><br><span class="line">    token_num_uses=10 \</span><br><span class="line">    token_ttl=20m \</span><br><span class="line">    token_max_ttl=30m \</span><br><span class="line">    secret_id_num_uses=0 \</span><br><span class="line">    token_policies=&quot;jenkins-policy&quot;</span><br></pre></td></tr></table></figure><p>当 secret_id_ttl&#x3D;0s，secret_id_num_uses&#x3D;0 时表示secret 永不过期<br>5.4 更新secret_id_num_uses字段</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vault write auth/approle/role/jenkins \</span><br><span class="line">    secret_id_num_uses=0</span><br></pre></td></tr></table></figure><p>5.5 get key&#x2F;secret<br>vault read auth&#x2F;approle&#x2F;role&#x2F;jenkins&#x2F;role-id<br>vault write -f auth&#x2F;approle&#x2F;role&#x2F;jenkins&#x2F;secret-id</p><p>5.6 login with approle</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vault write auth/approle/login \</span><br><span class="line">    role_id=&lt;role_id&gt; \</span><br><span class="line">    secret_id=&lt;secret_id&gt;</span><br><span class="line">export VAULT_TOKEN=&lt;vault_token&gt;</span><br></pre></td></tr></table></figure><h2 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h2><ol><li>vault初始化<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vault operator init</span><br></pre></td></tr></table></figure></li><li>封锁<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vault operator seal</span><br></pre></td></tr></table></figure></li><li>解封<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vault operator unseal &lt;key1&gt;</span><br><span class="line">vault operator unseal &lt;key2&gt;</span><br><span class="line">vault operator unseal &lt;key3&gt;</span><br></pre></td></tr></table></figure></li><li>生成新的解封key<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vault operator rekey</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> vault </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lego签SSL证书</title>
      <link href="/DevOps/Lego%E7%AD%BESSL%E8%AF%81%E4%B9%A6/"/>
      <url>/DevOps/Lego%E7%AD%BESSL%E8%AF%81%E4%B9%A6/</url>
      
        <content type="html"><![CDATA[<p>HTTPS已经成为当今网站的标准配置,为网站提供加密和身份验证功能。但是申请和维护SSL证书一直是一个繁琐的过程。幸运的是,Lego这个强大的工具可以帮助我们轻松地自动化获取和更新Let’s Encrypt免费SSL证书。</p><h1 id="Lego-简介"><a href="#Lego-简介" class="headerlink" title="Lego 简介"></a>Lego 简介</h1><p>Lego是一个用Go语言编写的Let’s Encrypt客户端,它可以帮助我们自动化完成SSL证书的申请、验证和更新过程。相比于其他工具,Lego的优势在于:</p><ul><li>支持多种验证方式,包括HTTP和DNS验证</li><li>集成了众多DNS服务商的API,可以自动完成DNS验证</li><li>使用简单,只需几个命令即可完成证书申请</li><li>支持通配符证书</li></ul><h2 id="安装-Lego"><a href="#安装-Lego" class="headerlink" title="安装 Lego"></a>安装 Lego</h2><ul><li>mac<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install lego</span><br></pre></td></tr></table></figure></li><li>docker<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run goacme/lego -h</span><br></pre></td></tr></table></figure></li></ul><h2 id="签发rout53证书"><a href="#签发rout53证书" class="headerlink" title="签发rout53证书"></a>签发rout53证书</h2><ol><li>配置AWS密钥<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export AWS_ACCESS_KEY_ID=xxx</span><br><span class="line">export AWS_SECRET_ACCESS_KEY=xxx</span><br><span class="line">export AWS_REGION=us-east-1</span><br></pre></td></tr></table></figure></li><li>生成ssl证书<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lego --email xhuaustc@gmail.com --domains jenkins.douhua.com --dns route53 --accept-tos --dns.disable-cp  --path ~/.lego/jenkins run</span><br></pre></td></tr></table></figure>证书将保存在 ~&#x2F;.lego&#x2F;jenkins 目录下。</li></ol><ul><li>其中email用来接收证书快过期时的提示</li><li>lego支持多种<a href="https://go-acme.github.io/lego/dns/">dns provider</a>, 如：阿里云，腾讯云，Route53等</li><li>对于不同的证书，需要指定不同的path目录</li></ul><ol start="3"><li>可生成泛域名证书，以腾讯云为例<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export TENCENTCLOUD_SECRET_ID=your_secret_id</span><br><span class="line">export TENCENTCLOUD_SECRET_KEY=your_secret_key</span><br><span class="line">lego --email xhuaustc@gmail.com --domains douhua.com --domains *.douhua.com --dns tencentcloud --accept-tos --dns.disable-cp  --path ~/.lego/tencent/jenkins run</span><br></pre></td></tr></table></figure></li></ol><h2 id="对于一些java应用需要jks证书"><a href="#对于一些java应用需要jks证书" class="headerlink" title="对于一些java应用需要jks证书"></a>对于一些java应用需要jks证书</h2><ol><li>将ssl证书转为jks<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -export -in domain.crt -inkey domain.key -out certificate.p12 -name jenkins</span><br><span class="line">keytool -importkeystore -srckeystore certificate.p12 -srcstoretype PKCS12 -destkeystore jenkins.douhua.com.jks -deststoretype JKS</span><br></pre></td></tr></table></figure>过程中需要输入密码。密码也可以通过命令行指定<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -export -in domain.crt -inkey domain.key -out certificate.p12 -name &quot;jenkins&quot; -password pass:yourpassword</span><br><span class="line">keytool -importkeystore -srckeystore certificate.p12 -srcstoretype PKCS12 -destkeystore jenkins.douhua.com.jks -deststoretype JKS -srcstorepass yourpassword -deststorepass yourpassword</span><br></pre></td></tr></table></figure></li><li>验证jks<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -list -v -keystore jenkins.douhua.com.jks</span><br></pre></td></tr></table></figure></li><li>jenkins中配置证书<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/jenkins/jenkins.conf</span><br><span class="line">JENKINS_WAR=/opt/jenkins/jenkins.war</span><br><span class="line"></span><br><span class="line">JENKINS_HOME=/opt/jenkins/data</span><br><span class="line"></span><br><span class="line">JAVA_ARGS=&quot;-Djava.awt.headless=true \</span><br><span class="line">  -Djava.net.preferIPv4Stack=true \</span><br><span class="line">  -XX:+AlwaysPreTouch \</span><br><span class="line">  -XX:+UseG1GC \</span><br><span class="line">  -Xms8192m \</span><br><span class="line">  -Xmx8192m \</span><br><span class="line">  -Xss127m \</span><br><span class="line">  -Xlog:gc*=debug:file=gclog.log:utctime,level,tags:filecount=9,filesize=1M&quot;</span><br><span class="line"></span><br><span class="line">JENKINS_ARGS=&quot;--httpPort=-1 --httpsPort=8800  --logfile=/var/log/jenkins/jenkins.log \</span><br><span class="line">  --httpsKeyStore=/opt/jenkins/jenkins.douhua.com.jks \</span><br><span class="line">  --httpsKeyStorePassword=xxxxxx \</span><br><span class="line">  --useJmx&quot;</span><br><span class="line"></span><br><span class="line">$ /usr/bin/java $JAVA_ARGS -jar $JENKINS_WAR $JENKINS_ARGS</span><br></pre></td></tr></table></figure></li></ol><h2 id="更新route53证书"><a href="#更新route53证书" class="headerlink" title="更新route53证书"></a>更新route53证书</h2><p>当证书有效期在30天以内，可以使用renew更新证书</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lego --email xhuaustc@gmail.com --domains jenkins.douhua.com --dns route53 --accept-tos --dns.disable-cp  --path ~/.lego/jenkins renew</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>selenium+Xvfb+ffmpeg实现服务器录屏</title>
      <link href="/DevOps/selenium+Xvfb+ffmpeg%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BD%95%E5%B1%8F/"/>
      <url>/DevOps/selenium+Xvfb+ffmpeg%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BD%95%E5%B1%8F/</url>
      
        <content type="html"><![CDATA[<p>在现代软件开发中，自动化测试变得越来越重要，而录屏功能则为测试结果的验证提供了直观的方式。通过结合Selenium、Xvfb和FFmpeg这三个强大的工具，我们可以在服务器上实现无头(headless)的录屏环境，这对于没有图形界面的服务器尤其有用。</p><p>Selenium是一个自动化测试工具，它可以模拟用户对网页的操作，如点击、输入文本等。Xvfb（X虚拟帧缓冲）提供了一个虚拟的显示环境，使得我们可以在不需要实际显示器的情况下运行图形应用程序。FFmpeg是一个强大的多媒体框架，能够处理视频和音频的录制、转换和流式传输。</p><p>将这三个工具结合起来，我们可以创建一个自动化的录屏流程，这个流程可以在后台运行，录制Selenium驱动的浏览器会话。这样，无论是进行自动化测试验证，还是生成用户操作教程，都可以通过这种方式来实现。</p><p>例如，我们可以使用Selenium启动一个浏览器会话，然后用Xvfb创建一个虚拟的显示环境来捕获这个会话的屏幕。接着，使用FFmpeg开始录制屏幕内容，直到测试完成。这个过程完全自动化，可以集成到持续集成&#x2F;持续部署（CI&#x2F;CD）的流程中，提高开发效率和质量。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ol><li>安装软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 安装浏览器</span><br><span class="line">wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb</span><br><span class="line">dpkg -i google-chrome-stable_current_amd64.deb</span><br><span class="line"></span><br><span class="line"># 下载 chromedrive，选择合适的版本</span><br><span class="line"># https://googlechromelabs.github.io/chrome-for-testing/</span><br><span class="line">wget https://storage.googleapis.com/chrome-for-testing-public/123.0.6312.105/linux64/chromedriver-linux64.zip</span><br><span class="line">unzip chromedriver-linux64.zip</span><br><span class="line">mv chromedriver-linux64/chromedriver /usr/bin/</span><br><span class="line"></span><br><span class="line"># 安装xvfb, ffmpeg</span><br><span class="line">sudo apt install  -y xvfb ffmpeg xrandr</span><br><span class="line"></span><br><span class="line"># 安装selenium package</span><br><span class="line">pip3 install selenium screeninfo # screeninfo 可以获取屏幕分辨率，为录屏做准备</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><h2 id="Xvfb开启虚拟桌面"><a href="#Xvfb开启虚拟桌面" class="headerlink" title="Xvfb开启虚拟桌面"></a>Xvfb开启虚拟桌面</h2><ol><li>后台运行Xvfb开启虚拟桌面，终端将会默认在该桌面运行。此时能成功使用selenium控制浏览器<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Xvfb -ac :99 -screen 0 1024x768x16 &amp;</span><br><span class="line">export DISPLAY=:99</span><br><span class="line">xrandr</span><br></pre></td></tr></table></figure></li><li>使用xvfb-run开户虚拟桌面<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xvfb-run -a --server-args=&quot;-screen 0 1920x1080x24&quot; xrandr # 在虚拟桌面下运行xrandr,运行完毕后，自动关闭桌面。可通过添加server参数 --server-args=&quot; -displayID 99&quot;指定display id.</span><br></pre></td></tr></table></figure>-a : 自动使用不重复的DisplayId, 在运行的脚本中，可使用环境变量$DISPLAY来获取桌面ID，如：”:99”</li></ol><h2 id="使用selenium-控制浏览器"><a href="#使用selenium-控制浏览器" class="headerlink" title="使用selenium 控制浏览器"></a>使用selenium 控制浏览器</h2><p>不同浏览器可设置不同的参数，以chrom浏览器为例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 初始化driver</span><br><span class="line">from selenium import webdriver</span><br><span class="line">def local_chrome_driver():</span><br><span class="line">    option = webdriver.ChromeOptions()</span><br><span class="line">    option.add_experimental_option(&#x27;useAutomationExtension&#x27;, False)</span><br><span class="line">    option.add_experimental_option(</span><br><span class="line">        &quot;excludeSwitches&quot;, [&#x27;enable-automation&#x27;])</span><br><span class="line">    option.add_argument(&quot;--disable-infobars&quot;)</span><br><span class="line">    option.add_argument(&quot;--guest&quot;)</span><br><span class="line">    option.add_argument(&quot;--log-level=3&quot;)</span><br><span class="line">    driver = webdriver.Chrome(options=option)</span><br><span class="line">    driver.maximize_window()</span><br><span class="line">    return driver</span><br></pre></td></tr></table></figure><p>以上参数设置将便得浏览器打开更干净。获取<code>driver</code>后，便可通过selenium代码对其进行控制了。</p><h2 id="使用ffmpeg开启录屏"><a href="#使用ffmpeg开启录屏" class="headerlink" title="使用ffmpeg开启录屏"></a>使用ffmpeg开启录屏</h2><p>不同的操作系统使用不同的参数,例如：开始录制20s视频</p><ol><li>windows<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -hide_banner -f gdigrab -i desktop -t 20 -f mp4 out.mp4</span><br></pre></td></tr></table></figure></li><li>Mac<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -hide_banner -f avfoundation -i &#x27;1:none&#x27; -t 20 -r 30 -y -f mp4 out.mp4</span><br></pre></td></tr></table></figure>其中’1:none’为显示器与音频的编号。可通过命令<code>ffmpeg -f avfoundation -list_devices true -i &quot;&quot;</code>查看</li><li>Linux<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -hide_banner -video_size &#123;width&#125;x&#123;height&#125; -f x11grab -i &#123;os.getenv(&quot;DISPLAY&quot;)&#125; -t 20 -vcodec h264 -y -f mp4 out.mp4</span><br></pre></td></tr></table></figure>录屏完整代码如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import subprocess</span><br><span class="line">import platform</span><br><span class="line">from screeninfo import get_monitors</span><br><span class="line">def record_screen_with_ffmpeg(self, duration, output_path):</span><br><span class="line">    ffmpeg_cmd = &quot;ffmpeg&quot;</span><br><span class="line">    platform_os = platform.system().lower()</span><br><span class="line">    if platform_os == &#x27;windows&#x27;:</span><br><span class="line">        ffmpeg_format = &quot;-f gdigrab -i desktop -t &#123;duration&#125;&quot;</span><br><span class="line">    elif platform_os == &#x27;darwin&#x27;:</span><br><span class="line">        ffmpeg_format = f&quot;-f avfoundation -i &#x27;1:none&#x27; -t &#123;duration&#125; -r 30 -y &quot;</span><br><span class="line">    elif platform_os == &#x27;linux&#x27;:</span><br><span class="line">        monitors = get_monitors()</span><br><span class="line">        monitor = monitors[0]</span><br><span class="line">        width = monitor.width</span><br><span class="line">        height = monitor.height</span><br><span class="line">        display_number = os.getenv(&quot;DISPLAY&quot;)</span><br><span class="line">        ffmpeg_format = f&quot; -video_size &#123;width&#125;x&#123;height&#125; -f x11grab -i &#123;display_number&#125; -t &#123;duration&#125; -vcodec h264 -y &quot;</span><br><span class="line">    else:</span><br><span class="line">        raise Exception(&quot;Unsupported platform&quot;)</span><br><span class="line">    command = f&quot;&#123;ffmpeg_cmd&#125; -hide_banner &#123;ffmpeg_format&#125; -f mp4 &#123;output_path&#125;&quot;</span><br><span class="line">    print(f&quot;start record screen: &#123;command&#125;&quot;)</span><br><span class="line">    subprocess.call(command, shell=True, stdin=subprocess.PIPE)</span><br><span class="line">    print(f&quot;completed record. save mp4 file to &#123;output_path&#125;&quot;)</span><br></pre></td></tr></table></figure></li></ol><h2 id="补充ffmpeg工具"><a href="#补充ffmpeg工具" class="headerlink" title="补充ffmpeg工具"></a>补充ffmpeg工具</h2><ol><li><p>ffmpeg 工具可以方便对视频进行压缩, vcodec可选择编码格式，其中编码名中有nv字符串，则会利用nvidia gpu加速压缩，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">## cpu 编码</span><br><span class="line">ffmpeg -i ./source.mp4 -vcodec libx264 -acodec aac dest.mp4</span><br><span class="line">ffmpeg -i ./source.mp4 -vcodec libx265 -acodec aac dest.mp4</span><br><span class="line">## gpu 编码</span><br><span class="line">ffmpeg -i ./source.mp4 -vcodec h264_nvenc -acodec aac dest.mp4</span><br><span class="line">ffmpeg -i ./source.mp4 -vcodec hevc_nvenc -acodec aac dest.mp4</span><br></pre></td></tr></table></figure><table><thead><tr><th align="left">-vcodec 参数</th><th align="left">含义说明</th></tr></thead><tbody><tr><td align="left">copy</td><td align="left">复制原始视频流解码器，不重新编码。</td></tr><tr><td align="left">libx264</td><td align="left">将视频压缩为H.264格式。</td></tr><tr><td align="left">libx265</td><td align="left">将视频压缩为H.265&#x2F;HEVC格式。</td></tr><tr><td align="left">h264_nvenc</td><td align="left">使用NVIDIA GPU硬件加速进行H.264编码。</td></tr><tr><td align="left">hevc_nvenc</td><td align="left">使用NVIDIA GPU硬件加速进行H.265&#x2F;HEVC编码。</td></tr><tr><td align="left">h264_qsv</td><td align="left">使用Intel Quick Sync Video硬件加速进行H.264编码。</td></tr><tr><td align="left">hevc_qsv</td><td align="left">使用Intel Quick Sync Video硬件加速进行H.265&#x2F;HEVC编码。</td></tr><tr><td align="left">libvpx</td><td align="left">将视频压缩为VP8或VP9格式（通过<code>-b:v</code>指定压缩比特率）。</td></tr><tr><td align="left">huffyuv</td><td align="left">生成无损视频。</td></tr></tbody></table></li><li><p>ffmpeg 可对mp4文件进行diff</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 生成一个差值视频</span><br><span class="line">ffmpeg -i video1.mp4 -i video2.mp4 -filter_complex &quot;[0:v][1:v]blend=all_mode=&#x27;difference&#x27;&quot; -y diff.mp4</span><br><span class="line"></span><br><span class="line">## 计算视频相似度，结果存放在diff_ssim.log</span><br><span class="line">ffmpeg -i video1.mp4 -i video2.mp4 -filter_complex &quot;[0:v][1:v]ssim=diff_ssim.log&quot; -f null -</span><br></pre></td></tr></table></figure><p>对比前需确保两个视频的分辨率和帧率相同，否则FFmpeg可能无法正确处理。如果两个视频的规格不一致，需要先对其进行转码，使它们匹配后再进行差异比较。</p></li></ol><h2 id="使用-x11vnc-远程访问服务器应用界面"><a href="#使用-x11vnc-远程访问服务器应用界面" class="headerlink" title="使用 x11vnc 远程访问服务器应用界面"></a>使用 x11vnc 远程访问服务器应用界面</h2><ol><li>安装x11vnc<br>在服务器上安装 x11vnc。可以通过以下命令进行安装<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install x11vnc -y</span><br></pre></td></tr></table></figure></li><li>启动 Xserver<br>启动一个虚拟的 Xserver。使用 Xvfb 可以创建一个虚拟显示器<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Xvfb -ac :99 -screen 0 1024x768x16</span><br></pre></td></tr></table></figure></li><li>设置x11vnc密码<br>为了确保连接的安全性，您需要为 x11vnc 设置一个访问密码。运行以下命令来设置密码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x11vnc -storepasswd</span><br></pre></td></tr></table></figure>默认情况下，密码会保存在 ~&#x2F;.vnc&#x2F;passwd 文件中。</li><li>启动 x11vnc<br>启动 x11vnc 并指定使用虚拟显示器 :99：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x11vnc -display :99 -rfbport 5900 -forever -shared -rfbauth ~/.vnc/passwd</span><br></pre></td></tr></table></figure>这将使 x11vnc 在虚拟显示器 :99 上运行，并通过端口 5900 提供 VNC 服务。</li><li>在虚拟显示器中运行 Google Chrome<br>为了在远程访问中看到浏览器界面，您需要在虚拟显示器 :99 中启动 Google Chrome<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export DISPLAY=:99</span><br><span class="line">google-chrome</span><br></pre></td></tr></table></figure></li><li>通过 VNC 客户端访问 VNC 服务器<br>使用常规的 VNC 客户端连接到您的 VNC 服务器。输入服务器的 IP 地址和端口号（例如 192.168.1.100:5900），您将能够看到并控制服务器上的 Google Chrome 界面。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7857519abb9a1a5861bc59693095cd461cf16535b367273f80f6fa5f5d4591da.png" alt="vnc google chrome"></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过Selenium、Xvfb和FFmpeg的结合使用，我们可以在服务器上实现高效、灵活的自定义录屏解决方案，为软件开发和测试提供了极大的便利。</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> selenium </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用的Tcpdump命令</title>
      <link href="/DevOps/%E5%B8%B8%E7%94%A8%E7%9A%84Tcpdump%E5%91%BD%E4%BB%A4/"/>
      <url>/DevOps/%E5%B8%B8%E7%94%A8%E7%9A%84Tcpdump%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<ol><li><p>监控某一网络接口的数据包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0</span><br></pre></td></tr></table></figure></li><li><p>查看dns解析的包 port domain</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nt  -s 500 port domain</span><br></pre></td></tr></table></figure><p>-t 不显示时间<br>-n 不会将ip显示为hostname</p></li><li><p>过滤IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 host 202.22.22.22</span><br><span class="line">tcpdump -i eth0 src host 202.22.22.22  ## 指定源地址</span><br><span class="line">tcpdump -i eth0 dst host 202.22.22.22  ## 指定目的地址</span><br><span class="line">tcpdump -i eth0 host 202.22.22.22 and \(202.22.22.21 or 202.22.22.20 \)  ## 获取202.22.22.22 与 202.22.22.21或202.22.22.20之间的包</span><br><span class="line">tcpdump -i eth0 host 202.22.22.22 and !202.22.22.21  ## 获取202.22.22.22 与 除了202.22.22.21 之外的ip之间的包</span><br></pre></td></tr></table></figure></li><li><p>过滤端口 port</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 port 22</span><br><span class="line">tcpdump -i eth0 src port 22  ## 指定源端口</span><br><span class="line">tcpdump -i eth0 dst port 22  ## 指定目的端口</span><br></pre></td></tr></table></figure></li><li><p>过滤协议</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 arp</span><br><span class="line">tcpdump -i eth0 ip</span><br><span class="line">tcpdump -i eth0 tcp</span><br><span class="line">tcpdump -i eth0 udp</span><br><span class="line">tcpdump -i eth0 icmp</span><br></pre></td></tr></table></figure></li></ol><p>参考文章：</p><p><a href="https://www.cnblogs.com/jiujuan/p/9017495.html">tcpdump高级过滤</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> infra tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins Pipeline局部变量</title>
      <link href="/DevOps/Jenkins%20pipeline%20%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F/"/>
      <url>/DevOps/Jenkins%20pipeline%20%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="变量未定义"><a href="#变量未定义" class="headerlink" title="变量未定义"></a>变量未定义</h2><p>在编写Jenkinsfile时，经常会遇到变量问题，明明已经定义过了，但是函数是就是无法读取。<br>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def some_var = &quot;some value&quot;</span><br><span class="line"></span><br><span class="line">def pr() &#123;</span><br><span class="line">    def another_var = &quot;another &quot; + some_var</span><br><span class="line">    echo &quot;$&#123;another_var&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line"></span><br><span class="line">    stages &#123;</span><br><span class="line">        stage (&quot;Run&quot;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                pr()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将获得如下错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groovy.lang.MissingPropertyException: No such property: some_var for class: groovy.lang.Binding</span><br></pre></td></tr></table></figure><p>在该例子中明明开始已经定义了dome_var变量，但是在pr函数中却无法引用。</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><ul><li>在main script中使用def定义的变量并不能被其它函数引用， def some_var &#x3D; “some value”</li><li>在main script中不使用def定义的变量，能够被其它函数引用, some_var &#x3D; “some value”</li><li>使用def定义的变量，添加@Field标注手，能够被同一个script中的其它函数引用，  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">   import groovy.transform.Field</span><br><span class="line"></span><br><span class="line">@Field</span><br><span class="line">def some_var = &quot;some value&quot;</span><br></pre></td></tr></table></figure>这是因为在groovy编译该script时，会将脚本中的内容包含在一个class中，内容大致如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class Script1 &#123;</span><br><span class="line">    def pr() &#123;</span><br><span class="line">        def another_var = &quot;another &quot; + some_var</span><br><span class="line">        echo &quot;$&#123;another_var&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    def run() &#123;</span><br><span class="line">        def some_var = &quot;some value&quot;</span><br><span class="line">        pipeline &#123;</span><br><span class="line">            agent any</span><br><span class="line">            stages &#123;</span><br><span class="line">                stage (&quot;Run&quot;) &#123;</span><br><span class="line">                    steps &#123;</span><br><span class="line">                        pr()</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>从以上脚本中看到，some_var 并不在pr函数的范围中，所以无法识别该变量。</li></ul><p>如果在script中定义变量不带def的话，groovy编译时，会将该变量保存到groovy.lang.Binding中，这样的话，groovy的任意函数均可访问到该变量，但这里存在一个风险，就是会被覆盖，因为Binding是全局的。</p><p>最后使用@Field方式，将变量定义为该script下的变量，在该例子中，如果变量some_var添加了@Field标注，则script会被编译为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class Script1 &#123;</span><br><span class="line">    def some_var = &quot;some value&quot;</span><br><span class="line"></span><br><span class="line">    def pr() &#123;</span><br><span class="line">        def another_var = &quot;another &quot; + some_var</span><br><span class="line">        echo &quot;$&#123;another_var&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    def run() &#123;</span><br><span class="line">        pipeline &#123;</span><br><span class="line">            agent any</span><br><span class="line">            stages &#123;</span><br><span class="line">                stage (&quot;Run&quot;) &#123;</span><br><span class="line">                    steps &#123;</span><br><span class="line">                        pr()</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时some_var变量做为该Script下的成员变量，该Script下的函数均可访问到。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://stackoverflow.com/questions/50571316/strange-variable-scoping-behavior-in-jenkinsfile">Strange variable scoping behavior in Jenkinsfile</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx stream代理多个网站</title>
      <link href="/infra/nginx%20stream%E4%BB%A3%E7%90%86%E5%A4%9A%E4%B8%AA%E7%BD%91%E7%AB%99/"/>
      <url>/infra/nginx%20stream%E4%BB%A3%E7%90%86%E5%A4%9A%E4%B8%AA%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<p>在一些特殊场景下，尤其是多网络区的环境中，难免使用proxy来代理请求。其中HTTPS会提供更安全的数据传输，同时也添加了代理配置的复杂性（特别是证书的管理）。</p><p>通过nginx <code>ngx_stream_ssl_preread_module</code>模块，可以使用四层代理代理不同的服务。它允许从 ClientHello 消息中提取信息，而不会终止 SSL&#x2F;TLS，例如提取通过 SNI 请求的服务器名称并保存在变量$ssl_preread_server_name中，于是我们可以通过对该变量进行转发请求到对应的上游服务。</p><p>配置示例如下：</p><p>proxy 1配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stream &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen      443;</span><br><span class="line">        resolver 8.8.8.8;</span><br><span class="line">        proxy_pass  10.0.0.4:10443;</span><br><span class="line">        ssl_preread on;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>proxy 2 配置 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">stream &#123;</span><br><span class="line">    map $ssl_preread_server_name $name &#123;</span><br><span class="line">        baidu.com     prod;</span><br><span class="line">        stg.baidu.com     stage;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    upstream prod &#123;</span><br><span class="line">        server baidu.com:443;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    upstream stage &#123;</span><br><span class="line">        server stg.baidu.com:443;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen      10443;</span><br><span class="line">        resolver 8.8.8.8;</span><br><span class="line">        proxy_pass  $name;</span><br><span class="line">        ssl_preread on;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>做好域名解析后，在本地curl&#x2F;浏览器访问资源，即可获得对应的资源。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://baidu.com</span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://nginx.org/en/docs/stream/ngx_stream_ssl_preread_module.html">http://nginx.org/en/docs/stream/ngx_stream_ssl_preread_module.html</a>: ngx_stream_ssl_preread_module 模块（1.11.5）允许从 ClientHello 消息中提取信息，而不会终止 SSL&#x2F;TLS，例如提取通过 SNI 请求的服务器名称。默认情况下不构建此模块，您可以在构建时使用 –with-stream_ssl_preread_module 配置参数启用此模块。</p>]]></content>
      
      
      
        <tags>
            
            <tag> infra </tag>
            
            <tag> nginx </tag>
            
            <tag> proxy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible kubernetes.core 模块的使用</title>
      <link href="/DevOps/Ansible%20kubernetes.core%20%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/DevOps/Ansible%20kubernetes.core%20%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Ansible Guide: <a href="https://docs.ansible.com/ansible/latest/collections/kubernetes/core/index.html#description">https://docs.ansible.com/ansible/latest/collections/kubernetes/core/index.html#description</a></p><p>code: <a href="https://github.com/ansible-collections/kubernetes.core">https://github.com/ansible-collections/kubernetes.core</a></p><p>模块列表：<a href="https://github.com/ansible-collections/kubernetes.core#modules">https://github.com/ansible-collections/kubernetes.core#modules</a></p><p>kubernetes.core可以自动化管理kubernetes或openshift集群的应用与资源对象，以及集群的运维管理。</p><p>该collection环境要求：<br>kubernetes &gt;&#x3D; 1.19<br>python &gt;&#x3D; 3.6<br>ansible &gt;&#x3D; 2.9.17</p><h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><p>kubernetes.core collection包含有多个模块插件：inventory plugin, lookup plugin, connection plugin, K8s filter plugin以及多个Model</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_module.rst">kubernetes.core.helm</a></td><td>Manages Kubernetes packages with the Helm package manager</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_info_module.rst">kubernetes.core.helm_info</a></td><td>Get information from Helm package deployed inside the cluster</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_plugin_module.rst">kubernetes.core.helm_plugin</a></td><td>Manage Helm plugins</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_plugin_info_module.rst">kubernetes.core.helm_plugin_info</a></td><td>Gather information about Helm plugins</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_pull_module.rst">kubernetes.core.helm_pull</a></td><td>download a chart from a repository and (optionally) unpack it in local directory.</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_repository_module.rst">kubernetes.core.helm_repository</a></td><td>Manage Helm repositories.</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.helm_template_module.rst">kubernetes.core.helm_template</a></td><td>Render chart templates</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_module.rst">kubernetes.core.k8s</a></td><td>Manage Kubernetes (K8s) objects</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_cluster_info_module.rst">kubernetes.core.k8s_cluster_info</a></td><td>Describe Kubernetes (K8s) cluster, APIs available and their respective versions</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_cp_module.rst">kubernetes.core.k8s_cp</a></td><td>Copy files and directories to and from pod.</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_drain_module.rst">kubernetes.core.k8s_drain</a></td><td>Drain, Cordon, or Uncordon node in k8s cluster</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_exec_module.rst">kubernetes.core.k8s_exec</a></td><td>Execute command in Pod</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_info_module.rst">kubernetes.core.k8s_info</a></td><td>Describe Kubernetes (K8s) objects</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_json_patch_module.rst">kubernetes.core.k8s_json_patch</a></td><td>Apply JSON patch operations to existing objects</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_log_module.rst">kubernetes.core.k8s_log</a></td><td>Fetch logs from Kubernetes resources</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_rollback_module.rst">kubernetes.core.k8s_rollback</a></td><td>Rollback Kubernetes (K8S) Deployments and DaemonSets</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_scale_module.rst">kubernetes.core.k8s_scale</a></td><td>Set a new size for a Deployment, ReplicaSet, Replication Controller, or Job.</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_service_module.rst">kubernetes.core.k8s_service</a></td><td>Manage Services on Kubernetes</td></tr><tr><td><a href="https://github.com/ansible-collections/kubernetes.core/blob/main/docs/kubernetes.core.k8s_taint_module.rst">kubernetes.core.k8s_taint</a></td><td>Taint a node in a Kubernetes&#x2F;OpenShift cluster</td></tr></tbody></table><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>查看当前支持的inventory插件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ ansible-doc -t inventory -l | grep kubernetes</span><br><span class="line">kubernetes.core.k8s                                     Kubernetes (K8s) in...</span><br></pre></td></tr></table></figure><p>判断是否安装了kubernetes.core collection</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ ansible-galaxy  collection list | grep kubernetes</span><br><span class="line">kubernetes.core               2.4.0</span><br></pre></td></tr></table></figure><p>如果没有的话，需要安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">❯ ansible-galaxy collection install kubernetes.core</span><br></pre></td></tr></table></figure><h2 id="配置inventory"><a href="#配置inventory" class="headerlink" title="配置inventory"></a>配置inventory</h2><p>kubernetes.core.k8s inventory支持多种方式配置，如token, kubeconfig</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">❯ cat k8s.yaml</span><br><span class="line">plugin: kubernetes.core.k8s</span><br><span class="line">connections:</span><br><span class="line">  - kubeconfig: /Users/mpan/.kube/config</span><br><span class="line"></span><br><span class="line"># Authenticate with token, and return all pods and services for all namespaces</span><br><span class="line">---</span><br><span class="line">plugin: kubernetes.core.k8s</span><br><span class="line">connections:</span><br><span class="line">  - host: https://192.168.64.4:8443</span><br><span class="line">    api_key: xxxxxxxxxxxxxxxx</span><br><span class="line">    validate_certs: false</span><br><span class="line"></span><br><span class="line"># Use default config (~/.kube/config) file and active context, and return objects for a specific namespace</span><br><span class="line">plugin: kubernetes.core.k8s</span><br><span class="line">connections:</span><br><span class="line">  - namespaces:</span><br><span class="line">    - testing</span><br><span class="line"></span><br><span class="line"># Use a custom config file, and a specific context.</span><br><span class="line">plugin: kubernetes.core.k8s</span><br><span class="line">connections:</span><br><span class="line">  - kubeconfig: /path/to/config</span><br><span class="line">    context: &#x27;awx/192-168-64-4:8443/developer&#x27;</span><br></pre></td></tr></table></figure><p>配置完成inventory后，可以查看inventory内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">❯ ansible-inventory -i k8s.yaml --list &gt; out</span><br></pre></td></tr></table></figure><p>该inventory将根据namespace, 及label信息等为k8s中的资源创建了很多组，方便在运行具体tasks时进行选择。同时为pod默认配置了连接方式 <code>&quot;ansible_connection&quot;: &quot;kubernetes.core.kubectl&quot;,</code></p><h2 id="运行ansible-playbook"><a href="#运行ansible-playbook" class="headerlink" title="运行ansible playbook"></a>运行ansible playbook</h2><p>ansible将通过kubectl工具，在相关的pod中运行指定的模块，其中pod就相当于一台机器，它必须安装有python环境，才能正常运行模块。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">- hosts: namespace_blossom_pods</span><br><span class="line">  gather_facts: false</span><br><span class="line">  tasks:</span><br><span class="line">    - name: debug info</span><br><span class="line">      debug: msg=&quot;&#123;&#123; container_state &#125;&#125;&quot;</span><br><span class="line">      when: container_state == &quot;Running&quot;</span><br><span class="line">    </span><br><span class="line">    - name: Execute a command</span><br><span class="line">      shell: echo &quot;Hello&quot;</span><br><span class="line">      when: container_state == &quot;Running&quot;</span><br></pre></td></tr></table></figure><p>运行 playbook</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -i k8s.yaml a.yaml</span><br></pre></td></tr></table></figure><h2 id="使用kubernetes-core-k8s-exec模块在指定的pod中运行命令"><a href="#使用kubernetes-core-k8s-exec模块在指定的pod中运行命令" class="headerlink" title="使用kubernetes.core.k8s_exec模块在指定的pod中运行命令"></a>使用kubernetes.core.k8s_exec模块在指定的pod中运行命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- hosts: localhost</span><br><span class="line">  gather_facts: false</span><br><span class="line">  tasks:</span><br><span class="line">  - name: Execute a command</span><br><span class="line">    kubernetes.core.k8s_exec:</span><br><span class="line">      namespace: myproject</span><br><span class="line">      pod: sample-pod</span><br><span class="line">      command: echo &quot;hello&quot;</span><br><span class="line">      kubeconfig: /path/to/config</span><br></pre></td></tr></table></figure><p>运行Playbook</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">❯ ansible-playbook main.yaml</span><br><span class="line">[WARNING]: No inventory was parsed, only implicit localhost is available</span><br><span class="line">[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match</span><br><span class="line">&#x27;all&#x27;</span><br><span class="line"></span><br><span class="line">PLAY [localhost] *******************************************************************************************************</span><br><span class="line"></span><br><span class="line">TASK [Execute a command] ***********************************************************************************************</span><br><span class="line">[DEPRECATION WARNING]: The &#x27;return_code&#x27; return key is being renamed to &#x27;rc&#x27;. Both keys are being returned for now to</span><br><span class="line">allow users to migrate their automation. This feature will be removed from kubernetes.core in version 4.0.0.</span><br><span class="line">Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.</span><br><span class="line">changed: [localhost]</span><br><span class="line"></span><br><span class="line">PLAY RECAP *************************************************************************************************************</span><br><span class="line">localhost                  : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对于其它模块可以参考它的说明，配置相关的参数。</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> ansible </tag>
            
            <tag> kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bash中的换行</title>
      <link href="/DevOps/Bash%E4%B8%AD%E7%9A%84%E6%8D%A2%E8%A1%8C%E7%AC%A6/"/>
      <url>/DevOps/Bash%E4%B8%AD%E7%9A%84%E6%8D%A2%E8%A1%8C%E7%AC%A6/</url>
      
        <content type="html"><![CDATA[<p>换行在平常的shell编程中是经常遇到的，但是有时也会忽略掉一些问题。本篇中将会介绍多种方式实现输出换行的方法。</p><h2 id="使用-echo"><a href="#使用-echo" class="headerlink" title="使用 echo"></a>使用 echo</h2><h3 id="echo-自带换行"><a href="#echo-自带换行" class="headerlink" title="echo 自带换行"></a>echo 自带换行</h3><p>echo 命令输出字符串，在最后后会添加一个换行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# echo hello world</span><br><span class="line">hello world</span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>添加 <code>-n</code> 可以禁用echo最后的换行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# echo -n hello world</span><br><span class="line">hello worldroot@Michael:~#</span><br></pre></td></tr></table></figure><h3 id="换行符”-n”"><a href="#换行符”-n”" class="headerlink" title="换行符”\n”"></a>换行符”\n”</h3><p>但是当我们使用bash执行以下命令时，发现它并没有换行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~#  bash -c &quot;echo \&quot;\n\&quot;&quot;</span><br><span class="line">\n</span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>而是需要加一个 <code>-e</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# bash -c &quot;echo -e \&quot;\n\&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>从echo的说明中可以看到 <code>-e</code> 指的是让转义符生效，其中有：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">If -e is in effect, the following sequences are recognized:</span><br><span class="line">     \\     backslash</span><br><span class="line">     \a     alert (BEL)</span><br><span class="line">     \b     backspace</span><br><span class="line">     \c     produce no further output</span><br><span class="line">     \e     escape</span><br><span class="line">     \f     form feed</span><br><span class="line">     \n     new line</span><br><span class="line">     \r     carriage return</span><br><span class="line">     \t     horizontal tab</span><br><span class="line">     \v     vertical tab</span><br><span class="line">     \0NNN  byte with octal value NNN (1 to 3 digits)</span><br><span class="line">     \xHH   byte with hexadecimal value HH (1 to 2 digits)</span><br></pre></td></tr></table></figure><p>另外可以在字符串前加 <code>$</code> 符号</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# echo $&#x27;hello\nworld&#x27;</span><br><span class="line">hello</span><br><span class="line">world</span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><h3 id="使用echo多行模式"><a href="#使用echo多行模式" class="headerlink" title="使用echo多行模式"></a>使用echo多行模式</h3><p>上例子</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# echo &quot;&quot;&quot;hello</span><br><span class="line">world</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">hello</span><br><span class="line">world</span><br><span class="line"></span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>使用”””符号，包裹着多行字符串，实现多行输出。<br>但是这种方式有个问题，即当字符串中存在变量时，会将变量先进行解析，如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;&quot;&quot;hello</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">hello</span></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">hello</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>而有的时候我们希望是保留原始字符串$hello。这时可以在变量$前加上转义符$</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# echo &quot;&quot;&quot;hello</span><br><span class="line">\$hello</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">hello</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">hello</span></span><br><span class="line"></span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>也可以使用三个单引号’’’替换三个双引号”””</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# echo &#x27;&#x27;&#x27;hello</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="variable">$hello</span></span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span></span><br><span class="line">hello</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="string">hello</span></span></span><br><span class="line"></span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><h2 id="使用cat命令输出多行"><a href="#使用cat命令输出多行" class="headerlink" title="使用cat命令输出多行"></a>使用cat命令输出多行</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# cat &lt;&lt;EOF</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">hello</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">world</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">EOF</span></span><br><span class="line">hello</span><br><span class="line">world</span><br></pre></td></tr></table></figure><p>与echo一样，如果字符串中存在变量，该方式同样会解析变量。这时可以在第一个EOF两边添加引号，如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# cat &lt;&lt;&#x27;EOF&#x27;</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">hello</span></span><br><span class="line">world</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">hello</span></span><br><span class="line">world</span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><h2 id="使用printf"><a href="#使用printf" class="headerlink" title="使用printf"></a>使用printf</h2><p>使用printf打印字符串中的\n换行符，单引号，双引号均可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# printf &quot;hello\nworld\n&quot;</span><br><span class="line">hello</span><br><span class="line">world</span><br><span class="line">root@Michael:~# printf &#x27;hello\nworld\n&#x27;</span><br><span class="line">hello</span><br><span class="line">world</span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure><p>对于变量问题，与echo一样，可以为<code>$</code>添加转义符<code>\$</code>, 或者使用单引号。<br>如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@Michael:~# printf &#x27;hello \n$hello\n&#x27;</span><br><span class="line">hello </span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">hello</span></span><br><span class="line">root@Michael:~#</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenResty</title>
      <link href="/DevOps/OpenResty/"/>
      <url>/DevOps/OpenResty/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是OpenResty"><a href="#什么是OpenResty" class="headerlink" title="什么是OpenResty"></a>什么是OpenResty</h1><p>OpenResty是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。<br>可用于实现：</p><ul><li>路由控制</li><li>高并发入口</li><li>动态服务降级</li><li>动态负载均衡</li><li>WAF应用防火墙</li></ul><h2 id="安装OpenResty"><a href="#安装OpenResty" class="headerlink" title="安装OpenResty"></a>安装OpenResty</h2><ul><li><p>二进制安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# yum-config-manager --add-repo https://openresty.org/yum/cn/centos/OpenResty.repo</span><br><span class="line">[root@localhost ~]# yum install openresty -y</span><br><span class="line">[root@localhost ~]# systemctl start openresty</span><br></pre></td></tr></table></figure></li><li><p>Docker 安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -e KEY_ENV --name proxy --rm -p 443:443 -p 80:80 -v ~/openresty/:/etc/nginx/ docker.io/openresty/openresty:alpine /etc/nginx/startup.sh</span><br></pre></td></tr></table></figure></li></ul><h2 id="Openresty生命周期"><a href="#Openresty生命周期" class="headerlink" title="Openresty生命周期"></a>Openresty生命周期</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/3f41ed18271c316eaea312d85b5eada8299559142761722d5c5844ff457ea897.png" alt="生命周期">  </p><ul><li>init_by_lua：master-initing阶段，初始化全局配置或模块</li><li>init_worker_by_lua：worker-initing阶段，初始化进程专用功能</li><li>ssl_certificate_by_lua：ssl阶段，在“握手”时设置安全证书</li><li>set_by_lua：rewrite阶段，改写Nginx变量</li><li>rewrite_by_lua：rewrite阶段，改写URI，实现跳转&#x2F;重定向</li><li>access_by_lua：access阶段，访问控制或限速</li><li>content_by_lua：content阶段，产生响应内容</li><li>balancer_by_lua：balancer阶段，反向代理时选择upstream</li><li>header_filter_by_lua：header_filter阶段，加工处理响应头,处理response header</li><li>body_filter_by_lua：body_filter阶段，加工处理响应体</li><li>log_by_lua：log阶段，记录日志或其他的收尾工作</li></ul><p>通常指定有三种模式：</p><ol><li>xx_by_lua: 执行字符串形式的Lua代码</li><li>xx_by_lua_block: 功能相同，但指令后是｛…｝的Lua代码块</li><li>xx_by_lua_file: 功能相同，但执行磁盘上的源码文件</li></ol><h2 id="Openresty-模块"><a href="#Openresty-模块" class="headerlink" title="Openresty 模块"></a>Openresty 模块</h2><p>Openresty组件：<a href="http://openresty.org/cn/components.html">http://openresty.org/cn/components.html</a><br>社区模块：<a href="https://opm.openresty.org/packages">https://opm.openresty.org/packages</a><br>可使用<a href="https://opm.openresty.org/docs">opm工具</a>管理openresty模块。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># show usage</span><br><span class="line">opm --help</span><br><span class="line"></span><br><span class="line"># search package names and abstracts with the user pattern &quot;lock&quot;.</span><br><span class="line">opm search lock</span><br><span class="line"></span><br><span class="line"># search package names and abstracts with multiple patterns &quot;lru&quot; and &quot;cache&quot;.</span><br><span class="line">opm search lru cache</span><br><span class="line"></span><br><span class="line"># install a package named lua-resty-foo under the name of some_author</span><br><span class="line">opm get some_author/lua-resty-foo</span><br><span class="line"></span><br><span class="line"># get a list of lua-resty-foo packages under all authors.</span><br><span class="line">opm get lua-resty-foo</span><br><span class="line"></span><br><span class="line"># show the details of the installed package specified by name.</span><br><span class="line">opm info lua-resty-foo</span><br><span class="line"></span><br><span class="line"># show all the installed packages.</span><br><span class="line">opm list</span><br><span class="line"></span><br><span class="line"># upgrade package lua-resty-foo to the latest version.</span><br><span class="line">opm upgrade lua-resty-foo</span><br><span class="line"></span><br><span class="line"># update all the installed packages to their latest version.</span><br><span class="line">opm update</span><br><span class="line"></span><br><span class="line"># uninstall the newly installed package</span><br><span class="line">opm remove lua-resty-foo</span><br></pre></td></tr></table></figure><p>例如，下载ledgetech&#x2F;lua-resty-http模块：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">4576e3cdb5be:/usr/local/openresty/# opm get ledgetech/lua-resty-http</span><br><span class="line">* Fetching ledgetech/lua-resty-http</span><br><span class="line">  Downloading https://opm.openresty.org/api/pkg/tarball/ledgetech/lua-resty-http-0.17.1.opm.tar.gz</span><br><span class="line"><span class="meta prompt_">  % </span><span class="language-bash">Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span></span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100 20622  100 20622    0     0  40595      0 --:--:-- --:--:-- --:--:-- 40594</span><br><span class="line">Package ledgetech/lua-resty-http 0.17.1 installed successfully under /usr/local/openresty/site/ .</span><br></pre></td></tr></table></figure><h2 id="Openresty-共享数据"><a href="#Openresty-共享数据" class="headerlink" title="Openresty 共享数据"></a>Openresty 共享数据</h2><p>使用ngx.shared实现不同请求间的数据共享</p><ol><li>在nginx.conf配置http模块下初始化共享块,并加载自定义lua模块<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    lua_shared_dict my_cache 1m;</span><br><span class="line">    lua_package_path &quot;/etc/nginx/lua/?.lua;;&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>新建cache模块<br>在&#x2F;etc&#x2F;nginx&#x2F;lua&#x2F;cache.lua中新建cache模块<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> _M = &#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.get</span><span class="params">(key)</span></span></span><br><span class="line">    <span class="keyword">local</span> cache_ngx = ngx.shared.my_cache</span><br><span class="line">    <span class="keyword">local</span> value = cache_ngx:get(key)</span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.set</span><span class="params">(key, value, exptime)</span></span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> exptime <span class="keyword">then</span></span><br><span class="line">        exptime = <span class="number">0</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">local</span> cache_ngx = ngx.shared.my_cache</span><br><span class="line">    <span class="keyword">local</span> succ, err, forcible = cache_ngx:set(key, value, exptime)</span><br><span class="line">    <span class="keyword">return</span> succ</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> _M</span><br></pre></td></tr></table></figure></li><li>在业务逻辑中使用cache模块<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> cache = <span class="built_in">require</span>(<span class="string">&quot;cache&quot;</span>)</span><br><span class="line"><span class="keyword">local</span> cacheExpireTime = <span class="number">1800</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> maglevToken = <span class="string">&quot;&quot;</span></span><br><span class="line">cache.set(<span class="string">&quot;MaglevToken&quot;</span>, maglevToken, cacheExpireTime)</span><br><span class="line">maglevToken = cache.get(<span class="string">&quot;MaglevToken&quot;</span>)</span><br></pre></td></tr></table></figure></li></ol><h2 id="Openresty-调用外部接口"><a href="#Openresty-调用外部接口" class="headerlink" title="Openresty 调用外部接口"></a>Openresty 调用外部接口</h2><p>使用resty.http模块: <a href="https://github.com/ledgetech/lua-resty-http">https://github.com/ledgetech/lua-resty-http</a></p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> httpc = <span class="built_in">require</span>(<span class="string">&quot;resty.http&quot;</span>).new()</span><br><span class="line">    <span class="keyword">local</span> uri = <span class="string">&quot;https://&quot;</span> .. appHostIP .. <span class="string">&quot;/data.json&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">local</span> res, err = httpc:request_uri(uri, &#123;</span><br><span class="line">        method = <span class="string">&quot;GET&quot;</span>,</span><br><span class="line">        ssl_verify = <span class="literal">false</span>,</span><br><span class="line">        headers = &#123;</span><br><span class="line">            [<span class="string">&quot;Content-Type&quot;</span>] = <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,</span><br><span class="line">            [<span class="string">&quot;Host&quot;</span>] = appHostName,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    data = json.decode(res.body)</span><br><span class="line">    <span class="built_in">print</span>(data.data)</span><br></pre></td></tr></table></figure><h2 id="Lua-语法"><a href="#Lua-语法" class="headerlink" title="Lua 语法"></a>Lua 语法</h2><p>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。<br><a href="https://www.w3cschool.cn/lua/lua-basic-syntax.html">w3cschool lua基本语法</a><br><a href="https://www.runoob.com/manual/lua53doc/contents.html">lua参考手册</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Github使用技巧</title>
      <link href="/DevOps/Github%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
      <url>/DevOps/Github%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h2><p><a href="https://docs.github.com/zh/get-started/using-github/keyboard-shortcuts">Github快捷键官方文档</a></p><ul><li>S, 快速搜索</li><li>T, 搜索当前项目文件</li><li>L, 跳转文件行号</li><li>B, 查看文件历史改动记录</li><li>., 代码库将会在vscode online中打开，方便代码阅读</li><li>Ctrl + K, 命令面板<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4854aad1a83a08e1e008e809c6f240af24eaa152586f5f71ee8842b60f3a0d00.png" alt="github.dev"></li></ul><p><a href="https://github.com/search/advanced">高级搜索</a></p><h2 id="仓库搜索限定符"><a href="#仓库搜索限定符" class="headerlink" title="仓库搜索限定符"></a>仓库搜索限定符</h2><p><a href="https://docs.github.com/zh/search-github/searching-on-github/searching-for-repositories">Github上搜索仓库官方说明</a><br>go in:name star:&gt;&#x3D;1000 pushed:&gt;2022-06-01 language:go<br>jenkins in:readme </p><h3 id="in-限定符范围："><a href="#in-限定符范围：" class="headerlink" title="in 限定符范围："></a>in 限定符范围：</h3><ul><li>in:name, jquery in:name 匹配名称中带有“jquery”的存储库。</li><li>in:description, jquery in:name,description 匹配名称或说明中带有“jquery”的存储库。</li><li>in:topics, jquery in:topics 将带“jquery”标签的存储库匹配为主题。</li><li>in:readme, jquery in:readme 匹配自述文件中提及“jquery”的存储库。</li><li>repo:owner&#x2F;name, repo:octocat&#x2F;hello-world 匹配特定的存储库名称。</li></ul><h3 id="followers-关注度限定符"><a href="#followers-关注度限定符" class="headerlink" title="followers 关注度限定符"></a>followers 关注度限定符</h3><ul><li>followers:&gt;&#x3D;n, node followers:&gt;&#x3D;10000 匹配有 10,000 名或更多关注者提及“node”一词的存储库。</li><li>followers:n..n, styleguide linter followers:1..10 匹配有 1 至 10 名关注者提及“styleguide linter”一词的存储库。</li></ul><h3 id="stars-按照标星限定符"><a href="#stars-按照标星限定符" class="headerlink" title="stars 按照标星限定符"></a>stars 按照标星限定符</h3><ul><li>stars:n, stars:500 匹配正好有 500 个星标的存储库。</li><li>stars:n..n size:&lt;n, stars:10..20 size:&lt;1000 匹配有 10 到 20 个星标、小于 1000 KB 的存储库。</li><li>stars:&gt;&#x3D;n fork:true language:LANGUAGE, stars:&gt;&#x3D;500 fork:true language:php 匹配至少有 500 个星标（包括用 PHP 编写的分支星标）的存储库。</li></ul><h3 id="created-pushed-时间限定符"><a href="#created-pushed-时间限定符" class="headerlink" title="created, pushed 时间限定符"></a>created, pushed 时间限定符</h3><ul><li>created:&lt;YYYY-MM-DD,webos created:&lt;2011-01-01 匹配具有 2011 年之前创建的“webos”一词的存储库。</li><li>pushed:&gt;YYYY-MM-DD, css pushed:&gt;2013-02-01 匹配具有在 2013 年 1 月之后推送到其中的“css”一词的存储库。</li><li>pushed:&gt;&#x3D;YYYY-MM-DD fork:only, case pushed:&gt;&#x3D;2013-03-06 fork:only 匹配在 2013 年 3 月 6 日或之后将“case”一词推送到其中的存储库（即分支）。</li></ul><h3 id="language-语言限定符"><a href="#language-语言限定符" class="headerlink" title="language 语言限定符"></a>language 语言限定符</h3><ul><li>language:LANGUAGE, rails language:javascript 匹配具有以 JavaScript 编写的“rails”一词的存储库。</li></ul><h3 id="topics-主题限定符"><a href="#topics-主题限定符" class="headerlink" title="topics 主题限定符"></a>topics 主题限定符</h3><ul><li>topic:TOPIC, topic:jekyll 匹配按“Jekyll”主题分类的存储库。</li></ul><h2 id="代码搜索语法"><a href="#代码搜索语法" class="headerlink" title="代码搜索语法"></a>代码搜索语法</h2><p><a href="https://docs.github.com/zh/search-github/github-code-search/understanding-github-code-search-syntax">GitHub 代码搜索语法</a></p><h3 id="一个没有限定符的裸词将与文件的内容或文件的路径匹配"><a href="#一个没有限定符的裸词将与文件的内容或文件的路径匹配" class="headerlink" title="一个没有限定符的裸词将与文件的内容或文件的路径匹配"></a>一个没有限定符的裸词将与文件的内容或文件的路径匹配</h3><ul><li>http-push<br>匹配文件名或文本内容中带有http-push的文件</li></ul><h3 id="输入多个用空格分隔的术语，以搜索满足这两个字词的文档"><a href="#输入多个用空格分隔的术语，以搜索满足这两个字词的文档" class="headerlink" title="输入多个用空格分隔的术语，以搜索满足这两个字词的文档"></a>输入多个用空格分隔的术语，以搜索满足这两个字词的文档</h3><ul><li>sparse index<br>匹配文件或内容中包含有sparse和index两个词的文件，不管顺序</li><li>&#x2F;sparse.*index&#x2F;<br>使用&#x2F;…&#x2F;支持正则表达式，如果正则表达式中&#x2F;需要用/表示。</li></ul><h3 id="完全匹配"><a href="#完全匹配" class="headerlink" title="完全匹配"></a>完全匹配</h3><ul><li>“name &#x3D; &quot;tensorflow&quot;“<br>完全匹配name&#x3D;”tensorfow”的文本</li></ul><h3 id="运算符-AND-x2F-OR-x2F-NOT"><a href="#运算符-AND-x2F-OR-x2F-NOT" class="headerlink" title="运算符 AND&#x2F;OR&#x2F;NOT"></a>运算符 AND&#x2F;OR&#x2F;NOT</h3><ul><li>“fatal error” NOT path:<strong>testing</strong><br>文件或者内容中包含fatal error,同时排除__testing__目录中的文件 </li><li>(language:ruby OR language:python) AND NOT path:”&#x2F;tests&#x2F;“<br>语言为ruby或者python,并且排除&#x2F;tests&#x2F;目录中的文件</li></ul><h3 id="path-路径限定符"><a href="#path-路径限定符" class="headerlink" title="path 路径限定符"></a>path 路径限定符</h3><ul><li>path:src&#x2F;<em>.js<br>匹配src&#x2F;</em>.js 路径下的文件，以上为src目录下的文件，如果需要包含其子目录，写法为 path:src&#x2F;**&#x2F;*.js</li><li>path:*.a?c<br>?全局字符，匹配任意字符：file.aac, file.abc</li></ul><h2 id="codespaces"><a href="#codespaces" class="headerlink" title="codespaces"></a>codespaces</h2><p>每个月可免费使用15GB,120小时。</p><p><a href="https://docs.github.com/zh/codespaces">codespaces官方文档</a><br>在项目的Code按键中选择codespaces,并创建codespace，将会打开vscode界面，在该codespace中不仅可以查看代码，还可以进行开发、调试，运行项目。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ba4e888a3038d7f43c48c8326c9617e08d8ba03534891548e88accd2ec8ffddb.png" alt="codespace">  </p><h2 id="github-action"><a href="#github-action" class="headerlink" title="github action"></a>github action</h2><p><a href="https://docs.github.com/zh/actions/learn-github-actions">action官方文档</a><br><a href="https://github.com/marketplace?type=actions">action市场</a><br><a href="https://github.com/sdras/awesome-actions">awesom actions</a></p><p>Github Action 是一种持续集成和持续交付 (CI&#x2F;CD) 平台，可用于自动执行生成、测试和部署管道，而且可以免费使用。<br>GitHub 提供 Linux、Windows 和 macOS 虚拟机来运行工作流程，也可以在自己托管的机器运行。</p><p>在之前文章<a href="/devops/hexo/">Hexo + Butterfly + Github Page + Github Action 配置自己的个人网站</a>中就使用了Github Action 来实现hexo自动发布。</p><p>示例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Deploy</span> <span class="string">Blog</span> <span class="string">site</span></span><br><span class="line"><span class="attr">run-name:</span> <span class="string">$&#123;&#123;</span> <span class="string">github.actor</span> <span class="string">&#125;&#125;</span> <span class="string">is</span> <span class="string">deploy</span> <span class="string">blog</span> <span class="string">site</span> <span class="string">🚀</span></span><br><span class="line"><span class="attr">on:</span> [<span class="string">push</span>]</span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">Deploy-Actions:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">container:</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">xhuaustc/hexo:latest</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="attr">TOKEN:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.GIT_TOKEN</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">fetch-depth:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Deploy</span> <span class="string">blog</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          npm install --force</span></span><br><span class="line"><span class="string">          hexo deploy</span></span><br></pre></td></tr></table></figure><p>workflow中配置的说明：</p><p><a href="https://docs.github.com/zh/actions/using-workflows/workflow-syntax-for-github-actions">工作流语法</a></p><p>workflow在具体执行中，可以全用 steps.uses 来调用Action，也可以使用 steps.run 来运行指定的 shell 命令，其中 shell 默认为运行器操作系统的默认shell，它还可以为 cmd, python, sh等。可参考：<a href="https://docs.github.com/zh/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsshell">jobs.<job_id>.steps[*].shell</a></p><h3 id="Github-Action-基本概念"><a href="#Github-Action-基本概念" class="headerlink" title="Github Action 基本概念"></a>Github Action 基本概念</h3><ul><li>Workflow: 工作流，一个可配置的自动化过程，它将运行一个或多个作业。</li><li>on: 事件, 存储库中触发工作流程运行的特定活动。</li><li>job: 任务，工作流中在同一运行器上执行的一组步骤。 </li><li>step: 步骤, 要么是一个将要执行的 shell 脚本，要么是一个将要运行的动作。</li><li>action: 动作，用于 GitHub Actions 平台的自定义应用程序，它执行复杂但经常重复的任务。</li></ul><p>Github Action的配置文件，会以yaml的形式定义，并保存在项目的<code>.github/workflows/</code>目录中。github将会自动检查该目录下的文件，触发相关的任务。</p><h3 id="创建自定义Action"><a href="#创建自定义Action" class="headerlink" title="创建自定义Action"></a>创建自定义Action</h3><p>Action动作是工作流中具体执行的最小单元。<br>一个Action单元，包括：name, description, inputs, outputs, runs<br>其中runs为具体的执行操作。<br><a href="https://docs.github.com/zh/actions/creating-actions/metadata-syntax-for-github-actions">GitHub Actions 的元数据语法</a></p><p><a href="https://docs.github.com/zh/actions/creating-actions/creating-a-docker-container-action">创建 Docker 容器Action</a>：使用 Docker 容器Action作为执行环境。</p><p><a href="https://docs.github.com/zh/actions/creating-actions/creating-a-composite-action">创建组合Action</a>：使用steps进行组合Action</p><p><a href="https://docs.github.com/zh/actions/creating-actions/creating-a-javascript-action">创建 JavaScript Action</a>：使用Javascript 作为Action执行环境</p><h3 id="查找和自定义Action"><a href="#查找和自定义Action" class="headerlink" title="查找和自定义Action"></a>查找和自定义Action</h3><p>Action除了自己编写外，还可以包含社区创建的Action，也可以直接在应用程序的仓库中创建您自己的Action。</p><ol><li>在Marketplace市场中查找并使用Action<br>打开仓库中的具体workflow, 并点击编辑工作流按钮。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e9c771cf5edb4acff05cbb0f60e37208706d7205c62cbfd9e18d4d788446f4fd.png" alt="编辑"></li></ol><p>在编辑框的右侧，将会出现Marketplace,在其中搜索需要的action,并复制到workflow.yaml中。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/31de3e52aaf4212b84720497eca040e3d13e2ed6b7fc059fa39cedc20f849924.png" alt="Marketplace">  </p><ol start="2"><li><p>引入本仓库中的Action<br>Action可以在工作流文件同一仓库中定义，在工作流文件中通过 {owner}&#x2F;{repo}@{ref} 或 .&#x2F;path&#x2F;to&#x2F;dir 语法引用操作。<br>示例仓库文件结构：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">|-- hello-world (repository)</span><br><span class="line">|   |__ .github</span><br><span class="line">|       └── workflows</span><br><span class="line">|           └── my-first-workflow.yml</span><br><span class="line">|       └── actions</span><br><span class="line">|           |__ hello-world-action</span><br><span class="line">|               └── action.yml</span><br></pre></td></tr></table></figure><p>示例工作流程文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="comment"># This step checks out a copy of your repository.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">      <span class="comment"># This step references the directory that contains the action.</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">./.github/actions/hello-world-action</span></span><br></pre></td></tr></table></figure><p>action.yml 文件用于提供操作的元数据。<br><a href="https://docs.github.com/zh/actions/creating-actions/publishing-actions-in-github-marketplace">如何将自己的Action发布到MarketPlace</a></p></li><li><p>引入外部仓库中的Action</p></li></ol><p>如果操作在与工作流文件不同的仓库中定义，可在工作流文件中通过 {owner}&#x2F;{repo}@{ref} 语法引用该操作。该操作必须存储在公共仓库中。<br>示例工作流文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">my_first_job:</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">My</span> <span class="string">first</span> <span class="string">step</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br></pre></td></tr></table></figure><ol start="4"><li>引入Docker镜像中的Action<br>如果Action在 Docker Hub 上发布的 Docker 容器镜像中定义，必须在工作流文件中通过 docker:&#x2F;&#x2F;{image}:{tag} 语法引用该操作。<br>示例工作流文件：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  my_first_job:</span><br><span class="line">    steps:</span><br><span class="line">      - name: My first step</span><br><span class="line">        uses: docker://alpine:3.8</span><br></pre></td></tr></table></figure>如何构建Docker镜像类Action，请参考：<a href="https://docs.github.com/zh/actions/creating-actions/creating-a-docker-container-action">创建 Docker 容器Action</a></li></ol><p>示例构建go项目</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">name: Upload Go test results</span><br><span class="line"></span><br><span class="line">on: [push]</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line"></span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    strategy:</span><br><span class="line">      matrix:</span><br><span class="line">        go-version: [ &#x27;1.14&#x27;, &#x27;1.15&#x27;, &#x27;1.16.x&#x27; ]</span><br><span class="line"></span><br><span class="line">    steps:</span><br><span class="line">      - uses: actions/checkout@v3</span><br><span class="line">      - name: Setup Go</span><br><span class="line">        uses: actions/setup-go@v4</span><br><span class="line">        with:</span><br><span class="line">          go-version: $&#123;&#123; matrix.go-version &#125;&#125;</span><br><span class="line">      - name: Install dependencies</span><br><span class="line">        run: go get .</span><br><span class="line">      - name: Test with Go</span><br><span class="line">        run: go test -json &gt; TestResults-$&#123;&#123; matrix.go-version &#125;&#125;.json</span><br><span class="line">      - name: Upload Go test results</span><br><span class="line">        uses: actions/upload-artifact@v3</span><br><span class="line">        with:</span><br><span class="line">          name: Go-results-$&#123;&#123; matrix.go-version &#125;&#125;</span><br><span class="line">          path: TestResults-$&#123;&#123; matrix.go-version &#125;&#125;.json</span><br></pre></td></tr></table></figure><h2 id="项目探索-Explore"><a href="#项目探索-Explore" class="headerlink" title="项目探索 Explore"></a>项目探索 Explore</h2><p>Explore界面中，可以通过邮件订阅感兴趣的项目</p><h2 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h2><p>Github 趋势：<a href="https://github.com/trending">https://github.com/trending</a> </p><p>代码片段：<a href="https://gist.github.com/">https://gist.github.com</a></p><p>Github课堂：<a href="https://classroom.github.com/">https://classroom.github.com</a></p><p>Git教程：<a href="https://try.github.io/">https://try.github.io</a></p><p>Github项目榜单：<a href="https://hellogithub.com/">https://hellogithub.com</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker in docker测试docker的proxy功能</title>
      <link href="/container/docker-in-docker%E6%B5%8B%E8%AF%95docker%E7%9A%84proxy%E5%8A%9F%E8%83%BD/"/>
      <url>/container/docker-in-docker%E6%B5%8B%E8%AF%95docker%E7%9A%84proxy%E5%8A%9F%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<h2 id="docker-in-docker是什么？"><a href="#docker-in-docker是什么？" class="headerlink" title="docker in docker是什么？"></a>docker in docker是什么？</h2><p>顾名思义，docker in docker就是在docker容器中运行docker服务端。这种技术通常用于CI&#x2F;CD流水线中，因为它可以提供一个干净的环境来运行构建和测试。例如，如果您正在使用Jenkins作为CI&#x2F;CD工具，您可以使用DinD来运行构建和测试，而无需在Jenkins服务器上安装Docker。这样可以避免与Jenkins服务器上的其他应用程序发生冲突。<br>使用DinD时，需要注意的是，它会增加容器的复杂性，并且可能会导致性能下降。此外，由于容器内部运行的是另一个容器，因此可能会出现一些安全问题。<br>本篇中用DinD来完成对docker proxy功能的验证。</p><h2 id="为什么docker要使用代理？"><a href="#为什么docker要使用代理？" class="headerlink" title="为什么docker要使用代理？"></a>为什么docker要使用代理？</h2><p>Docker使用代理的原因有很多，其中一些原因包括：</p><ul><li>访问公司私有化部署的镜像仓库，对网络环境有限制。</li><li>对于一些公共仓库，下载速度很慢，通过代理实现加速上传与下载。</li></ul><p>在本测试环境中，docker容器所在环境与目标docker 镜像仓库是网络隔离的，同时两个网络之间可以通过一个http proxy来进行通信。</p><h2 id="如何配置proxy代理"><a href="#如何配置proxy代理" class="headerlink" title="如何配置proxy代理?"></a>如何配置proxy代理?</h2><p>官方说明：<a href="https://docs.docker.com/config/daemon/systemd/#httphttps-proxy">https://docs.docker.com/config/daemon/systemd/#httphttps-proxy</a></p><ol><li>运行dockerindocker<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --privileged --rm  --entrypoint=&quot;sh&quot; docker:24.0.1-dind</span><br></pre></td></tr></table></figure></li><li>设置proxy, 有两种方法进行配置(docker 23.0以版本)</li></ol><ul><li>通过&#x2F;etc&#x2F;docker&#x2F;daemon.json<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;proxies&quot;: &#123;</span><br><span class="line">    &quot;http-proxy&quot;: &quot;http://proxy.example.com:3128&quot;,</span><br><span class="line">    &quot;https-proxy&quot;: &quot;https://proxy.example.com:3129&quot;,</span><br><span class="line">    &quot;no-proxy&quot;: &quot;*.test.example.com,.example.org,127.0.0.0/8&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>设置代理环境变量<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/ # export http_proxy=http://proxy.example.com:3128</span><br><span class="line">/ # export https_proxy=https://proxy.example.com:3129</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li>正常使用docker命令，docker pull&#x2F;push 均会使用该proxy与镜像仓库交互<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># dockerd &amp;</span></span><br><span class="line">/ <span class="comment"># docker pull docker:24.01-dind</span></span><br><span class="line">/ <span class="comment"># docker tag docker:24.01-dind remote-repo.app/docker:24.01-dind</span></span><br><span class="line">/ <span class="comment"># docker push remote-repo.app/docker:24.01-dind</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> docker </tag>
            
            <tag> container </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo + Butterfly + Github Page + Github Action 配置自己的个人网站</title>
      <link href="/DevOps/hexo/"/>
      <url>/DevOps/hexo/</url>
      
        <content type="html"><![CDATA[<p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>Butterfly 是 Hexo 的一个流行的主题，它的用户量很大，使其扩展丰富，使用方便。<br>Github Action 是一种持续集成和持续交付 (CI&#x2F;CD) 平台，可用于自动执行生成、测试和部署管道，而且可以免费使用。<br>Github Page 是免费的静态站点，只需要一个代码库，就可以免费构建自己的网站。</p><p>本文将以上四者相结合，构建个人博客网站。部署流水线，让我们只需要关注内容的产出，而无需关心 hexo 的部署与博客的发布。Let’s go.</p><h2 id="1-预准备"><a href="#1-预准备" class="headerlink" title="1. 预准备"></a>1. 预准备</h2><ol><li>github 上创建账号，并创建两个 git repo。<ul><li>一个 repo 用来保存平时编辑的博客文件</li><li>一个用来保存 hexo 生成的静态文件，并为其设置为 github page.</li></ul></li><li>本机安装 docker 与 vscode 软件。<ul><li>docker 用来运行 hexor 容器，用来本地开发与调试</li><li>vscode 用来日常编写博客文本</li><li>安装 vscode 插件 docker, <a href="https://marketplace.visualstudio.com/items?itemName=hancel.markdown-image">markdown images</a></li></ul></li></ol><h2 id="2-准备-hexo，使用-docker-image"><a href="#2-准备-hexo，使用-docker-image" class="headerlink" title="2. 准备 hexo，使用 docker image"></a>2. 准备 hexo，使用 docker image</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">docker run --name hexo -p 4000:4000 -it --<span class="built_in">rm</span> --entrypoint=<span class="string">&quot;bash&quot;</span> -v ~/blog/:/app xhuaustc/hexo:latest</span></span><br><span class="line">root@291c4cec0506:/app/# hexo init myblog</span><br><span class="line">root@291c4cec0506:/app/# cd myblog</span><br><span class="line">root@291c4cec0506:/app/# cd myblog</span><br><span class="line">root@a20365558032:/app/myblog# hexo s</span><br><span class="line">INFO  Validating config</span><br><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure><p>该镜像已经准备好了 hexo 的编译与运行环境，其中 ~&#x2F;blog&#x2F;中存放第 1 步创建的 git 代码。</p><h2 id="3-安装-butterfly-主题"><a href="#3-安装-butterfly-主题" class="headerlink" title="3. 安装 butterfly 主题"></a>3. 安装 butterfly 主题</h2><ol><li>安装 butterfly</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i hexo-theme-butterfly</span><br></pre></td></tr></table></figure><ol start="2"><li>: 将 butterfly 的默认配置拷贝到项目根目录_config.butterfly.yml</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/jerryc127/hexo-theme-butterfly/dev/_config.yml _config.butterfly.yml</span><br></pre></td></tr></table></figure><ol start="3"><li>: hexo 设置主题 buterfly</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: butterfly</span><br></pre></td></tr></table></figure><h2 id="4-配置本地搜索"><a href="#4-配置本地搜索" class="headerlink" title="4. 配置本地搜索"></a>4. 配置本地搜索</h2><ol><li>安装 hexo-generator-search</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure><ol start="2"><li>hexo 配置中配置 search</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br><span class="line">  content: true</span><br><span class="line">  format: html</span><br></pre></td></tr></table></figure><ol start="3"><li>butterfly 配置中打开 search</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure><h2 id="5-配置-tags-页面"><a href="#5-配置-tags-页面" class="headerlink" title="5. 配置 tags 页面"></a>5. 配置 tags 页面</h2><ol><li>新建 tags page</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page <span class="string">&quot;tags&quot;</span></span></span><br></pre></td></tr></table></figure><ol start="2"><li>更新 source&#x2F;tags 文件夹下 index.md 文件内容为</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type: &quot;tags&quot;</span><br><span class="line">layout: &quot;tags&quot;</span><br><span class="line">comments: false</span><br></pre></td></tr></table></figure><ol start="3"><li>在_config.butterfly.yml 中 menue 打开 tags</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Menu 目錄</span><br><span class="line">menu:</span><br><span class="line">  主页: / || fas fa-home</span><br><span class="line">  归档: /archives/ || fas fa-archive</span><br><span class="line">  标签: /tags/ || fas fa-tags</span><br></pre></td></tr></table></figure><h2 id="6-配置-categories-页面"><a href="#6-配置-categories-页面" class="headerlink" title="6. 配置 categories 页面"></a>6. 配置 categories 页面</h2><p>同tags页面</p><ol><li><p>新建 categories page</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hexo new page <span class="string">&quot;categories&quot;</span></span></span><br></pre></td></tr></table></figure></li><li><p>更新 source&#x2F;tags 文件夹下 index.md 文件内容为</p></li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type: &quot;categories&quot;</span><br><span class="line">layout: &quot;tags&quot;</span><br><span class="line">comments: false</span><br></pre></td></tr></table></figure><ol start="3"><li>在_config.butterfly.yml 中 menue 打开 tags</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Menu 目錄</span><br><span class="line">menu:</span><br><span class="line">  主页: / || fas fa-home</span><br><span class="line">  归档: /archives/ || fas fa-archive</span><br><span class="line">  标签: /tags/ || fas fa-tags</span><br><span class="line">  分类: /categories/ || fas fa-folder-open</span><br></pre></td></tr></table></figure><h2 id="7-添加置顶功能"><a href="#7-添加置顶功能" class="headerlink" title="7. 添加置顶功能"></a>7. 添加置顶功能</h2><p>安装置顶插件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm uninstall hexo-generator-index --save</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">npm install hexo-generator-index-pin-top --save</span></span><br></pre></td></tr></table></figure><p>在post的元数据描述中添加top标识即可：如</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 置顶配置</span><br><span class="line">date: 2021-09-08 12:00:25</span><br><span class="line">categories: 教程</span><br><span class="line">top: true # true 或者数字</span><br><span class="line">---</span><br></pre></td></tr></table></figure><h2 id="6-配置-github-page"><a href="#6-配置-github-page" class="headerlink" title="6. 配置 github page"></a>6. 配置 github page</h2><p>只需要将 repo 名字设置为<username>.github.io,即可通过浏览器 https:&#x2F;&#x2F;<username>.github.io 访问。</p><h2 id="7-使用-github-action-实现自动部署"><a href="#7-使用-github-action-实现自动部署" class="headerlink" title="7. 使用 github action 实现自动部署"></a>7. 使用 github action 实现自动部署</h2><ol><li>安装 hexo-deployer-git 插件并配置</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><p>在 hexo 项目的配置中设置 deploy</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">https://&lt;username&gt;:GIT-TOKEN@github.com/&lt;username&gt;/&lt;username&gt;.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&lt;username&gt;</span></span><br><span class="line">  <span class="attr">email:</span> <span class="string">&lt;email&gt;</span></span><br></pre></td></tr></table></figure><p>repository 便是静态文件 repo, 也是 Github Page 对应的 repo。 2. 在 github 中创建 token(Settings Developer &#x2F; settings &#x2F; personal access tokens &#x2F; tokens(classic)，并为其添加 repo、workflow 权限 3. 在代码 repo 中创建 secret，将 2 步创建的 token 保存为 secret,名为 GIT_TOKEN<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/a1c676f79c6eae085e7ccbfe6370de1f266ededc6865711103c734cd30087064.png" alt="github设置secret"><br>4. 在代码 repo 中设置 github action.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .github/workflows/build.yaml</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">Deploy</span> <span class="string">Blog</span> <span class="string">site</span></span><br><span class="line"><span class="attr">run-name:</span> <span class="string">$&#123;&#123;</span> <span class="string">github.actor</span> <span class="string">&#125;&#125;</span> <span class="string">is</span> <span class="string">deploy</span> <span class="string">blog</span> <span class="string">site</span> <span class="string">🚀</span></span><br><span class="line"><span class="attr">on:</span> [<span class="string">push</span>]</span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">Deploy-Actions:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">env:</span></span><br><span class="line">      <span class="attr">TOKEN:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.GIT_TOKEN</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/checkout@v3</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">fetch-depth:</span> <span class="number">0</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">uses:</span> <span class="string">actions/setup-node@v3</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">node-version:</span> <span class="string">&quot;20&quot;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          sed -i &quot;s/GIT-TOKEN/$&#123;TOKEN&#125;/&quot; _config.yml</span></span><br><span class="line"><span class="string">          npm install hexo-cli -g</span></span><br><span class="line"><span class="string">          npm install --force</span></span><br><span class="line"><span class="string">          hexo clean</span></span><br><span class="line"><span class="string">          hexo deploy</span></span><br></pre></td></tr></table></figure><h2 id="8-加速-github-page-网站"><a href="#8-加速-github-page-网站" class="headerlink" title="8. 加速 github page 网站"></a>8. 加速 github page 网站</h2><p>国内访问 github page 速度很慢，可以通过<a href="https://app.netlify.com/">Netlify</a>对其进行免费加速<br>具体操作请参考：<a href="https://www.cnblogs.com/37Y37/p/12551839.html">Github Pages 访问太慢？通过 Netlify 免费加速 </a></p><h2 id="9-提交文章"><a href="#9-提交文章" class="headerlink" title="9. 提交文章"></a>9. 提交文章</h2><p>以上就绪后，在_source&#x2F;_posts 中创建新的博客，并其提交到代码库。 Github Action 将自动触发，生成静态文件，并将其提交到静态文件 repo。通过 Github Page 便可访问最新的博客了。<br>vscode插件<a href="https://github.com/imlinhanchao/vsc-markdown-image">Markdown Image</a>可以方便（Alt+Shift+V）上传插件，并生成Markdown文本。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/9214156396272c0535b6e9b540ec28fd7354fb935a530eaccd3ad4c78b22d5d5.png" alt="vscode 插件 Markdown Image配置">  </p><h2 id="10-免费域名"><a href="#10-免费域名" class="headerlink" title="10. 免费域名"></a>10. 免费域名</h2><p><a href="https://nic.eu.org/">https://nic.eu.org/</a> 该网站可申请免费域名，并支持通过dnspod.cn进行域名管理。</p><p>##参考文章<br><a href="https://butterfly.js.org/posts/4aa8abbe/">Butterfly 安裝文檔(三) 主題配置-1</a><br><a href="https://butterfly.js.org/posts/ceeb73f/">Butterfly 安裝文檔(四) 主題配置-2</a><br><a href="https://www.cnblogs.com/37Y37/p/12551839.html">Github Pages 访问太慢？通过 Netlify 免费加速 </a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> butterfly </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>晒一晒Jenkins那些常用插件</title>
      <link href="/DevOps/%E6%99%92%E4%B8%80%E6%99%92Jenkins%E9%82%A3%E4%BA%9B%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/"/>
      <url>/DevOps/%E6%99%92%E4%B8%80%E6%99%92Jenkins%E9%82%A3%E4%BA%9B%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>作为 CI&#x2F;CD 的调度中心，Jenkins 具有十八般武艺，目前已有 1700 多个插件，功能强大到似乎有点过分了。本文主要列出平时我们常用的插件。</p><p>以下这两个网站是 Jenkins 所有的插件及说明</p><h3 id="Jenkins-Plugins-https-plugins-jenkins-io"><a href="#Jenkins-Plugins-https-plugins-jenkins-io" class="headerlink" title="Jenkins Plugins https://plugins.jenkins.io"></a>Jenkins Plugins <a href="https://plugins.jenkins.io/">https://plugins.jenkins.io</a></h3><h3 id="Jinkins-Plugins-Wiki-https-wiki-jenkins-io"><a href="#Jinkins-Plugins-Wiki-https-wiki-jenkins-io" class="headerlink" title="Jinkins Plugins Wiki https://wiki.jenkins.io"></a>Jinkins Plugins Wiki <a href="https://wiki.jenkins.io/">https://wiki.jenkins.io</a></h3><hr><h1 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h1><h3 id="Jenkins-CASC-configuration-as-code"><a href="#Jenkins-CASC-configuration-as-code" class="headerlink" title="Jenkins CASC: configuration-as-code"></a><a href="https://plugins.jenkins.io/configuration-as-code">Jenkins CASC: configuration-as-code</a></h3><p>将Jenkins的配置以Code的方式进行保存，方便Jenkins的迁移与重建。该插件对于敏捷管理Jenkins服务非常有用。</p><h3 id="jobConfigHistory"><a href="#jobConfigHistory" class="headerlink" title="jobConfigHistory"></a><a href="https://plugins.jenkins.io/jobConfigHistory/">jobConfigHistory</a></h3><p>记录和跟踪Jenkins作业配置的历史变更，方便查看配置修改记录和回滚操作。</p><h1 id="Parameter"><a href="#Parameter" class="headerlink" title="Parameter"></a>Parameter</h1><h3 id="Git-Parameter"><a href="#Git-Parameter" class="headerlink" title="Git Parameter"></a><a href="https://plugins.jenkins.io/git-parameter">Git Parameter</a></h3><p>这是一个参数构建扩展，可以在构建的时候选择git的某一个分支来构建服务。</p><h3 id="file-parameters"><a href="#file-parameters" class="headerlink" title="file-parameters"></a><a href="https://plugins.jenkins.io/file-parameters">file-parameters</a></h3><p>这个让Jenkinsfile支持将文件作为参数。</p><h3 id="Hidden-Parameter"><a href="#Hidden-Parameter" class="headerlink" title="Hidden Parameter"></a><a href="https://plugins.jenkins.io/hidden-parameter/">Hidden Parameter</a></h3><p>参数化构建时，隐藏相关参数。可用于设置默认参数，同时通过API来传递参数。</p><h3 id="Extended-Choice-Parameter"><a href="#Extended-Choice-Parameter" class="headerlink" title="Extended Choice Parameter"></a><a href="https://plugins.jenkins.io/extended-choice-parameter/">Extended Choice Parameter</a></h3><p>支持更多类型的参数，如单选，多选，多级单选，多级多选类型</p><h3 id="Build-Name-and-Description-Setter"><a href="#Build-Name-and-Description-Setter" class="headerlink" title="Build Name and Description Setter"></a><a href="https://plugins.jenkins.io/build-name-setter/">Build Name and Description Setter</a></h3><p>自定义每个Build名字</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buildName &quot;$&#123;GERRIT_CHANGE_SUBJECT&#125;&quot;</span><br><span class="line">buildDescription &quot;Executed @ $&#123;NODE_NAME&#125;&quot;</span><br></pre></td></tr></table></figure><h3 id="build-user-vars"><a href="#build-user-vars" class="headerlink" title="build user vars"></a><a href="https://plugins.jenkins.io/build-user-vars-plugin/">build user vars</a></h3><p>为job注入用户信息环境变量</p><table><thead><tr><th>Variable</th><th>Description</th></tr></thead><tbody><tr><td>BUILD_USER</td><td>Full name (first name + last name)</td></tr><tr><td>BUILD_USER_FIRST_NAME</td><td>First name</td></tr><tr><td>BUILD_USER_LAST_NAME</td><td>Last name</td></tr><tr><td>BUILD_USER_ID</td><td>Jenkins user ID</td></tr><tr><td>BUILD_USER_GROUPS</td><td>Jenkins user groups</td></tr><tr><td>BUILD_USER_EMAIL</td><td>Email address</td></tr></tbody></table><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/16408b2436a240b6d4840a38a97e29cd93a097483fd1e890139174f8bce20a65.png" alt="picture 0">  </p><p>Pipeline examples:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stages &#123;</span><br><span class="line">    stage(&#x27;create user&#x27;) &#123;</span><br><span class="line">      steps&#123;</span><br><span class="line">        wrap([$class: &#x27;BuildUser&#x27;]) &#123;</span><br><span class="line">          sh &#x27;&#x27;&#x27;</span><br><span class="line">echo $BUILD_USER</span><br><span class="line">          &#x27;&#x27;&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Environment-Injector"><a href="#Environment-Injector" class="headerlink" title="Environment Injector"></a><a href="https://plugins.jenkins.io/envinject/">Environment Injector</a></h3><p>在jenkins构建job时，可以自定义添加环境变量。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/3783bfdd45a57670ebd93905a66a0bd8a26d7f7aea22cdac0b8a1cfe00d58fcc.png" alt="Environment Injector">  </p><h3 id="HashiCorp-Vault"><a href="#HashiCorp-Vault" class="headerlink" title="HashiCorp Vault"></a><a href="https://plugins.jenkins.io/hashicorp-vault-plugin/">HashiCorp Vault</a></h3><p>可以帮助Jenkins安全地管理和使用存储在Vault中的敏感信息。从Vault中获取密钥，并将其注入到Jenkins 构建环装中作为环境变量。这样可以安全地使用Vault中存储的敏感信息,而不需要将其直接写入Jenkins job中。</p><h1 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h1><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a><a href="https://plugins.jenkins.io/docker-plugin">Docker</a></h3><p>利用Docker容器动态创建Jenkins Slave。如果有了Kubernetes&#x2F;Openshift集群，就不需要这个插件了。直接使用下面的Kubernetes插件。<br>jenkins非root启动的话，为了运行docker需要执行<code>sudo chmod 777 /var/run/docker.sock</code></p><h3 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a><a href="https://plugins.jenkins.io/kubernetes">Kubernetes</a></h3><p>这个插件可以将Jenkins Slave Node动态配置为Kubernetes集群上的pod。</p><h3 id="Openshift"><a href="#Openshift" class="headerlink" title="Openshift"></a><a href="https://github.com/openshift/jenkins-plugin">Openshift</a></h3><p>这个插件支持调度Openshift的对象，包括触发 BuildConfig、Deployment、Scale up a Deployment，给ImageStream打新的Tag，以及创建新的对象、删除已有对象等。</p><h3 id="swarm"><a href="#swarm" class="headerlink" title="swarm"></a><a href="https://plugins.jenkins.io/swarm/">swarm</a></h3><p>这个插件可以方便地为jenkins master添加slave agent.</p><h1 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h1><h3 id="GitLab"><a href="#GitLab" class="headerlink" title="GitLab"></a><a href="https://plugins.jenkins.io/gitlab-plugin">GitLab</a></h3><p>配置Gitlab的相关认证，同时也支持GitLab的Webhook触发。</p><h3 id="GitLab-Hook"><a href="#GitLab-Hook" class="headerlink" title="GitLab Hook"></a><a href="https://plugins.jenkins.io/gitlab-hook">GitLab Hook</a></h3><p>支持GitLab更好的触发。</p><h3 id="Gogs-WebHook"><a href="#Gogs-WebHook" class="headerlink" title="Gogs WebHook"></a><a href="https://plugins.jenkins.io/gogs-webhook">Gogs WebHook</a></h3><p>支持Gogs代码仓库的触发。</p><h1 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h1><h3 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a><a href="https://plugins.jenkins.io/maven-plugin">Maven</a></h3><p>这个插件为Maven 2 &#x2F; 3项目提供了高级集成功能。</p><h3 id="Pyenv-Pipeline"><a href="#Pyenv-Pipeline" class="headerlink" title="Pyenv Pipeline"></a><a href="https://plugins.jenkins.io/pyenv-pipeline">Pyenv Pipeline</a></h3><p>方便对python进行项目级别的环境隔离。<br>jenkins机器上需要安装python、pip、virtualenv</p><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a><a href="https://plugins.jenkins.io/python">Python</a></h3><p>这个插件支持在Jenkins的构建过程中执行Python脚本。</p><h3 id="SonarQube-Scanner"><a href="#SonarQube-Scanner" class="headerlink" title="SonarQube Scanner"></a><a href="https://plugins.jenkins.io/sonar">SonarQube Scanner</a></h3><p>支持SonarQube的代码扫描。</p><h3 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a><a href="https://plugins.jenkins.io/ansible">Ansible</a></h3><p>在构建任务中可以执行Ansible任务。</p><h3 id="Publish-Over-SSH"><a href="#Publish-Over-SSH" class="headerlink" title="Publish Over SSH"></a><a href="https://plugins.jenkins.io/publish-over-ssh">Publish Over SSH</a></h3><p>通过SSH拷贝文件到目标机器，同时可以在目标机器上执行脚本</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/bce13516803cf6a5041580feec7e6f85f6bf63ec1e29f8902840a5f9d94d0973.png" alt="Publish Over SSH">  </p><p>事先要在设置中添加目标机器的访问方式。</p><h3 id="Condition-BuildStep"><a href="#Condition-BuildStep" class="headerlink" title="Condition BuildStep"></a><a href="https://plugins.jenkins.io/conditional-buildstep">Condition BuildStep</a></h3><p>可以使用 when 对 step 做判断</p><h3 id="Http-Request"><a href="#Http-Request" class="headerlink" title="Http Request"></a><a href="https://plugins.jenkins.io/http_request/">Http Request</a></h3><p>向用户发送一个 HTTP &#x2F; HTTPS 请求</p><h3 id="Workspace-Cleanup"><a href="#Workspace-Cleanup" class="headerlink" title="Workspace Cleanup"></a><a href="https://plugins.jenkins.io/ws-cleanup">Workspace Cleanup</a></h3><p>每次 build 之前删除 workspace 目录下指定的文件</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/71420772a75e4b64f9247fdd756ed5cea1d32f5805907d6dfbadb76e87063f61.png" alt="Workspace Cleanup">  </p><h3 id="Pipeline-Utility-Steps"><a href="#Pipeline-Utility-Steps" class="headerlink" title="Pipeline Utility Steps"></a><a href="https://github.com/jenkinsci/pipeline-utility-steps-plugin/blob/master/docs/STEPS.md">Pipeline Utility Steps</a></h3><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/70e0489bc2a99e71ce4feac72d344b74b241c3cabaf7c2357e44feb357d3b118.png" alt="Pipeline Utility Steps">  </p><h3 id="xvfb"><a href="#xvfb" class="headerlink" title="xvfb"></a><a href="https://plugins.jenkins.io/xvfb/">xvfb</a></h3><p>为应用程序提供虚拟的 X server，主要用于界面自动化测试。</p><h3 id="Timestamper"><a href="#Timestamper" class="headerlink" title="Timestamper"></a><a href="https://plugins.jenkins.io/Timestamper">Timestamper</a></h3><p>为构建日志的每一行添加时间戳，方便调试和分析构建过程的时间消耗。</p><h1 id="Job-Manager"><a href="#Job-Manager" class="headerlink" title="Job Manager"></a>Job Manager</h1><h3 id="Job-Generator"><a href="#Job-Generator" class="headerlink" title="Job Generator"></a><a href="https://plugins.jenkins.io/jobgenerator">Job Generator</a></h3><p>定义一个参数化的模板，通过这个模板快速的在 Jenkins 上创建出任务。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/d7556870702a351f390fdb88e8b96e286588ca34a4885bf162e16dc3aabf8f51.png" alt="Job Generator ">  </p><h3 id="Parameterized-Remote-Trigger"><a href="#Parameterized-Remote-Trigger" class="headerlink" title="Parameterized Remote Trigger"></a><a href="https://plugins.jenkins.io/Parameterized-Remote-Trigger/">Parameterized Remote Trigger</a></h3><p>触发远程的Jenkins server的Job</p><h3 id="Job-DSL-Plugin"><a href="#Job-DSL-Plugin" class="headerlink" title="Job DSL Plugin"></a><a href="https://plugins.jenkins.io/job-dsl/">Job DSL Plugin</a></h3><p>Jenkins Job DSL Plugin 可以让开发者通过 Groovy 脚本来定义和配置任务，随后插件会通过执行这些脚本来维护 Jenkins 任务。与 Job Generator 相比，它需要了解 Groovy。</p><h3 id="Pipeline-Job"><a href="#Pipeline-Job" class="headerlink" title="Pipeline:Job"></a><a href="https://plugins.jenkins.io/workflow-job">Pipeline:Job</a></h3><p>添加一个新的 Job 类型：Pipeline。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/bdaace3ff75ca2c152b35f5c7a9a71ad8a4c11724b3ba02052f1d2a396614a12.png" alt="Pipeline:Job">  </p><h3 id="Multijob"><a href="#Multijob" class="headerlink" title="Multijob"></a><a href="https://plugins.jenkins.io/jenkins-multijob-plugin">Multijob</a></h3><p>把多个 Job 组织起来。</p><h3 id="Parameterized-Trigger"><a href="#Parameterized-Trigger" class="headerlink" title="Parameterized Trigger"></a><a href="https://plugins.jenkins.io/parameterized-trigger">Parameterized Trigger</a></h3><p>这是一个扩展型的插件，使各个 job 连接的时候可以传递一些 job 相关的信息。</p><h3 id="Parameterized-Scheduler"><a href="#Parameterized-Scheduler" class="headerlink" title="Parameterized Scheduler"></a><a href="https://plugins.jenkins.io/parameterized-scheduler/">Parameterized Scheduler</a></h3><p>这个扩展是 Parameterized Trigger 的定时触发版</p><h3 id="Join"><a href="#Join" class="headerlink" title="Join"></a><a href="https://plugins.jenkins.io/join">Join</a></h3><p>这也是一个触发 job 的插件，亮点在于它触发 job 的条件是等待所有当前 job 的下游的 job 都完成才会发生。</p><h3 id="Build-Pipeline"><a href="#Build-Pipeline" class="headerlink" title="Build Pipeline"></a><a href="https://plugins.jenkins.io/build-pipeline-plugin">Build Pipeline</a></h3><p>这个插件提供一个构建流水线的视图。同时它提供了一个任务的手动触发器。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f58dd587a84713c0c83ef1453e0a8316c5d309a6187673e8f7e5df99905850ab.png" alt="Build Pipeline">  </p><h1 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h1><h3 id="JUnit"><a href="#JUnit" class="headerlink" title="JUnit"></a><a href="https://plugins.jenkins.io/junit">JUnit</a></h3><p>展示JUnit单元测试报告。</p><h3 id="TestNG-Results"><a href="#TestNG-Results" class="headerlink" title="TestNG Results"></a><a href="https://plugins.jenkins.io/testng-plugin">TestNG Results</a></h3><p>导出TestNG的测试报告。</p><h3 id="JaCoCo"><a href="#JaCoCo" class="headerlink" title="JaCoCo"></a><a href="https://plugins.jenkins.io/jacoco">JaCoCo</a></h3><p>生成测试覆盖率的报告。</p><h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a><a href="https://plugins.jenkins.io/performance">Performance</a></h3><p>生成性能测试报告<br>需要在Jenkins机器上安装Taurus（开源负载测试工具和功能测试工具自动化框架）</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7ad1908a7532934994dcae9ea09338e2e49d7781c47e8dbe2f0a6146d70b204f.png" alt="Performance">  </p><h3 id="Html-Publisher"><a href="#Html-Publisher" class="headerlink" title="Html Publisher"></a><a href="https://plugins.jenkins.io/htmlpublisher">Html Publisher</a></h3><p>生成报告文档。参考资料：<a href="https://www.jianshu.com/p/8fb776f83243">https://www.jianshu.com/p/8fb776f83243</a></p><h1 id="Authorization"><a href="#Authorization" class="headerlink" title="Authorization"></a>Authorization</h1><h3 id="Role-based-Authorization-Strategy-用户角色"><a href="#Role-based-Authorization-Strategy-用户角色" class="headerlink" title="Role-based Authorization Strategy 用户角色"></a><a href="https://plugins.jenkins.io/role-strategy">Role-based Authorization Strategy 用户角色</a></h3><p>给Jenkins用户权限管理添加了角色组。</p><h3 id="Matrix-Authorization-Strategy-Plugin"><a href="#Matrix-Authorization-Strategy-Plugin" class="headerlink" title="Matrix Authorization Strategy Plugin"></a><a href="https://plugins.jenkins.io/matrix-auth">Matrix Authorization Strategy Plugin</a></h3><p>为每个项目设置用户权限</p><h1 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h1><h3 id="Build-Monitor-View"><a href="#Build-Monitor-View" class="headerlink" title="Build Monitor View"></a><a href="https://plugins.jenkins.io/build-monitor-plugin">Build Monitor View</a></h3><p>将 Jenkins 项目以一块看板的形式呈现。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c18ed2c73e66fd40efb6453c80354adb70eb33c469f2a276fe628274ad33ac83.png" alt="Build Monitor View">  </p><h3 id="Disk-Usage"><a href="#Disk-Usage" class="headerlink" title="Disk Usage"></a><a href="https://plugins.jenkins.io/disk-usage">Disk Usage</a></h3><p>对Jenkins节点服务器磁盘的监控。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4b3e5d097990660b1da566b592859fd3d52d6e20028c008ff005e724503162a7.png" alt="Disk Usage">  </p><h3 id="Monitoring-监控"><a href="#Monitoring-监控" class="headerlink" title="Monitoring 监控"></a><a href="https://plugins.jenkins.io/monitoring">Monitoring 监控</a></h3><p>监控 Jenkins 节点的 CPU、系统负载、平均响应时间和内存使用。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4deac06a7f302d75cc46830e3a7c220e0d7e6d9018bfc551fe0a837ab9cd2298.png" alt="Monitoring监控">  </p><h3 id="Prometheus-Metrics"><a href="#Prometheus-Metrics" class="headerlink" title="Prometheus Metrics"></a><a href="https://plugins.jenkins.io/prometheus/">Prometheus Metrics</a></h3><p>将Jenkins 服务及job监控指标统一由Prometheus采集。<br><a href="https://grafana.com/grafana/dashboards/9524-jenkins-performance-and-health-overview/">a Jenkins performance and health overview for jenkinsci&#x2F;prometheus-plugin</a></p><h1 id="Alert"><a href="#Alert" class="headerlink" title="Alert"></a>Alert</h1><h3 id="Email-Extension"><a href="#Email-Extension" class="headerlink" title="Email Extension"></a><a href="https://plugins.jenkins.io/email-ext">Email Extension</a></h3><p>扩展了发送告警邮件的控制力度。可以定义邮件触发器、邮件内容、收件人。</p><h3 id="Mailer"><a href="#Mailer" class="headerlink" title="Mailer"></a><a href="https://plugins.jenkins.io/mailer">Mailer</a></h3><p>每次不稳定的构建都发送邮件通知。<br>单独发送邮件给对构建造成不良影响的责任人，会从 SCM 提交者人的信息中，拼出邮箱。</p><h3 id="Sounds"><a href="#Sounds" class="headerlink" title="Sounds"></a><a href="https://plugins.jenkins.io/sounds">Sounds</a></h3><p>这个插件能让 Jenkins 通过播放声音来发出通知。</p><h1 id="Backup-And-Restore"><a href="#Backup-And-Restore" class="headerlink" title="Backup And Restore"></a>Backup And Restore</h1><h3 id="Backup-备份-Jenkins"><a href="#Backup-备份-Jenkins" class="headerlink" title="Backup 备份 Jenkins"></a><a href="https://plugins.jenkins.io/backup">Backup 备份 Jenkins</a></h3><p>自定义备份 Jenkins Home 目录。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e20187d7b29d99411d45f2c21e16309c9d35163abfc0d8ef4325dc68522f6b0d.png" alt="Backup备份Jenkins">  </p><h3 id="ThinBackup-轻量备份-Jenkins"><a href="#ThinBackup-轻量备份-Jenkins" class="headerlink" title="ThinBackup 轻量备份 Jenkins"></a><a href="https://plugins.jenkins.io/thinBackup">ThinBackup 轻量备份 Jenkins</a></h3><p>轻量备份 Jenkins 上的配置与 Job</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/6e4fcb80f1dd4c149aab540886aa9df716d0d6114771c06b1ca2f8af9fa625bb.png" alt="ThinBackup轻量备份Jenkins">  </p><h3 id="SCM-Sync-Configuration"><a href="#SCM-Sync-Configuration" class="headerlink" title="SCM Sync Configuration"></a><a href="https://plugins.jenkins.io/scm-sync-configuration">SCM Sync Configuration</a></h3><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7120667b91d2c1798ca366d6d04e787a6d9de475697e3f19d612e4a36ba8b156.png" alt="SCM Sync Configuration">  </p><h3 id="备份与恢复secrets"><a href="#备份与恢复secrets" class="headerlink" title="备份与恢复secrets"></a>备份与恢复secrets</h3><p>备份</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /var/lib/jenkins</span><br><span class="line">tar czvf /tmp/jenkins_secrets.tgz secret* credentials.xml</span><br></pre></td></tr></table></figure><p>恢复</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop jenkins</span><br><span class="line">rm /var/lib/jenkins/identity.key.enc</span><br><span class="line">cd /var/lib/jenkins</span><br><span class="line">tar xzvf /tmp/jenkins_secrets.tgz -C ./</span><br><span class="line">chown jenkins:jenkins /var/lib/jenkins/credentials.xml</span><br><span class="line">chown jenkins:jenkins /var/lib/jenkins/secret*</span><br><span class="line">systemctl start jenkins</span><br></pre></td></tr></table></figure><p>通过这种方法，新的Jenkins实例将能够正确解密和使用credentials.xml中的加密凭证。这是因为Jenkins使用master.key和hudson.util.Secret文件来加密和解密凭证信息。通过复制这些文件，新的Jenkins实例将拥有相同的加密密钥，从而能够正确读取加密的凭证。</p><p>预先要在全局配置中设置代码版本控制库的配置，每次创建或更新 job 配置时都会提示是否同步配置</p><h3 id="Job-Import-Plugin"><a href="#Job-Import-Plugin" class="headerlink" title="Job Import Plugin"></a><a href="https://plugins.jenkins.io/job-import-plugin/">Job Import Plugin</a></h3><p>可方便地从一个Jenkins实例导入job到另一个实例。</p><hr>参考文章[jenkins常用插件汇总](http://www.cnblogs.com/honeybee/p/7877875.html)[Jenkins插件大全](https://blog.csdn.net/pansaky/article/details/80755739)]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
            <tag> jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cue-Lang介绍</title>
      <link href="/DevOps/Cue-Lang%E4%BB%8B%E7%BB%8D/"/>
      <url>/DevOps/Cue-Lang%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/cuelang/cue">Cue</a>，是一种开源语言，用于定义，生成和验证各种数据：配置，API，数据库模式，代码……。它能够将数据的结构、约束、数值作为同一层级成员，从而简化配置文件的生成。<br><a href="https://cuetorials.com/">Cue教程</a></p><h2 id="Cue格式说明"><a href="#Cue格式说明" class="headerlink" title="Cue格式说明"></a>Cue格式说明</h2><ol><li>使用<code>//</code>进行单行注释</li><li>对象被称为结构体</li><li>对象成员称为结构字段</li><li>对于没有特殊字符的字段名，可以省略引号</li><li>结构字段后面无需<code>,</code></li><li>在列表中的最后一个元素后放置<code>,</code></li><li>最外层的<code>&#123;&#125;</code>可省略</li></ol><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">str: &quot;hello world&quot;</span><br><span class="line">num: 42</span><br><span class="line">flt: 3.14</span><br><span class="line"></span><br><span class="line">// Special field name (and a comment)</span><br><span class="line">&quot;k8s.io/annotation&quot;: &quot;secure-me&quot;</span><br><span class="line"></span><br><span class="line">// lists can have different element types</span><br><span class="line">list: [</span><br><span class="line">&quot;a&quot;, &quot;b&quot;, &quot;c&quot;,</span><br><span class="line">1,</span><br><span class="line">2,</span><br><span class="line">3,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">obj: &#123;</span><br><span class="line">foo: &quot;bar&quot;</span><br><span class="line">// reuse another field?!</span><br><span class="line">L: list</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Cue-结构、约束、数据"><a href="#Cue-结构、约束、数据" class="headerlink" title="Cue 结构、约束、数据"></a>Cue 结构、约束、数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 结构</span><br><span class="line">album: &#123;</span><br><span class="line">title: string</span><br><span class="line">year: int</span><br><span class="line">live: bool</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 约束</span><br><span class="line">album: &#123;</span><br><span class="line">title: string</span><br><span class="line">year: &gt;1950</span><br><span class="line">live: false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 数据</span><br><span class="line">album: &#123;</span><br><span class="line">title: &quot;Houses of the Holy&quot;</span><br><span class="line">year: 1973</span><br><span class="line">live: false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Cue的最佳实践：从开放的结构模式开始，限制上下文可能性，最终具体到数据实例。<br>Cue哲学：为了保证唯一性，Cue的数据不会被覆盖。</p><h2 id="Cue核心规则"><a href="#Cue核心规则" class="headerlink" title="Cue核心规则"></a>Cue核心规则</h2><ol><li>数据可被重复定义，但必须值保持一致</li><li>结构字段可以被更强限制覆盖</li><li>结构的字段会被合并，如果是列表，必须严格匹配</li><li>规则可被递规应用<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">hello: &quot;world&quot;</span><br><span class="line">hello: &quot;world&quot;</span><br><span class="line"></span><br><span class="line">// set a type</span><br><span class="line">s: &#123; a: int &#125;</span><br><span class="line"></span><br><span class="line">// set some data</span><br><span class="line">s: &#123; a: 1, b: 2 &#125;</span><br><span class="line"></span><br><span class="line">// set a nested field without curly braces</span><br><span class="line">s: c: d: 3</span><br><span class="line"></span><br><span class="line">// lists must have the same elements</span><br><span class="line">// and cannot change length</span><br><span class="line">l: [&quot;abc&quot;, &quot;123&quot;]</span><br><span class="line">l: [</span><br><span class="line">&quot;abc&quot;,</span><br><span class="line">&quot;123&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li></ol><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><ol><li>结构并不会输出</li><li>它的值可能是不确认、不完整的</li><li>字段必须完全</li></ol><p>使用<code>#mydef</code>来定义结构，使用<code>...</code>来定义一个开放的结构体</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#Album: &#123;</span><br><span class="line">artist: string</span><br><span class="line">title: string</span><br><span class="line">year: int</span><br><span class="line"></span><br><span class="line">// ...  uncomment to open, must be last</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// This is a conjunction, it says &quot;album&quot; has to be &quot;#Album&quot;</span><br><span class="line">album: #Album &amp; &#123;</span><br><span class="line">artist: &quot;Led Zeppelin&quot;</span><br><span class="line">title: &quot;Led Zeppelin I&quot;</span><br><span class="line">year: 1969</span><br><span class="line"></span><br><span class="line">// studio: true  (uncomment to trigger error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#Person: &#123;</span><br><span class="line"> name: string</span><br><span class="line">... // open struct</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Jim: #Person &amp; &#123;</span><br><span class="line"> name: &quot;jim&quot;</span><br><span class="line"> age: 12</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h2><p>约束与数值使用<code>&amp;</code>字符进行连接时，会将值进行校验</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// conjunctions on a field</span><br><span class="line">n: int &amp; &gt;0 &amp; &lt;100</span><br><span class="line">n: 23</span><br><span class="line"></span><br><span class="line">// conjuction of schemas</span><br><span class="line">val: #Def1 &amp; #Def2</span><br><span class="line">val: &#123; foo: &quot;bar&quot;, ans: 42 &#125;</span><br><span class="line"></span><br><span class="line">#Def1: &#123;</span><br><span class="line">foo: string</span><br><span class="line">ans: int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#Def2: &#123;</span><br><span class="line">foo: =~ &quot;[a-z]+&quot;</span><br><span class="line">ans: &gt;0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h2><p>使用<code>|</code>可以实现支持多种结构。同时它也可以为出错值设置替换值</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">// disjunction of values (like an enum)</span><br><span class="line">hello: &quot;world&quot; | &quot;bob&quot; | &quot;mary&quot;</span><br><span class="line">hello: &quot;world&quot;</span><br><span class="line"></span><br><span class="line">// disjunction of types</span><br><span class="line">port: string | int</span><br><span class="line">port: 5432</span><br><span class="line"></span><br><span class="line">// disjunction of schemas</span><br><span class="line">val: #Def1 | #Def2</span><br><span class="line">val: &#123; foo: &quot;bar&quot;, ans: 42 &#125;</span><br><span class="line"></span><br><span class="line">#Def1: &#123;</span><br><span class="line">foo: string</span><br><span class="line">ans: int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#Def2: &#123;</span><br><span class="line">name: string</span><br><span class="line">port: int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="默认值与可选"><a href="#默认值与可选" class="headerlink" title="默认值与可选"></a>默认值与可选</h2><p>使用<code>*</code>来设置默认值， <code>?</code>设置可选字段 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">s: &#123;</span><br><span class="line">// field with a default</span><br><span class="line">hello: string | *&quot;world&quot; | &quot;apple&quot;</span><br><span class="line">// an optional integer</span><br><span class="line">count?: int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="开放模式与封闭模式"><a href="#开放模式与封闭模式" class="headerlink" title="开放模式与封闭模式"></a>开放模式与封闭模式</h2><p>开放模式意味着结构可以扩展，关闭模式意味着不能扩展。 默认情况下，结构是开放模式，定义是封闭模式。 可以通过定义的最后添加<code>...</code>来申明开放模式定义；另外通过过close强制为结构体设置为关闭模式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// Open definition</span><br><span class="line">#d: &#123;</span><br><span class="line">foo: &quot;bar&quot;</span><br><span class="line">... // must be last</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Closed struct</span><br><span class="line">s: close(&#123;</span><br><span class="line">foo: &quot;bar&quot;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">jim: &#123;</span><br><span class="line">  name: &quot;Jim&quot;</span><br><span class="line">&#125;</span><br><span class="line">jim: &#123;</span><br><span class="line">  age: 12</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="推荐从基础定义开始，复用定义"><a href="#推荐从基础定义开始，复用定义" class="headerlink" title="推荐从基础定义开始，复用定义"></a>推荐从基础定义开始，复用定义</h2><p>在编写Cue时，推荐从基础定义开始，这样能够有更好的复用能力。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#Base: &#123;</span><br><span class="line">name: string</span><br><span class="line">kind: string</span><br><span class="line">... // so it can be extended</span><br><span class="line">&#125;</span><br><span class="line">#Meta: &#123;</span><br><span class="line">// string and a semver regex</span><br><span class="line">version: string &amp; =~&quot;^v[0-9]+\\.[0-9]+\\.[0-9]+$&quot;</span><br><span class="line">// list of strings</span><br><span class="line">labels: [...string]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#Permissions: &#123;</span><br><span class="line">role: string</span><br><span class="line">public: bool | *false</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Building up a schema using a conjunction and embedding</span><br><span class="line">#Schema: #Base &amp; &#123;</span><br><span class="line">// &quot;embed&quot; meta and permissions</span><br><span class="line">#Meta</span><br><span class="line">#Permissions</span><br><span class="line">// with no &#x27;...&#x27; this is final</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">value: #Schema &amp; &#123;</span><br><span class="line">name: &quot;app&quot;</span><br><span class="line">kind: &quot;deploy&quot;</span><br><span class="line">version: &quot;v1.0.42&quot;</span><br><span class="line">labels: [&quot;server&quot;, &quot;prod&quot;]</span><br><span class="line">role: &quot;backend&quot;</span><br><span class="line">// public: false  (by default)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="定义多行字符串"><a href="#定义多行字符串" class="headerlink" title="定义多行字符串"></a>定义多行字符串</h2><ol><li>使用<code>&quot;&quot;&quot;</code>来定义多行字符串<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">str1: #&quot;avoid using \ to &quot;escape&quot;&quot;#</span><br><span class="line">str2: &quot;&quot;&quot;</span><br><span class="line">a nested multiline</span><br><span class="line">string goes here</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure></li><li>使用反引号(&#96;)定义原始字符串<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">multiline: `</span><br><span class="line">这是一个</span><br><span class="line">多行字符串</span><br><span class="line">保留了换行和空格</span><br><span class="line">`</span><br></pre></td></tr></table></figure></li><li>使用#”…”# 定义原始字符串,可以避免转义<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">multiline: #&quot;</span><br><span class="line">这种写法可以包含 &quot;引号&quot; 而不需要转义</span><br><span class="line">还可以包含 \反斜杠\ 等特殊字符</span><br><span class="line">&quot;#</span><br></pre></td></tr></table></figure></li><li>使用 + 连接多个字符串<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">multiline: &quot;第一行\n&quot; +</span><br><span class="line">           &quot;第二行\n&quot; +</span><br><span class="line">           &quot;第三行&quot;</span><br></pre></td></tr></table></figure></li></ol><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>List 可被定义为开放模式，这样便可与其它数据进行合并，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">empty: []</span><br><span class="line">any: [...]</span><br><span class="line">ints: [...int]</span><br><span class="line">nested: [...[...string]]</span><br><span class="line"></span><br><span class="line">opened: ints &amp; [1,2,...]</span><br><span class="line">closed: ints &amp; [1,2,3]</span><br><span class="line"></span><br><span class="line">// list of for constrained ints</span><br><span class="line">ip: 4 * [uint8]</span><br><span class="line">// sets the first element</span><br><span class="line">tendot: ip &amp; [10, ...uint8]</span><br><span class="line">// uses constraint as second element</span><br><span class="line">one72: ip &amp; [172, &gt;=16 &amp; &lt;=32, ...]</span><br><span class="line"></span><br><span class="line">mixed: any &amp; [...] &amp; [&quot;a&quot;,1, &#123; foo: &quot;bar&quot; &#125;]</span><br><span class="line">join: [1,2] + [3,4]</span><br><span class="line">Join: opened &amp; join</span><br></pre></td></tr></table></figure><h2 id="Struct"><a href="#Struct" class="headerlink" title="Struct"></a>Struct</h2><p>结构体是Cue的主要内容，也是最终数据的输出。如上介绍，默认情况下它是开放模式。除了使用Json类型形式进行设置值，还可通过级联<code>:</code>来设置，如<code>a: hello: &quot;world&quot;</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// an open struct</span><br><span class="line">a: &#123;</span><br><span class="line">foo: &quot;bar&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// shorthand nested field</span><br><span class="line">a: hello: &quot;world&quot;</span><br><span class="line"></span><br><span class="line">// a closed struct</span><br><span class="line">b: close(&#123;</span><br><span class="line">left: &quot;right&quot;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h2 id="模式匹配约束"><a href="#模式匹配约束" class="headerlink" title="模式匹配约束"></a>模式匹配约束</h2><p>模式匹配允许您为与模式匹配的标签指定约束。可以将约束应用于字符串标签，并使用标识符来设置字段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#schema: &#123;</span><br><span class="line">name: string</span><br><span class="line">ans: string</span><br><span class="line">num: int | *42</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// match elem fields and alias labels to Name,</span><br><span class="line">// unify with schema, set name to Name by label</span><br><span class="line">elems: [Name=_]: #schema &amp; &#123; name: Name &#125;</span><br><span class="line"></span><br><span class="line">elems: &#123;</span><br><span class="line">one: &#123;</span><br><span class="line">ans: &quot;solo&quot;</span><br><span class="line">num: 1</span><br><span class="line">&#125;</span><br><span class="line">two: &#123;</span><br><span class="line">ans: &quot;life&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">elems: other: &#123; ans: &quot;id&quot;, num: 23 &#125;</span><br></pre></td></tr></table></figure><h2 id="表达式"><a href="#表达式" class="headerlink" title="表达式"></a>表达式</h2><ol><li>引用字段，使用<code>\(**)</code>显用其它字段<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">container: &#123;</span><br><span class="line">repo: &quot;docker.io/cuelang&quot;</span><br><span class="line">image: &quot;cue&quot;</span><br><span class="line">version: &quot;v0.3.0&quot;</span><br><span class="line">full: &quot;\(repo)/\(image):\(version)&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">name: &quot;Tony&quot;</span><br><span class="line">msg: &quot;Hello \(name)&quot;</span><br><span class="line">// conver string to bytes</span><br><span class="line">b: &#x27;\(msg)&#x27;</span><br><span class="line">// convert bytes to string</span><br><span class="line">s: &quot;\(b)&quot;</span><br></pre></td></tr></table></figure></li><li>Cue也能够为通过<code>\(**)</code>来设置key<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apps: [&quot;nginx&quot;, &quot;express&quot;, &quot;postgres&quot;]</span><br><span class="line">#labels: [string]: string</span><br><span class="line">stack: &#123;</span><br><span class="line">for i, app in apps &#123;</span><br><span class="line">&quot;\(app)&quot;: &#123;</span><br><span class="line">name: app</span><br><span class="line">labels: #labels &amp; &#123;</span><br><span class="line">app: &quot;foo&quot;</span><br><span class="line">tier: &quot;\(i)&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>List遍历<br>遍历List数据格式如下：<code>[ for key, val in &lt;iterable&gt; [condition] &#123; production &#125; ]</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">nums: [1,2,3,4,5,6]</span><br><span class="line">sqrd: [ for _, n in nums &#123; n*n &#125; ]</span><br><span class="line">even: [ for _, n in nums if mod(n,2) == 0 &#123; n &#125; ]</span><br><span class="line"></span><br><span class="line">listOfStructs: [ for p, n in nums &#123;</span><br><span class="line">pos: p</span><br><span class="line">val: n</span><br><span class="line">&#125;]</span><br><span class="line"></span><br><span class="line">extractVals: [ for p, S in listOfStructs &#123; S.val &#125; ]</span><br></pre></td></tr></table></figure></li><li>条件控制语句<br>没有else，所有判断都会被执行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">app: &#123;</span><br><span class="line">name: string</span><br><span class="line">tech: string</span><br><span class="line">mem: int</span><br><span class="line"></span><br><span class="line">if tech == &quot;react&quot; &#123;</span><br><span class="line">tier: &quot;frontend&quot;</span><br><span class="line">&#125;</span><br><span class="line">if tech != &quot;react&quot; &#123;</span><br><span class="line">tier: &quot;backend&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if mem &lt; 1Gi &#123;</span><br><span class="line">footprint: &quot;small&quot;</span><br><span class="line">&#125;</span><br><span class="line">if mem &gt;= 1Gi &amp;&amp; mem &lt; 4Gi &#123;</span><br><span class="line">footprint: &quot;medium&quot;</span><br><span class="line">&#125;</span><br><span class="line">if mem  &gt;= 4Gi &#123;</span><br><span class="line">footprint: &quot;large&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="标准库"><a href="#标准库" class="headerlink" title="标准库"></a>标准库</h2><p>Cue的标准库中包含了很多的帮助包（helper packages）。</p><ol><li>Encoding<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">package stdlib</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">&quot;encoding/json&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">data: &quot;&quot;&quot;</span><br><span class="line">&#123;</span><br><span class="line">&quot;hello&quot;: &quot;world&quot;,</span><br><span class="line">&quot;list&quot;: [ 1, 2 ],</span><br><span class="line">&quot;nested&quot;: &#123;</span><br><span class="line">&quot;foo&quot;: &quot;bar&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">jval: json.Unmarshal(data)</span><br><span class="line"></span><br><span class="line">val: &#123;</span><br><span class="line">hello: &quot;world&quot;</span><br><span class="line">list: [1,2]</span><br><span class="line">nested: foo: &quot;bar&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cjson: json.Marshal(val)</span><br></pre></td></tr></table></figure></li><li>Strings<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">package stdlib</span><br><span class="line"></span><br><span class="line">import &quot;strings&quot;</span><br><span class="line"></span><br><span class="line">s: &quot;HelloWorld&quot;</span><br><span class="line"></span><br><span class="line">u: strings.ToUpper(s)</span><br><span class="line">l: strings.ToLower(s)</span><br><span class="line"></span><br><span class="line">line: &quot;Cue stands for configure, unify, execute&quot;</span><br><span class="line">words: strings.Split(line, &quot; &quot;)</span><br><span class="line">lined: strings.Join(words, &quot; &quot;)</span><br><span class="line"></span><br><span class="line">haspre: strings.HasPrefix(line, &quot;Cue&quot;)</span><br><span class="line">index:  strings.Index(line, &quot;unify&quot;)</span><br></pre></td></tr></table></figure></li><li>List<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">package stdlib</span><br><span class="line"></span><br><span class="line">import &quot;list&quot;</span><br><span class="line"></span><br><span class="line">l1: [1,2,3,4,5]</span><br><span class="line">l2: [&quot;c&quot;,&quot;b&quot;,&quot;a&quot;]</span><br><span class="line"></span><br><span class="line">// constrain length</span><br><span class="line">l2: list.MinItems(1)</span><br><span class="line">l2: list.MaxItems(3)</span><br><span class="line"></span><br><span class="line">// slice a list</span><br><span class="line">l3: list.Slice(l1, 2,4)</span><br><span class="line"></span><br><span class="line">// get the sum and product</span><br><span class="line">sum: list.Sum(l1)</span><br><span class="line">prd: list.Product(l1)</span><br><span class="line"></span><br><span class="line">// linear search for list (no binary)</span><br><span class="line">lc: list.Contains(l1, 2)</span><br><span class="line"></span><br><span class="line">// sort a list</span><br><span class="line">ls: list.Sort(l2, list.Ascending)</span><br><span class="line">l2s: list.IsSorted(l2, list.Ascending)</span><br><span class="line">lss: list.IsSorted(ls, list.Ascending)</span><br><span class="line"></span><br><span class="line">// Flatten a list</span><br><span class="line">ll: [1,[2,3],[4,[5]]]</span><br><span class="line">lf: list.FlattenN(ll, 1)</span><br></pre></td></tr></table></figure></li><li>Constrain<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">package stdlib</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">&quot;net&quot;</span><br><span class="line">&quot;time&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">// string with ip format</span><br><span class="line">ip: net.IPv4</span><br><span class="line">ip: &quot;10.1.2.3&quot;</span><br><span class="line"></span><br><span class="line">// string with time format</span><br><span class="line">ts: time.Format(time.ANSIC)</span><br><span class="line">ts: &quot;Mon Jan 2 15:04:05 2006&quot;</span><br></pre></td></tr></table></figure></li></ol><h2 id="模块和包"><a href="#模块和包" class="headerlink" title="模块和包"></a>模块和包</h2><p>cuelang有module和package系统，可以import依赖</p><ol><li>模块定义</li></ol><ul><li>通过在项目根目录创建cue.mod&#x2F;module.cue文件来定义模块。通过 <code>cue mod init &lt;模块名&gt;</code>来初始化。</li><li>模块名格式通常为<code>domain.com/name</code>或<code>github.com/owner/repo</code></li></ul><ol start="2"><li>package组织</li></ol><ul><li>一个模块可以包含多个package</li><li>允许在一个目录中包含多个package</li></ul><ol start="3"><li>导入package</li></ol><ul><li>使用绝对路径导入,不允许相对路径导入</li><li>导入时可以省略domain,表示导入内置标准包</li><li>可以在导入时重命名包</li><li>同一个包内的定义和值可以直接访问,无需导入</li></ul><p>例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">package deploy</span><br><span class="line">import  (</span><br><span class="line">p_spec &quot;douhua.com/name/devops/pkg/spec:spec&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">a: p_spec.#A &amp; &#123;</span><br><span class="line">name: &quot;test&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="使用Cue制作脚本命令工具"><a href="#使用Cue制作脚本命令工具" class="headerlink" title="使用Cue制作脚本命令工具"></a>使用Cue制作脚本命令工具</h2><p>Cue 拥有制作脚本命令工具的功能，它有一个工具层，可用来执行脚本、读写文件以及网络访问等。<br>规范：</p><ul><li>脚本文件以<code>_tool.cue</code>结尾</li><li>执行命令为<code>cue cmd &lt;name&gt;</code> or <code>cue &lt;name&gt;</code><br>例子：</li></ul><ol><li>脚本文件名为<code>ex_tool.cue</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">package foo</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">&quot;tool/cli&quot;</span><br><span class="line">&quot;tool/exec&quot;</span><br><span class="line">&quot;tool/file&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">// moved to the data.cue file to show how we can reference &quot;pure&quot; Cue files</span><br><span class="line">// city: &quot;Amsterdam&quot;</span><br><span class="line"></span><br><span class="line">// A command named &quot;prompter&quot;</span><br><span class="line">command: prompter: &#123;</span><br><span class="line"></span><br><span class="line">// save transcript to this file</span><br><span class="line">var: file: *&quot;out.txt&quot; | string @tag(file) // you can use &quot;-t flag=filename.txt&quot; to change the output file, see &quot;cue help injection&quot; for more details</span><br><span class="line"></span><br><span class="line">// prompt the user for some input</span><br><span class="line">ask: cli.Ask &amp; &#123;</span><br><span class="line">prompt:   &quot;What is your name?&quot;</span><br><span class="line">response: string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// run an external command, starts after ask</span><br><span class="line">echo: exec.Run &amp; &#123;</span><br><span class="line">// note the reference to ask and city here</span><br><span class="line">cmd:    [&quot;echo&quot;, &quot;Hello&quot;, ask.response + &quot;!&quot;, &quot;Have you been to&quot;, city + &quot;?&quot;]</span><br><span class="line">stdout: string // capture stdout, don&#x27;t print to the terminal</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// append to a file, starts after echo</span><br><span class="line">append: file.Append &amp; &#123;</span><br><span class="line">filename: var.file</span><br><span class="line">contents: echo.stdout // becuase we reference the echo task</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// also starts after echo, and concurrently with append</span><br><span class="line">print: cli.Print &amp; &#123;</span><br><span class="line">text: echo.stdout // write the output to the terminal since we captured it previously</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><ul><li>prompter为命令名</li><li>ask&#x2F;echo&#x2F;append&#x2F;print为唯一标识</li><li>cli.Ask&#x2F;exec.Run&#x2F;file.Append为函数,</li><li>&amp;{…}为函数参数</li></ul><ol start="2"><li>创建data.cue<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">package foo</span><br><span class="line"></span><br><span class="line">city: &quot;Amsterdam&quot;</span><br></pre></td></tr></table></figure></li><li>运行：<code>cue cmd prompter</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cue cmd prompter</span><br><span class="line">What is your name? he</span><br><span class="line">Hello he! Have you been to Amsterdam?</span><br><span class="line">$ cat out.txt</span><br><span class="line">Hello he! Have you been to Amsterdam?</span><br></pre></td></tr></table></figure></li><li>使用cuelang exec.Run 执行多行代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">package foo</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">        &quot;tool/exec&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">command: &#123;</span><br><span class="line">hello: &#123;</span><br><span class="line">script: #&quot;&quot;&quot;</span><br><span class="line">#!/bin/bash</span><br><span class="line">echo hello world</span><br><span class="line">key1=&quot;hello you&quot;</span><br><span class="line">ls</span><br><span class="line">echo $key1</span><br><span class="line">&quot;&quot;&quot;#</span><br><span class="line">run: cmd: _</span><br><span class="line">run: exec.Run &amp; &#123;</span><br><span class="line">cmd: &quot;bash&quot;</span><br><span class="line">stdin: script</span><br><span class="line">&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul><li>A &amp; B &#x3D;&#x3D;&#x3D; B &amp; A</li><li>A &#x3D;&#x3D;&#x3D; A</li><li>路径短写：{a : {b: {c: 5}}} &#x3D;&#x3D; a: b: c: 5</li><li>多种类型：a | b | c</li><li>默认值：number | *1</li><li>算术： 4 + 5</li><li>变量引用：”Hello (person)”</li><li>列表遍历：[ x for x in y ]</li><li>cue 执行 当前目录下的cue文件及父目录下同一个package的cue文件</li><li>cue .&#x2F;… 以上目录 + 遍历当前目录的子目录下的cue文件</li><li>_开头的变量不会在输出结果中显示，作为局部变量</li><li>[Name&#x3D;_] 可用来定义一个模板，其中Name匹配任意字段。例如：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">application: [Name=_]: &#123;</span><br><span class="line">name: string | *Name</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>_|_ 可判断是否存在。例如：if _variable !&#x3D; _|_ { &#x2F;&#x2F; … }<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a ?: string</span><br><span class="line">if a == _|_ &#123;</span><br><span class="line">b: &quot;a&quot;</span><br><span class="line">&#125;</span><br><span class="line">// 结果为</span><br><span class="line">// cue export a.cue</span><br><span class="line">// b: &quot;a&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a: string</span><br><span class="line">if a == _|_ &#123;</span><br><span class="line">b: &quot;a&quot;</span><br><span class="line">&#125;</span><br><span class="line">// 结果为</span><br><span class="line">// cue eval a.cue</span><br><span class="line">// a: string</span><br><span class="line">// b: &quot;a&quot;</span><br></pre></td></tr></table></figure></li><li>定义映射：map: [string]: string</li><li>定义切片：slice: […{name:string,value:string}]</li></ul><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/6d4d159471eb9f2fd69bd36139063b74586458b1b9b199855a7376ab5ffa6365.png" alt="Go To Cue">  </p><ol><li>使用 <code>cue import</code> 将已有的yaml转成<code>Cue</code>语言<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cue import ./... -p kube -l &#x27;&quot;\(strings.ToCamel(kind))&quot; &quot;\(metadata.name)&quot;&#x27; -fR </span><br></pre></td></tr></table></figure></li><li>引入k8s资源的模块<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ go mod init main</span><br><span class="line">$ cue get go k8s.io/api/extensions/v1beta1 -v</span><br></pre></td></tr></table></figure></li><li>导入k8s资源模块，并创建资源<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">package kube</span><br><span class="line">import (</span><br><span class="line">  &quot;k8s.io/api/core/v1&quot;</span><br><span class="line">  &quot;k8s.io/api/extensions/v1beta1&quot;</span><br><span class="line">)</span><br><span class="line">service &lt;Name&gt;: v1.Service</span><br><span class="line">deployment &lt;Name&gt;: v1beta1.Deployment</span><br></pre></td></tr></table></figure></li><li>cue trim 可用来自动删除冗余字段，以简化配置文件</li></ol><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://cuetorials.com/introduction/">cue torials</a><br><a href="https://shikanon.com/2021/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/cue%E8%AF%AD%E6%B3%95/">cue语法</a><br><a href="https://kubevela.io/zh/docs/next/platform-engineers/cue/basic">cue语言入门</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows-WSL2开发环境，一点不逊色于Mac</title>
      <link href="/DevOps/Windows-WSL2%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%8C%E4%B8%80%E7%82%B9%E4%B8%8D%E9%80%8A%E8%89%B2%E4%BA%8EMac/"/>
      <url>/DevOps/Windows-WSL2%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%8C%E4%B8%80%E7%82%B9%E4%B8%8D%E9%80%8A%E8%89%B2%E4%BA%8EMac/</url>
      
        <content type="html"><![CDATA[<p>一直使用Mac来做开发，但没想到现在Windows也这么好用。通过WSL，拥有了Windows酣畅的操作特性，又有了Linux的兼容性。作为开发环境一点不逊色于Mac，甚至更易使用。下面就操练起来吧。</p><h2 id="WSL2"><a href="#WSL2" class="headerlink" title="WSL2"></a>WSL2</h2><h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h3><p>控制面板 -&gt; 程序和功能 -&gt; 启用和关闭windows 功能， 勾选如下功能：<br>    - 适用于Linux的Windows子系统<br>    - 虚拟机平台</p><p>确定。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/5a2593017e4d18d45b08fbe0a0cc9e0e968c2182346446ba86a568aa1eb5f097.png" alt="功能特性">  </p><h3 id="2-升级WSL"><a href="#2-升级WSL" class="headerlink" title="2. 升级WSL"></a>2. 升级WSL</h3><p><a href="https://docs.microsoft.com/en-us/windows/wsl/install-manual#step-4---download-the-linux-kernel-update-package">https://docs.microsoft.com/en-us/windows/wsl/install-manual#step-4---download-the-linux-kernel-update-package</a><br>下载 Linux 内核更新包 <a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">WSL2 Linux kernel update package for x64 machines</a><br>，并安装。</p><pre><code>设置wsl默认版本为 `2`， PowerShell<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --set-default-version 2</span><br></pre></td></tr></table></figure>  升级已安装的分发，可使用wsl --set-version, PowerShell<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --set-version 分发版名称 版本号</span><br></pre></td></tr></table></figure></code></pre><h3 id="3-安装windows-terminal"><a href="#3-安装windows-terminal" class="headerlink" title="3. 安装windows terminal"></a>3. 安装windows terminal</h3><p>在windows appstore中安装windows terminal</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/99a63a3d2dd02b8c4d36af8df0855ee563751a4a446515f0ad749861e374936f.png" alt="windows terminal">  </p><h3 id="4-安装Linux系统"><a href="#4-安装Linux系统" class="headerlink" title="4. 安装Linux系统"></a>4. 安装Linux系统</h3><p>在windows appstore中安装 ubuntu 22.04</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8cc68ddac17609222dc8f85cf2b5751a0e5460ebe967aa85cd0697012a2c2061.png" alt="ubuntu">  </p><p>并在windows terminal 中设置WSL的访问</p><ul><li>命令行：wsl.exe -d Ubuntu-20.04 </li><li>启动目录: &#x2F;&#x2F;wsl$&#x2F;Ubuntu-20.04&#x2F;home&#x2F;{username}&#x2F;</li></ul><h3 id="5-WSL开机启动sshd"><a href="#5-WSL开机启动sshd" class="headerlink" title="5. WSL开机启动sshd"></a>5. WSL开机启动sshd</h3><p>通过windows terminal进行ubuntu系统，并配置ssh开机启动</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># /etc/init.wsl</span><br><span class="line">#!/bin/bash</span><br><span class="line">/etc/init.d/ssh start</span><br></pre></td></tr></table></figure><h3 id="5-将端口暴露"><a href="#5-将端口暴露" class="headerlink" title="5. 将端口暴露"></a>5. 将端口暴露</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">powershell:</span><br><span class="line">PS C:\Users\mpan&gt; netsh interface portproxy add v4tov4 listenport=22 connectaddress=127.0.0.1 connectport=22 listenaddress=* protocol=tcp</span><br></pre></td></tr></table></figure><p>如果需要删除该策略可执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\mpan&gt; netsh interface portproxy delete v4tov4 listenport=22 protocol=tcp</span><br></pre></td></tr></table></figure><p><strong>如果磁盘空间紧张，可以使用<a href="https://github.com/pxlrbt/move-wsl">pxlrbt&#x2F;move-wsl</a>工具迁移虚机到其它盘。</strong></p><h2 id="zsh"><a href="#zsh" class="headerlink" title="zsh"></a>zsh</h2><ol><li>安装<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ apt install zsh -y</span><br><span class="line">$ chsh -s /bin/zsh</span><br><span class="line">$ zsh</span><br></pre></td></tr></table></figure></li><li>安装 zinit 和插件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bash -c &quot;$(curl --fail --show-error --silent --location https://raw.githubusercontent.com/zdharma-continuum/zinit/HEAD/scripts/install.sh)&quot;</span><br></pre></td></tr></table></figure></li><li>配置zsh<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># ~/.zshrc</span><br><span class="line">...</span><br><span class="line"># Load powerlevel10k theme</span><br><span class="line">zinit ice depth&quot;1&quot; # git clone depth</span><br><span class="line">zinit light romkatv/powerlevel10k</span><br><span class="line"></span><br><span class="line"># Plugin history-search-multi-word loaded with investigating.</span><br><span class="line">zinit load zdharma-continuum/history-search-multi-word</span><br><span class="line"></span><br><span class="line"># Two regular plugins loaded without investigating.</span><br><span class="line">zinit light zsh-users/zsh-autosuggestions</span><br><span class="line">zinit light zdharma-continuum/fast-syntax-highlighting</span><br><span class="line"></span><br><span class="line">zinit snippet https://gist.githubusercontent.com/hightemp/5071909/raw/</span><br><span class="line">zinit ice lucid wait=&#x27;0&#x27;</span><br><span class="line">zinit snippet https://github.com/ohmyzsh/ohmyzsh/blob/master/plugins/git/git.plugin.zsh</span><br><span class="line"></span><br><span class="line">autoload -Uz compinit &amp;&amp; compinit</span><br><span class="line"></span><br><span class="line">## 解决粘贴慢的问题</span><br><span class="line">pasteinit() &#123;</span><br><span class="line">  OLD_SELF_INSERT=$&#123;$&#123;(s.:.)widgets[self-insert]&#125;[2,3]&#125;</span><br><span class="line">  zle -N self-insert url-quote-magic # I wonder if you&#x27;d need `.url-quote-magic`?</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pastefinish() &#123;</span><br><span class="line">  zle -N self-insert $OLD_SELF_INSERT</span><br><span class="line">&#125;</span><br><span class="line">zstyle :bracketed-paste-magic paste-init pasteinit</span><br><span class="line">zstyle :bracketed-paste-magic paste-finish pastefinish</span><br><span class="line"></span><br><span class="line"># ~/.bashrc</span><br><span class="line">export PATH=&quot;$&#123;KREW_ROOT:-$HOME/.krew&#125;/bin:$HOME/shtool:$PATH:$HOME/go/bin:/home/mpan/.local/bin&quot;</span><br><span class="line">export BROWSER=wslview</span><br><span class="line">source $&#123;fpath[1]&#125;/_kubectl</span><br><span class="line">unsetopt prompt_cr prompt_sp</span><br><span class="line"></span><br><span class="line">alias pbcopy=&quot;clip.exe&quot;</span><br><span class="line">alias pbpaste=&quot;powershell.exe -command &#x27;Get-Clipboard&#x27;|head -n 1&quot;</span><br><span class="line">alias bd=&#x27;ostr=`pbpaste`; echo $&#123;ostr:0:-1&#125;  | base64 -d&#x27;</span><br><span class="line">alias b=&#x27;ostr=`pbpaste`; echo -n $&#123;ostr:0:-1&#125; | base64&#x27;</span><br><span class="line">alias gpush=&quot;git push origin HEAD:refs/for/main&quot;</span><br><span class="line"></span><br><span class="line">### ctrl+arrows</span><br><span class="line">bindkey &quot;\e[1;5C&quot; forward-word</span><br><span class="line">bindkey &quot;\e[1;5D&quot; backward-word</span><br></pre></td></tr></table></figure></li></ol><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><ol><li>安装并启动</li></ol><p>下载Docker Desktop安装： <a href="https://docs.docker.com/desktop/windows/install/">Install Docker Desktop on Windows | Docker Documentation</a></p><ol start="2"><li>配置</li></ol><p>开启 WSL2作为基础引擎<br>3. 验证, WSL Ubuntu</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker ps</span></span><br></pre></td></tr></table></figure><blockquote><p>随着docker镜像越来越多，占用的空间也会越来越多，默认docker的数据目录存放在C盘(C:\Users&lt;Username&gt;\AppData\Local\Docker)，可以使用软链接的方式将数据文件移到其它分区。<br>其中<username> 为用户名<br>在将Docker目录移到其它空间足够的磁盘后（通过剪切-&gt; 粘贴 或者 按住Shift键，鼠标移动）执行创建软链接命令，如：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmd /c mklink /j  C:\Users\admin\AppData\Local\Docker E:\WSL2\Docker-Data</span><br></pre></td></tr></table></figure><p>另外，如果只希望压缩文件大小，可以使用分区工具 diskpart</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\admin&gt; diskpart.exe</span><br><span class="line">DISKPART&gt; select vdisk file=&quot;C:\Users\admin\AppData\Local\Docker\wsl\disk\docker_data.vhdx&quot;</span><br><span class="line"></span><br><span class="line">DiskPart 已成功选择虚拟磁盘文件。</span><br><span class="line"></span><br><span class="line">DISKPART&gt; compact vdisk</span><br><span class="line"></span><br><span class="line">  100 百分比已完成</span><br><span class="line"></span><br><span class="line">DiskPart 已成功压缩虚拟磁盘文件。</span><br></pre></td></tr></table></figure><h2 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h2><ol><li>Docker Desktop设置中开启Kubernetes，即可获得一个单节点的K8s集群。<br>如果镜像无法下载，可参考： <a href="https://github.com/AliyunContainerService/k8s-for-docker-desktop">https://github.com/AliyunContainerService/k8s-for-docker-desktop</a> 预先导入镜像</li></ol><p>也可以设置registry-mirrors，在docker desktop的设置-&gt;Docker Engine中添加配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;https://docker.m.daocloud.io&quot;</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure><ol start="2"><li>可使用其它方式部署K8S&#x2F;K3S，以kind为例：<br>安装 kind<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64</span><br><span class="line">$ sudo install kind-linux-amd64 /usr/local/bin/kind</span><br></pre></td></tr></table></figure>创建集群<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  kind  create cluster --name wsl2-k8s</span><br></pre></td></tr></table></figure>查看集群 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kind get clusters</span><br></pre></td></tr></table></figure>删除集群 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kind delete cluster --name wsl2-k8s</span><br></pre></td></tr></table></figure></li><li>kubectl命令扩展工具安装<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># windows</span><br><span class="line"> winget install --id ahmetb.kubectx</span><br><span class="line"> winget install --id ahmetb.kubens</span><br><span class="line"></span><br><span class="line"># linux</span><br><span class="line"> curl -L https://github.com/ahmetb/kubectx/releases/download/v0.9.1/kubens -o /bin/kubens</span><br><span class="line"> chmod +x /bin/kubens</span><br><span class="line"></span><br><span class="line"># mac</span><br><span class="line"> brew install kubectx</span><br></pre></td></tr></table></figure>或者作为Kubectl的一个插件安装<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl krew install ns</span><br></pre></td></tr></table></figure></li></ol><h2 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a>vscode</h2><ol><li><p>安装 <a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a><br>下载vscode，并安装</p></li><li><p>安装插件<br>安装插件 Remote - WSL</p></li><li><p>通过远程资源管理器，打开连接WSL的vscode windows<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/da2598fe2c03184b5be459f5481a2ea79ccae7581dac67eca55981fcb9496f93.png" alt="连接wsl">  </p></li><li><p>在新窗口中选择WSL系统下的目录，开始愉快编码。</p></li></ol><h2 id="wsl挂载外部硬盘"><a href="#wsl挂载外部硬盘" class="headerlink" title="wsl挂载外部硬盘"></a>wsl挂载外部硬盘</h2><ol><li><p>PowerShell 升级wsl，如果没有’–mount’ 命令的话</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --update</span><br></pre></td></tr></table></figure></li><li><p>PowerShell 查看所有磁盘</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET-CimInstance -query &quot;SELECT * from Win32_DiskDrive&quot;</span><br></pre></td></tr></table></figure></li><li><p>PowerShell 挂载磁盘,其中<DiskPath>的格式为：<code>\\.\PHYSICALDRIVE*</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --mount &lt;DiskPath&gt; --bare</span><br></pre></td></tr></table></figure></li><li><p>Linux 登录wsl验证</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk</span><br></pre></td></tr></table></figure></li><li><p>PowerShell 卸载磁盘，其中<DiskPath>的格式为：<code>\\.\PHYSICALDRIVE*</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --unmount &lt;DiskPath&gt;</span><br></pre></td></tr></table></figure><p><strong>小拓展：</strong></p></li><li><p>插件：git history, gitlens, live server</p></li><li><p>添加快捷键。 命令：<code>清除控制台 </code>  绑定键：<code>ctrl + k</code>  当（条件）：<code>terminalFocus</code></p></li><li><p>析本机磁盘文件Windows工具分：<a href="https://windirstat.net/">WinDirStat</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SciKit-Learn-机器学习入门（一）</title>
      <link href="/ml/SciKit-Learn-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89/"/>
      <url>/ml/SciKit-Learn-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/10ea9e68b0c56173d6b8af926ace443c8cb89d7a1f7ec73cc707c0b34df11b12.png" alt="机器学习逻辑表">  </p><h2 id="安装SciKit-Learn"><a href="#安装SciKit-Learn" class="headerlink" title="安装SciKit Learn"></a>安装SciKit Learn</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy</span><br><span class="line">pip install sklearn</span><br><span class="line">pip install matplotlib</span><br></pre></td></tr></table></figure><h2 id="sklean中自带的数据"><a href="#sklean中自带的数据" class="headerlink" title="sklean中自带的数据"></a>sklean中自带的数据</h2><blockquote><ol><li>iris 鸢尾属植物数据（分类）</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">iris = datasets.load_iris()</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>Boston房价信息（线性回归）</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">boston = datasets.load_boston()</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>等等</li></ol></blockquote><h2 id="分类器实例"><a href="#分类器实例" class="headerlink" title="分类器实例"></a>分类器实例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">iris = datasets.load_iris()  ## 加载数据</span><br><span class="line"></span><br><span class="line">iris_X = iris.data  ## X坐标，叶子长宽等属性</span><br><span class="line">iris_Y = iris.target  ## Y坐标， 植物品种[0, 1, 2]</span><br><span class="line">X_tain, X_test, Y_train, Y_test = train_test_split(iris_X, iris_Y, test_size=0.3)  ## 将数据中的70%做为训练数据，30%作为测试数据</span><br><span class="line"></span><br><span class="line">knn = KNeighborsClassifier()  ## 使用Neighbors分类器模型</span><br><span class="line">knn.fit(X_tain, Y_train)   ## 使用数据中的70%对模型进行训练</span><br><span class="line"></span><br><span class="line">print(knn.predict(X_test)) ## 对剩下的30%的属性进行预测品种</span><br><span class="line">print(Y_test)  ## 剩下的30%属性对应的真实品种值</span><br><span class="line"></span><br><span class="line">print(knn.score(X_test, Y_test))  ## 对该模型中的30%预测结果与真实结果比较，对模型准确度打分</span><br></pre></td></tr></table></figure><p>以上对该分类器实例得到的准确度达到93%以上</p><h2 id="线性回归实例"><a href="#线性回归实例" class="headerlink" title="线性回归实例"></a>线性回归实例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">boston = datasets.load_boston() ## 加载波士顿房价信息</span><br><span class="line"></span><br><span class="line">boston_X = boston.data ## X坐标，房价相关属性：大小，位置等</span><br><span class="line">boston_Y = boston.target  ## 房价</span><br><span class="line"></span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split(boston_X, boston_Y, test_size=0.3) ##将数据中的70%作为训练数据，30%作为测试数据</span><br><span class="line"></span><br><span class="line">model = LinearRegression() ## 使用LinearRegression线性回归模型</span><br><span class="line">model.fit(X_train, Y_train) ## 对模型进行训练</span><br><span class="line">Y_pre = model.predict(X_test) ## 对30%的测试数据进行预测</span><br><span class="line"></span><br><span class="line"># plt.scatter(X_test[:,0], Y_test) ## 在图上展示与第一个属性相关图表</span><br><span class="line"># plt.scatter(X_test[:,0], Y_pre)</span><br><span class="line"># plt.show() </span><br><span class="line"></span><br><span class="line"># y = model.coef_ * X + model.intercept_</span><br><span class="line">print(model.coef_) ## 得到对于每个属性的斜率</span><br><span class="line">print(model.intercept_) ## 得到在Y坐标的截距</span><br><span class="line">print(model.score(X_test, Y_test)) ## 对该模型中的30%预测结果与真实结果比较，对模型准确度打分</span><br></pre></td></tr></table></figure><p>以上对房价预测得到的准确度只有60%左右</p><h2 id="Normalization（Scale"><a href="#Normalization（Scale" class="headerlink" title="Normalization（Scale)"></a>Normalization（Scale)</h2><p><code>如果X自变量的范围很大</code>，会影响到数据的预测精确度，可以先对X坐标进行压缩，再对数据进行训练预测</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import preprocessing</span><br><span class="line">import numpy as np</span><br><span class="line">data = np.array([[10, 23, 3], [-100, 5, 2], [150, 23, 4]], dtype=np.float64)</span><br><span class="line">print(data)</span><br><span class="line">print(preprocessing.scale(data))</span><br><span class="line"></span><br><span class="line">## 执行结果</span><br><span class="line">[[  10.   23.    3.]</span><br><span class="line"> [-100.    5.    2.]</span><br><span class="line"> [ 150.   23.    4.]]</span><br><span class="line">[[-0.09774528  0.70710678  0.        ]</span><br><span class="line"> [-1.17294338 -1.41421356 -1.22474487]</span><br><span class="line"> [ 1.27068866  0.70710678  1.22474487]]</span><br></pre></td></tr></table></figure><p>更适合机器学习进行处理</p><h2 id="Cross-Validation-交叉验证"><a href="#Cross-Validation-交叉验证" class="headerlink" title="Cross Validation 交叉验证"></a>Cross Validation 交叉验证</h2><p>对一个模型打分，之前使用score方法进行评分，但是它只能对于一部分数据作为测试数据进行比较。使用cross_val_score的方法，会将数据分成多组训练数据与测试数据，最后取平均值的方式，对模型打分更准确。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/585d4d2fc2999cdd95104ade0ed1dbf7c4ba7a09c2a9d39647464f2b0c15a623.png" alt="交叉验证">  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">iris = datasets.load_iris()  ## 加载数据</span><br><span class="line">iris_X = iris.data  ## X坐标，叶子长宽等属性</span><br><span class="line">iris_Y = iris.target  ## Y坐标， 植物品种[0, 1, 2]</span><br><span class="line">knn= KNeighborsClassifier() ## 使用KNeighborsClassifier分类模型</span><br><span class="line">scores = cross_val_score(knn, iris_X, iris_Y, cv=5, scoring=&#x27;accuracy&#x27;) ## 将数据分为5份，其中4份为训练数据，1份为测试数据</span><br><span class="line">print(scores.mean())</span><br></pre></td></tr></table></figure><p>这样得到的评分会更准确。<br>对于KNeighborsClassifier模型训练时，设置n_neighbors的值多少更合适，可以对它的值进行遍历，根据cross_val_score的值得到最合适的配置参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">iris = datasets.load_iris()  ## 加载数据</span><br><span class="line">iris_X = iris.data  ## X坐标，叶子长宽等属性</span><br><span class="line">iris_Y = iris.target  ## Y坐标， 植物品种[0, 1, 2]</span><br><span class="line">k_range = range(1, 31)</span><br><span class="line">max_score = []</span><br><span class="line">for k in k_range:</span><br><span class="line">    knn= KNeighborsClassifier(n_neighbors=k) ## 使用KNeighborsClassifier分类模型</span><br><span class="line">    scores = cross_val_score(knn, iris_X, iris_Y, cv=10) ## 进行交叉验证打分 这个值（准确度）是越大，越准确</span><br><span class="line">    max_score.append(scores.mean()) ## 计算交叉验证打分的平均值</span><br><span class="line"></span><br><span class="line">## 将数据在图中打印出来，显目地看到不同n_neighbors值对结果的影响</span><br><span class="line">plt.plot(k_range, max_score) </span><br><span class="line">plt.xlabel(u&#x27;n_neighbors Value&#x27;)</span><br><span class="line">plt.ylabel(u&#x27;Score&#x27;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/bf53414371312f8a31ee1ad366a1f3d6028771c31d203545c7ee9b1ce51cab23.png" alt="不同n_neighbors值对就的评分">  </p><p>从图中可以我们选择k值，选择12到18之前的值，会有更准确的预测。</p><h2 id="过度学习（随着训练数据越多，准确度越低）"><a href="#过度学习（随着训练数据越多，准确度越低）" class="headerlink" title="过度学习（随着训练数据越多，准确度越低）"></a>过度学习（随着训练数据越多，准确度越低）</h2><blockquote><p>learning_curve参数固定时，随着训练数据增多，查看准确度</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import learning_curve</span><br><span class="line">from sklearn.datasets import load_digits</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">digits = load_digits() ## 导入数据</span><br><span class="line">X = digits.data ## 数据X坐标值</span><br><span class="line">Y = digits.target ##数据Y坐标值</span><br><span class="line"></span><br><span class="line">train_sizes, train_loss, test_loss = learning_curve(SVC(gamma=0.001), X, Y, cv=10,</span><br><span class="line">                                                    train_sizes=[0.1, 0.25, 0.5, 0.75, 1]) ## 对SVC(gamma=0.001)进行训练，并标记下10%, 25%, 50%, 75%, 100%作为训练集时的精确度</span><br><span class="line">train_loss_mean = np.mean(train_loss, axis=1) ## 训练集准确度</span><br><span class="line">test_loss_mean = np.mean(test_loss, axis=1) ## 测试集准确度</span><br><span class="line"></span><br><span class="line">## 将训练准确度与测试准确度画出来，看到模型不断训练，准确度不断提升</span><br><span class="line">plt.plot(train_sizes, train_loss_mean, &#x27;o-&#x27;, color=&quot;r&quot;, label=&quot;Training&quot;)</span><br><span class="line">plt.plot(train_sizes, test_loss_mean, &#x27;o-&#x27;, color=&quot;g&quot;, label=&quot;Cross-validation&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/b71520e17ba47abaac014381f205972dd9870f0e102bd34eb9e4a23a53cf3b25.png" alt="不断训练准确度不断提升learning_curve">  </p><blockquote><p>validation_curve 遍历可能的参数值，找到最合适的参数值</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.model_selection import learning_curve, validation_curve</span><br><span class="line">from sklearn.datasets import load_digits</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">Y = digits.target</span><br><span class="line">param_range = np.logspace(-6, -2.3, 5)</span><br><span class="line">train_loss, test_loss = validation_curve(SVC(), X, Y, param_name=&#x27;gamma&#x27;, param_range=param_range, cv=10)</span><br><span class="line">## train_sizes为10%， 25%等记录一下</span><br><span class="line">train_loss_mean = np.mean(train_loss, axis=1)</span><br><span class="line">test_loss_mean = np.mean(test_loss, axis=1)</span><br><span class="line"></span><br><span class="line">plt.plot(param_range, train_loss_mean, &#x27;o-&#x27;, color=&quot;r&quot;, label=&quot;Training&quot;)</span><br><span class="line">plt.plot(param_range, test_loss_mean, &#x27;o-&#x27;, color=&quot;g&quot;, label=&quot;Cross-validation&quot;)</span><br><span class="line"></span><br><span class="line">plt.xlabel(&quot;gamma&quot;)</span><br><span class="line">plt.ylabel(&quot;value&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2f08a39294de44a6e63f852553fc01c18f82548a602040abddb7092506dd8023.png" alt="参数validation_curve">  </p><p>从图中可以看到，gamma使用0.0005值左右的数据准确度会更适合，也不会出现过度训练的问题。</p><h2 id="保存训练后的模型"><a href="#保存训练后的模型" class="headerlink" title="保存训练后的模型"></a>保存训练后的模型</h2><blockquote><ol><li>使用pickle模块保存对象</li></ol></blockquote><p>将模型保存到save&#x2F;clf.pickle文件中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import svm</span><br><span class="line">from sklearn import datasets</span><br><span class="line"></span><br><span class="line">clf = svm.SVC()</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, Y = iris.data, iris.target</span><br><span class="line">clf.fit(X, Y)  ## 训练模型</span><br><span class="line"></span><br><span class="line">import pickle</span><br><span class="line">with open(&#x27;save/clf.pickle&#x27;, &#x27;wb&#x27;) as clf_file:</span><br><span class="line">    pickle.dump(clf, clf_file) ## 将模型保存到save/clf.pickle文件中</span><br></pre></td></tr></table></figure><p>将模型从save&#x2F;clf.pickle文件中导入，并进行预测</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import svm</span><br><span class="line">from sklearn import datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">with open(&#x27;save/clf.pickle&#x27;, &#x27;rb&#x27;) as clf_file:</span><br><span class="line">    clf = pickle.load(clf_file)</span><br><span class="line">print(clf.predict(X[0:1]))</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>使用joblib</li></ol></blockquote><p>将模型保存到save&#x2F;clf.pkl</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import svm</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line"></span><br><span class="line">clf = svm.SVC()</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X, Y = iris.data, iris.target</span><br><span class="line">clf.fit(X, Y)</span><br><span class="line"></span><br><span class="line">## 保存数据</span><br><span class="line">joblib.dump(clf, &#x27;save/clf.pkl&#x27;)</span><br></pre></td></tr></table></figure><p>将模型从save&#x2F;clf.pkl文件中导入，并进行预测</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn import svm</span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line"></span><br><span class="line">## 导入对象</span><br><span class="line">clf = joblib.load(&#x27;save/clf.pkl&#x27;)</span><br><span class="line">print(clf.predict(X[0:1])) ## 对数据进行预测</span><br></pre></td></tr></table></figure><h2 id="参考教程："><a href="#参考教程：" class="headerlink" title="参考教程："></a>参考教程：</h2><ul><li>莫烦教学 SKLearn</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SciKit-Learn机器学习入门（二）——Pipeline</title>
      <link href="/ml/SciKit-Learn%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94Pipeline/"/>
      <url>/ml/SciKit-Learn%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94Pipeline/</url>
      
        <content type="html"><![CDATA[<p>在我们平常的机器学习得到的数据并不能直接使用，必须先对它进行预处理后才能正常使用。以股票数据为例，当前的股价并不是独立的，它与之前的股价是有关系的，一个可用的方法是对对股价处理转为增长幅度。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">time1, price1</span><br><span class="line">time2, price2</span><br></pre></td></tr></table></figure><p>转为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">time1, Nan</span><br><span class="line">time2, (price2-price1)/price1</span><br></pre></td></tr></table></figure><p>SKLear提供了Pipeline工具方便数据处理。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">## 定义数据处理类ColumnExtractor，获取指定列的数据</span><br><span class="line">class ColumnExtractor(BaseEstimator, TransformerMixin):</span><br><span class="line">    def __init__(self, column_name):</span><br><span class="line">        self.column_name = column_name</span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line">        return self</span><br><span class="line">    def transform(self, X, y=None):</span><br><span class="line">        return X[self.column_name]</span><br><span class="line"></span><br><span class="line">## 定义数据处理类TimeSeriesDiff， 对数据作data.diff()/data.shift(1)处理</span><br><span class="line">class TimeSeriesDiff(BaseEstimator, TransformerMixin):</span><br><span class="line">    def __init__(self, k=1):</span><br><span class="line">        self.k = k </span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line">        return self</span><br><span class="line">    def transform(self, X, y=None):</span><br><span class="line">        if type(X) is pd.core.frame.DataFrame or type(X) is pd.core.series.Series:</span><br><span class="line">            return X.diff(self.k) / X.shift(self.k)</span><br><span class="line">        else:</span><br><span class="line">            raise Exception(&quot;Have to be a pandas data frame or Series object!&quot;)</span><br><span class="line"></span><br><span class="line">## 定义数据处理类TimeSeriesEmbedder，每k个数据组成新的数据，共有N-k组数据</span><br><span class="line">class TimeSeriesEmbedder(BaseEstimator, TransformerMixin):</span><br><span class="line">    def __init__(self, k):</span><br><span class="line">        self.k = k </span><br><span class="line">    def fit(self, X, y= None):</span><br><span class="line">        return self</span><br><span class="line">    def transform(self, X, y = None):</span><br><span class="line">        return embed_time_series(X, self.k)</span><br><span class="line"></span><br><span class="line">def embed_time_series(x, k):</span><br><span class="line">    n = len(x)</span><br><span class="line">    if k &gt;= n: </span><br><span class="line">        raise Exception(&quot;Can not deal with k greater than the length of x&quot;)</span><br><span class="line">    output_x = list(map(lambda i: list(x[i:(i+k)]), </span><br><span class="line">                        range(0, n-k)))</span><br><span class="line">    return np.array(output_x)</span><br></pre></td></tr></table></figure><p>使用PipeLine对数据进行预处理组成新的模型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">## 对&quot;Close&quot;列数据进行处理</span><br><span class="line">pipeline_closing_price = Pipeline([(&quot;ColumnEx&quot;, ColumnExtractor(&quot;Close&quot;)),</span><br><span class="line">                                   (&quot;Diff&quot;, TimeSeriesDiff()),</span><br><span class="line">                                   (&quot;Embed&quot;, TimeSeriesEmbedder(10)),</span><br><span class="line">                                   (&quot;ImputerNA&quot;, Imputer())])</span><br><span class="line"></span><br><span class="line">## 对&quot;Volume&quot;列数据进行处理</span><br><span class="line">pipeline_volume = Pipeline([(&quot;ColumnEx&quot;, ColumnExtractor(&quot;Volume&quot;)),</span><br><span class="line">                            (&quot;Diff&quot;, TimeSeriesDiff()),</span><br><span class="line">                            (&quot;Embed&quot;, TimeSeriesEmbedder(10)),</span><br><span class="line">                            (&quot;ImputerNA&quot;, Imputer())])</span><br><span class="line"></span><br><span class="line">## 联合将”Close&quot;与&quot;Volume&quot;处理后的数据</span><br><span class="line">merged_features = FeatureUnion([(&quot;ClosingPriceFeature&quot;, pipeline_closing_price),</span><br><span class="line">                                (&quot;VolumeFeature&quot;, pipeline_volume)])</span><br><span class="line"></span><br><span class="line">## 将数据中添加多项式特征</span><br><span class="line">pipeline_2 = Pipeline([(&quot;MergedFeatures&quot;, merged_features),</span><br><span class="line">                       (&quot;PolyFeature&quot;,PolynomialFeatures()),</span><br><span class="line">                       (&quot;LinReg&quot;, LinearRegression())])</span><br></pre></td></tr></table></figure><p>使用新模型进行数据训练与预测</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pipeline_2.fit(data_train, y_train)</span><br><span class="line">y_pred_2 = pipeline_2.predict(data_test)</span><br></pre></td></tr></table></figure><p>对预测数据进行打分</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import r2_score</span><br><span class="line">r2_score(y_test, y_pred_2)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个性化聚类推荐Kmeans实战</title>
      <link href="/ml/%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%9A%E7%B1%BB%E6%8E%A8%E8%8D%90Kmeans%E5%AE%9E%E6%88%98/"/>
      <url>/ml/%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%9A%E7%B1%BB%E6%8E%A8%E8%8D%90Kmeans%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="1-去除不需要的数据"><a href="#1-去除不需要的数据" class="headerlink" title="1. 去除不需要的数据"></a>1. 去除不需要的数据</h2><p><strong>目标是：一个用户，后面全是用户的特征</strong></p><ul><li>列数据中 Null 数据 &gt; 80% 所有数据 isnull().sum()</li><li>列数据中一样的数据 &gt; 80%所有数据 value_counts()</li><li>表示同一个意思的字段，只需要保留一个：如用户名、用户账号、支付账号、收货人姓名</li><li>根据场景分析不需要的字段：如买家应付货款、应付邮费等</li></ul><h2 id="2-只获取指定的列数据"><a href="#2-只获取指定的列数据" class="headerlink" title="2. 只获取指定的列数据"></a>2. 只获取指定的列数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_order.ix[:, <span class="string">&#x27;订单编号&#x27;</span>, <span class="string">&#x27;买家会员名&#x27;</span>, <span class="string">&#x27;买家实际支付金额&#x27;</span>, <span class="string">&#x27;收货地址&#x27;</span>, <span class="string">&#x27;种类&#x27;</span>, <span class="string">&#x27;数量&#x27;</span>, <span class="string">&#x27;退款金额&#x27;</span>]</span><br><span class="line"><span class="comment"># ix是loc与iloc的合集，其中loc是按照列名来取数据，iloc是按照列的index来取数据</span></span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_order[[<span class="string">&#x27;订单编号&#x27;</span>, <span class="string">&#x27;买家会员名&#x27;</span>, <span class="string">&#x27;买家实际支付金额&#x27;</span>, <span class="string">&#x27;收货地址&#x27;</span>, <span class="string">&#x27;种类&#x27;</span>, <span class="string">&#x27;数量&#x27;</span>, <span class="string">&#x27;退款金额&#x27;</span>]]</span><br></pre></td></tr></table></figure><h2 id="3-对数据进行格式化"><a href="#3-对数据进行格式化" class="headerlink" title="3. 对数据进行格式化"></a>3. 对数据进行格式化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_order[<span class="string">&#x27;收货地址&#x27;</span>] = df_order[<span class="string">&#x27;收货地址&#x27;</span>].apply(<span class="keyword">lambda</span> x:x.split()[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h2 id="4-按照某列数据给整行数据打tag"><a href="#4-按照某列数据给整行数据打tag" class="headerlink" title="4. 按照某列数据给整行数据打tag"></a>4. 按照某列数据给整行数据打tag</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_tag</span>(<span class="params">info</span>):</span><br><span class="line">  <span class="keyword">if</span> <span class="string">&#x27;月&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">    tag = <span class="string">&#x27;婴儿|&#x27;</span></span><br><span class="line">  <span class="keyword">if</span> <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">    tag = <span class="string">&#x27;幼儿|&#x27;</span></span><br><span class="line">  <span class="keyword">if</span>:</span><br><span class="line">    tag = <span class="string">&#x27;学生|&#x27;</span></span><br><span class="line">  <span class="keyword">return</span> tag[:-<span class="number">1</span>]</span><br><span class="line">attrs[<span class="string">&#x27;tag&#x27;</span>] = attrs[<span class="string">&#x27;适用年龄&#x27;</span>].apply(add_tag)</span><br></pre></td></tr></table></figure><h2 id="5-数据合并"><a href="#5-数据合并" class="headerlink" title="5. 数据合并"></a>5. 数据合并</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(items, attrs, on=<span class="string">&#x27;标题&#x27;</span>, how=<span class="string">&#x27;inner&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="6-对每个用户进行分组汇总"><a href="#6-对每个用户进行分组汇总" class="headerlink" title="6. 对每个用户进行分组汇总"></a>6. 对每个用户进行分组汇总</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">order_tag[<span class="string">&#x27;购买次数&#x27;</span>] = <span class="number">1</span></span><br><span class="line">test2 = order_tag.groupby([<span class="string">&#x27;买家会员名&#x27;</span>, <span class="string">&#x27;tag2&#x27;</span>]).count()</span><br><span class="line">test2.unstack(<span class="string">&#x27;tag2&#x27;</span>).fillna(<span class="number">0</span>) <span class="comment"># unstack将会把索引数据中的一列转为列名</span></span><br></pre></td></tr></table></figure><h2 id="7-对重复的数据取平均值"><a href="#7-对重复的数据取平均值" class="headerlink" title="7. 对重复的数据取平均值"></a>7. 对重复的数据取平均值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res1 = res1.groupby([<span class="string">&#x27;会员&#x27;</span>, <span class="string">&#x27;地址&#x27;</span>]).mean()</span><br><span class="line">res1.reset_index(inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h2 id="8-将字符串转为数值的方法有两种："><a href="#8-将字符串转为数值的方法有两种：" class="headerlink" title="8. 将字符串转为数值的方法有两种："></a>8. 将字符串转为数值的方法有两种：</h2><ol><li>用数值表示具体值，如：好、一般、差就用相关数值表示</li><li>unstack将它转为column，或者get_dummies方法将非数值型转为column</li></ol>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.get_dummies?</span><br><span class="line">result2= pd.get_dummies(res1) <span class="comment">##只会对非数值型有效</span></span><br></pre></td></tr></table></figure><p>最后得到的数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">       买家实际支付金额  宝贝种类  宝贝总数量  退款金额  收货地址_上海  收货地址_云南省  收货地址_内蒙古自治区  收货地址_北京  \</span><br><span class="line">买家会员名                                                                         </span><br><span class="line"><span class="number">409</span>       <span class="number">35.31</span>     <span class="number">8</span>     <span class="number">11</span>   <span class="number">0.0</span>        <span class="number">0</span>         <span class="number">0</span>            <span class="number">0</span>        <span class="number">0</span>   </span><br><span class="line"><span class="number">2270</span>      <span class="number">13.70</span>     <span class="number">1</span>      <span class="number">3</span>   <span class="number">0.0</span>        <span class="number">0</span>         <span class="number">0</span>            <span class="number">0</span>        <span class="number">0</span>   </span><br><span class="line"><span class="number">1908</span>      <span class="number">55.09</span>     <span class="number">7</span>      <span class="number">7</span>   <span class="number">0.0</span>        <span class="number">0</span>         <span class="number">0</span>            <span class="number">0</span>        <span class="number">0</span>   </span><br><span class="line"><span class="number">1727</span>      <span class="number">62.72</span>    <span class="number">11</span>     <span class="number">14</span>   <span class="number">0.0</span>        <span class="number">1</span>         <span class="number">0</span>            <span class="number">0</span>        <span class="number">0</span>   </span><br><span class="line"><span class="number">1976</span>      <span class="number">18.80</span>     <span class="number">1</span>      <span class="number">2</span>   <span class="number">0.0</span>        <span class="number">0</span>         <span class="number">1</span>            <span class="number">0</span>        <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">       收货地址_吉林省  收货地址_四川省    ...      收货地址_湖北省  收货地址_湖南省  收货地址_甘肃省  收货地址_福建省  \</span><br><span class="line">买家会员名                        ...                                               </span><br><span class="line"><span class="number">409</span>           <span class="number">0</span>         <span class="number">0</span>    ...             <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>   </span><br><span class="line"><span class="number">2270</span>          <span class="number">0</span>         <span class="number">0</span>    ...             <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>   </span><br><span class="line"><span class="number">1908</span>          <span class="number">0</span>         <span class="number">0</span>    ...             <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>   </span><br><span class="line"><span class="number">1727</span>          <span class="number">0</span>         <span class="number">0</span>    ...             <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>   </span><br><span class="line"><span class="number">1976</span>          <span class="number">0</span>         <span class="number">0</span>    ...             <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>   </span><br><span class="line"></span><br><span class="line">       收货地址_贵州省  收货地址_辽宁省  收货地址_重庆  收货地址_陕西省  收货地址_青海省  收货地址_黑龙江省  </span><br><span class="line">买家会员名                                                              </span><br><span class="line"><span class="number">409</span>           <span class="number">0</span>         <span class="number">0</span>        <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>          <span class="number">0</span>  </span><br><span class="line"><span class="number">2270</span>          <span class="number">0</span>         <span class="number">0</span>        <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>          <span class="number">0</span>  </span><br><span class="line"><span class="number">1908</span>          <span class="number">0</span>         <span class="number">0</span>        <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>          <span class="number">0</span>  </span><br><span class="line"><span class="number">1727</span>          <span class="number">0</span>         <span class="number">0</span>        <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>          <span class="number">0</span>  </span><br><span class="line"><span class="number">1976</span>          <span class="number">0</span>         <span class="number">0</span>        <span class="number">0</span>         <span class="number">0</span>         <span class="number">0</span>          <span class="number">0</span>  </span><br></pre></td></tr></table></figure><h1 id="基于用户聚类"><a href="#基于用户聚类" class="headerlink" title="基于用户聚类"></a>基于用户聚类</h1><p><strong>目标：对用户进行标记分类</strong></p><h2 id="1-数据标准化"><a href="#1-数据标准化" class="headerlink" title="1. 数据标准化"></a>1. 数据标准化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">data = order_df.ix[:,<span class="number">1</span>:].values  <span class="comment">#去掉第一列数据，也就是用户id</span></span><br><span class="line">mms=MinMaxScaler()</span><br><span class="line">data_nore = mms.fit_transform(data)</span><br><span class="line"><span class="built_in">print</span>(data_nore)</span><br></pre></td></tr></table></figure><h2 id="2-聚类"><a href="#2-聚类" class="headerlink" title="2. 聚类"></a>2. 聚类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">- 手肘法</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">sse = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">15</span>):</span><br><span class="line">    km = KMeans(n_clusters=k)</span><br><span class="line">    km.fit(data_nore)</span><br><span class="line">    sse.append(km.inertia_)</span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">15</span>)</span><br><span class="line">y = sse</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">- 轮廓法</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line">score = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">15</span>):</span><br><span class="line">    km=KMeans(n_clusters=k)</span><br><span class="line">    res_km = km.fit(data_nore)</span><br><span class="line">    score.append(silhouette_score(data_nore, res_km.labels_))</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">2</span>, <span class="number">15</span>), score, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据上面的值取得最优n_clusters值，例如为8</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">km=KMeans(n_clusters=<span class="number">8</span>)</span><br><span class="line">res_km = km.fit(data_nore)</span><br><span class="line">km.labels_ <span class="comment"># 这个就是聚类结果,也是最终需要的结果</span></span><br></pre></td></tr></table></figure><h2 id="3-将类别添加到分析数据中"><a href="#3-将类别添加到分析数据中" class="headerlink" title="3. 将类别添加到分析数据中"></a>3. 将类别添加到分析数据中</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result2[<span class="string">&#x27;类别&#x27;</span>] = km.labels_ <span class="comment">#对原始用户进行类别标记</span></span><br></pre></td></tr></table></figure><h1 id="基于用户聚类进行推荐"><a href="#基于用户聚类进行推荐" class="headerlink" title="基于用户聚类进行推荐"></a>基于用户聚类进行推荐</h1><p><strong>目标：向用户推荐产品</strong></p><p>同一类群中，大多数人喜欢的商品，用户也喜欢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">order_df[<span class="string">&#x27;商品购买次数&#x27;</span>] = <span class="number">1</span></span><br><span class="line">data = order_df.groupby([<span class="string">&#x27;类别&#x27;</span>,<span class="string">&#x27;商品&#x27;</span>].count()) <span class="comment">#不同类别人对商品的关注程度</span></span><br><span class="line">data.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(data.ix[:, [<span class="string">&#x27;类别&#x27;</span>,<span class="string">&#x27;商品&#x27;</span>, <span class="string">&#x27;商品购买次数&#x27;</span>]]) <span class="comment">#得到类别-&gt;商品-&gt;购买次数</span></span><br></pre></td></tr></table></figure><p>推荐给用户同一个类别，而没有购买过的商品，按照购买次数排序推荐。</p><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="pandas-DataFrame基本方法"><a href="#pandas-DataFrame基本方法" class="headerlink" title="pandas.DataFrame基本方法"></a>pandas.DataFrame基本方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df.info() <span class="comment">#查看数据信息</span></span><br><span class="line">df.shape <span class="comment">#获得数据行列数</span></span><br><span class="line"><span class="keyword">del</span>(df[<span class="string">&#x27;a&#x27;</span>]) <span class="comment">#删除某列数据</span></span><br><span class="line">df[<span class="string">&#x27;col&#x27;</span>].values <span class="comment">#查看数据</span></span><br><span class="line">df.columns <span class="comment">#查看列名</span></span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>) <span class="comment">#重置索引</span></span><br><span class="line">df.index = df[<span class="string">&#x27;index&#x27;</span>] <span class="comment">#创建索引</span></span><br><span class="line">df = df.set_index(<span class="string">&#x27;index&#x27;</span>) <span class="comment">#将某列设置为索引</span></span><br></pre></td></tr></table></figure><h2 id="df合并"><a href="#df合并" class="headerlink" title="df合并"></a>df合并</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merged_df = left_df.merge(right_df, how=<span class="string">&quot;left&quot;</span>, left_on=<span class="string">u&#x27;主机配置&#x27;</span>, right_on=<span class="string">u&#x27;主机说明&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="根据某条数据的属性添加新的数据列"><a href="#根据某条数据的属性添加新的数据列" class="headerlink" title="根据某条数据的属性添加新的数据列"></a>根据某条数据的属性添加新的数据列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;b&#x27;</span>] = <span class="number">0</span></span><br><span class="line">df[<span class="string">&#x27;b&#x27;</span>][df[<span class="string">&#x27;a&#x27;</span>]==<span class="number">1</span>] = <span class="number">8</span> <span class="comment">##注意先选完整的列，再过滤才能赋值</span></span><br></pre></td></tr></table></figure><h2 id="读取文件时，默认是utf8格式，也可以指定编码"><a href="#读取文件时，默认是utf8格式，也可以指定编码" class="headerlink" title="读取文件时，默认是utf8格式，也可以指定编码"></a>读取文件时，默认是utf8格式，也可以指定编码</h2><p>常见的编码方式有：ascii&#x2F;utf8&#x2F;unicode&#x2F;utf-16&#x2F;gb2312&#x2F;gbk&#x2F;gb18030</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.read_csv(<span class="string">&#x27;file_path.csv&#x27;</span>, encoding=<span class="string">&#x27;gb2312&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="将一列数据转为多列数据"><a href="#将一列数据转为多列数据" class="headerlink" title="将一列数据转为多列数据"></a>将一列数据转为多列数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame([&#123;<span class="string">&quot;a&quot;</span>: <span class="number">1</span>, <span class="string">&quot;name&quot;</span>:<span class="string">&quot;1|2|4&quot;</span>&#125;, &#123;<span class="string">&quot;a&quot;</span>: <span class="number">2</span>, <span class="string">&quot;name&quot;</span>:<span class="string">&quot;1|5|9&quot;</span>&#125;])</span><br><span class="line">df[[<span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>]] = df[<span class="string">&#x27;name&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>, expand=<span class="literal">True</span>)  <span class="comment"># 多名字分列</span></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">df = df.join(df[<span class="string">&#x27;name&#x27;</span>].<span class="built_in">str</span>.split(<span class="string">&#x27;|&#x27;</span>, expand=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">result:</span><br><span class="line">   a   name  b  c  d</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">1</span>|<span class="number">2</span>|<span class="number">4</span>  <span class="number">1</span>  <span class="number">2</span>  <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">1</span>|<span class="number">5</span>|<span class="number">9</span>  <span class="number">1</span>  <span class="number">5</span>  <span class="number">9</span></span><br></pre></td></tr></table></figure><h2 id="将DataFrame中的tuple分割成数据框的多列"><a href="#将DataFrame中的tuple分割成数据框的多列" class="headerlink" title="将DataFrame中的tuple分割成数据框的多列"></a>将DataFrame中的tuple分割成数据框的多列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>:[<span class="number">1</span>,<span class="number">2</span>], <span class="string">&#x27;b&#x27;</span>:[(<span class="number">1</span>,<span class="number">2</span>), (<span class="number">3</span>,<span class="number">4</span>)]&#125;)</span><br><span class="line">df[[<span class="string">&#x27;b1&#x27;</span>, <span class="string">&#x27;b2&#x27;</span>]] = df[<span class="string">&#x27;b&#x27;</span>].apply(pd.Series)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">df = df.join(df[<span class="string">&#x27;b&#x27;</span>].apply(pd.Series))</span><br><span class="line"></span><br><span class="line">result:</span><br><span class="line">     a       b  <span class="number">0</span>  <span class="number">1</span></span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  (<span class="number">1</span>, <span class="number">2</span>)  <span class="number">1</span>  <span class="number">2</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  (<span class="number">3</span>, <span class="number">4</span>)  <span class="number">3</span>  <span class="number">4</span></span><br></pre></td></tr></table></figure><h2 id="stack与unstack使用说明：python-pandas-stack和unstack函数"><a href="#stack与unstack使用说明：python-pandas-stack和unstack函数" class="headerlink" title="stack与unstack使用说明：python pandas stack和unstack函数"></a>stack与unstack使用说明：<a href="https://www.cnblogs.com/bambipai/p/7658311.html">python pandas stack和unstack函数</a></h2><h2 id="利用当前数据的多列数据得到新的数据列"><a href="#利用当前数据的多列数据得到新的数据列" class="headerlink" title="利用当前数据的多列数据得到新的数据列"></a>利用当前数据的多列数据得到新的数据列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;new_column&#x27;</span>] = df.apply(<span class="keyword">lambda</span> row: row[<span class="string">&#x27;column1&#x27;</span>] * row[<span class="string">&#x27;column2&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">df[<span class="string">&#x27;new_column&#x27;</span>]  = df[<span class="string">&#x27;column1&#x27;</span>] * df[<span class="string">&#x27;column2&#x27;</span>]</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">df.ix[:, <span class="string">&#x27;new_column&#x27;</span>] = df[<span class="string">&#x27;column1&#x27;</span>] * df[<span class="string">&#x27;column2&#x27;</span>]</span><br></pre></td></tr></table></figure><h2 id="得到类型中有关系数据库的数据"><a href="#得到类型中有关系数据库的数据" class="headerlink" title="得到类型中有关系数据库的数据"></a>得到<code>类型</code>中有<code>关系数据库</code>的数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[df[u&#x27;类型&#x27;].str.contains(u&#x27;关系数据库&#x27;)]</span><br></pre></td></tr></table></figure><h2 id="apply函数返回多列数据"><a href="#apply函数返回多列数据" class="headerlink" title="apply函数返回多列数据"></a>apply函数返回多列数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">item</span>):</span><br><span class="line">    <span class="keyword">return</span> pd.Series([item*<span class="number">2</span>, item*<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">a = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;b&#x27;</span>: [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]&#125;)</span><br><span class="line">a[[<span class="string">&#x27;2倍&#x27;</span>, <span class="string">&#x27;4倍&#x27;</span>]] = a[<span class="string">&#x27;a&#x27;</span>].apply(parse)</span><br><span class="line"></span><br><span class="line">result:</span><br><span class="line">   a  b  <span class="number">2</span>倍  <span class="number">4</span>倍</span><br><span class="line"><span class="number">0</span>  <span class="number">1</span>  <span class="number">4</span>   <span class="number">2</span>   <span class="number">4</span></span><br><span class="line"><span class="number">1</span>  <span class="number">2</span>  <span class="number">5</span>   <span class="number">4</span>   <span class="number">8</span></span><br><span class="line"><span class="number">2</span>  <span class="number">3</span>  <span class="number">6</span>   <span class="number">6</span>  <span class="number">12</span></span><br></pre></td></tr></table></figure><h2 id="过滤逻辑类型"><a href="#过滤逻辑类型" class="headerlink" title="过滤逻辑类型"></a>过滤逻辑类型</h2><p>np.logical_and</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = df[np.logical_and(df[<span class="string">&#x27;col1&#x27;</span>].notnull(), df[<span class="string">&#x27;col1&#x27;</span>].<span class="built_in">str</span>.contains(<span class="string">&#x27;item&#x27;</span>))]</span><br></pre></td></tr></table></figure><h2 id="更改列名"><a href="#更改列名" class="headerlink" title="更改列名"></a>更改列名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = df.rename(columns=&#123;<span class="string">&#x27;col1&#x27;</span>: <span class="string">u&#x27;列1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>: <span class="string">u&#x27;列2&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure><h2 id="将数据转化为常用类型"><a href="#将数据转化为常用类型" class="headerlink" title="将数据转化为常用类型"></a>将数据转化为常用类型</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">col1_data = df[&#x27;col1&#x27;].tolist()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> python </tag>
            
            <tag> pandas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DevOps工具汇总大全</title>
      <link href="/DevOps/DevOps%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB%E5%A4%A7%E5%85%A8/"/>
      <url>/DevOps/DevOps%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB%E5%A4%A7%E5%85%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a>DevOps</h2><p>神道：项目管理工具</p><p>Jenkins：CI工具</p><p>Ansible：配置管理工具</p><p>GitLab&#x2F;Gogs：代码库</p><p>Docker：容器引擎</p><p>Kubernetes：容器调度</p><p>SonarQube：代码静态扫描</p><p>Harbor：制品库</p><p>Nexus：制品库</p><p>TestLink：测试管理</p><p>Jmeter：压测工具</p><p>Selenium&#x2F;RobotFramework：UI自动化测试</p><p>Mattermost：是一款易于使用、经过简化且可扩展的团队通信和企业消息传送系统。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/5d2646df64fd674967b4d5248a6dcfc2896e63b116e1b6bd5ac3e4f44a00ff95.png" alt="DevOps工具大全">  </p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/102f601ad86af1dcbd108b99e4621ad01d839bdb285d55a2aa6b33b8d700011c.png" alt="DevOps工具大全">  </p><p>二、<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c8f85598a13ef97b9a75f22ddea67fafbd049845633181b1eb2d04f33a8bfb45.png" alt="DevOps工具大全">  </p><p>DevOps 的工具链<br>DevOps中包括版本控制&amp;协作开发工具、自动化构建和测试工具、持续集成&amp;交付工具、部署工具、维护工具、监控，警告&amp;分析工具等等，补充了一些国内的服务，可以让你更好的执行实施 DevOps 工作流。</p><p>版本控制&amp;协作开发：GitHub、GitLab、BitBucket、SubVersion、Coding、Bazaar</p><p>自动化构建和测试:Apache Ant、Maven 、Selenium、PyUnit、QUnit、JMeter、Gradle、PHPUnit、Nexus</p><p>持续集成&amp;交付:Jenkins、Capistrano、BuildBot、Fabric、Tinderbox、Travis CI、flow.ci Continuum、LuntBuild、CruiseControl、Integrity、Gump、Go</p><p>容器平台: Docker、Rocket、Ubuntu（LXC）、第三方厂商如（AWS&#x2F;阿里云）</p><p>容器编排：Kubernetes、helm、kustomize、cue</p><p>配置管理：Chef、Puppet、CFengine、Bash、Rudder、Powershell、RunDeck、Saltstack、Ansible</p><p>微服务平台：OpenShift、Cloud Foundry、Kubernetes、Mesosphere</p><p>服务开通：Puppet、Docker Swarm、Vagrant、Powershell、OpenStack Heat</p><p>日志管理：Logstash、CollectD、StatsD</p><p>监控，警告&amp;分析：Nagios、Ganglia、Sensu、zabbix、ICINGA、Graphite、Kibana</p><p>代码管理（SCM）：GitHub、GitLab、BitBucket、SubVersion</p><p>构建工具：Ant、Gradle、maven</p><p>自动部署：Capistrano、CodeDeploy</p><p>持续集成（CI）：Bamboo、Hudson、Jenkins</p><p>配置管理：Ansible、Chef、Puppet、SaltStack、ScriptRock GuardRail</p><p>容器：Docker、LXC、第三方厂商如AWS</p><p>编排：Kubernetes、Core、Apache Mesos、DC&#x2F;OS</p><p>服务注册与发现：Zookeeper、etcd、Consul</p><p>脚本语言：python、ruby、shell</p><p>日志管理：ELK、Logentries</p><p>系统监控：Datadog、Graphite、Icinga、Nagios、Prometheus、Grafana</p><p>性能监控：AppDynamics、New Relic、Splunk</p><p>压力测试：JMeter、Blaze Meter、loader.io</p><p>预警：PagerDuty、pingdom、厂商自带如AWS SNS</p><p>HTTP加速器：Varnish</p><p>消息总线：ActiveMQ、SQS</p><p>应用服务器：Tomcat、JBoss</p><p>Web服务器：Apache、Nginx、IIS</p><p>数据库：MySQL、Oracle、PostgreSQL等关系型数据库；cassandra、mongoDB、redis等NoSQL数据库</p><p>项目管理（PM）：Jira、Asana、Taiga、Trello、Basecamp、Pivotal Tracker</p><p>文档管理 ：HedgeDoc</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2e0d2e3097b32d7a123ba5961646011d36c1a871745b932ee529b4c41471e10c.png" alt="picture 5">  </p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GO语言相关命令</title>
      <link href="/golang/GO%E8%AF%AD%E8%A8%80%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/"/>
      <url>/golang/GO%E8%AF%AD%E8%A8%80%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="下载包-go-get"><a href="#下载包-go-get" class="headerlink" title="下载包 go get"></a>下载包 go get</h2><p>-x ：下载依赖包，并显示执行的命令</p><h2 id="构建-go-build"><a href="#构建-go-build" class="headerlink" title="构建 go build"></a>构建 go build</h2><p>-n ：显示构建过程的命令，但不执行<br>-x ：显示执行构建的命令<br>-o ：构建输出可执行文件  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go build -o app </span><br></pre></td></tr></table></figure><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go run . </span><br></pre></td></tr></table></figure><h2 id="包依赖"><a href="#包依赖" class="headerlink" title="包依赖"></a>包依赖</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go mod tidy &amp;&amp; go mod vendor</span><br></pre></td></tr></table></figure><p>如果遇到以下问题，则是由代码中引入的package地址与项目的git仓库不一致导致的。<br>例如：<br>代码中引入package <code>github.com/coreos/prometheus-operator/pkg/client</code>, 但它的git仓库是<code>github.com/prometheus-operator/prometheus-operator/pkg/client</code>，在执行<strong>go mod tidy</strong>则会报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">go: example.com/operator imports</span><br><span class="line">        github.com/coreos/prometheus-operator/pkg/client/versioned: github.com/coreos/prometheus-operator/pkg/client@v0.57.0: parsing go.mod:</span><br><span class="line">        module declares its path as: github.com/prometheus-operator/prometheus-operator/pkg/client</span><br><span class="line">                but was required as: github.com/coreos/prometheus-operator/pkg/client</span><br></pre></td></tr></table></figure><p>需要在当前项目中的go.mod中添加replace</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">module example.com</span><br><span class="line"></span><br><span class="line">go 1.18</span><br><span class="line"></span><br><span class="line">replace github.com/coreos/prometheus-operator/pkg/client =&gt; github.com/prometheus-operator/prometheus-operator/pkg/client v0.57.0</span><br></pre></td></tr></table></figure><p>或者执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go mod edit -replace github.com/coreos/prometheus-operator/pkg/client=github.com/prometheus-operator/prometheus-operator/pkg/client@v0.57.0</span><br></pre></td></tr></table></figure><h2 id="展示包下的函数-go-doc"><a href="#展示包下的函数-go-doc" class="headerlink" title="展示包下的函数 go doc"></a>展示包下的函数 go doc</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">go doc net/http</span><br><span class="line">go doc fmt.Printf</span><br></pre></td></tr></table></figure><h2 id="Go-升级"><a href="#Go-升级" class="headerlink" title="Go 升级"></a>Go 升级</h2><p>下载最新版GO:<a href="https://golang.google.cn/dl/">The Go Programming Language</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ go env GOROOT</span><br><span class="line">/usr/local/go</span><br><span class="line">## 将下载文件解压，替换GOROO文件夹内容</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言语法</title>
      <link href="/golang/GO%E8%AF%AD%E8%A8%80%E8%AF%AD%E6%B3%95/"/>
      <url>/golang/GO%E8%AF%AD%E8%A8%80%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="顺序编程"><a href="#顺序编程" class="headerlink" title="顺序编程"></a>顺序编程</h1><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">var v10 int</span><br><span class="line">v10 = 123</span><br><span class="line"></span><br><span class="line">v11 := 234</span><br><span class="line"></span><br><span class="line">// 匿名变量示例</span><br><span class="line">func GetName() (firstName, lastName nickName string) &#123;</span><br><span class="line">  return &quot;May&quot;, &quot;Chan&quot;, &quot;Chibi&quot;</span><br><span class="line">&#125;</span><br><span class="line">_, _, nickName := GetName()</span><br></pre></td></tr></table></figure><h2 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h2><p>iota是一个特殊的常量，它会在每一个const关键字出现时重置为0，然后在下一个const出现前，每出现一次iota，它代表的值加1。如果两个const的赋值语句表达式一样，后一个赋值可省略。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">const (</span><br><span class="line">  c0 = iota</span><br><span class="line">  c1 = iota</span><br><span class="line">  c2</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">const (</span><br><span class="line">  Sunday = iota</span><br><span class="line">  Monday</span><br><span class="line">  Tuesday</span><br><span class="line">  Wednesday</span><br><span class="line">  Thursday</span><br><span class="line">  Friday</span><br><span class="line">  Saturday</span><br><span class="line">  numberOfDays</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><ul><li>布尔：bool</li><li>整型：int8、byte、int16、int、uint、unitptr等</li><li>浮点：float32、float64</li><li>复数：complex64、complex128</li><li>字符串：string：在初始化后不能被修改</li><li>字符：rune</li><li>错误：error</li><li>指针（pointer）</li><li>数组（array）</li><li>切片（slice）：可动态增减元素</li><li>字典（map）</li><li>通道（chan）</li><li>接口（interface）</li><li>结构体（struct）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// 切片例子</span><br><span class="line">mySlice := make([]int, 5, 10)</span><br><span class="line"></span><br><span class="line">fmt.Println(&quot;len(mySlice):&quot;, len(mySlice))</span><br><span class="line">fmt.Println(&quot;cap(mySlice):&quot;, cap(mySlice))</span><br><span class="line"></span><br><span class="line">mySlice = append(mySlice, 1, 2, 3)</span><br><span class="line"></span><br><span class="line">mySlice2 := []int&#123;8, 9, 10&#125;</span><br><span class="line">mySlice = append(mySlice, mySlice2)</span><br><span class="line"></span><br><span class="line">slice1 := []int&#123;1, 2, 3, 4, 5&#125;</span><br><span class="line">slice2 := []int&#123;5, 4, 3&#125;</span><br><span class="line"></span><br><span class="line">copy(slice2, slice1) //将slice1中的前3个元素复制到slice2</span><br><span class="line">copy(slice1, slice2) //将slice2中的前3个元素复制到slice1</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">// Map例子</span><br><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">&quot;fmt&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type PersonInfo struct&#123;</span><br><span class="line">ID string</span><br><span class="line">Name string</span><br><span class="line">Address string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main()&#123;</span><br><span class="line">var personDB map[string] PersonInfo</span><br><span class="line">personDB = make(map[string] PersonInfo)</span><br><span class="line"></span><br><span class="line">personDB[&quot;12345&quot;] = PersonInfo&#123;&quot;12345&quot;, &quot;Tom&quot;, &quot;Room 12345&quot;&#125;</span><br><span class="line">personDB[&quot;546&quot;] = PersonInfo&#123;&quot;546&quot;, &quot;Tom&quot;, &quot;Room 546&quot;&#125;</span><br><span class="line"></span><br><span class="line">person, ok := personDB[&quot;1234&quot;]</span><br><span class="line"></span><br><span class="line">if ok &#123;</span><br><span class="line">fmt.Println(&quot;Found person&quot;, person.Name)</span><br><span class="line">&#125;else&#123;</span><br><span class="line">fmt.Println(&quot;Did not find person&quot;)</span><br><span class="line">&#125;</span><br><span class="line">delete(personDB, &quot;546&quot;)</span><br><span class="line">fmt.Println(personDB[&quot;12345&quot;].Name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">// if else</span><br><span class="line">func if_else(x int) int &#123;</span><br><span class="line">if x == 0 &#123;</span><br><span class="line">return 5</span><br><span class="line">&#125;else&#123;</span><br><span class="line">return x</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// switch case</span><br><span class="line">func switch_case(i int)&#123; //无需break</span><br><span class="line">switch i&#123;</span><br><span class="line">case 0:</span><br><span class="line">fmt.Println(&quot;0&quot;)</span><br><span class="line">case 1:</span><br><span class="line">fmt.Println(&quot;1&quot;)</span><br><span class="line">default:</span><br><span class="line">fmt.Println(&quot;Default&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// for</span><br><span class="line">sum := 0</span><br><span class="line">for &#123;</span><br><span class="line">sum ++</span><br><span class="line">if sum &gt; 10 &#123;</span><br><span class="line">break</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for j := 0; j &lt; 5; j++ &#123;</span><br><span class="line">ftm.Println(j)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// goto</span><br><span class="line">func myfunc()&#123;</span><br><span class="line">i := 0</span><br><span class="line">HERE:</span><br><span class="line">fmt.Println(i)</span><br><span class="line">i++</span><br><span class="line">if i &lt; 10 &#123;</span><br><span class="line">goto HERE</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import &quot;mymath&quot;  //假设Add被放在一个叫mymath的包中</span><br><span class="line">c := mymath.Add(1, 2)</span><br></pre></td></tr></table></figure><p>小写字母开头的函数只在本包内可见，大写字母开头的函数才能被其他包使用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">func myfunc(args ...int) &#123;</span><br><span class="line">  for _, arg := range args &#123;</span><br><span class="line">    fmt.Println(arg)</span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func myfunc(args ...int) &#123;</span><br><span class="line">for _, arg := range args &#123;</span><br><span class="line">fmt.Println(arg)</span><br><span class="line">&#125;</span><br><span class="line">myfunc2(args...)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>任意类型的不定参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">func Printf(format string, args ...interface&#123;&#125;)&#123;</span><br><span class="line">for _, arg := range args &#123;</span><br><span class="line">switch arg.(type) &#123;</span><br><span class="line">case int:</span><br><span class="line">fmt.Println(arg, &quot;is an int value&quot;)</span><br><span class="line">case string:</span><br><span class="line">fmt.Println(arg, &quot;is a string value&quot;)</span><br><span class="line">case int64:</span><br><span class="line">fmt.Println(arg, &quot;is an int64 value&quot;)</span><br><span class="line">default:</span><br><span class="line">fmt.Println(arg, &quot;is an unknown type&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>多返回值</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">func (file *File) Read(b []byte) (n int, err Error)</span><br></pre></td></tr></table></figure><p>匿名函数与闭包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import(</span><br><span class="line">&quot;fmt&quot;</span><br><span class="line">)</span><br><span class="line">func main()&#123;</span><br><span class="line">var j int = 5</span><br><span class="line">a := func()(func())&#123;</span><br><span class="line">var i int = 10</span><br><span class="line">return func() &#123;</span><br><span class="line">fmt.Printf(&quot;i, j: %d, %d\n&quot;, i, j)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line">a()</span><br><span class="line">j *= 2</span><br><span class="line">a()</span><br><span class="line">&#125;</span><br><span class="line">// 结果</span><br><span class="line">// i, j: 10, 5</span><br><span class="line">// i, j: 10, 10</span><br></pre></td></tr></table></figure><h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">type error interface &#123;</span><br><span class="line">  Error() string</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大多数函数，如果要返回错误，可以定义如下模式。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">func Foo(param int)(n int, err error) &#123;</span><br><span class="line">  // ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">n, err := Foo(0)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">  // 错误处理</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  // 使用返回值n</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type PathError struct &#123;</span><br><span class="line">  Op string</span><br><span class="line">  Path string</span><br><span class="line">  Err  error</span><br><span class="line">&#125;</span><br><span class="line">func (e *PathError) Error() string &#123;</span><br><span class="line">  return e.Op + &quot; &quot; + e.Path + &quot;: &quot; + e.Err.Error()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>defer</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">func CopyFile(dst, src string) (w int64, err error)&#123;</span><br><span class="line">srcFile, err := os.Open(src)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">defer srcFile.Close()</span><br><span class="line"></span><br><span class="line">dstFile, err := os.Create(dst)</span><br><span class="line">if err != nil &#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">defer dstFile.Close()</span><br><span class="line"></span><br><span class="line">return io.Copy(dstFile, srcFile)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>panic&#x2F;recover</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">defer func() &#123;</span><br><span class="line">if r := recover(); r != nil &#123;</span><br><span class="line">log.Printf(&quot;Runtime error caught: %v&quot;, r)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure><h1 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h1><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">type Integer int</span><br><span class="line">func (a Integer) Less(b Integer) bool &#123;</span><br><span class="line">  return a &lt; b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">type Header map[string] []string</span><br><span class="line">func (h Header) Add(key, value string)&#123;</span><br><span class="line">  textproto.MIMEHeader(h).Add(key, value)</span><br><span class="line">&#125;</span><br><span class="line">func (h Header) Set(key, value string)&#123;</span><br><span class="line">  textproto.MIMEHeader(h).Set(key, value)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>引用类型：数组切片、map、channel、接口(interface)<br>值类型：byte、int、bool、float32、float64、string、array、struct、pointer等</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">type Animal struct &#123;</span><br><span class="line">    Name   string  //名称</span><br><span class="line">    Color  string  //颜色</span><br><span class="line">    Height float32 //身高</span><br><span class="line">    Weight float32 //体重</span><br><span class="line">    Age    int     //年龄</span><br><span class="line">&#125;</span><br><span class="line">//奔跑</span><br><span class="line">func (a Animal)Run() &#123;</span><br><span class="line">    fmt.Println(a.Name + &quot;is running&quot;)</span><br><span class="line">&#125;</span><br><span class="line">type Lion struct &#123;</span><br><span class="line">Animal //匿名字段</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main()&#123;</span><br><span class="line">    var lion = Lion&#123;</span><br><span class="line">        Animal&#123;</span><br><span class="line">            Name:  &quot;小狮子&quot;,</span><br><span class="line">            Color: &quot;灰色&quot;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line">    lion.Run()</span><br><span class="line">    fmt.Println(lion.Name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>匿名组合相当于以其类型名称（去掉包名部分）作为成员变量的名字。<br>Go语言中，要使某个符号对其他包可见，需要将该符号定义为以大写字母开头。Go语言中符号的可访问性是包一级别，而不是类型级别。</p><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>Go语言中，一个类只需要实现了接口要求的所有函数，就说这个类实现了该接口。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">type File struct &#123;</span><br><span class="line">  // ...</span><br><span class="line">&#125;</span><br><span class="line">func (f *File) Read(buf []byte) (n int, err error)</span><br><span class="line">func (f *File) Write(buf []byte) (n int, err error)</span><br><span class="line">func (f *File) Close() error</span><br><span class="line"></span><br><span class="line">type IFile interface&#123;</span><br><span class="line">  IReader</span><br><span class="line">  IWrite</span><br><span class="line">  IClose</span><br><span class="line">&#125;</span><br><span class="line">type IReader interface&#123;</span><br><span class="line">  Read(buf []byte) (n int, err error)</span><br><span class="line">&#125;</span><br><span class="line">type IWriter interface&#123;</span><br><span class="line">  Write(buf []byte) (n int, err error)</span><br><span class="line">&#125;</span><br><span class="line">type IClose interface&#123;</span><br><span class="line">  Close() error</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var file1 IFile = new(File)</span><br><span class="line">var file2 IReader = new(File)</span><br></pre></td></tr></table></figure><p>Go语言中任何对象实例都满足空接口interface{}。</p><h1 id="并发编程"><a href="#并发编程" class="headerlink" title="并发编程"></a>并发编程</h1><p>go channel</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import &quot;fmt&quot;</span><br><span class="line"></span><br><span class="line">func Count(ch chan int)&#123;</span><br><span class="line">fmt.Println(&quot;Counting&quot;)</span><br><span class="line">ch &lt;- 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main()&#123;</span><br><span class="line">chs := make([]chan int, 10)</span><br><span class="line">for i :=0; i &lt; 10; i++ &#123;</span><br><span class="line">chs[i] = make(chan int)</span><br><span class="line">go Count(chs[i])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for _, ch := range(chs) &#123;</span><br><span class="line">a := &lt;- ch</span><br><span class="line">fmt.Println(a)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>超时机制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">timeout := make(chan bool, 1)</span><br><span class="line">go func()&#123;</span><br><span class="line">time.Sleep(1e9)</span><br><span class="line">timeout &lt;- true</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">select &#123;</span><br><span class="line">case &lt;-ch:</span><br><span class="line">//从ch中读取到数据</span><br><span class="line">case &lt;-timeout</span><br><span class="line">//一直没有从ch中读取到数据，但从timeout中读取到了数据</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>channel的传递</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">type PipeData struct &#123;</span><br><span class="line">value int</span><br><span class="line">handler func(int) int</span><br><span class="line">next chan int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func handle(queue chan *PipeData)&#123;</span><br><span class="line">for data := range queue&#123;</span><br><span class="line">data.next &lt;- data.handler(data.value)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关闭channel</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">close(ch)</span><br></pre></td></tr></table></figure><p>同步锁</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var l sync.Mutex</span><br><span class="line">func foo()&#123;</span><br><span class="line">l.Lock()</span><br><span class="line">defer l.Unlock()</span><br><span class="line">//...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>全局唯一操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">var a string</span><br><span class="line">var once sync.once</span><br><span class="line">func setup()&#123;</span><br><span class="line">a = &quot;hello&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func doprint() &#123;</span><br><span class="line">once.Do(setup)</span><br><span class="line">print(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func twoprint()&#123;</span><br><span class="line">go doprint()</span><br><span class="line">go doprint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码setup只会运行一次。</p><h1 id="网络编程"><a href="#网络编程" class="headerlink" title="网络编程"></a>网络编程</h1><h2 id="Socket编程"><a href="#Socket编程" class="headerlink" title="Socket编程"></a>Socket编程</h2><p>Dial()：连接，支持如下协议：tcp,tcp4,tcp6,udp,udp4,udp6,ip,ip4,ip6</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conn, err := net.Dial(&quot;tcp&quot;, &quot;192.168.0.2:2100&quot;)</span><br><span class="line">conn2, err := net.Dial(&quot;udp&quot;, &quot;192.168.0.2:53&quot;)</span><br><span class="line">conn3, err := net.Dial(&quot;ip4:icmp&quot;, &quot;www.baidu.com&quot;)</span><br></pre></td></tr></table></figure><p>Write()与Read()方法来发送数据与接收数据。</p><h2 id="HTTP编程"><a href="#HTTP编程" class="headerlink" title="HTTP编程"></a>HTTP编程</h2><p>net&#x2F;http包，包含HTTP客户端与服务端的具体实现。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">resp, err := http.Get(&quot;http://example.com/&quot;)</span><br><span class="line">if err != nil&#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">defer resp.Body.close()</span><br><span class="line">io.Copy(os.Stdout, resp.Body)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">resp, err := http.Post(&quot;http://example.com/upload&quot;, &quot;image/jpeg&quot;, &amp;imageDataBuf)</span><br><span class="line">if err != nil&#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">if resp.StatusCode != http.StatusOK&#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resp, err := http.PostForm(&quot;http://example.com/posts&quot;, url.Values&#123;&quot;title&quot;: &#123;&quot;article title&quot;&#125;, &quot;content&quot;: &#123;&quot;artical body&quot;&#125;&#125;)</span><br><span class="line">if err != nil&#123;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">resp, err := http.Head(&quot;http://example.com/&quot;)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">req, err := http.NewRequest(&quot;GET&quot;, &quot;http://example.com/posts&quot;, nil)</span><br><span class="line">req.Header.Add(&quot;User-Agent&quot;, &quot;Gobook User-Agent&quot;)</span><br><span class="line"></span><br><span class="line">client := &amp;http.Client&#123;...&#125;</span><br><span class="line">resp, err := client.Do(req)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http.HandleFunc(&quot;/bar&quot;, func(w http.ResponseWriter, r *http.Request)&#123;</span><br><span class="line">  fmt.Fprintf(w, &quot;hello&quot;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><p>net&#x2F;rpc，包实现RPC协议的细节</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">func (t *T) MethodName(argType T1, replyType *T2) error</span><br></pre></td></tr></table></figure><p>T1与T2默认会使用encoding&#x2F;gob包进行编码与解码。<br>argType表示由RPC客户端传入的参数<br>replyType表示要返回给RPC客户端的结果<br>服务端示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">&quot;log&quot;</span><br><span class="line">&quot;net&quot;</span><br><span class="line">&quot;net/http&quot;</span><br><span class="line">&quot;net/rpc&quot;</span><br><span class="line">)</span><br><span class="line">type Args struct&#123;</span><br><span class="line">A, B int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type Arith int</span><br><span class="line"></span><br><span class="line">func (t *Arith) Multiply(args *Args, reply *int) error&#123;</span><br><span class="line">*reply = args.A * args.B</span><br><span class="line">return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main()&#123;</span><br><span class="line">arith := new(Arith)</span><br><span class="line">rpc.Register(arith)</span><br><span class="line">rpc.HandleHTTP()</span><br><span class="line">l, e := net.Listen(&quot;tcp&quot;, &quot;:1234&quot;)</span><br><span class="line">if e != nil&#123;</span><br><span class="line">log.Fatal(&quot;listen error&quot;, e)</span><br><span class="line">&#125;</span><br><span class="line">http.Serve(l, nil)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>客户端示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">&quot;net/rpc&quot;</span><br><span class="line">&quot;fmt&quot;</span><br><span class="line">&quot;log&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type Args struct&#123;</span><br><span class="line">A, B int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main()&#123;</span><br><span class="line">// 顺序执行RPC</span><br><span class="line">client, _ := rpc.DialHTTP(&quot;tcp&quot;, &quot;127.0.0.1:1234&quot;)</span><br><span class="line">args := &amp;Args&#123;7,8&#125;</span><br><span class="line">var reply int</span><br><span class="line">err := client.Call(&quot;Arith.Multiply&quot;, args, &amp;reply)</span><br><span class="line">if err != nil&#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(reply)</span><br><span class="line"></span><br><span class="line">//异步执行RPC</span><br><span class="line">        var reply2 int</span><br><span class="line">divCall := client.Go(&quot;Arith.Multiply&quot;, &amp;Args&#123;6,8&#125;, &amp;reply2, nil)</span><br><span class="line">divCall = &lt;-divCall.Done</span><br><span class="line">fmt.Println(reply2)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><p>encoding&#x2F;json标准库<br>json.Marshal()，将一组数据进行JSON格式化编码<br>json.Unmarshal()，将JSON格式的文档解码为Go里边预期的数据结构。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data := make(map[string] string)</span><br><span class="line">data[&quot;name&quot;] = &quot;Michael&quot;</span><br><span class="line">data2, err := json.Marshal(data)</span><br><span class="line">if err != nil&#123;</span><br><span class="line">fmt.Println(&quot;err&quot;)</span><br><span class="line">return</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(string(data2[:]))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data := make(map[string] string)</span><br><span class="line">data_json := []byte(&quot;&#123;\&quot;name\&quot;:\&quot;Michael\&quot;&#125;&quot;)</span><br><span class="line"></span><br><span class="line">json.Unmarshal(data_json, &amp;data)</span><br><span class="line">fmt.Println(data)</span><br></pre></td></tr></table></figure><h1 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">type T struct&#123;</span><br><span class="line">A int</span><br><span class="line">B string</span><br><span class="line">&#125;</span><br><span class="line">t := T&#123;203, &quot;mh203&quot;&#125;</span><br><span class="line">s := reflect.ValueOf(&amp;t).Elem()</span><br><span class="line">typeOfT := s.Type()</span><br><span class="line"></span><br><span class="line">for i := 0; i &lt; s.NumField(); i++ &#123;</span><br><span class="line">f := s.Field(i)</span><br><span class="line">fmt.Printf(&quot;%d: %s %s = %v\n&quot;, i, typeOfT.Field(i).Name, f.Type(), f.Interface())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Go工具"><a href="#Go工具" class="headerlink" title="Go工具"></a>Go工具</h1><p>包文档查看（网站形式）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ godoc -http=:8080</span><br><span class="line">$ godoc -http=:8080 -path=&quot;.&quot;</span><br></pre></td></tr></table></figure><p>包文档查看（命令行形式）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go doc foo</span><br></pre></td></tr></table></figure><p>代码格式化</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ go fmt hello.go</span><br><span class="line">$ gofmt -l -w .</span><br></pre></td></tr></table></figure><p>项目构建<br>go build：用于测试编译包，在项目目录下生成可执行文件（有main包）；不能生成包文件<br>go install：主要用来生成库和工具。一是编译包文件（无main包），将编译后的包文件放到 pkg 目录下（$GOPATH&#x2F;pkg）。二是编译生成可执行文件（有main包），将可执行文件放到 bin 目录（$GOPATH&#x2F;bin）；生成可执行文件在当前目录下， go install 生成可执行文件在bin目录下（$GOPATH&#x2F;bin）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ GOOS=linux GOARCH=amd64 go build calc </span><br><span class="line">$ go install calc</span><br></pre></td></tr></table></figure><p>GOOS：系统，linux&#x2F;darwin&#x2F;windows<br>GOARCH：386&#x2F;amd64</p><p>单元测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go test calc</span><br></pre></td></tr></table></figure><p>模块管理go mod</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ go mod download  # 下载指定模块</span><br><span class="line">$ go mod init test.com/go  #初始化当前模块</span><br><span class="line">$ go mod vendor       # 将依赖复制到当前vendor目录下</span><br></pre></td></tr></table></figure><p>使用go module后，项目代码不需要放在GOPATH目录下。import项目的package时使用module路径。</p><p>以下是beego应用使用module来管理依赖的例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ cat &lt;&lt;EOF &gt; go.mod</span><br><span class="line">module beegoapp</span><br><span class="line"></span><br><span class="line">go 1.12</span><br><span class="line"></span><br><span class="line">replace (</span><br><span class="line">golang.org/x/crypto =&gt; github.com/golang/crypto v0.0.0-20191227163750-53104e6ec876</span><br><span class="line">golang.org/x/mod =&gt; github.com/golang/mod v0.1.0</span><br><span class="line">golang.org/x/net =&gt; github.com/golang/net v0.0.0-20191209160850-c0dbc17a3553</span><br><span class="line">golang.org/x/sync =&gt; github.com/golang/sync v0.0.0-20190911185100-cd5d95a43a6e</span><br><span class="line">golang.org/x/sys =&gt; github.com/golang/sys v0.0.0-20191228213918-04cbcbbfeed8</span><br><span class="line">golang.org/x/text =&gt; github.com/golang/text v0.3.2</span><br><span class="line">golang.org/x/tools =&gt; github.com/golang/tools v0.0.0-20191230220329-2aa90c603ae3</span><br><span class="line">golang.org/x/xerrors =&gt; github.com/golang/xerrors v0.0.0-20191204190536-9bdfabe68543</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">require (</span><br><span class="line">github.com/astaxie/beego v1.12.0</span><br><span class="line">github.com/shiena/ansicolor v0.0.0-20151119151921-a422bbe96644 // indirect</span><br><span class="line">github.com/smartystreets/goconvey v1.6.4</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go-常用设计模式</title>
      <link href="/golang/Go-%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/golang/Go-%E5%B8%B8%E7%94%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f5c4d1d854ec517dca03673b4bc9ae1d5d5c5d2294128a654a5de5689d0b92cc.png" alt="常用设计模式">  </p><h2 id="1-单例模式："><a href="#1-单例模式：" class="headerlink" title="1. 单例模式："></a>1. 单例模式：</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package singleton</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">    &quot;sync&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type singleton struct &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">var ins *singleton</span><br><span class="line">var once sync.Once</span><br><span class="line"></span><br><span class="line">func GetInsOr() *singleton &#123;</span><br><span class="line">    once.Do(func() &#123;</span><br><span class="line">        ins = &amp;singleton&#123;&#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    return ins</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-简单工厂模式"><a href="#2-简单工厂模式" class="headerlink" title="2. 简单工厂模式"></a>2. 简单工厂模式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">type Person struct &#123;</span><br><span class="line">  Name string</span><br><span class="line">  Age int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (p Person) Greet() &#123;</span><br><span class="line">  fmt.Printf(&quot;Hi! My name is %s&quot;, p.Name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func NewPerson(name string, age int) *Person &#123;</span><br><span class="line">  return &amp;Person&#123;</span><br><span class="line">    Name: name,</span><br><span class="line">    Age: age,</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-抽象工厂模式"><a href="#3-抽象工厂模式" class="headerlink" title="3. 抽象工厂模式"></a>3. 抽象工厂模式</h2><p>它返回的是接口而不是结构体。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">type Person interface &#123;</span><br><span class="line">  Greet()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type person struct &#123;</span><br><span class="line">  name string</span><br><span class="line">  age int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (p person) Greet() &#123;</span><br><span class="line">  fmt.Printf(&quot;Hi! My name is %s&quot;, p.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Here, NewPerson returns an interface, and not the person struct itself</span><br><span class="line">func NewPerson(name string, age int) Person &#123;</span><br><span class="line">  return person&#123;</span><br><span class="line">    name: name,</span><br><span class="line">    age: age,</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-工厂方法模式"><a href="#4-工厂方法模式" class="headerlink" title="4. 工厂方法模式"></a>4. 工厂方法模式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">type Person struct &#123;</span><br><span class="line">  name string</span><br><span class="line">  age int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func NewPersonFactory(age int) func(name string) Person &#123;</span><br><span class="line">  return func(name string) Person &#123;</span><br><span class="line">    return Person&#123;</span><br><span class="line">      name: name,</span><br><span class="line">      age: age,</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-策略模式"><a href="#5-策略模式" class="headerlink" title="5. 策略模式"></a>5. 策略模式</h2><p>在项目开发中，我们经常要根据不同的场景，采取不同的措施，也就是不同的策略。比如，假设我们需要对 a、b 这两个整数进行计算，根据条件的不同，需要执行不同的计算方式。为了解耦，需要使用策略模式，定义一些独立的类来封装不同的算法，每一个类封装一个具体的算法（即策略）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package strategy</span><br><span class="line"></span><br><span class="line">// 策略模式</span><br><span class="line"></span><br><span class="line">// 定义一个策略类</span><br><span class="line">type IStrategy interface &#123;</span><br><span class="line">  do(int, int) int</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 策略实现：加</span><br><span class="line">type add struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">func (*add) do(a, b int) int &#123;</span><br><span class="line">  return a + b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 策略实现：减</span><br><span class="line">type reduce struct&#123;&#125;</span><br><span class="line"></span><br><span class="line">func (*reduce) do(a, b int) int &#123;</span><br><span class="line">  return a - b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 具体策略的执行者</span><br><span class="line">type Operator struct &#123;</span><br><span class="line">  strategy IStrategy</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 设置策略</span><br><span class="line">func (operator *Operator) setStrategy(strategy IStrategy) &#123;</span><br><span class="line">  operator.strategy = strategy</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 调用策略中的方法</span><br><span class="line">func (operator *Operator) calculate(a, b int) int &#123;</span><br><span class="line">  return operator.strategy.do(a, b)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-模板模式"><a href="#6-模板模式" class="headerlink" title="6. 模板模式"></a>6. 模板模式</h2><p>模板模式就是将一个类中能够公共使用的方法放置在抽象类中实现，将不能公共使用的方法作为抽象方法，强制子类去实现，这样就做到了将一个类作为一个模板，让开发者去填充需要填充的地方。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package template</span><br><span class="line"></span><br><span class="line">import &quot;fmt&quot;</span><br><span class="line"></span><br><span class="line">type Cooker interface &#123;</span><br><span class="line">  fire()</span><br><span class="line">  cooke()</span><br><span class="line">  outfire()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 类似于一个抽象类</span><br><span class="line">type CookMenu struct &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (CookMenu) fire() &#123;</span><br><span class="line">  fmt.Println(&quot;开火&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 做菜，交给具体的子类实现</span><br><span class="line">func (CookMenu) cooke() &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (CookMenu) outfire() &#123;</span><br><span class="line">  fmt.Println(&quot;关火&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 封装具体步骤</span><br><span class="line">func doCook(cook Cooker) &#123;</span><br><span class="line">  cook.fire()</span><br><span class="line">  cook.cooke()</span><br><span class="line">  cook.outfire()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type XiHongShi struct &#123;</span><br><span class="line">  CookMenu</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (*XiHongShi) cooke() &#123;</span><br><span class="line">  fmt.Println(&quot;做西红柿&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type ChaoJiDan struct &#123;</span><br><span class="line">  CookMenu</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (ChaoJiDan) cooke() &#123;</span><br><span class="line">  fmt.Println(&quot;做炒鸡蛋&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>##7. 代理模式<br>可以为另一个对象提供一个替身或者占位符，以控制对这个对象的访问。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package proxy</span><br><span class="line"></span><br><span class="line">import &quot;fmt&quot;</span><br><span class="line"></span><br><span class="line">type Seller interface &#123;</span><br><span class="line">  sell(name string)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 火车站</span><br><span class="line">type Station struct &#123;</span><br><span class="line">  stock int //库存</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (station *Station) sell(name string) &#123;</span><br><span class="line">  if station.stock &gt; 0 &#123;</span><br><span class="line">    station.stock--</span><br><span class="line">    fmt.Printf(&quot;代理点中：%s买了一张票,剩余：%d \n&quot;, name, station.stock)</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    fmt.Println(&quot;票已售空&quot;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 火车代理点</span><br><span class="line">type StationProxy struct &#123;</span><br><span class="line">  station *Station // 持有一个火车站对象</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (proxy *StationProxy) sell(name string) &#123;</span><br><span class="line">  if proxy.station.stock &gt; 0 &#123;</span><br><span class="line">    proxy.station.stock--</span><br><span class="line">    fmt.Printf(&quot;代理点中：%s买了一张票,剩余：%d \n&quot;, name, proxy.station.stock)</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    fmt.Println(&quot;票已售空&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-选项模式"><a href="#8-选项模式" class="headerlink" title="8. 选项模式"></a>8. 选项模式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package options</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">  &quot;time&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type Connection struct &#123;</span><br><span class="line">  addr    string</span><br><span class="line">  cache   bool</span><br><span class="line">  timeout time.Duration</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">const (</span><br><span class="line">  defaultTimeout = 10</span><br><span class="line">  defaultCaching = false</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type options struct &#123;</span><br><span class="line">  timeout time.Duration</span><br><span class="line">  caching bool</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Option overrides behavior of Connect.</span><br><span class="line">type Option interface &#123;</span><br><span class="line">  apply(*options)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type optionFunc func(*options)</span><br><span class="line"></span><br><span class="line">func (f optionFunc) apply(o *options) &#123;</span><br><span class="line">  f(o)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func WithTimeout(t time.Duration) Option &#123;</span><br><span class="line">  return optionFunc(func(o *options) &#123;</span><br><span class="line">    o.timeout = t</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func WithCaching(cache bool) Option &#123;</span><br><span class="line">  return optionFunc(func(o *options) &#123;</span><br><span class="line">    o.caching = cache</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// Connect creates a connection.</span><br><span class="line">func NewConnect(addr string, opts ...Option) (*Connection, error) &#123;</span><br><span class="line">  options := options&#123;</span><br><span class="line">    timeout: defaultTimeout,</span><br><span class="line">    caching: defaultCaching,</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  for _, o := range opts &#123;</span><br><span class="line">    o.apply(&amp;options)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  return &amp;Connection&#123;</span><br><span class="line">    addr:    addr,</span><br><span class="line">    cache:   options.caching,</span><br><span class="line">    timeout: options.timeout,</span><br><span class="line">  &#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>选项模式通常适用于以下场景：</p><ul><li>结构体参数很多，创建结构体时，我们期望创建一个携带默认值的结构体变量，并选择性修改其中一些参数的值。</li><li>结构体参数经常变动，变动时我们又不想修改创建实例的函数。例如：结构体新增一个 retry 参数，但是又不想在 NewConnect 入参列表中添加retry int这样的参数声明。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li>Go 语言项目开发实战&#x2F;设计模式</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go常用资源列表</title>
      <link href="/golang/Go%E5%B8%B8%E7%94%A8%E8%B5%84%E6%BA%90%E5%88%97%E8%A1%A8/"/>
      <url>/golang/Go%E5%B8%B8%E7%94%A8%E8%B5%84%E6%BA%90%E5%88%97%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/avelino/awesome-go"><strong>Awesome go 最全资源列表</strong></a><br><a href="https://github.com/jobbole/awesome-go-cn"><strong>Awesome go 中文版</strong></a><br>以下是项目中使用到的部分package。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p><a href="https://github.com/gorilla/mux"><strong>mux</strong></a><br>实现了请求路由器和调度程序，用于将传入请求与其各自的处理程序匹配。例如统一HTTP与RPC服务入口。</p><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><p><a href="https://github.com/golang-migrate/migrate"><strong>db migrate</strong></a><br>支持常见的数据库升级与降级<br><a href="https://github.com/go-redis/redis"><strong>redis</strong></a><br><a href="https://github.com/olivere/elastic"><strong>elasticsearch cli</strong></a><br><a href="https://github.com/go-gorm/gorm"><strong>gorm</strong></a><br>GORM 是 Go 语言的 ORM 包，功能强大，调用方便。</p><h2 id="模板引擎"><a href="#模板引擎" class="headerlink" title="模板引擎"></a>模板引擎</h2><p><a href="https://github.com/flosch/pongo2"><strong>pongo2</strong></a><br>非预编译，类django特性的引擎，简单易用<br><a href="https://github.com/shiyanhui/hero"><strong>hero</strong></a><br>预编译模板引擎，性能更好</p><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p><a href="https://github.com/prometheus/client_golang"><strong>Prometheus Client</strong></a><br>开发exporter</p><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p><a href="https://github.com/uber-go/zap"><strong>Uber zap</strong></a><br>对性能和内存做了极致的优化</p><h2 id="命令工具"><a href="#命令工具" class="headerlink" title="命令工具"></a>命令工具</h2><p><a href="https://github.com/spf13/cobra"><strong>Cobra</strong></a><br>kubectl使用Cobra开发命令行工具<br><a href="https://github.com/alecthomas/kingpin"><strong>Kingpin</strong></a><br><a href="https://github.com/jessevdk/go-flags"><strong>go-flags</strong></a><br><a href="https://github.com/urfave/cli"><strong>cli</strong></a><br>goctl工具使用是这个命令行工具</p><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p><a href="https://github.com/stretchr/testify">Mock <strong>testify&#x2F;mock</strong></a><br>可用来Mock Http请求<br><a href="https://github.com/DATA-DOG/go-sqlmock">Sql mock driver</a><br>可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。<br><a href="https://github.com/stretchr/testify">Testify</a><br>测试断言包<br><a href="https://github.com/cweill/gotests"> Automatically generate Go test boilerplate from your source code</a><br>自动生成测试用例<br><a href="https://github.com/smartystreets/goconvey">Go testing in the browser</a><br>GoConvey 是一款针对 Golang 的测试框架，可以管理和运行测试用例，同时提供了丰富的断言函数，并支持很多 Web 界面特性。</p><p>go自带代码测试覆盖率分析工具</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ go test -coverprofile=coverage.out</span><br><span class="line">$ go tool cover -func=coverage.out</span><br><span class="line">$ go tool cover -html=coverage.out -o coverage.html</span><br></pre></td></tr></table></figure><h2 id="工具集"><a href="#工具集" class="headerlink" title="工具集"></a>工具集</h2><p><a href="https://github.com/go-yaml/yaml"><strong>go yaml</strong></a><br><a href="https://github.com/satori/go.uuid"><strong>uuid</strong></a><br>uuid的创建与解析<br><a href="https://github.com/cenkalti/backoff"><strong>backoff</strong></a><br>重试工具，支持指数退避算法<br><a href="https://github.com/kubernetes/client-go.git"><strong>Kubernetes client</strong></a><br><a href="https://github.com/aws/aws-sdk-go"><strong>aws client</strong></a><br><a href="https://pkg.go.dev/text/tabwriter"><strong>text&#x2F;tabwriter</strong></a> go自带输出对齐<br><a href="github.com/PuerkitoBio/goquery"><strong>goquery</strong></a><br>类似jquery解析html dom<br><a href="https://github.com/elazarl/go-bindata-assetfs"><strong>bindata</strong></a><br>将静态文件转为GO文件<br><a href="https://www.cnblogs.com/taceywong/p/10506032.html"><strong>cookiecutter</strong></a><br>项目初始化生成，可按照生产最佳实践快速启动各种项目</p><p>##分布式作业系统<br><a href="https://github.com/distribworks/dkron">Dkron - Distributed, fault tolerant job scheduling system https://dkron.io</a><br>dkron 是一个分布式、启动迅速、带容错机制的定时作业系统，支持 crontab 表达式。它具有下面这些核心特性。</p><ul><li>易用：可以通过易操作、漂亮的 Web 界面来管理作业。</li><li>可靠：具备容错机制，一个节点不可用，其他节点可继续执行作业。</li><li>高可扩展性：能够处理大量的计划作业和数千个节点。</li></ul><p><a href="https://github.com/ouqiang/gocron">ouqiang&#x2F;gocron: 定时任务管理系统</a><br>gocron 是国人开发的轻量级定时任务集中调度和管理系统, 用于替代 Linux-crontab。它具有下面这些核心特性。</p><ul><li>具有 Web 界面管理定时任务。</li><li>支持 crontab 时间格式，并精确到秒。</li><li>支持 shell 命令和 HTTP 请求两种任务格式。具</li><li>有任务超时机制、任务依赖机制、任务执行失败可重试机制。</li><li>支持查看任务执行日志，并支持用邮件、Slack、Webhook 等方式通知任务执行结果。</li></ul><p><a href="https://github.com/robfig/cron">robfig&#x2F;cron: a cron library for go (github.com)</a><br>一个可以实现类似 Linux crontab 定时任务的 cron 包，支持到秒</p><h2 id="微服务框架"><a href="#微服务框架" class="headerlink" title="微服务框架"></a>微服务框架</h2><p><a href="https://github.com/go-kit/kit">go-kit&#x2F;kit: 微服务标准库</a>: <a href="https://peter.bourgon.org/applied-go-kit/">应用Go kit</a><br><a href="https://github.com/zeromicro/go-zero">go-zero: 云原生生产级别微服务框架</a><br><a href="https://go-kratos.dev/docs/">Kratos: 一套轻量级 Go 微服务框架，包含大量微服务相关框架及工具</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言编码规范指导</title>
      <link href="/golang/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83%E6%8C%87%E5%AF%BC/"/>
      <url>/golang/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83%E6%8C%87%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p>From：茹姐  <a href="https://zhuanlan.zhihu.com/p/63250689">https://zhuanlan.zhihu.com/p/63250689</a><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2a8fad95acbb7103051cbc1e1ab88df2e4baf73bf6b5dd5fa58c62722d3d33b8.png" alt="关键字">  </p><p>本规范旨在为日常Go项目开发提供一个代码的规范指导，方便团队形成一个统一的代码风格，提高代码的可读性，规范性和统一性。本规范将从命名规范，注释规范，代码风格和 Go 语言提供的常用的工具这几个方面做一个说明。该规范参考了 go 语言官方代码的风格制定。</p><h2 id="一、-命名规范"><a href="#一、-命名规范" class="headerlink" title="一、 命名规范"></a>一、 命名规范</h2><p>命名是代码规范中很重要的一部分，统一的命名规则有利于提高的代码的可读性，好的命名仅仅通过命名就可以获取到足够多的信息。</p><p>Go在命名时以字母a到Z或a到Z或下划线开头，后面跟着零或更多的字母、下划线和数字(0到9)。Go不允许在命名时中使用@、$和%等标点符号。Go是一种区分大小写的编程语言。因此，Manpower和manpower是两个不同的命名。</p><p>当命名（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；<br>命名如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 private ）</p><h3 id="1、包命名：package"><a href="#1、包命名：package" class="headerlink" title="1、包命名：package"></a>1、包命名：package</h3><p>保持package的名字和目录保持一致，尽量采取有意义的包名，简短，有意义，尽量和标准库不要冲突。包名应该为小写单词，不要使用下划线或者混合大小写。</p><p>package demo</p><p>package main</p><h3 id="2、-文件命名"><a href="#2、-文件命名" class="headerlink" title="2、 文件命名"></a>2、 文件命名</h3><p>尽量采取有意义的文件名，简短，有意义，应该为小写单词，使用下划线分隔各个单词。</p><p>my_test.go</p><h3 id="3、-结构体命名"><a href="#3、-结构体命名" class="headerlink" title="3、 结构体命名"></a>3、 结构体命名</h3><p>采用驼峰命名法，首字母根据访问控制大写或者小写<br>struct 申明和初始化格式采用多行，例如下面：<br>&#x2F;&#x2F; 多行申明<br>type User struct{<br>    Username  string<br>    Email     string<br>}</p><p>&#x2F;&#x2F; 多行初始化<br>u :&#x3D; User{<br>    Username: “astaxie”,<br>    Email:    “<a href="mailto:&#x61;&#115;&#x74;&#97;&#120;&#x69;&#101;&#x40;&#x67;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#x6f;&#109;">&#x61;&#115;&#x74;&#97;&#120;&#x69;&#101;&#x40;&#x67;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#x6f;&#109;</a>“,<br>}</p><h3 id="4、-接口命名"><a href="#4、-接口命名" class="headerlink" title="4、 接口命名"></a>4、 接口命名</h3><p>命名规则基本和上面的结构体类型<br>单个函数的结构名以 “er” 作为后缀，例如 Reader , Writer 。<br>type Reader interface {<br>        Read(p []byte) (n int, err error)<br>}</p><h3 id="5、变量命名"><a href="#5、变量命名" class="headerlink" title="5、变量命名"></a>5、变量命名</h3><p>和结构体类似，变量名称一般遵循驼峰法，首字母根据访问控制原则大写或者小写，但遇到特有名词时，需要遵循以下规则：<br>如果变量为私有，且特有名词为首个单词，则使用小写，如 apiClient<br>其它情况都应当使用该名词原有的写法，如 APIClient、repoID、UserID<br>错误示例：UrlArray，应该写成 urlArray 或者 URLArray<br>若变量类型为 bool 类型，则名称应以 Has, Is, Can 或 Allow 开头<br>var isExist bool<br>var hasConflict bool<br>var canManage bool<br>var allowGitHook bool</p><h3 id="6、常量命名"><a href="#6、常量命名" class="headerlink" title="6、常量命名"></a>6、常量命名</h3><p>常量均需使用全部大写字母组成，并使用下划线分词</p><p>const APP_VER &#x3D; “1.0”<br>如果是枚举类型的常量，需要先创建相应类型：</p><p>type Scheme string</p><p>const (<br>    HTTP  Scheme &#x3D; “http”<br>    HTTPS Scheme &#x3D; “https”<br>)</p><h3 id="7、-关键字"><a href="#7、-关键字" class="headerlink" title="7、 关键字"></a>7、 关键字</h3><p>下面的列表显示了Go中的保留字。这些保留字不能用作常量或变量或任何其他标识符名称。</p><h2 id="二、注释"><a href="#二、注释" class="headerlink" title="二、注释"></a>二、注释</h2><p>Go提供C风格的&#x2F;* *&#x2F;块注释和C ++风格的&#x2F;&#x2F;行注释。行注释是常态；块注释主要显示为包注释，但在表达式中很有用或禁用大量代码。</p><p>单行注释是最常见的注释形式，你可以在任何地方使用以 &#x2F;&#x2F; 开头的单行注释<br>多行注释也叫块注释，均已以 &#x2F;* 开头，并以 *&#x2F; 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段<br>go 语言自带的 godoc 工具可以根据注释生成文档，生成可以自动生成对应的网站（ <a href="http://golang.org/">http://golang.org</a> 就是使用 godoc 工具直接生成的），注释的质量决定了生成的文档的质量。每个包都应该有一个包注释，在package子句之前有一个块注释。对于多文件包，包注释只需要存在于一个文件中，任何一个都可以。包评论应该介绍包，并提供与整个包相关的信息。它将首先出现在godoc页面上，并应设置下面的详细文档。</p><p>详细的如何写注释可以 参考：<a href="http://golang.org/doc/effective_go.html#commentary">http://golang.org/doc/effective_go.html#commentary</a></p><h3 id="1、包注释"><a href="#1、包注释" class="headerlink" title="1、包注释"></a>1、包注释</h3><p>每个包都应该有一个包注释，一个位于package子句之前的块注释或行注释。包如果有多个go文件，只需要出现在一个go文件中（一般是和包同名的文件）即可。 包注释应该包含下面基本信息(请严格按照这个顺序，简介，创建人，创建时间）：</p><p>包的基本简介（包名，简介）<br>创建者，格式： 创建人： rtx 名<br>创建时间，格式：创建时间： yyyyMMdd<br>例如 util 包的注释示例如下</p><p>&#x2F;&#x2F; util 包， 该包包含了项目共用的一些常量，封装了项目中一些共用函数。<br>&#x2F;&#x2F; 创建人： hanru<br>&#x2F;&#x2F; 创建时间： 20190419</p><h3 id="2、结构（接口）注释"><a href="#2、结构（接口）注释" class="headerlink" title="2、结构（接口）注释"></a>2、结构（接口）注释</h3><p>每个自定义的结构体或者接口都应该有注释说明，该注释对结构进行简要介绍，放在结构体定义的前一行，格式为： 结构体名， 结构体说明。同时结构体内的每个成员变量都要有说明，该说明放在成员变量的后面（注意对齐），实例如下：</p><p>&#x2F;&#x2F; User ， 用户对象，定义了用户的基础信息<br>type User struct{<br>    Username  string &#x2F;&#x2F; 用户名<br>    Email     string &#x2F;&#x2F; 邮箱<br>}</p><h3 id="3、函数（方法）注释"><a href="#3、函数（方法）注释" class="headerlink" title="3、函数（方法）注释"></a>3、函数（方法）注释</h3><p>每个函数，或者方法（结构体或者接口下的函数称为方法）都应该有注释说明，函数的注释应该包括三个方面（严格按照此顺序撰写）：</p><p>简要说明，格式说明：以函数名开头，“，”分隔说明部分<br>参数列表：每行一个参数，参数名开头，“，”分隔说明部分<br>返回值： 每行一个返回值<br>示例如下：</p><p>&#x2F;&#x2F; NewtAttrModel ， 属性数据层操作类的工厂方法<br>&#x2F;&#x2F; 参数：<br>&#x2F;&#x2F;      ctx ： 上下文信息<br>&#x2F;&#x2F; 返回值：<br>&#x2F;&#x2F;      属性操作类指针<br>func NewAttrModel(ctx *common.Context) *AttrModel {<br>}</p><h3 id="4、代码逻辑注释"><a href="#4、代码逻辑注释" class="headerlink" title="4、代码逻辑注释"></a>4、代码逻辑注释</h3><p>对于一些关键位置的代码逻辑，或者局部较为复杂的逻辑，需要有相应的逻辑说明，方便其他开发者阅读该段代码，实例如下：</p><p>&#x2F;&#x2F; 从 Redis 中批量读取属性，对于没有读取到的 id ， 记录到一个数组里面，准备从 DB 中读取<br>xxxxx<br>xxxxxxx<br>xxxxxxx</p><h3 id="5、注释风格"><a href="#5、注释风格" class="headerlink" title="5、注释风格"></a>5、注释风格</h3><p>统一使用中文注释，对于中英文字符之间严格使用空格分隔， 这个不仅仅是中文和英文之间，英文和中文标点之间也都要使用空格分隔，例如：</p><p>&#x2F;&#x2F; 从 Redis 中批量读取属性，对于没有读取到的 id ， 记录到一个数组里面，准备从 DB 中读取<br>上面 Redis 、 id 、 DB 和其他中文字符之间都是用了空格分隔。</p><p>建议全部使用单行注释<br>和代码的规范一样，单行注释不要过长，禁止超过 120 字符。</p><h2 id="三、代码风格"><a href="#三、代码风格" class="headerlink" title="三、代码风格"></a>三、代码风格</h2><h3 id="1、缩进和折行"><a href="#1、缩进和折行" class="headerlink" title="1、缩进和折行"></a>1、缩进和折行</h3><p>缩进直接使用 gofmt 工具格式化即可（gofmt 是使用 tab 缩进的）；<br>折行方面，一行最长不超过120个字符，超过的请使用换行展示，尽量保持格式优雅。<br>我们使用Goland开发工具，可以直接使用快捷键：ctrl+alt+L，即可。</p><h3 id="2、语句的结尾"><a href="#2、语句的结尾" class="headerlink" title="2、语句的结尾"></a>2、语句的结尾</h3><p>Go语言中是不需要类似于Java需要冒号结尾，默认一行就是一条数据</p><p>如果你打算将多个语句写在同一行，它们则必须使用 ;</p><h3 id="3、括号和空格"><a href="#3、括号和空格" class="headerlink" title="3、括号和空格"></a>3、括号和空格</h3><p>括号和空格方面，也可以直接使用 gofmt 工具格式化（go 会强制左大括号不换行，换行会报语法错误），所有的运算符和操作数之间要留空格。</p><p>&#x2F;&#x2F; 正确的方式<br>if a &gt; 0 {</p><p>} </p><p>&#x2F;&#x2F; 错误的方式<br>if a&gt;0  &#x2F;&#x2F; a ，0 和 &gt; 之间应该空格<br>{       &#x2F;&#x2F; 左大括号不可以换行，会报语法错误</p><p>}</p><h3 id="4、import-规范"><a href="#4、import-规范" class="headerlink" title="4、import 规范"></a>4、import 规范</h3><p>import在多行的情况下，goimports会自动帮你格式化，但是我们这里还是规范一下import的一些规范，如果你在一个文件里面引入了一个package，还是建议采用如下格式：</p><p>import (<br>    “fmt”<br>)<br>如果你的包引入了三种类型的包，标准库包，程序内部包，第三方包，建议采用如下方式进行组织你的包：</p><p>import (<br>    “encoding&#x2F;json”<br>    “strings”</p><pre><code>&quot;myproject/models&quot;&quot;myproject/controller&quot;&quot;myproject/utils&quot;&quot;github.com/astaxie/beego&quot;&quot;github.com/go-sql-driver/mysql&quot;</code></pre><p>)<br>有顺序的引入包，不同的类型采用空格分离，第一种实标准库，第二是项目包，第三是第三方包。</p><p>在项目中不要使用相对路径引入包：</p><p>&#x2F;&#x2F; 这是不好的导入<br>import “..&#x2F;net”</p><p>&#x2F;&#x2F; 这是正确的做法<br>import “github.com&#x2F;repo&#x2F;proj&#x2F;src&#x2F;net”<br>但是如果是引入本项目中的其他包，最好使用相对路径。</p><h3 id="5、错误处理"><a href="#5、错误处理" class="headerlink" title="5、错误处理"></a>5、错误处理</h3><p>错误处理的原则就是不能丢弃任何有返回err的调用，不要使用 _ 丢弃，必须全部处理。接收到错误，要么返回err，或者使用log记录下来<br>尽早return：一旦有错误发生，马上返回<br>尽量不要使用panic，除非你知道你在做什么<br>错误描述如果是英文必须为小写，不需要标点结尾<br>采用独立的错误流进行处理<br>&#x2F;&#x2F; 错误写法<br>if err !&#x3D; nil {<br>    &#x2F;&#x2F; error handling<br>} else {<br>    &#x2F;&#x2F; normal code<br>}</p><p>&#x2F;&#x2F; 正确写法<br>if err !&#x3D; nil {<br>    &#x2F;&#x2F; error handling<br>    return &#x2F;&#x2F; or continue, etc.<br>}<br>&#x2F;&#x2F; normal code</p><h3 id="6、测试"><a href="#6、测试" class="headerlink" title="6、测试"></a>6、测试</h3><p>单元测试文件名命名规范为 example_test.go 测试用例的函数名称必须以 Test 开头，例如：TestExample 每个重要的函数都要首先编写测试用例，测试用例和正规代码一起提交方便进行回归测试</p><h2 id="四、常用工具"><a href="#四、常用工具" class="headerlink" title="四、常用工具"></a>四、常用工具</h2><p>上面提到了很过规范， go 语言本身在代码规范性这方面也做了很多努力，很多限制都是强制语法要求，例如左大括号不换行，引用的包或者定义的变量不使用会报错，此外 go 还是提供了很多好用的工具帮助我们进行代码的规范，</p><p>gofmt 大部分的格式问题可以通过gofmt解决， gofmt 自动格式化代码，保证所有的 go 代码与官方推荐的格式保持一致，于是所有格式有关问题，都以 gofmt 的结果为准。</p><p>goimport 我们强烈建议使用 goimport ，该工具在 gofmt 的基础上增加了自动删除和引入包.</p><p>go get golang.org&#x2F;x&#x2F;tools&#x2F;cmd&#x2F;goimports<br>go vet vet工具可以帮我们静态分析我们的源码存在的各种问题，例如多余的代码，提前return的逻辑，struct的tag是否符合标准等。</p><p>go get golang.org&#x2F;x&#x2F;tools&#x2F;cmd&#x2F;vet<br>使用如下：</p><p>go vet .</p>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vagrant扩展虚拟机盘</title>
      <link href="/DevOps/Vagrant%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A1%AC%E7%9B%98%E6%89%A9%E5%AE%B9/"/>
      <url>/DevOps/Vagrant%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%A1%AC%E7%9B%98%E6%89%A9%E5%AE%B9/</url>
      
        <content type="html"><![CDATA[<h2 id="扩展虚拟机盘"><a href="#扩展虚拟机盘" class="headerlink" title="扩展虚拟机盘"></a>扩展虚拟机盘</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 停止虚拟机</span><br><span class="line">vagrant halt &lt;machine_name&gt;</span><br><span class="line"># 进入VirtualBox VMs目录，查看并记录原磁盘uuid，留作后用</span><br><span class="line">vboxmanage showhdinfo box-disk1.vmdk</span><br><span class="line"># 克隆磁盘，vmdk格式无法调整大小，需要转成vdi格式</span><br><span class="line">vboxmanage clonehd box-disk1.vmdk new-virtualdisk.vdi --format vdi</span><br><span class="line"># 调整克隆磁盘的大小，这里调整为400G</span><br><span class="line">vboxmanage modifyhd new-virtualdisk.vdi --resize 409600</span><br><span class="line"># 在克隆磁盘的基础上再克隆vdi格式的磁盘</span><br><span class="line">vboxmanage clonehd new-virtualdisk.vdi resized.vmdk --format vmdk</span><br><span class="line"># 覆盖原磁盘（如果担心磁盘数据出现不可逆损坏，请先做好备份）</span><br><span class="line">mv resized.vmdk box-disk1.vmdk</span><br><span class="line"># 此时节已删除中间文件</span><br><span class="line">rm new-virtualdisk.vdi</span><br><span class="line"># !!!此时启动虚机或查看磁盘信息会报错，提示uuid不匹配，因为磁盘已经变了，需要改回之前记录的uuid</span><br><span class="line">vboxmanage internalcommands sethduuid box-disk1.vmdk &lt;old_uuid&gt;</span><br><span class="line"># done，可以重启虚机了，可根据需要在虚机上进行磁盘分配，这里不再展开</span><br><span class="line">vagrant up &lt;machine_name&gt;</span><br></pre></td></tr></table></figure><h2 id="进入主机，创建盘分区"><a href="#进入主机，创建盘分区" class="headerlink" title="进入主机，创建盘分区"></a>进入主机，创建盘分区</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看分区：比如/dev/sad</span><br><span class="line">fdisk -l </span><br><span class="line"># 开始分区</span><br><span class="line">fdisk /dev/sda</span><br><span class="line"># m 帮助菜单 \ p 该整磁盘详细信息 \ d 删除分区 \ n 添加分区 \w保存变更</span><br></pre></td></tr></table></figure><h2 id="重启并挂载目录"><a href="#重启并挂载目录" class="headerlink" title="重启并挂载目录"></a>重启并挂载目录</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 重启虚拟机</span><br><span class="line">vagrant reload</span><br><span class="line"># 格式化分区</span><br><span class="line">mkfs.ext4 /dev/sda4</span><br><span class="line"># 挂载</span><br><span class="line">mount /dev/sda4 /mnt</span><br><span class="line"># 设置开机自动挂载</span><br><span class="line">echo &quot;/dev/sda4 /mnt ext4 defaults 0 0&quot; &gt;&gt; /etc/fstab</span><br><span class="line"># 查看当前挂载目录情况</span><br><span class="line">df -h</span><br></pre></td></tr></table></figure><h1 id="Vagrant国内相关镜像下载"><a href="#Vagrant国内相关镜像下载" class="headerlink" title="Vagrant国内相关镜像下载"></a>Vagrant国内相关镜像下载</h1><p>参考<a href="https://cloud.tencent.com/developer/article/1658648">Vagrant使用国内镜像安装插件和box镜像</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-常见运维脚本及问题解决</title>
      <link href="/openshift/Openshift-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
      <url>/openshift/Openshift-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
      
        <content type="html"><![CDATA[<h2 id="1-扩容计算结点"><a href="#1-扩容计算结点" class="headerlink" title="1.扩容计算结点"></a>1.扩容计算结点</h2><p>在执行扩容前需检查扩容节点的以下几点信息：</p><ul><li>内核版本</li><li>selinux已经开启enforcing</li><li>docker数据盘已经就绪</li><li>&#x2F;etc&#x2F;resolv.conf配置正确</li><li>hostname已经设置</li><li>时间同步已配置</li><li>在每个节点都能解析新增节点的域名，如果是通过&#x2F;etc&#x2F;hosts来配置域名解析，需要在配置后重启所有节点的dnsmasq服务</li><li>docker证书的问题需要添加到自动化配置中来，特别是私有镜像仓库的证书。有三个地方：<ol><li>&#x2F;etc&#x2F;sysconfig&#x2F;docker配置，</li><li>&#x2F;etc&#x2F;pki&#x2F;ca-trust&#x2F;source&#x2F;anchors&#x2F;目录下的证书，</li><li>&#x2F;etc&#x2F;docker&#x2F;certs.d下docker拉取镜像认证证书</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># /etc/ansible/hosts</span><br><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">etcd</span><br><span class="line">new_nodes</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">[new_nodes]</span><br><span class="line">node04.internal.aws.testdrive.openshift.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;apps&#x27;&#125;&quot; openshift_hostname=node04.internal.aws.testdrive.openshift.com openshift_public_hostname=node04.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node05.internal.aws.testdrive.openshift.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;apps&#x27;&#125;&quot; openshift_hostname=node05.internal.aws.testdrive.openshift.com openshift_public_hostname=node05.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node06.internal.aws.testdrive.openshift.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;apps&#x27;&#125;&quot; openshift_hostname=node06.internal.aws.testdrive.openshift.com openshift_public_hostname=node06.580763383722.aws.testdrive.openshift.com</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>在dns中配置新增的节点。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml</span><br></pre></td></tr></table></figure><p><code>注意：</code>如果集群是通过&#x2F;etc&#x2F;hosts文件来配置的解析，则需在添加好对应配置关系后，重启所有节点的dnsmasq。否则会报“could not find csr for nodes”的错误。</p><h2 id="2-OpenShift-Metrics"><a href="#2-OpenShift-Metrics" class="headerlink" title="2.OpenShift Metrics"></a>2.OpenShift Metrics</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">[OSEv3:vars]</span><br><span class="line">...</span><br><span class="line">openshift_metrics_install_metrics=true</span><br><span class="line">openshift_metrics_cassandra_storage_type=pv</span><br><span class="line">openshift_metrics_cassandra_pvc_size=10Gi</span><br><span class="line">openshift_metrics_hawkular_hostname=metrics.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-metrics.yml</span><br></pre></td></tr></table></figure><h2 id="3-OpenShift-Logging"><a href="#3-OpenShift-Logging" class="headerlink" title="3.OpenShift Logging"></a>3.OpenShift Logging</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">[OSEv3:vars]</span><br><span class="line">...</span><br><span class="line">openshift_logging_install_logging=true</span><br><span class="line">openshift_logging_namespace=logging</span><br><span class="line">openshift_logging_es_pvc_size=10Gi</span><br><span class="line">openshift_logging_kibana_hostname=kibana.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">openshift_logging_public_master_url=https://kibana.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-logging.yml</span><br></pre></td></tr></table></figure><h2 id="4-OpenShift-Multitenant-Networking"><a href="#4-OpenShift-Multitenant-Networking" class="headerlink" title="4.OpenShift Multitenant Networking"></a>4.OpenShift Multitenant Networking</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os_sdn_network_plugin_name=redhat/openshift-ovs-multitenant</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># net-proj.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># create NetworkA, NetworkB projects</span><br><span class="line">/usr/bin/oc new-project netproj-a</span><br><span class="line">/usr/bin/oc new-project netproj-b</span><br><span class="line"></span><br><span class="line"># deploy the DC definition into the projects</span><br><span class="line">/usr/bin/oc create -f /opt/lab/support/ose.yaml -n netproj-a</span><br><span class="line">/usr/bin/oc create -f /opt/lab/support/ose.yaml -n netproj-b</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">#ose.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: ose</span><br><span class="line">  labels:</span><br><span class="line">    run: ose</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    type: Rolling</span><br><span class="line">    rollingParams:</span><br><span class="line">      updatePeriodSeconds: 1</span><br><span class="line">      intervalSeconds: 1</span><br><span class="line">      timeoutSeconds: 600</span><br><span class="line">      maxUnavailable: 25%</span><br><span class="line">      maxSurge: 25%</span><br><span class="line">    resources:</span><br><span class="line">  triggers:</span><br><span class="line">    -</span><br><span class="line">      type: ConfigChange</span><br><span class="line">  replicas: 1</span><br><span class="line">  test: false</span><br><span class="line">  selector:</span><br><span class="line">    run: ose</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        run: ose</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        -</span><br><span class="line">          name: ose</span><br><span class="line">          image: &#x27;registry.access.redhat.com/openshift3/ose:v3.5&#x27;</span><br><span class="line">          command:</span><br><span class="line">            - bash</span><br><span class="line">            - &#x27;-c&#x27;</span><br><span class="line">            - &#x27;while true; do sleep 60; done&#x27;</span><br><span class="line">          resources:</span><br><span class="line">          terminationMessagePath: /dev/termination-log</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      securityContext:</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#podbip.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">/usr/bin/oc get pod -n netproj-b $(oc get pod -n netproj-b | awk &#x27;/ose-/ &#123;print $1&#125;&#x27;) -o jsonpath=&#x27;&#123;.status.podIP&#125;&#123;&quot;\n&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure><h3 id="将netproj-a网络与netproj-b网络连接"><a href="#将netproj-a网络与netproj-b网络连接" class="headerlink" title="将netproj-a网络与netproj-b网络连接"></a>将netproj-a网络与netproj-b网络连接</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc adm pod-network join-projects netproj-a --to=netproj-b</span><br><span class="line">oc get netnamespace</span><br></pre></td></tr></table></figure><h3 id="将netproj-a网络脱离"><a href="#将netproj-a网络脱离" class="headerlink" title="将netproj-a网络脱离"></a>将netproj-a网络脱离</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc adm pod-network isolate-projects netproj-a</span><br><span class="line">oc get netnamespace</span><br><span class="line">oc exec -n netproj-a $POD_A_NAME -- ping -c1 -W1 $POD_B_IP</span><br></pre></td></tr></table></figure><h2 id="5-Node管理"><a href="#5-Node管理" class="headerlink" title="5.Node管理"></a>5.Node管理</h2><h3 id="将Node隔离出集群"><a href="#将Node隔离出集群" class="headerlink" title="将Node隔离出集群"></a>将Node隔离出集群</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --schedulable=false</span><br></pre></td></tr></table></figure><h3 id="查看指定Node上运行的pod"><a href="#查看指定Node上运行的pod" class="headerlink" title="查看指定Node上运行的pod"></a>查看指定Node上运行的pod</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --list-pods</span><br></pre></td></tr></table></figure><h3 id="迁移指定Node上的pod"><a href="#迁移指定Node上的pod" class="headerlink" title="迁移指定Node上的pod"></a>迁移指定Node上的pod</h3><h4 id="模拟迁移"><a href="#模拟迁移" class="headerlink" title="模拟迁移"></a>模拟迁移</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --evacuate --dry-run</span><br></pre></td></tr></table></figure><h4 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --evacuate</span><br></pre></td></tr></table></figure><h3 id="恢复Node的可调度"><a href="#恢复Node的可调度" class="headerlink" title="恢复Node的可调度"></a>恢复Node的可调度</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm manage-node node02.internal.aws.testdrive.openshift.com --schedulable=true</span><br></pre></td></tr></table></figure><h3 id="创建volume"><a href="#创建volume" class="headerlink" title="创建volume"></a>创建volume</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc volume dc/file-uploader --add --name=my-shared-storage \</span><br><span class="line">-t pvc --claim-mode=ReadWriteMany --claim-size=5Gi \</span><br><span class="line">--claim-name=my-shared-storage --mount-path=/opt/app-root/src/uploaded</span><br></pre></td></tr></table></figure><h3 id="Increasing-Storage-Capacity-in-CNS"><a href="#Increasing-Storage-Capacity-in-CNS" class="headerlink" title="Increasing Storage Capacity in CNS"></a>Increasing Storage Capacity in CNS</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line"></span><br><span class="line">[cns]</span><br><span class="line">node01.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node02.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node03.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node04.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node05.580763383722.aws.testdrive.openshift.com</span><br><span class="line">node06.580763383722.aws.testdrive.openshift.com</span><br><span class="line"></span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook /opt/lab/support/configure-firewall.yaml</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc label node/node04.internal.aws.testdrive.openshift.com storagenode=glusterfs</span><br><span class="line">oc label node/node05.internal.aws.testdrive.openshift.com storagenode=glusterfs</span><br><span class="line">oc label node/node06.internal.aws.testdrive.openshift.com storagenode=glusterfs</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HEKETI_CLI_SERVER=http://heketi-container-native-storage.apps.580763383722.aws.testdrive.openshift.com</span><br><span class="line">export HEKETI_CLI_USER=admin</span><br><span class="line">export HEKETI_CLI_KEY=myS3cr3tpassw0rd</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">#/opt/lab/support/topology-extended.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;clusters&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;nodes&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node01.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.1.30&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node02.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.3.130&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 2</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node03.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.4.150&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 3</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;nodes&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node04.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.1.23&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 1</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node05.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.3.141&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 2</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;,</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;node&quot;: &#123;</span><br><span class="line">                        &quot;hostnames&quot;: &#123;</span><br><span class="line">                            &quot;manage&quot;: [</span><br><span class="line">                                &quot;node06.internal.aws.testdrive.openshift.com&quot;</span><br><span class="line">                            ],</span><br><span class="line">                            &quot;storage&quot;: [</span><br><span class="line">                                &quot;10.0.4.234&quot;</span><br><span class="line">                            ]</span><br><span class="line">                        &#125;,</span><br><span class="line">                        &quot;zone&quot;: 3</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;devices&quot;: [</span><br><span class="line">                        &quot;/dev/xvdd&quot;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli topology load --json=/opt/lab/support/topology-extended.json</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli topology info ##得到Cluster ID</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># /opt/lab/support/second-cns-storageclass.yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1beta1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: cns-silver</span><br><span class="line">provisioner: kubernetes.io/glusterfs</span><br><span class="line">parameters:</span><br><span class="line">  resturl: &quot;http://heketi-container-native-storage.apps.580763383722.aws.testdrive.openshift.com&quot;</span><br><span class="line">  restauthenabled: &quot;true&quot;</span><br><span class="line">  restuser: &quot;admin&quot;</span><br><span class="line">  volumetype: &quot;replicate:3&quot;</span><br><span class="line">  clusterid: &quot;INSERT-CLUSTER-ID-HERE&quot;</span><br><span class="line">  secretNamespace: &quot;default&quot;</span><br><span class="line">  secretName: &quot;cns-secret&quot;</span><br></pre></td></tr></table></figure><h3 id="添加已有节点的盘"><a href="#添加已有节点的盘" class="headerlink" title="添加已有节点的盘"></a>添加已有节点的盘</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 获取NODEID</span><br><span class="line">heketi-cli node list | grep ca777ae0285ef6d8cd7237c862bd591c（CLUSTERID）</span><br><span class="line"></span><br><span class="line">heketi-cli device add --name=/dev/xvde --node=33e0045354db4be29b18728cbe817605(NODEID)</span><br></pre></td></tr></table></figure><h3 id="移除有问题的盘"><a href="#移除有问题的盘" class="headerlink" title="移除有问题的盘"></a>移除有问题的盘</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli node info 33e0045354db4be29b18728cbe817605（NODEID）</span><br></pre></td></tr></table></figure><p>以上的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Node Id: 33e0045354db4be29b18728cbe817605</span><br><span class="line">State: online</span><br><span class="line">Cluster Id: ca777ae0285ef6d8cd7237c862bd591c</span><br><span class="line">Zone: 1</span><br><span class="line">Management Hostname: node04.internal.aws.testdrive.openshift.com</span><br><span class="line">Storage Hostname: 10.0.1.23</span><br><span class="line">Devices:</span><br><span class="line">Id:01c94798bf6b1af87974573b420c4dff   Name:/dev/xvdd           State:online    Size (GiB):9       Used (GiB):1       Free (GiB):8</span><br><span class="line">Id:da91a2f1c9f62d9916831de18cc09952   Name:/dev/xvde           State:online    Size (GiB):9       Used (GiB):1       Free (GiB):8</span><br></pre></td></tr></table></figure><p>移除盘</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heketi-cli device disable 01c94798bf6b1af87974573b420c4dff</span><br></pre></td></tr></table></figure><h2 id="6-给Registry组件添加Volume"><a href="#6-给Registry组件添加Volume" class="headerlink" title="6.给Registry组件添加Volume"></a>6.给Registry组件添加Volume</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc volume dc/docker-registry --add --name=registry-storage -t pvc \</span><br><span class="line">--claim-mode=ReadWriteMany --claim-size=5Gi \</span><br><span class="line">--claim-name=registry-storage --overwrite</span><br></pre></td></tr></table></figure><h2 id="7-更改dc的镜像"><a href="#7-更改dc的镜像" class="headerlink" title="7.更改dc的镜像"></a>7.更改dc的镜像</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc patch dc nginx -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;template&quot;:&#123;&quot;spec&quot;:&#123;&quot;containers&quot;:[&#123;&quot;name&quot;:&quot;nginx&quot;,&quot;image&quot;:&quot;harbor.apps.example.com/public/nginx:1.14&quot;&#125;]&#125;&#125;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure><h2 id="8-给A项目授予拉取B项目IS的权限"><a href="#8-给A项目授予拉取B项目IS的权限" class="headerlink" title="8.给A项目授予拉取B项目IS的权限"></a>8.给A项目授予拉取B项目IS的权限</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc policy add-role-to-user system:image-puller system:serviceaccount:A:default -n B</span><br></pre></td></tr></table></figure><h2 id="9-给Jenkins授予管理A项目资源的权限"><a href="#9-给Jenkins授予管理A项目资源的权限" class="headerlink" title="9.给Jenkins授予管理A项目资源的权限"></a>9.给Jenkins授予管理A项目资源的权限</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc policy add-role-to-user edit system:serviceaccount:jenkins:jenkins -n A</span><br></pre></td></tr></table></figure><h2 id="10-手动维护etcd"><a href="#10-手动维护etcd" class="headerlink" title="10.手动维护etcd"></a>10.手动维护etcd</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.com:2379,https://master2.os10.openshift.com:2379,https://master3.os10.openshift.com:2379 endpoint health</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.com:2379,https://master2.os10.openshift.com:2379,https://master3.os10.openshift.com:2379 get / --prefix --keys-only</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.com:2379,https://master2.os10.openshift.com:2379,https://master3.os10.openshift.com:2379 del /kubernetes.io/pods/bookinfo/nginx-4-bkdb4</span><br></pre></td></tr></table></figure><h2 id="11-执行镜像对应的任务"><a href="#11-执行镜像对应的任务" class="headerlink" title="11.执行镜像对应的任务"></a>11.执行镜像对应的任务</h2><p>–restart&#x3D;Always 默认值，创建一个deploymentconfig<br>–restart&#x3D;OnFailure 创建一个Job（但是实践证实为一个Pod）<br>–restart&#x3D;OnFailure –schedule&#x3D;”0&#x2F;5 * * * *” 创建一个Cron Job<br>–restart&#x3D;Never 创建一个单独的Pod</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc run nginx -it --rm  --image=nginx --restart=OnFailure  ls</span><br><span class="line">oc run nginx -it --rm  --image=nginx --restart=OnFailure  bash</span><br></pre></td></tr></table></figure><h2 id="12-清理主机容器"><a href="#12-清理主机容器" class="headerlink" title="12.清理主机容器"></a>12.清理主机容器</h2><p>当容器存储docker-storage的storage-driver引擎使用devicemapper时会出现如下错误：<code>devmapper: Thin Pool has 162394 free data blocks which is less than minimum required 163840 free data blocks. Create more free space in thin pool or use dm.min_free_space option to change behavior</code>。这个时候需要清理下容器主机的存储。<br>具体操作如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 清理exited进程：</span><br><span class="line">exited_containers=$(docker ps -q -f status=exited); if [ &quot;$exited_containers&quot; != &quot;&quot; ]; then docker rm $exited_containers; fi</span><br><span class="line"># 清理dangling volumes：</span><br><span class="line">dangling_volumes=$(docker volume ls -qf dangling=true); if [ &quot;$dangling_volumes&quot; != &quot;&quot; ]; then docker volume rm $dangling_volumes; fi</span><br><span class="line"># 清理dangling image：</span><br><span class="line">dangling_images=$(docker images --filter &quot;dangling=true&quot; -q --no-trunc); if [ &quot;$dangling_images&quot; != &quot;&quot; ]; then docker rmi $dangling_images; fi</span><br></pre></td></tr></table></figure><p>参考文档 <a href="http://www.cnblogs.com/mhc-fly/p/9324425.html">http://www.cnblogs.com/mhc-fly/p/9324425.html</a><br>还可在不同在子命令下执行 prune，这样删除的就是某类资源：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker container prune -f <span class="comment"># 删除所有退出状态的容器</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker volume prune -f <span class="comment"># 删除未被使用的数据卷</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker image prune -f <span class="comment"># 删除 dangling 或所有未被使用的镜像</span></span></span><br></pre></td></tr></table></figure><h2 id="13-Node节点内存与CPU预留"><a href="#13-Node节点内存与CPU预留" class="headerlink" title="13.Node节点内存与CPU预留"></a>13.Node节点内存与CPU预留</h2><p><code>/etc/origin/node/node-config.yaml</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeletArguments:</span><br><span class="line">  system-reserved:</span><br><span class="line">  - cpu=200m</span><br><span class="line">  - memory=1G</span><br><span class="line">  kube-reserved:</span><br><span class="line">  - cpu=200m</span><br><span class="line">  - memory=1G</span><br></pre></td></tr></table></figure><h2 id="14-用oc-get只查看dc的镜像名"><a href="#14-用oc-get只查看dc的镜像名" class="headerlink" title="14.用oc get只查看dc的镜像名"></a>14.用oc get只查看dc的镜像名</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@maser]$ oc get dc test-app --template=&#123;&#123;range.spec.template.spec.containers&#125;&#125;&#123;&#123;.image&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line">registry.example.com/test/test-app:1.13</span><br></pre></td></tr></table></figure><p>获取第一个dc的第一个容器的镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@maser]$ </span><span class="language-bash">oc get dc --template=<span class="string">&#x27;&#123;&#123;with $dc:=(index .items 0)&#125;&#125;&#123;&#123;with $container:=(index $dc.spec.template.spec.containers 0)&#125;&#125;&#123;&#123;$container.image&#125;&#125;&#123;&#123;&quot;\n&quot;&#125;&#125;&#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><p>或者使用–jsonpath</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">[root@maser]$ </span><span class="language-bash">oc get dc -o jsonpath=<span class="string">&#x27;&#123;range.items[*]&#125;&#123;range .spec.template.spec.containers[*]&#125;&#123;.image&#125;&#123;&quot;\n&quot;&#125;&#123;end&#125;&#123;end&#125;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">[root@maser]$ </span><span class="language-bash">oc get dc -o jsonpath=<span class="string">&#x27;&#123;.items[0].spec.template.spec.containers[0].image&#125;&#123;&quot;\n&quot;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><h2 id="15-Openshift-Webconsole支持私有镜像仓库"><a href="#15-Openshift-Webconsole支持私有镜像仓库" class="headerlink" title="15.Openshift Webconsole支持私有镜像仓库"></a>15.Openshift Webconsole支持私有镜像仓库</h2><ul><li>创建私有镜像仓库的证书<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@registry ~]# mkdir /etc/crts/ &amp;&amp; cd /etc/crts</span><br><span class="line">[root@registry ~]# openssl req \</span><br><span class="line">   -newkey rsa:2048 -nodes -keyout example.com.key \</span><br><span class="line">   -x509 -days 365 -out example.com.crt -subj \</span><br><span class="line">   &quot;/C=CN/ST=GD/L=SZ/O=Global Security/OU=IT Department/CN=*.example.com&quot;</span><br></pre></td></tr></table></figure></li><li>将私有镜像仓库的CA文件拷贝到镜像仓库所在服务器的<code>/etc/pki/ca-trust/source/anchors/</code>目录下</li><li>在镜像仓库中配置tls，如果是docker-distribution <code>/etc/docker-distribution/registry/config.yml</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http:</span><br><span class="line">   addr: :443</span><br><span class="line">   tls:</span><br><span class="line">       certificate: /etc/crts/example.com.crt</span><br><span class="line">       key: /etc/crts/example.com.key</span><br></pre></td></tr></table></figure></li><li>重启docker-distribution<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@registry ~]# systemctl daemon-reload &amp;&amp; systemctl restart docker-distribution &amp;&amp; systemctl enable docker-distribution</span><br></pre></td></tr></table></figure></li><li>在镜像仓库所在服务器上执行<code>update-ca-trust extract</code></li><li>将私有镜像仓库的CA文件拷贝到每台Openshift节点的<code>/etc/pki/ca-trust/source/anchors/</code>目录下</li><li>每台Openshift节点上执行<code>update-ca-trust extract</code></li></ul><h2 id="16-Docker支持私有镜像仓库tls认证"><a href="#16-Docker支持私有镜像仓库tls认证" class="headerlink" title="16.Docker支持私有镜像仓库tls认证"></a>16.Docker支持私有镜像仓库tls认证</h2><p>&#x2F;etc&#x2F;docker&#x2F;certs.d目录下创建对应的域名目录，如私有镜像仓库的域名为:example.harbor.com</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /etc/docker/certs.d/example.harbor.com</span><br></pre></td></tr></table></figure><p>将私有镜像仓库的CA文件拷贝到该目录下即可。</p><h2 id="17-查看etcd数据"><a href="#17-查看etcd数据" class="headerlink" title="17.查看etcd数据"></a>17.查看etcd数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">etcdctl --cert-file=/etc/origin/master/master.etcd-client.crt --key-file /etc/origin/master/master.etcd-client.key --ca-file /etc/origin/master/master.etcd-ca.crt --endpoints=&quot;https://master1.os10.openshift.example.com:2379,https://master2.os10.openshift.example.com:2379,https://master3.os10.openshift.example.com:2379&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.example.com:2379,https://master2.os10.openshift.example.com:2379,https://master3.os10.openshift.example.com:2379 endpoint health</span><br><span class="line"></span><br><span class="line">ETCDCTL_API=3 etcdctl --cacert=/etc/origin/master/master.etcd-ca.crt --cert=/etc/origin/master/master.etcd-client.crt --key=/etc/origin/master/master.etcd-client.key --endpoints=https://master1.os10.openshift.example.com:2379,https://master2.os10.openshift.example.com:2379,https://master3.os10.openshift.example.com:2379 get / --prefix --keys-only</span><br></pre></td></tr></table></figure><h2 id="计算某个项目project下所有pod的limits-cpu-x2F-memory的总和"><a href="#计算某个项目project下所有pod的limits-cpu-x2F-memory的总和" class="headerlink" title="计算某个项目project下所有pod的limits cpu&#x2F;memory的总和"></a>计算某个项目project下所有pod的limits cpu&#x2F;memory的总和</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 计算pod总的limits cpu的总和</span><br><span class="line">data=$(pods=`oc get pod|awk &#x27;&#123;print $1&#125;&#x27;|grep -v NAME`; for pod in $pods; do oc get pod $pod --template=&#123;&#123;range.spec.containers&#125;&#125;&#123;&#123;.resources.limits.cpu&#125;&#125;&#123;&#123;println&#125;&#125;&#123;&#123;end&#125;&#125;; done); i=0; for j in $(echo $data); do i=$(($i+$j)); done ; echo $i;</span><br><span class="line">## 18.计算pod总的limits memory的总和</span><br><span class="line">data=$(pods=`oc get pod|awk &#x27;&#123;print $1&#125;&#x27;|grep -v NAME`; for pod in $pods; do oc get pod $pod --template=&#123;&#123;range.spec.containers&#125;&#125;&#123;&#123;.resources.limits.memory&#125;&#125;&#123;&#123;println&#125;&#125;&#123;&#123;end&#125;&#125;; done);i=0; for j in $(echo $data); do mj=$(echo $j|cut -dG -f1); i=$(($i+$mj)); done; echo $i;</span><br></pre></td></tr></table></figure><h2 id="19-DNSMasq启动失败报错“DBus-error-Connection-“-1-180”-is-not-allowed-to-own-the-service-“uk-org-thekelleys-dnsmasq”-”"><a href="#19-DNSMasq启动失败报错“DBus-error-Connection-“-1-180”-is-not-allowed-to-own-the-service-“uk-org-thekelleys-dnsmasq”-”" class="headerlink" title="19.DNSMasq启动失败报错“DBus error: Connection “:1.180” is not allowed to own the service “uk.org.thekelleys.dnsmasq” ”"></a>19.DNSMasq启动失败报错“DBus error: Connection “:1.180” is not allowed to own the service “uk.org.thekelleys.dnsmasq” ”</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/dbus-1/system.d/dnsmasq.conf</span><br><span class="line">&lt;!DOCTYPE busconfig PUBLIC</span><br><span class="line"> &quot;-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN&quot;</span><br><span class="line"> &quot;http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd&quot;&gt;</span><br><span class="line">&lt;busconfig&gt;</span><br><span class="line">&lt;policy user=&quot;root&quot;&gt;</span><br><span class="line">&lt;allow own=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">&lt;allow send_destination=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">&lt;/policy&gt;</span><br><span class="line">&lt;policy context=&quot;default&quot;&gt;</span><br><span class="line">                &lt;allow own=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">                &lt;allow send_destination=&quot;uk.org.thekelleys.dnsmasq&quot;/&gt;</span><br><span class="line">        &lt;/policy&gt;</span><br><span class="line">&lt;/busconfig&gt;</span><br><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl restart dbus</span><br><span class="line">$ systemctl restart dnsmasq</span><br></pre></td></tr></table></figure><h2 id="20-ssh特别慢，卡在debug1-pledge-network位置"><a href="#20-ssh特别慢，卡在debug1-pledge-network位置" class="headerlink" title="20.ssh特别慢，卡在debug1: pledge: network位置"></a>20.ssh特别慢，卡在<code>debug1: pledge: network</code>位置</h2><p>重启下systemd-logind</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart systemd-logind</span></span><br></pre></td></tr></table></figure><p>如果是卡在Authentication上，可以把ssh client端的StrictHostKeyChecking设置为no</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/ssh/ssh_config</span></span><br><span class="line">Host *</span><br><span class="line">          GSSAPIAuthentication no</span><br><span class="line">          StrictHostKeyChecking no</span><br></pre></td></tr></table></figure><h2 id="21-清理私有镜像仓库"><a href="#21-清理私有镜像仓库" class="headerlink" title="21.清理私有镜像仓库"></a>21.清理私有镜像仓库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /usr/bin/cleanregistry.sh &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">!/bin/bash</span></span></span><br><span class="line">oc login -u admin -p password</span><br><span class="line">oc adm prune builds --orphans --keep-complete=25 --keep-failed=5 --keep-younger-than=60m --confirm</span><br><span class="line">oc adm prune deployments --orphans --keep-complete=25 --keep-failed=10 --keep-younger-than=60m --confirm</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">oc rollout latest docker-registry -n default</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">sleep 20</span></span></span><br><span class="line">oc adm prune images --keep-younger-than=400m --confirm</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">crontab -l</span></span></span><br><span class="line">0 0 * * * /usr/bin/cleanregistry.sh &gt;&gt; /var/log/cleanregistry.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h2 id="22-docker-run覆盖entrypoint"><a href="#22-docker-run覆盖entrypoint" class="headerlink" title="22.docker run覆盖entrypoint"></a>22.docker run覆盖entrypoint</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --entrypoint=<span class="string">&quot;/bin/bash&quot;</span> --<span class="built_in">rm</span> -it xhuaustc/nginx-openshift-router:1.15</span></span><br></pre></td></tr></table></figure><h2 id="23-oc-image-mirror同步镜像"><a href="#23-oc-image-mirror同步镜像" class="headerlink" title="23.oc image mirror同步镜像"></a>23.oc image mirror同步镜像</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc image mirror myregistry.com/myimage:latest docker.io/myrepository/myimage:stable --insecure=<span class="literal">true</span></span></span><br></pre></td></tr></table></figure><h2 id="24-开通端口防火墙"><a href="#24-开通端口防火墙" class="headerlink" title="24.开通端口防火墙"></a>24.开通端口防火墙</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vi /etc/sysconfig/iptables</span></span><br><span class="line">-A OS_FIREWALL_ALLOW -p tcp -m state --state NEW -m tcp  --dport 9100 -j ACCEPT</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemctl restart iptables</span></span><br></pre></td></tr></table></figure><h2 id="25-查看crt证书有效时间"><a href="#25-查看crt证书有效时间" class="headerlink" title="25.查看crt证书有效时间"></a>25.查看crt证书有效时间</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -noout -text -<span class="keyword">in</span> ca.crt | grep Validity -A2</span></span><br><span class="line">    Validity</span><br><span class="line">        not Before: Sep 7 08:48.13 2018 GMT</span><br><span class="line">        not After: Sep 6 08:48.14 2020 GMT</span><br></pre></td></tr></table></figure><h2 id="26-将主机设为不可调度"><a href="#26-将主机设为不可调度" class="headerlink" title="26.将主机设为不可调度"></a>26.将主机设为不可调度</h2><p>方法一：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm cordon <span class="variable">$nodename</span></span></span><br></pre></td></tr></table></figure><p>方法二：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm manage-node --schedulable=<span class="literal">false</span> <span class="variable">$nodename</span></span></span><br></pre></td></tr></table></figure><h2 id="27-驱逐主机上的POD"><a href="#27-驱逐主机上的POD" class="headerlink" title="27.驱逐主机上的POD"></a>27.驱逐主机上的POD</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm manage-node --evacuate <span class="variable">$nodename</span></span></span><br></pre></td></tr></table></figure><h2 id="28-Service的域名"><a href="#28-Service的域名" class="headerlink" title="28.Service的域名"></a>28.Service的域名</h2><p>正常情况下<br>Service的域名格式为：<code>service-name.project-name.svc.cluster.local</code><br>对应的IP是Service Cluster IP<br>设置Service的clusterIP&#x3D;None，同时该Pod需要添加subdomain字段，如果是statefulset资源需要添加serviceName字段。<br>Service的域名格式为：<code>service-name.project-name.svc.cluster.local</code><br>对应的IP是后台对应的Pod的容器的IP<br>同时后台对应的Pod都有DNS记录，格式为<code>pod-name.service-name.project-name.svc.cluster.local</code></p><h2 id="29-查看Docker镜像的构建历史命令"><a href="#29-查看Docker镜像的构建历史命令" class="headerlink" title="29.查看Docker镜像的构建历史命令"></a>29.查看Docker镜像的构建历史命令</h2><p><code>docker history $&#123;镜像名/ID&#125; -H --no-trunc | awk -F&quot;[ ]&#123;3,&#125;&quot; &#39;&#123;print $3&#125;&#39; | sed -n -e  &quot;s#/bin/sh -c##g&quot; -e &quot;s/#(nop)  //g&quot; -e  &#39;2,$p&#39; | sed  &#39;1!G;h;$!d&#39;</code></p><p>例如查看镜像mysql:5.6.41的构建命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ docker history mysql:5.6.41 -H --no-trunc | awk -F&quot;[ ]&#123;3,&#125;&quot; &#x27;&#123;$1=&quot;&quot;;$2=&quot;&quot;;$(NF-1)=&quot;&quot;;print $0&#125;&#x27; | sed -n -e  &quot;s#/bin/sh -c##g&quot; -e &quot;s/#(nop)  //g&quot; -e  &#x27;2,$p&#x27; | sed  &#x27;1!G;h;$!d&#x27;</span><br><span class="line">   #(nop) ADD file:f8f26d117bc4a9289b7cd7447ca36e1a70b11701c63d949ef35ff9c16e190e50 in /</span><br><span class="line">   CMD [&quot;bash&quot;]</span><br><span class="line">   groupadd -r mysql &amp;&amp; useradd -r -g mysql mysql</span><br><span class="line">   apt-get update &amp;&amp; apt-get install -y --no-install-recommends gnupg dirmngr &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">   ENV GOSU_VERSION=1.7</span><br><span class="line">   set -x  &amp;&amp; apt-get update &amp;&amp; apt-get install -y --no-install-recommends ca-certificates wget &amp;&amp; rm -rf /var/lib/apt/lists/*  &amp;&amp; wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture)&quot;  &amp;&amp; wget -O /usr/local/bin/gosu.asc &quot;https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$(dpkg --print-architecture).asc&quot;  &amp;&amp; export GNUPGHOME=&quot;$(mktemp -d)&quot;  &amp;&amp; gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4  &amp;&amp; gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu  &amp;&amp; gpgconf --kill all  &amp;&amp; rm -rf &quot;$GNUPGHOME&quot; /usr/local/bin/gosu.asc  &amp;&amp; chmod +x /usr/local/bin/gosu  &amp;&amp; gosu nobody true  &amp;&amp; apt-get purge -y --auto-remove ca-certificates wget</span><br><span class="line">   mkdir /docker-entrypoint-initdb.d</span><br><span class="line">   apt-get update &amp;&amp; apt-get install -y --no-install-recommends pwgen perl  &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line">   set -ex;  key=&#x27;A4A9406876FCBD3C456770C88C718D3B5072E1F5&#x27;;  export GNUPGHOME=&quot;$(mktemp -d)&quot;;  gpg --keyserver ha.pool.sks-keyservers.net --recv-keys &quot;$key&quot;;  gpg --export &quot;$key&quot; &gt; /etc/apt/trusted.gpg.d/mysql.gpg;  gpgconf --kill all;  rm -rf &quot;$GNUPGHOME&quot;;  apt-key list &gt; /dev/null</span><br><span class="line">   ENV MYSQL_MAJOR=5.6</span><br><span class="line">   ENV MYSQL_VERSION=5.6.41-1debian9</span><br><span class="line">   echo &quot;deb http://repo.mysql.com/apt/debian/ stretch mysql-$&#123;MYSQL_MAJOR&#125;&quot; &gt; /etc/apt/sources.list.d/mysql.list</span><br><span class="line">   &#123; echo mysql-community-server mysql-community-server/data-dir select &#x27;&#x27;; echo mysql-community-server mysql-community-server/root-pass password &#x27;&#x27;; echo mysql-community-server mysql-community-server/re-root-pass password &#x27;&#x27;; echo mysql-community-server mysql-community-server/remove-test-db select false;  &#125; | debconf-set-selections  &amp;&amp; apt-get update &amp;&amp; apt-get install -y mysql-server=&quot;$&#123;MYSQL_VERSION&#125;&quot; &amp;&amp; rm -rf /var/lib/apt/lists/*  &amp;&amp; rm -rf /var/lib/mysql &amp;&amp; mkdir -p /var/lib/mysql /var/run/mysqld  &amp;&amp; chown -R mysql:mysql /var/lib/mysql /var/run/mysqld  &amp;&amp; chmod 777 /var/run/mysqld  &amp;&amp; find /etc/mysql/ -name &#x27;*.cnf&#x27; -print0 | xargs -0 grep -lZE &#x27;^(bind-address|log)&#x27; | xargs -rt -0 sed -Ei &#x27;s/^(bind-address|log)/#&amp;/&#x27;  &amp;&amp; echo &#x27;[mysqld]\nskip-host-cache\nskip-name-resolve&#x27; &gt; /etc/mysql/conf.d/docker.cnf</span><br><span class="line">   VOLUME [/var/lib/mysql]</span><br><span class="line">   #(nop) COPY file:b79e447a4154d7150da6897e9bfdeac5eef0ebd39bb505803fdb0315c929d983 in /usr/local/bin/</span><br><span class="line">   ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compat</span><br><span class="line">   ENTRYPOINT [&quot;docker-entrypoint.sh&quot;]</span><br><span class="line">   EXPOSE 3306/tcp</span><br><span class="line">   CMD [&quot;mysqld&quot;]</span><br></pre></td></tr></table></figure><h2 id="30-应用在完成Build后推送到内部镜像仓库如下报错误"><a href="#30-应用在完成Build后推送到内部镜像仓库如下报错误" class="headerlink" title="30.应用在完成Build后推送到内部镜像仓库如下报错误"></a>30.应用在完成Build后推送到内部镜像仓库如下报错误</h2><p><code> Pushing image docker-registry.default.svc:5000/apb/my-test-apb:latest ...</code><br><code>Pushed 0/15 layers, 0% complete</code><br><code>Registry server Address:</code><br><code>Registry server User Name: serviceaccount</code><br><code>Registry server Email: serviceaccount@example.org</code><br><code>Registry server Password: &lt;&lt;non-empty&gt;&gt;</code><br><code>error: build error: Failed to push image: unauthorized: unable to validate token</code></p><p>此时很大可能是因为一些变更，导致镜像仓库的Token有变化，但是镜像仓库未重启，重启镜像仓库即可恢复。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ oc get pod -n default | grep docker-registry</span><br><span class="line">docker-registry-1-8tjhk                   1/1       Running            0          4m</span><br><span class="line">$ oc delete pod `oc get pod -n default | grep docker-registry | awk &#x27;&#123;print $1&#125;&#x27;`</span><br></pre></td></tr></table></figure><h2 id="31-为容器用户指定用户名"><a href="#31-为容器用户指定用户名" class="headerlink" title="31.为容器用户指定用户名"></a>31.为容器用户指定用户名</h2><ol><li>在镜像构建中将文件&#x2F;etc&#x2F;passwd设置为容器启动用户可写<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN chmod g=u /etc/passwd</span><br></pre></td></tr></table></figure></li><li>容器启动时设置用户名<br>ENTRYPOINT&#x2F;CMD 脚本中添加设置用户名代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">USER_NAME=$&#123;USER_NAME:-ocpuid&#125;</span><br><span class="line">USER_ID=$(id -u)</span><br><span class="line">if ! whoami &amp;&gt; /dev/null; then</span><br><span class="line">  if [ -w /etc/passwd ]; then</span><br><span class="line">    echo &quot;$&#123;USER_NAME&#125;:x:$&#123;USER_ID&#125;:0:$&#123;USER_NAME&#125; user:$&#123;HOME&#125;:/sbin/nologin&quot; &gt;&gt; /etc/passwd</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line">exec &quot;$@&quot;</span><br></pre></td></tr></table></figure></li></ol><h2 id="32-升级Docker"><a href="#32-升级Docker" class="headerlink" title="32.升级Docker"></a>32.升级Docker</h2><p>升级不同OpenShift组件的思路是一样，主要是如下两条。</p><ul><li>逐个节点升级</li><li>升级前将业务应用迁走</li></ul><ol><li>更新yum源中的docker包<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp docker-rpm/* ./extras/Packages/d/</span><br><span class="line">$ createrepo --update extras</span><br></pre></td></tr></table></figure></li><li>迁移节点上的POD并将它设置为不可调度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm drain &lt;node_name&gt; --force --delete-local-data --ignore-daemonsets</span><br></pre></td></tr></table></figure></li><li>排除不需要升级的软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ atomic-openshift-docker-excluder exclude</span><br><span class="line">$ atomic-openshift-excluder exclude</span><br></pre></td></tr></table></figure></li><li>升级docker<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum clean all</span><br><span class="line">$ yum update docker</span><br></pre></td></tr></table></figure></li><li>重启服务或者重启主机</li></ol><p>Master节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart docker</span><br><span class="line">$ master-restart api</span><br><span class="line">$ master-restart controllers</span><br><span class="line">$ systemctl restart origin-node</span><br></pre></td></tr></table></figure><p>Node节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart docker</span><br><span class="line">$ systemctl restart origin-node</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ reboot</span><br></pre></td></tr></table></figure><ol start="5"><li>将节点设置为可调度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm uncordon &lt;node_name&gt;</span><br></pre></td></tr></table></figure></li></ol><h2 id="33-获取Token并请求OpenShift-ASB服务的例子"><a href="#33-获取Token并请求OpenShift-ASB服务的例子" class="headerlink" title="33.获取Token并请求OpenShift ASB服务的例子"></a>33.获取Token并请求OpenShift ASB服务的例子</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ curl -k -H &quot;Authorization: Bearer `oc serviceaccounts get-token asb-client`&quot; https://$(oc get routes -n openshift-ansible-service-broker --no-headers | awk &#x27;&#123;print $2&#125;&#x27;)/osb/v2/catalog</span><br><span class="line">&#123;</span><br><span class="line">  &quot;paths&quot;: [</span><br><span class="line">    &quot;/ansible-service-broker/&quot;,</span><br><span class="line">    &quot;/apis&quot;,</span><br><span class="line">    &quot;/healthz&quot;,</span><br><span class="line">    &quot;/healthz/ping&quot;,</span><br><span class="line">    &quot;/healthz/poststarthook/generic-apiserver-start-informers&quot;,</span><br><span class="line">    &quot;/metrics&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="34-调用OpenShift-API获取Pod信息"><a href="#34-调用OpenShift-API获取Pod信息" class="headerlink" title="34.调用OpenShift API获取Pod信息"></a>34.调用OpenShift API获取Pod信息</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get --raw /api/v1/namespaces/&lt;namespace-name&gt;/pods/&lt;pod-name&gt; | json_reformat</span><br></pre></td></tr></table></figure><h2 id="35-使用HostPath挂载本地目录"><a href="#35-使用HostPath挂载本地目录" class="headerlink" title="35.使用HostPath挂载本地目录"></a>35.使用HostPath挂载本地目录</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ chcon -Rt svirt_sandbox_file_t /testHostPath</span><br><span class="line">or</span><br><span class="line">$ chcon -R unconfined_u:object_r:svirt_sandbox_file_t:s0 /testHostPath</span><br><span class="line">or</span><br><span class="line">$ semanage fcontext -a -t svirt_sandbox_file_t &#x27;/testHostPath(/.*)?&#x27;</span><br><span class="line">$ restorecon -Rv /testHostPath</span><br><span class="line"># 确认设置 semanage fcontext -l | grep testHostPath</span><br><span class="line"># 确认文件生效 ls -Z /testHostPath</span><br><span class="line"></span><br><span class="line"># 删除 配置: semanage fcontext -d &#x27;/testHostPath(/.*)?&#x27;</span><br></pre></td></tr></table></figure><h2 id="36-将搜索镜像导出到本地文件脚本"><a href="#36-将搜索镜像导出到本地文件脚本" class="headerlink" title="36.将搜索镜像导出到本地文件脚本"></a>36.将搜索镜像导出到本地文件脚本</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker image | grep redis | awk &#x27;&#123;image=$1; gsub(/.*\//, &quot;&quot;, $1); printf(&quot;docker save -o %s.tar %s:%s\n&quot;, $1, image, $2)&#125;&#x27; | xargs -i bash -c &quot;&#123;&#125;&quot;</span><br></pre></td></tr></table></figure><h2 id="37-Docker日志中有错误-container-kill-failed-because-of-container-not-found-or-no-such-process"><a href="#37-Docker日志中有错误-container-kill-failed-because-of-container-not-found-or-no-such-process" class="headerlink" title="37.Docker日志中有错误 container kill failed because of container not found or no such process"></a>37.Docker日志中有错误 <code>container kill failed because of container not found or no such process</code></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 定期检查docker日志</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">journalctl -r -u docker --since <span class="string">&#x27;1 day ago&#x27;</span> --no-pager | grep -i error</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 处理办法重启docker</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart docker</span></span><br></pre></td></tr></table></figure><h2 id="38-查看所有应用重启次数，并且排序"><a href="#38-查看所有应用重启次数，并且排序" class="headerlink" title="38.查看所有应用重启次数，并且排序"></a>38.查看所有应用重启次数，并且排序</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod --sort-by=<span class="string">&#x27;.status.containerStatuses[0].restartCount&#x27;</span> --all-namespace | <span class="built_in">sort</span> -rn -k10</span></span><br></pre></td></tr></table></figure><h2 id="39-docker拉取镜像报错：400-unsupported-docker-v1-repository-request"><a href="#39-docker拉取镜像报错：400-unsupported-docker-v1-repository-request" class="headerlink" title="39.docker拉取镜像报错：400 unsupported docker v1 repository request"></a>39.docker拉取镜像报错：400 unsupported docker v1 repository request</h2><p>docker的配置中添加<code>--disable-legacy-registry</code>配置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/sysconfig/docker</span></span><br><span class="line">...</span><br><span class="line">OPTIONS=&#x27;... --disable-legacy-registry ...&#x27;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>原因：当docker客户端通过v2 API请求镜像库，而镜像不存在，客户端会尝试使用v1 API请求镜像仓库，而镜像仓库不支持v1 API请求，则会返回该错误。</p><h2 id="40-应用日志无法查看，oc-exec也无法进入容器"><a href="#40-应用日志无法查看，oc-exec也无法进入容器" class="headerlink" title="40.应用日志无法查看，oc exec也无法进入容器"></a>40.应用日志无法查看，oc exec也无法进入容器</h2><p>报错<code>Error from server: Get https://master.example.com:8443/containerLogs/namespace/pod-name/console: remote error: tls: internal error</code><br>处理办法，查看csr，并将它们手动授信</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get csr</span><br><span class="line">$ oc get csr -o name | xargs oc adm certificate approve</span><br></pre></td></tr></table></figure><h2 id="41-netmanager工具设置了dns，无法直接通过-x2F-etc-x2F-resolv-conf文件更改"><a href="#41-netmanager工具设置了dns，无法直接通过-x2F-etc-x2F-resolv-conf文件更改" class="headerlink" title="41.netmanager工具设置了dns，无法直接通过&#x2F;etc&#x2F;resolv.conf文件更改"></a>41.netmanager工具设置了dns，无法直接通过&#x2F;etc&#x2F;resolv.conf文件更改</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ nmcli con show # 查看所有的网络连接</span><br><span class="line">$ nmcli con show &lt;net-connect-name&gt; #查看网络连接详情，可查看dns的配置</span><br><span class="line">$ nmcli con mod &lt;net-connect-name&gt; -ipv4.dns &lt;dns-server-ip&gt; #删除指定的dns ip</span><br><span class="line">$ nmcli con mod &lt;net-connect-name&gt; +ipv4.dns &lt;dns-server-ip&gt; #添加指定的dns ip</span><br></pre></td></tr></table></figure><h2 id="42-查看集群当前计算节点资源的分配率"><a href="#42-查看集群当前计算节点资源的分配率" class="headerlink" title="42.查看集群当前计算节点资源的分配率"></a>42.查看集群当前计算节点资源的分配率</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nodes=$(oc get node --selector=node-role.kubernetes.io/compute=<span class="literal">true</span> --no-headers | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>); <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$nodes</span>; <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">$i</span>; oc describe node <span class="variable">$i</span> | grep Resource -A 3 | grep -v <span class="string">&#x27;\-\-\-&#x27;</span>; <span class="keyword">done</span></span></span><br><span class="line">node1</span><br><span class="line">  Resource    Requests          Limits</span><br><span class="line">  cpu         10445m (65%)      25770m (161%)</span><br><span class="line">  memory      22406Mi (34%)     49224Mi (76%)</span><br><span class="line">node2</span><br><span class="line">  Resource    Requests          Limits</span><br><span class="line">  cpu         8294m (51%)   25620m (160%)</span><br><span class="line">  memory      18298Mi (28%)     48600Mi (75%)</span><br></pre></td></tr></table></figure><h2 id="43-安装时master-api服务无法访问etcd"><a href="#43-安装时master-api服务无法访问etcd" class="headerlink" title="43.安装时master api服务无法访问etcd"></a>43.安装时master api服务无法访问etcd</h2><p>master主机绑定多张网卡，在&#x2F;etc&#x2F;ansible&#x2F;hosts中需要指定etcd_ip，如下所示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[etcd]</span><br><span class="line">master.example.com etcd_ip=10.1.2.3</span><br></pre></td></tr></table></figure><p>另外需要确保，etcd所在主机的hostname所指定的ip确切为etcd_ip指定的ip。</p><h2 id="44-安装时master节点有多张网卡，如何指定masterIP"><a href="#44-安装时master节点有多张网卡，如何指定masterIP" class="headerlink" title="44.安装时master节点有多张网卡，如何指定masterIP"></a>44.安装时master节点有多张网卡，如何指定masterIP</h2><p>在master安装时master-config.yml中设置的masterIP为openshift.common.ip，为节点的默认网卡。可以通过编辑<code>roles/openshift_facts/library/openshift_facts.py</code>文件来设置该ip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def get_defaults(self, roles):</span><br><span class="line">    &quot;&quot;&quot; Get default fact values</span><br><span class="line">        Args:</span><br><span class="line">            roles (list): list of roles for this host</span><br><span class="line">        Returns:</span><br><span class="line">            dict: The generated default facts</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    defaults = &#123;&#125;</span><br><span class="line">    ip_addr = self.system_facts[&#x27;ansible_default_ipv4&#x27;][&#x27;address&#x27;]</span><br><span class="line">    exit_code, output, _ = module.run_command([&#x27;hostname&#x27;, &#x27;-f&#x27;])  # noqa: F405</span><br><span class="line">    hostname_f = output.strip() if exit_code == 0 else &#x27;&#x27;</span><br><span class="line">    hostname_values = [hostname_f, self.system_facts[&#x27;ansible_nodename&#x27;],</span><br><span class="line">                       self.system_facts[&#x27;ansible_fqdn&#x27;]]</span><br><span class="line">    hostname = choose_hostname(hostname_values, ip_addr).lower()</span><br><span class="line">    exit_code, output, _ = module.run_command([&#x27;hostname&#x27;])  # noqa: F405</span><br><span class="line">    raw_hostname = output.strip() if exit_code == 0 else hostname</span><br><span class="line"></span><br><span class="line">    defaults[&#x27;common&#x27;] = dict(ip=ip_addr,</span><br><span class="line">                              public_ip=ip_addr,</span><br><span class="line">                              raw_hostname=raw_hostname,</span><br><span class="line">                              hostname=hostname,</span><br><span class="line">                              public_hostname=hostname,</span><br></pre></td></tr></table></figure><p>另外可以通过将目标网卡设置为默认网卡来解决。<br>还有OpenShift通过更新hosts也可以来配置，通过设置openshift_node_groups来设置<code>kubeletArguments.node-ip</code>的值，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;name&#x27;: &#x27;node-config-node1&#x27;, &#x27;labels&#x27;: [&#x27;...,...&#x27;], &#x27;edits&#x27;: [&#123; &#x27;key&#x27;: &#x27;kubeletArguments.node-ip&#x27;,&#x27;value&#x27;: [&#x27;x.x.x.x&#x27;]&#125;]&#125;</span><br></pre></td></tr></table></figure><h2 id="45-部署集群时，采用自定义证书，Master1节点报x509-certificate-signed-by-unknown-authority错误"><a href="#45-部署集群时，采用自定义证书，Master1节点报x509-certificate-signed-by-unknown-authority错误" class="headerlink" title="45.部署集群时，采用自定义证书，Master1节点报x509: certificate signed by unknown authority错误"></a>45.部署集群时，采用自定义证书，Master1节点报x509: certificate signed by unknown authority错误</h2><p>检查ansible inventory hosts文件中自定义证书名是否与openshift默认的组件证书名重复了。如ca.crt等</p><h2 id="46-部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置"><a href="#46-部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置" class="headerlink" title="46.部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置"></a>46.部署时网络错误，需要查看是否配置了默认路由，如果没有，则需要设置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip route</span></span><br><span class="line">10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 102</span><br><span class="line">172.16.10.0/24 dev eth1 proto kernel scope link src 172.16.10.11 metric 101</span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">## 添加默认路由</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip route add default via 172.16.10.1</span></span><br></pre></td></tr></table></figure><h2 id="47-删除指定文件夹下最近一个月的文件"><a href="#47-删除指定文件夹下最近一个月的文件" class="headerlink" title="47. 删除指定文件夹下最近一个月的文件"></a>47. 删除指定文件夹下最近一个月的文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">find /dir -<span class="built_in">type</span> f -mtime +30 -<span class="built_in">exec</span> <span class="built_in">rm</span> -rf &#123;&#125; \;</span></span><br></pre></td></tr></table></figure><h2 id="48-pod报the-node-was-low-on-resource-ephemeral-storage而被驱逐"><a href="#48-pod报the-node-was-low-on-resource-ephemeral-storage而被驱逐" class="headerlink" title="48.pod报the node was low on resource ephemeral-storage而被驱逐"></a>48.pod报<code>the node was low on resource ephemeral-storage</code>而被驱逐</h2><p>pod应用临时存储空间不足导致错误，需要查看本地磁盘，特别是&#x2F;var&#x2F;lib&#x2F;origin所在磁盘的空间情况。</p><h2 id="49-自签证书"><a href="#49-自签证书" class="headerlink" title="49.自签证书"></a>49.自签证书</h2><ol><li>根证书创建<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out ca.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -x509 -days 36500 -key ca.key -out ca.crt -subj <span class="string">&quot;/C=CN/ST=shanxi/L=taiyuan/O=cn/OU=test/CN=example.com&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#或者 openssl req -new -x509 -days 36500 -key ca.key -out ca.crt 手动输入配置</span></span></span><br></pre></td></tr></table></figure></li><li>创建证书并使用根证书签发<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out app.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -key app.key -out app.csr</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -req -<span class="keyword">in</span> app.csr -CA ca.crt -CAkey ca.key -out app.crt -days 3650  -CAcreateserial</span></span><br></pre></td></tr></table></figure></li><li>使用 Openssl 工具查看证书信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -dates</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -subject</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -text</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="50-ETCD某个节点无法重启，报错rafthttp-the-clock-difference-against-peer-27de23fad174dca-is-too-high-1m16-89887s-gt-1s"><a href="#50-ETCD某个节点无法重启，报错rafthttp-the-clock-difference-against-peer-27de23fad174dca-is-too-high-1m16-89887s-gt-1s" class="headerlink" title="50. ETCD某个节点无法重启，报错rafthttp: the clock difference against peer 27de23fad174dca is too high [1m16.89887s &gt; 1s]"></a>50. ETCD某个节点无法重启，报错<code>rafthttp: the clock difference against peer 27de23fad174dca is too high [1m16.89887s &gt; 1s]</code></h2><p>检查ETCD服务器的时间是否同步，如果不同步，强制同步后，ETCD会自动恢复。</p><h2 id="51-查看最近一小时的Event-告警事件"><a href="#51-查看最近一小时的Event-告警事件" class="headerlink" title="51. 查看最近一小时的Event 告警事件"></a>51. 查看最近一小时的Event 告警事件</h2><p>集群默认保留最近1小时的Event事件，通过field-selector过滤掉正常的事件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get event --field-selector=<span class="built_in">type</span>=Warning --all-namespaces</span></span><br></pre></td></tr></table></figure><h2 id="52-获取Alertmanager的告警信息"><a href="#52-获取Alertmanager的告警信息" class="headerlink" title="52. 获取Alertmanager的告警信息"></a>52. 获取Alertmanager的告警信息</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec -it alertmanager-main-0 -c alertmanager -n openshift-monitoring -- amtool alert query &#x27;severity=critical&#x27; --alertmanager.url http://localhost:9093</span><br></pre></td></tr></table></figure><h2 id="53-获取statefulset中的Pod的序号"><a href="#53-获取statefulset中的Pod的序号" class="headerlink" title="53. 获取statefulset中的Pod的序号"></a>53. 获取statefulset中的Pod的序号</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[ $(hostname) =~ -([0-9]+)$ ]]  || exit</span><br><span class="line">ordinal=$&#123;BASH_REMATCH[1]&#125;</span><br></pre></td></tr></table></figure><p>其中<code>ordinal</code>即为statefulset中的序号，一般可用在initContainers中对Pod进行初始化配置设置，具体生产实践中可灵活使用。</p><h2 id="54-清理镜像仓库中的镜像"><a href="#54-清理镜像仓库中的镜像" class="headerlink" title="54. 清理镜像仓库中的镜像"></a>54. 清理镜像仓库中的镜像</h2><p><code>镜像仓库必须开启可删除功能</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -k -I -H <span class="string">&quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot;</span> -I http://localhost:5000/v2/openshift/ocp-router/manifests/v3.11.129</span></span><br><span class="line">获取镜像层的sha256值</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -X DELETE http://localhost:5000/v2/openshift/ocp-router/manifests/sha256:39ad17c3e10f902d8b098ee5128a87d4293b6d07cbc2d1e52ed9ddf0076e3cf9</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="comment">#登录到镜像仓库</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">registry garbage-collect /etc/docker-distribution/registry/config.yml</span></span><br></pre></td></tr></table></figure><h2 id="55-AIX部署NFS服务，应用POD无法挂载mount-nfs-Remote-I-O-error"><a href="#55-AIX部署NFS服务，应用POD无法挂载mount-nfs-Remote-I-O-error" class="headerlink" title="55. AIX部署NFS服务，应用POD无法挂载mount.nfs: Remote I/O error."></a>55. AIX部署NFS服务，应用POD无法挂载<code>mount.nfs: Remote I/O error.</code></h2><p>默认情况下，NFS客户端通过NFSv4协议访问NFS服务，如果AIX部署NFS时不支持NFSv4协议，则在挂载时会报<code>mount.nfs: Remote I/O error.</code>的错误。可通过<code>nfsstat -s</code>查看服务端支持的NFS版本。<br>有两种解决方法：</p><ol><li>重新配置NFS Server，让其支持NFSv4；</li><li>配置PV，强制使用NFSv3来访问后端NFS服务。<br>参考配置如下：spec.mountOptions<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0003</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  mountOptions:</span><br><span class="line">    - hard</span><br><span class="line">    - nfsvers=3</span><br><span class="line">  nfs:</span><br><span class="line">    path: /tmp</span><br><span class="line">    server: 172.17.0.2</span><br></pre></td></tr></table></figure>另外也可以通过添加<code>annotations.volume.beta.kubernetes.io/mount-options</code>来设置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc patch pv pv0003 -p &#x27;&#123;&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&quot;volume.beta.kubernetes.io/mount-options&quot;:&quot;rw,nfsvers=3&quot;&#125;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure>参考文章：<a href="https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/">https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/</a></li></ol><h2 id="56-将POD从副本控制器中脱离"><a href="#56-将POD从副本控制器中脱离" class="headerlink" title="56. 将POD从副本控制器中脱离"></a>56. 将POD从副本控制器中脱离</h2><p>在应用运行过程中，某些场景下，需要将某个POD从业务流量中脱离。例如在问题排查时，一旦应用重启，将不易于具体线上问题的排查，这时我们需要在尽快恢复应用的情况下，保留问题POD的状态。<br>方法很简单，就是利用Label。我们知道在K8S&#x2F;OCP中，各种资源的关系都是通过Label来建立的，只需要将POD的Label去掉，让它就会成为一个孤立的POD，应用的迭代不会对POD的生命周期有影响，同时业务流量也不会分发到该POD。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc label pod xxx-pod --list //查看当前pod所有label</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc label pod xxx-pod &lt;LABEL-A&gt;-  &lt;LABEL-B&gt;- //删除关联的LABEL</span></span><br></pre></td></tr></table></figure><h2 id="57-Node状态变为NotReady，且检查状态为Unknown"><a href="#57-Node状态变为NotReady，且检查状态为Unknown" class="headerlink" title="57. Node状态变为NotReady，且检查状态为Unknown."></a>57. Node状态变为NotReady，且检查状态为Unknown.</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/85163586fd84e228718d24e7b9207a672004f64164519854aa8d435a203594ad.png" alt="Status">  </p><p>可检查下CSR，是否存在Pending</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get csr</span><br></pre></td></tr></table></figure><p>批准这些CSR即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ oc get csr -o name | xargs oc adm certificate approve</span><br><span class="line">或</span><br><span class="line">$ kubectl get csr -o name | xargs kubectl certificate approve</span><br></pre></td></tr></table></figure><h2 id="58-No-space-left-on-device，但df-h查看空间空空的"><a href="#58-No-space-left-on-device，但df-h查看空间空空的" class="headerlink" title="58. No space left on device，但df -h查看空间空空的"></a>58. No space left on device，但<code>df -h</code>查看空间空空的</h2><p>还需要检查一下inodes </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">df</span> -ih</span></span><br><span class="line">Filesystem     Inodes IUsed IFree IUse% Mounted on</span><br><span class="line">/dev/sdb          16M  502K   16M    4% /</span><br></pre></td></tr></table></figure><p><strong>如果发现IUse% 为100，就没法再存储数据了。</strong><br>解决办法 ： rm -rf 一些小而多的文件，如日志等。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Ansible-Tower与Jenkins集成实现CI-CD</title>
      <link href="/DevOps/%E4%BD%BF%E7%94%A8Ansible-Tower%E4%B8%8EJenkins%E9%9B%86%E6%88%90%E5%AE%9E%E7%8E%B0CI-CD/"/>
      <url>/DevOps/%E4%BD%BF%E7%94%A8Ansible-Tower%E4%B8%8EJenkins%E9%9B%86%E6%88%90%E5%AE%9E%E7%8E%B0CI-CD/</url>
      
        <content type="html"><![CDATA[<h2 id="Ansible-Tower是什么？"><a href="#Ansible-Tower是什么？" class="headerlink" title="Ansible Tower是什么？"></a>Ansible Tower是什么？</h2><p><a href="%5Bhttps://github.com/ansible/awx%5D(https://github.com/ansible/awx)">Ansible Tower</a>是一个基于Web的用户界面，提供了IT自动化的企业解决方案。它有一个友好用户的仪表板来管理部署和监控资源。Ansible Tower为Ansible增加自动化，可视化管理和监控能力。</p><h2 id="为什么要使用Ansible-Tower替换Ansible与Jenkins集成？"><a href="#为什么要使用Ansible-Tower替换Ansible与Jenkins集成？" class="headerlink" title="为什么要使用Ansible Tower替换Ansible与Jenkins集成？"></a>为什么要使用Ansible Tower替换Ansible与Jenkins集成？</h2><p>使用Ansible Tower与Jenkins集成，打开了一个充满可能性的世界。<br>与一篇中介绍的《Ansible与Jenkins集成实现CI&#x2F;CD》进行比较，它可以从Jenkins中删除很多配置，比如部署应用的服务器的访问配置，管理playbook执行，最重要的是，避免在Jenkins端配置SSH密钥，同时Jenkins不需要知道应用程序的部署服务器地址：它可能位于公有云中，物理机中，甚至是笔记本电脑上的虚拟客户端。 把这些配置与过程都放到Ansible Tower中进行集中管理。</p><h2 id="Ansible-Tower的组件"><a href="#Ansible-Tower的组件" class="headerlink" title="Ansible Tower的组件"></a>Ansible Tower的组件</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/417cb66870058dd036ecb4dd3a5f72dc88b36b52abfdda5217a1e56abbc6d983.png" alt="Ansible Tower组件">  </p><ul><li><a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/credentials.html"><strong>Credentials</strong></a>: Ansible Tower在运行作业时，访问Tower外部服务或者连接主机时需要进行身份验证。Credentials则是存储这些身份验证的配置信息。</li><li><a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/projects.html"><strong>Projects</strong></a>: Project是一组Ansible playbooks的集合，它是开始使用Tower的第一个组件。Projects中的playbooks文件可以手动添加在Tower服务器的目录中，但是一般推荐使用Git等代码仓库的方式存放playbooks文件，因为这样更容易对playbooks文件进行更改与管理。</li><li><a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/inventories.html"><strong>Inventories</strong></a>: Inventories是ansible Tower中的Job最终执行操作的主机，它可以通过静态方式添加，也可以使用脚本动态添加，比如访问CMDB服务、调用公有云API。</li><li><a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/job_templates.html"><strong>Job template</strong></a>: Job template是Ansible Job的一个模板，它可以为Job传递不同的参数，认证证书、Inventories配置等。</li><li><a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/jobs.html"><strong>Job</strong></a>: Job是最终执行的任务，可以在Tower上查看Job的执行过程，及日志</li></ul><p><code>说明：当然以上说明只是各组件最简单的功能介绍，其实每个组件的功能都会更加丰富，我们可以自己部署Ansible Tower，并通过具体的使用来熟悉各组件的功能。</code></p><h2 id="怎样集成Ansible-Tower与Jenkins"><a href="#怎样集成Ansible-Tower与Jenkins" class="headerlink" title="怎样集成Ansible Tower与Jenkins?"></a>怎样集成Ansible Tower与Jenkins?</h2><p>前提：部署好了Ansible Tower和Jenkins</p><h3 id="Ansible-Tower上的设置"><a href="#Ansible-Tower上的设置" class="headerlink" title="Ansible Tower上的设置"></a>Ansible Tower上的设置</h3><ul><li>创建用户jenkins给Jenkins调用Ansible Tower <code>Tower</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8b892c12661f022abe2163c7ccf59d16e11c73941fe54182699aaa11be9c1978.png" alt="Ansible Tower创新建用户jenkins">  </p><ul><li>创建Project，使用Git作为SCM Type，并给jenkins用户授权 <code>Tower</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4e18156e9c7ae7a23a9db3b6e0e82b30b5b24d5836b24d9312635721ba3b2deb.png" alt="新建Project">  </p><ul><li><p>创建Inventories <code>Tower</code>，将部署应用的主机信息添加到Hosts，并添加到”app_server” Group <code>Tower</code></p><ul><li>创建Inventory</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c470e81a99d9f2799cc13048b4a9922cfdb8e7c489505e25230bd786fee20496.png" alt="Inventories创建">  </p><ul><li>添加应用服务器主机</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/b4f78e01fd181bab00a7cfb51b0acca534e6a90767c4853226264f00e148e63d.png" alt="添加主机">  </p><ul><li>给Inventory授权给Jenkins用户</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/cf5e23115f72856b3fe5144fac358a22c944cd281f4a869d81a45cb65a03936d.png" alt="对Inventories授权">  </p><ul><li><p>创建访问应用主机的身份认证密钥 <code>Tower</code></p><ul><li>添加新的认证信息，可以是用户名+密码，也可以用户名+私钥</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c4fe4131b0a2fa6e64cfe414fa09928dcbda7b47cae22d166df852d4bc011974.png" alt="应用服务器登录密钥">  </p><ul><li>对认证信息授权给Jenkins用户</li></ul><p>  <img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/748149189d6a6f227bdbe8f1d7f9218afeafdc4396fa94277edcea7135821fa4.png" alt="对认证信息授权给Jenkins用户">  </p><ul><li>创建Job Template <code>Tower</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/51e8119cf18a88a28280d569941771917bf7b7c021fe214e4b00662cb47031ac.png" alt="Job Template">  </p><p><code>补充</code>: </p><ol><li>EXTRA VARIABLES是额外的补充参数。</li><li>大部分参数都有PROMPT ON LAUNCH选项，这个是在Template Job实际运行时，通过用户交互的方式进行配置</li><li>SURVEY的配置有更加友好的方式与用户交互进行配置参数</li></ol><h3 id="Jenkins上的设置"><a href="#Jenkins上的设置" class="headerlink" title="Jenkins上的设置"></a>Jenkins上的设置</h3><ul><li>安装Ansible Tower插件 <code>Jenkins</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8e1981d825e4dbc194171972d99b781a715291cc58e094fde7e65a5da7d8e5ba.png" alt="Jenkins 安装Ansible Tower插件">  </p><ul><li>设置访问Ansible Tower的登录Credentials <code>Jenkins</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/3386c636cec89e54b259e1e1f86b4c0a0bcd1eae08ded20c04967cf96a7e5634.png" alt="添加Ansible Tower用户">  </p><ul><li>在Configure System中设置Ansible Tower信息 <code>Jenkins</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2e8167507be0a1f0915961d03cebd92f2fafe808ead8700a469cf194df3f4580.png" alt="设置Ansible Tower信息">  </p><ul><li>新建Jenkins Job，设置Ansible Tower Job <code>jenkins</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages&#123;</span><br><span class="line">    statge(&quot;构建应用&quot;)&#123;</span><br><span class="line">    echo &#x27;构建应用&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">        statge(&quot;Jar包上传&quot;)&#123;</span><br><span class="line">    echo &#x27;Jar包上传到Nexus,以供Ansible Tower中的playbook下载部署&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(&quot;触发Ansible Tower Job&quot;)&#123;</span><br><span class="line">        ansibleTower credential: &#x27;2&#x27;, </span><br><span class="line">            extraVars: &#x27;&#x27;&#x27;APPNAME: App</span><br><span class="line">ARTIFACT_URL: http://test.com/app/1.0.jar&#x27;&#x27;&#x27;, </span><br><span class="line">            importTowerLogs: false, </span><br><span class="line">            inventory: &#x27;2&#x27;,</span><br><span class="line">            jobTemplate: &#x27;8&#x27;, </span><br><span class="line">            templateType: &#x27;job&#x27;, </span><br><span class="line">            throwExceptionWhenFail: false, </span><br><span class="line">            towerServer: &#x27;ansible tower&#x27;, </span><br><span class="line">            verbose: false</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>通过Jenkins Job的触发就会触发Ansible Tower中id为8的Job Template生成新的Job进行应用部署。</p><p><strong>最后一句话作为总结：<br>Ansible Tower与Jenkins双剑合璧才是运维自动化正确的打开方式。</strong></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="%5Bhttps://www.redhat.com/en/blog/take-ansible-and-jenkins-integration-next-level-cicd-ansible-tower%5D(https://www.redhat.com/en/blog/take-ansible-and-jenkins-integration-next-level-cicd-ansible-tower)">Take Ansible and Jenkins Integration to the next level: CI&#x2F;CD with Ansible Tower</a><br><a href="https://docs.ansible.com/ansible-tower/latest/html/userguide/index.html">Ansible Tower官方文档</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自动化工具集(持续更新------)</title>
      <link href="/DevOps/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E9%9B%86(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0------)/"/>
      <url>/DevOps/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7%E9%9B%86(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0------)/</url>
      
        <content type="html"><![CDATA[<h2 id="1-部署集群"><a href="#1-部署集群" class="headerlink" title="1. 部署集群"></a>1. 部署集群</h2><p><a href="https://github.com/kubernetes/kops">kops</a><br><a href="https://github.com/kubernetes-sigs/kubespray">kubespray</a><br><a href="https://kubeoperator.io/">kubeoperator</a><br><a href="https://kind.sigs.k8s.io/">k(8s) in d(ocker)</a></p><h2 id="2-部署应用"><a href="#2-部署应用" class="headerlink" title="2. 部署应用"></a>2. 部署应用</h2><p><a href="https://kustomize.io/">kustomize</a></p><ul><li>路径名中有<code>/</code>时，使用<code>~1</code>替换<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">kustomization.yaml</span><br><span class="line">---</span><br><span class="line">apiVersion: kustomize.config.k8s.io/v1beta1</span><br><span class="line">kind: Kustomization</span><br><span class="line">...</span><br><span class="line">patchesJson6902:</span><br><span class="line">- target:</span><br><span class="line">    version: v1</span><br><span class="line">    kind: Namespace</span><br><span class="line">    name: argocd</span><br><span class="line">  path: patch-namespace.yaml</span><br><span class="line"></span><br><span class="line">patch-namespace.yaml</span><br><span class="line">---</span><br><span class="line">- op: replace</span><br><span class="line">  path: &quot;/metadata/annotations/iam.amazonaws.com~1allowed-roles&quot;</span><br><span class="line">  value: &gt;</span><br><span class="line">    [&quot;arn:aws:iam::12313112:role/argocd&quot;]</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://github.com/vmware-tanzu/carvel-kapp">kapp</a><br><a href="https://helm.sh/">helm</a><br><a href="https://github.com/roboll/helmfile">helmfile</a><br><a href="https://argo-cd.readthedocs.io/en/stable/">argocd</a></p><h2 id="3-Kubernetes管理工具"><a href="#3-Kubernetes管理工具" class="headerlink" title="3. Kubernetes管理工具"></a>3. Kubernetes管理工具</h2><p><a href="https://github.com/derailed/k9s">k9s</a><br><a href="https://github.com/lensapp/lens">Lens</a>  &#x2F;  <a href="https://k8slens.dev/">Download</a><br><a href="https://github.com/KubeOperator/webkubectl">Web Kubectl</a></p><p>##3. 基础设施即代码<br><a href="https://www.terraform.io/">terraform</a><br><a href="https://github.com/tfutils/tfenv">tfenv</a><br><a href="http://www.ansible.com.cn/">ansible</a><br><a href="https://theforeman.org/">foreman</a><br><a href="https://rackn.com/rebar/">rackn rebar</a></p><h2 id="4-构建管理工具"><a href="#4-构建管理工具" class="headerlink" title="4. 构建管理工具"></a>4. 构建管理工具</h2><p><a href="https://bazel.build/">bazel</a><br>构建 go应用需要使用<code>gazelle</code>工具，来自动生成go包目录下的BUILD.bazel。同时构建前使用<code>go mod init</code>命令初始化包。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bazel run //:gazelle</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bazel build[run] //:sample</span></span><br></pre></td></tr></table></figure><p><a href="https://www.gnu.org/software/make/manual/make.html">make</a></p><h2 id="5-模板文件与解析工具"><a href="#5-模板文件与解析工具" class="headerlink" title="5. 模板文件与解析工具"></a>5. 模板文件与解析工具</h2><p><a href="https://jsonnet.org/">jsonnet</a><br><a href="https://github.com/jsonnet-bundler/jsonnet-bundler">jb</a><br><a href="https://github.com/tmrts/boilr">boilr</a><br><a href="https://github.com/kislyuk/yq">python-yq</a><br><a href="https://github.com/hairyhenderson/gomplate">gomplate</a><br><a href="https://cuelang.org/docs/tutorials/">cue</a></p><h2 id="6-安全加密"><a href="#6-安全加密" class="headerlink" title="6. 安全加密"></a>6. 安全加密</h2><p><a href="https://github.com/mozilla/sops">sops</a><br><a href="https://github.com/FiloSottile/age">age</a>，与Sops结合可对文件进行加密，实现对K8S中的secrets.yaml的保护。<br><a href="https://github.com/viaduct-ai/kustomize-sopsexec-plugin">kustomize-sops</a><br><a href="https://github.com/jtblin/kube2iam">kube2iam</a><br><a href="https://github.com/hashicorp/vault">vault</a><br><a href="https://go-acme.github.io/lego/">lego</a><br><a href="https://github.com/acmesh-official/acme.sh">acme.sh</a><br><a href="https://github.com/bitnami-labs/sealed-secrets">kubeseal</a><br>新版本默认隔一个月生成一个新的公&#x2F;私钥，默认kubeseal客户端会使用最新的公钥进行加密，但是之前的公&#x2F;私钥仍然有效。<br><a href="https://github.com/upmc-enterprises/registry-creds">registry-creds</a><br>管理镜像仓库密钥</p><h2 id="7-应用路由"><a href="#7-应用路由" class="headerlink" title="7. 应用路由"></a>7. 应用路由</h2><p><a href="https://www.getambassador.io/">ambassador</a><br><a href="https://github.com/openshift/router">router</a><br><a href="https://cert-manager.io/docs/">cert-manager</a> :ssl证书管理<br><a href="https://apisix.apache.org/">apisix</a></p><h2 id="8-moke"><a href="#8-moke" class="headerlink" title="8. moke"></a>8. moke</h2><p><a href="https://github.com/golang/mock">moke</a></p><h2 id="9-语言"><a href="#9-语言" class="headerlink" title="9.语言"></a>9.语言</h2><p><a href="https://golang.org/">go</a><br><a href="https://www.python.org/">python</a><br><a href="http://shouce.jb51.net/shell/index.html">shell</a></p><h2 id="10-代码管理"><a href="#10-代码管理" class="headerlink" title="10.代码管理"></a>10.代码管理</h2><p><a href="https://www.gerritcodereview.com/">gerrit</a><br><a href="https://about.gitlab.com/">gitlab</a><br><a href="https://github.com/">github</a><br><a href="https://gitea.io/zh-cn/">gitea</a></p><h2 id="11-持续构建工具"><a href="#11-持续构建工具" class="headerlink" title="11. 持续构建工具"></a>11. 持续构建工具</h2><p><a href="https://www.jenkins.io/">jeinkins</a><br><a href="http://circleci.com/">circleci</a><br><a href="https://github.com/ansible/awx">awx</a>（<a href="https://docs.ansible.com/ansible-tower/3.7.1/html_zh/userguide/index.html">用户指南</a>）</p><h2 id="12-监控"><a href="#12-监控" class="headerlink" title="12.监控"></a>12.监控</h2><p><a href="https://www.influxdata.com/time-series-platform/kapacitor/">kapacitor</a><br><a href="https://prometheus.io/">prometheus</a><br><a href="https://grafana.com/">grafana</a><br><a href="https://github.com/grafana/grafonnet-lib">grafana-lib</a><br><a href="https://github.com/jacksontj/promxy">promxy</a></p><h2 id="13-数据库"><a href="#13-数据库" class="headerlink" title="13. 数据库"></a>13. 数据库</h2><p><a href="https://kubedb.com/">kubedb</a><br><a href="https://vitess.io/zh/docs/">vitess</a><br><a href="https://bitnami.com/">bitnami 应用市场</a><br><a href="https://github.com/presslabs/mysql-operator">mysql-operator</a></p><h2 id="14-日志"><a href="#14-日志" class="headerlink" title="14. 日志"></a>14. 日志</h2><p><a href="https://github.com/grafana/loki">loki</a><br><a href="https://www.elastic.co/">elk</a><br><strong><a href="https://www.graylog.org/">graylog</a></strong></p><h2 id="15-存储"><a href="#15-存储" class="headerlink" title="15. 存储"></a>15. 存储</h2><p><a href="https://longhorn.io/">longhorn</a><br><a href="https://ceph.io/">ceph</a><br><a href="https://rook.io/">rook</a><br><a href="https://min.io/">minio</a></p><h2 id="16-消息渠道"><a href="#16-消息渠道" class="headerlink" title="16. 消息渠道"></a>16. 消息渠道</h2><p><a href="https://slack.com/">slack</a><br><a href="https://mattermost.com/">mattermost</a><br><a href="https://rocket.chat/">Rocket Chat</a></p><h2 id="17-开发人员门户"><a href="#17-开发人员门户" class="headerlink" title="17. 开发人员门户"></a>17. 开发人员门户</h2><p><a href="https://backstage.io/">Backstage</a></p><h2 id="18-镜像仓库"><a href="#18-镜像仓库" class="headerlink" title="18. 镜像仓库"></a>18. 镜像仓库</h2><p><a href="https://goharbor.io/">Harbor</a><br><a href="https://www.sonatype.com/products/repository-pro">Nexus</a></p><h2 id="19-Workflow-工具"><a href="#19-Workflow-工具" class="headerlink" title="19. Workflow 工具"></a>19. Workflow 工具</h2><p><a href="https://argoproj.github.io/argo-workflows/">Argo workflows</a><br><a href="https://airflow.apache.org/">airflow</a></p><h2 id="20-认证"><a href="#20-认证" class="headerlink" title="20. 认证"></a>20. 认证</h2><p><a href="https://azure.microsoft.com/en-us/services/active-directory/">Azure Active Directory</a><br><a href="https://www.keycloak.org/">keycloak</a><br><a href="https://www.openldap.org/">openldap</a><br><a href="https://www.okta.com/">okta</a></p><h2 id="21-办公"><a href="#21-办公" class="headerlink" title="21. 办公"></a>21. 办公</h2><p><a href="https://www.iredmail.org/">邮件iRedMail</a><br><a href="https://jitsi.github.io/handbook/docs/intro">视频会议jitsi</a><br><a href="https://docs.rocket.chat/quick-start/installing-and-updating/docker-containers/docker-compose">聊天工具Rocket Chat</a> 可以与jitsi集成<br><a href="https://nextcloud.com/">云盘Nextcloud</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift压测工作必不可少，使用Jmeter搞起来</title>
      <link href="/openshift/OpenShift%E5%8E%8B%E6%B5%8B%E5%B7%A5%E4%BD%9C%E5%BF%85%E4%B8%8D%E5%8F%AF%E5%B0%91%EF%BC%8C%E4%BD%BF%E7%94%A8Jmeter%E6%90%9E%E8%B5%B7%E6%9D%A5/"/>
      <url>/openshift/OpenShift%E5%8E%8B%E6%B5%8B%E5%B7%A5%E4%BD%9C%E5%BF%85%E4%B8%8D%E5%8F%AF%E5%B0%91%EF%BC%8C%E4%BD%BF%E7%94%A8Jmeter%E6%90%9E%E8%B5%B7%E6%9D%A5/</url>
      
        <content type="html"><![CDATA[<p>毫无疑问OpenShift是一个优秀的容器平台，但是我们有没有想过这些问题呢？OpenShift集群最多能运行多少个容器？每个请求的延时是多少呢？当有大量Pod并发启动时，容器平台是否还能轻松应对呢？等等这些问题在容器平台上生产时，我们都得心里有数。否则随着容器平台的压力不断扩大，到了无法承受之痛时，而我们却毫不知情。那么对OpenShift容器平台做压力测试就成了一项必不可少的工作。<br>但是怎样去做呢？业界使用最多的方法就是用<strong>Jmeter来模拟API请求进行压测</strong>。</p><h2 id="新建测试计划与进程组"><a href="#新建测试计划与进程组" class="headerlink" title="新建测试计划与进程组"></a>新建测试计划与进程组</h2><ol><li>创建一个名为”测试OpenShift Api”的Test Plan</li><li>右击”测试OpenShift Api”，Add-&gt;Threads(Users)-&gt;ThreadGroup，创建名为”模拟客户端”的Thread Group</li><li>右击”测试OpenShift Api”，Add-&gt;Listener-&gt;Aggregate Report，创建名为“测试OpenShift API Report”的Aggregate Report</li></ol><h2 id="通过模拟请求获取访问OpenShift平台的ACCESS-TOKEN"><a href="#通过模拟请求获取访问OpenShift平台的ACCESS-TOKEN" class="headerlink" title="通过模拟请求获取访问OpenShift平台的ACCESS_TOKEN"></a>通过模拟请求获取访问OpenShift平台的ACCESS_TOKEN</h2><ol start="4"><li>右击”模拟客户端”，Add-&gt;Sampler-&gt;HTTP Request，创建名为”获取TOKEN”的HTTP Request</li><li>设置”获取TOKEN”</li></ol><ul><li>Protocol: https</li><li>Server Name or IP：<a href="https://master.example.com/">https://master.example.com</a></li><li>Port Number：8443</li><li>Method：GET</li><li>Path：&#x2F;oauth&#x2F;authorize?response_type&#x3D;token&amp;client_id&#x3D;openshift-challenging-client</li></ul><ol start="6"><li>右击”获取TOKEN”，Add-&gt;Config Element-&gt;HTTP Header Manager，创建名为”获取TOKEN Header”的HTTP Header Manager</li><li>计算登录OpenShift平台的用户名与密码的base64值<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> -n <span class="string">&#x27;admin:password&#x27;</span> | <span class="built_in">base64</span></span></span><br><span class="line">YWRtaW46cGFzc3dvcmQ=</span><br></pre></td></tr></table></figure></li><li>为”获取TOKEN Header”添加Header</li></ol><ul><li>Authorization：Basic YWRtaW46cGFzc3dvcmQ&#x3D;</li></ul><ol start="9"><li>右击”获取TOKEN”，Add-&gt;Post Processors-&gt;Regular Expression Extractor，创建名为”获取TOKEN值”的Regular Expression Extractor</li><li>设置”获取TOKEN值”</li></ol><ul><li>Apply to：Main sample only</li><li>Field to check： Response Headers</li><li>Name of created variable：ACCESS_TOKEN</li><li>Regular Expression：#access_token&#x3D;([^&amp;]*)&amp;expires_in&#x3D;([^&amp;]*)&amp;</li><li>Template：$1$</li><li>Match NO: 1</li></ul><h2 id="使用ACCESS-TOKEN调用OpenShift-API获取Project列表"><a href="#使用ACCESS-TOKEN调用OpenShift-API获取Project列表" class="headerlink" title="使用ACCESS_TOKEN调用OpenShift API获取Project列表"></a>使用ACCESS_TOKEN调用OpenShift API获取Project列表</h2><ol start="11"><li>右击”模拟客户端”，Add-&gt;Sampler-&gt;HTTP Request，创建名为”获取projects列表”的HTTP Request</li><li>设置”获取projects列表”</li></ol><ul><li>Protocol: https</li><li>Server Name or IP：master.example.com</li><li>Port Number：8443</li><li>Method：GET</li><li>Path：&#x2F;apis&#x2F;project.openshift.io&#x2F;v1&#x2F;projects</li><li>Parameers：pretty&#x3D;true</li></ul><ol start="13"><li>右击”获取projects列表”，Add-&gt;Config Element-&gt;HTTP Header Manager，创建名为”获取projects列表 Header”的HTTP Header Manager</li></ol><ul><li>Authorization：Basic ${ACCESS_TOKEN}</li></ul><ol start="14"><li>右击”获取projects列表”，Add-&gt;Listener-&gt;view Results Tree，创建名为”Projects列表Result”的view Results Tree</li></ol><h2 id="使用ACCESS-TOKEN调用OpenShift-API创建测试Pod"><a href="#使用ACCESS-TOKEN调用OpenShift-API创建测试Pod" class="headerlink" title="使用ACCESS_TOKEN调用OpenShift API创建测试Pod"></a>使用ACCESS_TOKEN调用OpenShift API创建测试Pod</h2><ol start="15"><li>右击”模拟客户端”，Add-&gt;Sampler-&gt;HTTP Request，创建名为”创建Pod”的HTTP Request</li><li>设置”创建Pod”</li></ol><ul><li>Protocol: https</li><li>Server Name or IP：master.example.com</li><li>Port Number：8443</li><li>Method：POST</li><li>Path：&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;test&#x2F;pods</li><li>Body Data：Pod的创建Json文件，<strong>注意”kind”必须顶在行首</strong><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/590e0e9bec86921952ff6f5be088f34014bed6c3dec1dc5e9e73d55bd06a740b.png" alt="创建Pod.PNG"></li></ul><ol start="17"><li>右击”创建Pod”，Add-&gt;Config Element-&gt;HTTP Header Manager，创建名为”创建Pod Header”的HTTP Header Manager</li></ol><ul><li>Authorization：Basic ${ACCESS_TOKEN}</li><li>Accept：application&#x2F;json</li><li>Content-Type：application&#x2F;json</li></ul><ol start="18"><li>右击”创建Pod”，Add-&gt;Listener-&gt;view Results Tree，创建名为”Pod创建Result”的view Results Tree</li></ol><p><strong>最终的配置组件的部局如下图：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/654b0fead3fe5d79347969ddb6f76ff3a84f29f9ea8e095559286b7afbf3d3fd.png" alt="全局图.PNG">  </p><p><code>补充</code> 使用curl来调用Master API示例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -k -X DELETE https://master.example.com:8443/oapi/v1/namespaces/test/deploymentconfigs/busyapp -d <span class="string">&#x27;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Background&quot;&#125;&#x27;</span> -H <span class="string">&quot;Content-Type</span></span></span><br><span class="line">: application/json&quot; -H &quot;Authorization: Bearer $(oc whoami -t)&quot; -H &quot;Accept: application/json&quot;</span><br></pre></td></tr></table></figure><h2 id="执行测试计划"><a href="#执行测试计划" class="headerlink" title="执行测试计划"></a>执行测试计划</h2><ol start="19"><li>不断调整”模拟客户端”的并发数配置（以下配置模拟100个并发不断请求）</li></ol><ul><li>Number of Threads：100</li><li>Ramp-Up Period：1</li><li>Loop Count：Forever</li></ul><ol start="20"><li>在”Projects列表Result”中查看每个获取project列表请求的返回</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c9a372afd75ffde671cb096e8f26f9441051995a752431e6c8856d983b82f18a.png" alt="Project请求数据结果.PNG">  </p><ol start="21"><li>在”Pod创建Result”中查看每个创建Pod请求的返回</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/5011e8831cd8258d6d42b27e13f0bb45a63d3d6fe37e8e3db4fbd97c360207c2.png" alt="创建Pod请求数据结果.PNG">  </p><ol start="22"><li>在”测试OpenShift API Report”中查看所有请求的结果报告</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ff58104f5c9bfa733b684ca30eea85ab4eeb4db5165de1e89bdabd1d1cd613a1.png" alt="测试报告.PNG">  </p><h2 id="生成报表"><a href="#生成报表" class="headerlink" title="生成报表"></a>生成报表</h2><ol><li>确认jmeter&#x2F;bin&#x2F;jmeter.properties中的<strong>output_format配置为csv</strong><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">jmeter.save.saveservice.output_format=csv</span><br><span class="line">..</span><br></pre></td></tr></table></figure></li><li>执行保存的测试OpenShiftAPI.jmx生成报表文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">jmeter -n -t OpenShiftAPI.jmx -l result.jtl -e -o resultReport</span></span><br></pre></td></tr></table></figure></li><li>通过浏览器访问resultReport&#x2F;index.html</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/44d555b2d805a75eebb0b10183b1827d667a5e16c31c04ae19f5a9f1eaf96008.png" alt="报表">  </p><hr><p>以上通过调用获取projects列表的API的全过程，详细介绍了Jemter压测OpenShift的方法。在实际压测OpenShift过程中，我们需要调用更多的API，如创建Pod，删除Pod等。<strong>所有API的说明可查看OpenShift官方文档：<a href="https://docs.openshift.com/container-platform/3.11/rest_api/index.html">OpenShift API说明</a></strong></p><h2 id="压测OpenShift集群需要做详细的测试设计"><a href="#压测OpenShift集群需要做详细的测试设计" class="headerlink" title="压测OpenShift集群需要做详细的测试设计"></a>压测OpenShift集群需要做详细的测试设计</h2><p>名词解释</p><ul><li>集群容量：集群中有N个Node，每个Node上30个Pod，集群容量为30 * N个Pod。</li><li>集群负载：集群中Pod总数量占集群容量百分比。通过调整Pod总数控制集群负载。</li><li>百分位指标：指标的分布性。以API调用延时指标为例，90% API调用延时为180ms，99% API调用延时为400ms。</li></ul><h2 id="测试目标"><a href="#测试目标" class="headerlink" title="测试目标"></a>测试目标</h2><ol><li>集群容量上限：创建Pod总数</li><li>性能瓶颈</li><li>服务请求延迟</li><li>集群支持的并发请求数</li><li>测试容器间调用的性能</li><li>平台弹性扩缩的性能</li></ol><h2 id="服务质量目标（SLO）"><a href="#服务质量目标（SLO）" class="headerlink" title="服务质量目标（SLO）"></a>服务质量目标（SLO）</h2><ol><li>99%的Pod启动时间：5s</li><li>99%的API调用延时：1s</li></ol><h2 id="服务质量指标（SLI）"><a href="#服务质量指标（SLI）" class="headerlink" title="服务质量指标（SLI）"></a>服务质量指标（SLI）</h2><ol><li>Pod启动时间</li><li>API调用延时</li></ol><h2 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h2><p>统计不同集群负载下，Pod启动时间和API调用延时这两个指标的分布性:<br>集群负载：10%， 25%，50%，90%，100%<br>指标分布性：90%， 95%，99%</p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><p><strong>欢迎关注本人用python实现的一个简单的openshift sdk，轻松调用openshift api</strong><br>Openshift SDK Python：<a href="https://github.com/xhuaustc/openshift-sdk-python.git">https://github.com/xhuaustc/openshift-sdk-python.git</a></p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://supereagle.github.io/2017/03/09/kubemark/">Kubernetes集群性能测试</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Airflow简单介绍及测试安装</title>
      <link href="/DevOps/Airflow%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%B5%8B%E8%AF%95%E5%AE%89%E8%A3%85/"/>
      <url>/DevOps/Airflow%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%B5%8B%E8%AF%95%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h2 id="Airflow-是什么"><a href="#Airflow-是什么" class="headerlink" title="Airflow 是什么"></a>Airflow 是什么</h2><ul><li>Airflow 是 Airbnb 开发的用于工作流管理的开源项目，自带 web UI 和调度。它支持编程方式创建工作流，同时在平台上管理和监控工作流程的状态。</li><li>Airflow 于 2016 年 3 月加入了 Apache Software Foundation 的孵化计划，所以它未来的持续维护性有保障。</li><li>官方地址：<a href="https://github.com/apache/airflow%EF%BC%8C%E7%8E%B0%E6%9C%8911318%E4%B8%AAstar%EF%BC%8C732%E4%B8%AA%E8%B4%A1%E7%8C%AE%E8%80%85%EF%BC%8C%E6%98%AF%E4%B8%80%E4%B8%AA%E7%83%AD%E9%97%A8%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E3%80%82">https://github.com/apache/airflow，现有11318个star，732个贡献者，是一个热门的开源项目。</a></li><li>先看下这篇介绍 ：<a href="https://www.jianshu.com/p/e878bbc9ead2">浅谈调度工具——Airflow</a></li></ul><h2 id="为什么使用-Airflow"><a href="#为什么使用-Airflow" class="headerlink" title="为什么使用 Airflow"></a>为什么使用 Airflow</h2><ul><li>智能调度</li><li>图形化展示任务关系</li><li>程序化流水线定义</li><li>流水线间数据交互</li><li>扩展性强</li><li>分布式，可靠性高</li><li>执行方式多样化，除了定时执行还可手动触发，api 触发等</li></ul><h2 id="Airflow-常用的场景"><a href="#Airflow-常用的场景" class="headerlink" title="Airflow 常用的场景"></a>Airflow 常用的场景</h2><p>Airflow 主要用于执行预定的批处理作业。它能够很好地管理不同的批量作业的关系，并给将复杂的关系图形化展示。</p><ul><li>系统或运用的日常维护任务，批量作业</li><li>CD 部署任务，灰度发布，蓝绿部署等</li><li>数据分析，数据流管道管理</li></ul><p>一句话：任何批量任务或者需要手动去触发执行的任务都可以考虑一下 Airflow</p><h2 id="Airflow-安装"><a href="#Airflow-安装" class="headerlink" title="Airflow 安装"></a>Airflow 安装</h2><p><strong>airlow 使用 ansible role 方式安装 <a href="https://github.com/idealista/airflow-role">https://github.com/idealista/airflow-role</a></strong> 0. 安装准备软件 ansible、gcc、python-devel</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install ansible gcc python-devel -y</span></span><br></pre></td></tr></table></figure><ol><li>创建文件<code>requirements.yml </code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- src: idealista.airflow-role</span><br><span class="line">  version: 1.0.0</span><br><span class="line">  name: airflow</span><br></pre></td></tr></table></figure><ol start="2"><li>下载 airflow role</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-galaxy install -p roles -r requirements.yml -f</span></span><br></pre></td></tr></table></figure><ol start="3"><li>更改 role 中的 install.yml<br>将 roles&#x2F;airflow&#x2F;tasks&#x2F;install.yml 中的<code>apt</code>模块改成<code>package</code>模块<br>将 roles&#x2F;airflow&#x2F;tasks&#x2F;install.yml 中的 Copy Daemon scripts 中的 when 条件去掉</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> roles/airflow/tasks/install.yml</span></span><br><span class="line">...</span><br><span class="line">- name: Airflow | Installing dependencies</span><br><span class="line">  package:</span><br><span class="line">    name: &quot;&#123;&#123; item &#125;&#125;&quot;</span><br><span class="line">    state: present</span><br><span class="line">  with_items: &quot;&#123;&#123; airflow_required_libs &#125;&#125;&quot;</span><br><span class="line">...</span><br><span class="line">- name: Airflow | Copy Daemon scripts</span><br><span class="line">  template:</span><br><span class="line">    src: &quot;&#123;&#123; item.key &#125;&#125;.service.j2&quot;</span><br><span class="line">    dest: /lib/systemd/system/&#123;&#123; item.key &#125;&#125;.service</span><br><span class="line">    mode: 0644</span><br><span class="line">  notify: restart &#123;&#123; item.key &#125;&#125;</span><br><span class="line">  with_dict: &quot;&#123;&#123; airflow_services &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><p>更改 role 下的 config.yml 及 templates&#x2F;airflow-***.service.j2 文件<br>将<code>/usr/local/bin/airflow</code>改为<code>/usr/bin/airflow</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> roles/airflow/tasks/config.yml</span></span><br><span class="line">...</span><br><span class="line">- name: Airflow | Initializing DB</span><br><span class="line">  shell: AIRFLOW_HOME=&#123;&#123; airflow_home &#125;&#125; airflow initdb</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> roles/airflow/templates/airflow-webserver.service.j2</span></span><br><span class="line">...</span><br><span class="line">ExecStart=/usr/bin/airflow webserver --pid /run/airflow/webserver.pid</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>目的该 role 使用 pkg 只能在 Debian  或 Ubuntu 环境下安装，更改后，可以在 centos 环境下安装 4. 更新 ansible 的 hosts 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/ansible/hosts</span></span><br><span class="line">127.0.0.1 ansible_connection=local</span><br></pre></td></tr></table></figure><ol start="5"><li>创建部署 airflow 的 ansible yaml</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> airflow.yml</span></span><br><span class="line">---</span><br><span class="line">- hosts: all</span><br><span class="line">  roles:</span><br><span class="line">  - &#123; role: airflow &#125;</span><br></pre></td></tr></table></figure><ol start="6"><li>安装 airflow</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook airflow.yml</span></span><br></pre></td></tr></table></figure><p>执行完以上操作后本机就安装好了 airflow，同时也配置好了 service 等。 7. 手动初始化 db</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">HOME=/etc/airflow; airflow initdb</span></span><br></pre></td></tr></table></figure><ol start="8"><li>更新配置&#x2F;etc&#x2F;airflow&#x2F;airflow.cfg</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/airflow/airflow.cfg</span></span><br><span class="line">...</span><br><span class="line">max_threads = 1</span><br><span class="line">dagbag_import_timeout = 30</span><br><span class="line">...</span><br></pre></td></tr></table></figure><ol start="9"><li>启动 airflow-worker</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart airflow-worker</span></span><br></pre></td></tr></table></figure><p>安装好后展示</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e4e2b676dcb154cc30f8afcdb7f446c83c7c78e81d2ec1388410d89a20a8166a.png" alt="Airflow主页"></p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><ul><li>如果使用 CeleryExecutor，可以安装 Celery 管理器 flower。，默认会安装 tornado 最新版本，需要限定 tornado 版本需限制在 4.2.0。安装完成后运行<code>AIRFLOW_HOME=/etc/airflow airflow flower</code></li><li>使用 Mysql 作为后台数据库时，安装 mysql 扩展请安装 mysql-python。<br>同时 broker_url 设置为<code>broker_url =  mysql://airflow:airflow@localhost:3306/airflow</code></li><li>测试 Airflow 中的 DAG 时，需要在界面上将它先把状态改为 On 后，再点击运行。</li></ul><h2 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h2><p><a href="https://airflow.apachecn.org/">Airflow 中文文档</a><br><a href="https://www.jianshu.com/p/825629ffe3a7">任务调度神器 airflow 之初体验</a><br><a href="https://www.jianshu.com/p/9bed1e3ab93b">airflow 安装，部署，填坑</a><br><a href="https://www.jianshu.com/p/bddacfd66c1f">airflow 配置 CeleryExecutor</a><br><a href="https://www.jianshu.com/p/e878bbc9ead2">浅谈调度工具——Airflow</a><br><a href="https://www.jianshu.com/p/2ecef979c606">如何部署一个健壮的 apache-airflow 调度系统</a><br><a href="http://pylyria.com/2018/08/25/Airflow%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E5%8F%8A%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF/">Airflow 工作模式及适用场景</a><br><a href="https://www.jianshu.com/p/e878bbc9ead2">浅谈调度工具——Airflow</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible常用模块</title>
      <link href="/DevOps/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/"/>
      <url>/DevOps/Ansible%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<h1 id="lookup-函数"><a href="#lookup-函数" class="headerlink" title="lookup 函数"></a>lookup 函数</h1><p>在 playbooks 中可以使用一个名为 lookup()的函数，该函数用于 ansible 从外部资源访问数据，根据第一个参数的不同，该函数具有不同的功能，典型的就是读取外部文件内容。lookup()只在本地执行，而不是在远程主机上执行。<br>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">debug: msg=&quot;&#123;&#123; lookup(&#x27;file&#x27;, &#x27;/etc/foo.txt&#x27;) &#125;&#125;&quot;</span><br><span class="line">debug: msg=&quot;password - &#123;&#123; lookup(&#x27;password&#x27;, &#x27;/tmp/random_pass.txt length=10&#x27;) &#125;&#125;&quot;</span><br><span class="line">debug: msg=&quot;&#123;&#123; lookup(&#x27;env&#x27;,&#x27;HOME&#x27;) &#125;&#125; is an environment variable&quot;</span><br><span class="line">debug: msg=&quot;&#123;&#123; lookup(&#x27;pipe&#x27;,&#x27;date&#x27;) &#125;&#125; is the raw result of running this command&quot;</span><br><span class="line">debug: msg=&quot;&#123;&#123; lookup(&#x27;dnstxt&#x27;, &#x27;example.com&#x27;) &#125;&#125; is a DNS TXT record for example.com&quot;</span><br><span class="line">debug: msg=&quot;&#123;&#123; lookup(&#x27;template&#x27;, &#x27;./some_template.j2&#x27;) &#125;&#125; is a value from evaluation of this template&quot;</span><br></pre></td></tr></table></figure><p>k8s 模块使用 lookup 实例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- name: Read definition file from file after jinja templating</span><br><span class="line">  k8s:</span><br><span class="line">      state: present</span><br><span class="line">      definition: &quot;&#123;&#123; lookup(&#x27;template&#x27;, &#x27;/testing/deployment.yml&#x27;) | from_yaml &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><h1 id="git-模块"><a href="#git-模块" class="headerlink" title="git 模块"></a>git 模块</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>此模块用于 checkout 远程 git 仓库中的文件</p><h2 id="使用要求（在执行模块的主机上）"><a href="#使用要求（在执行模块的主机上）" class="headerlink" title="使用要求（在执行模块的主机上）"></a>使用要求（在执行模块的主机上）</h2><p>git&gt;&#x3D;1.7.1 (命令行工具)</p><h2 id="模块参数"><a href="#模块参数" class="headerlink" title="模块参数"></a>模块参数</h2><table><thead><tr><th>名称</th><th>必选</th><th>默认值</th><th>备注</th></tr></thead><tbody><tr><td>accept_hostkey</td><td>no</td><td>no</td><td>如果<code>yes</code>，请确保“-o StrictHostKeyChecking &#x3D; no”作为 ssh 选项存在。</td></tr><tr><td>archive</td><td>no</td><td></td><td>使用扩展名指定存档文件路径。 如果指定，则创建包含源树树结构的指定格式的存档文件。 允许的存档格式[“zip”，“tar.gz”，“tar”，“tgz”]<br>这将从本地目录克隆并执行 git archive</td></tr><tr><td>bare</td><td>no</td><td>no</td><td>如果<code>yes</code>，则将创建存储库作为裸存储库，否则它将是具有工作空间的标准存储库。</td></tr><tr><td>clone</td><td>no</td><td>yes</td><td>如果<code>no</code>，即使它本地不存在，也不要克隆存储库</td></tr><tr><td>depth</td><td>no</td><td></td><td>clone 的深度，最小值为 1， git&gt;&#x3D;1.9.1 才支持</td></tr><tr><td>dest</td><td>yes</td><td></td><td>应该检出存储库的路径。 除非将 clone 设置为 no，否则此参数是必需的。</td></tr><tr><td>executable</td><td>no</td><td></td><td>要使用的 git 可执行文件的路径</td></tr><tr><td>force</td><td>no</td><td>no</td><td>如果<code>yes</code>，则将丢弃工作存储库中的任何已修改文件。</td></tr><tr><td>key_file</td><td>no</td><td></td><td>私钥存放地址</td></tr><tr><td>recursive</td><td>no</td><td>yes</td><td>如果<code>no</code>，将使用–recursive 选项克隆存储库，跳过子模块。</td></tr><tr><td>reference</td><td>no</td><td></td><td>参考 git clone –reference</td></tr><tr><td>refspec</td><td>no</td><td>no</td><td>添加要获取的其他 refspec。 如果将版本设置为无法从任何分支或标记访问的 SHA-1，则可能需要此选项来指定包含 SHA-1 的 ref。 使用与’git fetch’命令相同的语法。 示例值可以是“refs &#x2F; meta &#x2F; config”。</td></tr><tr><td>remote</td><td>no</td><td>origin</td><td> 远程仓库名</td></tr><tr><td>repo</td><td>yes</td><td></td><td>git 仓库地址</td></tr><tr><td>separate_git_dir</td><td>no</td><td></td><td> 设置 git 仓库目录的存储</td></tr><tr><td>ssh_opts</td><td>no</td><td></td><td>ssh 命令参数，覆盖默认的 ssh 参数</td></tr><tr><td>track_submodules</td><td>no</td><td>no</td><td>如果 <code>yes</code>，子模块将跟踪其主分支（或.gitmodules 中指定的其他分支）上的最新提交。 如果<code>no</code>，则子模块将保留在主项目指定的修订版本中。 这相当于为 git 子模块更新指定了–remote 标志。</td></tr><tr><td>umask</td><td>no</td><td></td><td>在执行任何检出或任何其他存储库维护之前设置的 umask。</td></tr><tr><td>update</td><td>no</td><td>yes</td><td>如果<code>no</code>，请不要从源存储库中检索新修订</td></tr><tr><td>verify_commit</td><td>no</td><td>no</td><td>如果<code>yes</code>，则在克隆或签出版本时验证 GPG 签名提交的签名。git&gt;2.1.0</td></tr><tr><td>version</td><td>no</td><td>HEAD</td><td>clone 代码的版本号</td></tr></tbody></table><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># Example git checkout from Ansible Playbooks</span><br><span class="line">- git:</span><br><span class="line">    repo: &#x27;https://foosball.example.org/path/to/repo.git&#x27;</span><br><span class="line">    dest: /srv/checkout</span><br><span class="line">    version: release-0.22</span><br><span class="line"></span><br><span class="line"># Example read-write git checkout from github</span><br><span class="line">- git:</span><br><span class="line">    repo: git@github.com:mylogin/hello.git</span><br><span class="line">    dest: /home/mylogin/hello</span><br><span class="line"></span><br><span class="line"># Example just ensuring the repo checkout exists</span><br><span class="line">- git:</span><br><span class="line">    repo: &#x27;https://foosball.example.org/path/to/repo.git&#x27;</span><br><span class="line">    dest: /srv/checkout</span><br><span class="line">    update: no</span><br><span class="line"></span><br><span class="line"># Example just get information about the repository whether or not it has</span><br><span class="line"># already been cloned locally.</span><br><span class="line">- git:</span><br><span class="line">    repo: &#x27;https://foosball.example.org/path/to/repo.git&#x27;</span><br><span class="line">    dest: /srv/checkout</span><br><span class="line">    clone: no</span><br><span class="line">    update: no</span><br><span class="line"></span><br><span class="line"># Example checkout a github repo and use refspec to fetch all pull requests</span><br><span class="line">- git:</span><br><span class="line">    repo: https://github.com/ansible/ansible-examples.git</span><br><span class="line">    dest: /src/ansible-examples</span><br><span class="line">    refspec: &#x27;+refs/pull/*:refs/heads/*&#x27;</span><br><span class="line"></span><br><span class="line"># Example Create git archive from repo</span><br><span class="line">- git:</span><br><span class="line">    repo: https://github.com/ansible/ansible-examples.git</span><br><span class="line">    dest: /src/ansible-examples</span><br><span class="line">    archive: /tmp/ansible-examples.zip</span><br><span class="line"></span><br><span class="line"># Example clone a repo with separate git directory</span><br><span class="line">- git:</span><br><span class="line">    repo: https://github.com/ansible/ansible-examples.git</span><br><span class="line">    dest: /src/ansible-examples</span><br></pre></td></tr></table></figure><h1 id="expect-模块"><a href="#expect-模块" class="headerlink" title="expect 模块"></a>expect 模块</h1><h2 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h2><ul><li><code>expect</code>模块用于在给的的节点上执行一个命令并响应提示。</li><li>它不会通过 shell 处理命令，因此不支持像<code>$HOME</code>这样的变量和，以及<code>&lt;</code>, <code>&gt;</code>, <code>|</code>, <code>;</code>和<code>&amp;</code>等都是无效的。也就是在<code>command</code>模块中无法使用管道符。</li></ul><h2 id="使用要求（在执行模块的主机上）-1"><a href="#使用要求（在执行模块的主机上）-1" class="headerlink" title="使用要求（在执行模块的主机上）"></a>使用要求（在执行模块的主机上）</h2><p>python &gt;&#x3D; 2.6<br>pexpect &gt;&#x3D; 3.3</p><h2 id="模块参数-1"><a href="#模块参数-1" class="headerlink" title="模块参数"></a>模块参数</h2><table><thead><tr><th>名称</th><th>必选</th><th>默认值</th><th>备注</th></tr></thead><tbody><tr><td>chdir</td><td>no</td><td></td><td>运行 command 命令前先 cd 到这个目录</td></tr><tr><td>command</td><td>yes</td><td></td><td>命令模块执行命令运行</td></tr><tr><td>echo</td><td>no</td><td>no</td><td>是否回显你的回应字符串</td></tr><tr><td>responses</td><td>yes</td><td></td><td>期望的字符串&#x2F;正则表达式和字符串的映射来响应。 如果响应是一个列表，则连续的匹配将返回连续的响应。 列表功能是 2.1 中的新功能。</td></tr><tr><td>creates</td><td>no</td><td></td><td>如果这个参数对应的文件存在，就不运行 command</td></tr><tr><td>removes</td><td>no</td><td></td><td>如果这个参数对应的文件不存在，就不运行 command，与 creates 参数的作用相反</td></tr><tr><td>timeout</td><td>no</td><td>30</td><td>以秒为单位等待预期时间</td></tr></tbody></table><h2 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h2><ul><li>在远程主机上执行脚本</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">- name: Case insensitve password string match</span><br><span class="line">  expect:</span><br><span class="line">    command: passwd username</span><br><span class="line">    responses:</span><br><span class="line">      (?i)password: &quot;MySekretPa$$word&quot;</span><br><span class="line"></span><br><span class="line">- name: Generic question with multiple different responses</span><br><span class="line">  expect:</span><br><span class="line">    command: /path/to/custom/command</span><br><span class="line">    responses:</span><br><span class="line">      Question:</span><br><span class="line">        - response1</span><br><span class="line">        - response2</span><br><span class="line">        - response3</span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>如果你想通过 shell 运行一个命令（比如你正在使用&lt;,&gt;,|等），你必须在命令中指定一个 shell，比如<code>/bin/bash -c &quot;/path/to/something | grep else&quot;</code>。</li><li>在<code>responses</code>下关键是一个 python 正则表达式匹配，不区分大小写的搜索用前缀?i。</li><li>默认情况下，如果多次遇到问题，则会重复其字符串响应。 如果连续问题匹配需要不同的响应，而不是字符串响应，请使用字符串列表作为响应。</li><li><code>expect</code>模块设计用于简单场景，对于更复杂的需求，应该考虑在<code>shell</code>或<code>script</code>模块中使用 expect 代码</li></ul><h1 id="Ansible-执行命令小技巧"><a href="#Ansible-执行命令小技巧" class="headerlink" title="Ansible 执行命令小技巧"></a>Ansible 执行命令小技巧</h1><ol><li>执行时选择在某个 host 组而不在另一个 host 组的机器</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all:&#x27;!masters&#x27; --list-hosts</span><br></pre></td></tr></table></figure><ol start="2"><li>如果主机的密码都是一样的，可以在 inventory 中添加变量</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[k8s:children]</span><br><span class="line">masters</span><br><span class="line">infras</span><br><span class="line">nodes</span><br><span class="line"></span><br><span class="line">[k8s:vars]</span><br><span class="line">ansible_user=root</span><br><span class="line">ansible_password=password</span><br><span class="line"></span><br><span class="line">[masters]</span><br><span class="line">master1.example.com ansible_host=192.168.0.2</span><br><span class="line">master2.example.com ansible_host=192.168.0.3</span><br><span class="line"></span><br><span class="line">[infras]</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Ansible-注册结果数据"><a href="#Ansible-注册结果数据" class="headerlink" title="Ansible 注册结果数据"></a>Ansible 注册结果数据</h1><p>ansible playbook 中使用 register 注册数据，实现不同 playbook 中数据共享。当完成 regster 后，下游 playbook 可以直接使用注册的变量，这时获取的数据为第一个 hosts 中匹配的服务器执行完成任务后注册的数据。<br>如果需要获取全部数据，需要通过<code>hostvars</code>获取，它会根据主机名为 key，注册的数据为 value 保存在 hostvars 中。<br>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- name: get results</span><br><span class="line">  get_results:</span><br><span class="line">  register: results</span><br><span class="line">- name: out host1 result</span><br><span class="line">  run_once: yes</span><br><span class="line">  debug:</span><br><span class="line">    msg: &quot;&#123;&#123; hostvars[&#x27;host1&#x27;].results &#125;&#125;&quot;</span><br><span class="line">- name: out host2 result</span><br><span class="line">  run_once: yes</span><br><span class="line">  debug:</span><br><span class="line">    msg: &quot;&#123;&#123; hostvars[&#x27;host2&#x27;].results &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><p>另外通过<code>ansible_play_hosts</code>可获取当前运行任务的所有主机。</p><h1 id="Ansible-学习资料"><a href="#Ansible-学习资料" class="headerlink" title="Ansible 学习资料"></a>Ansible 学习资料</h1><ol><li><a href="https://sapser.github.io/ansible/2014/07/09/ansible-getting-started">ansible 学习之一：Getting Started</a></li><li><a href="https://sapser.github.io/ansible/2014/07/10/ansible-inventory">ansible 学习之二：Inventory</a></li><li><a href="https://sapser.github.io/ansible/2014/07/10/ansible-host-pattern">ansible 学习之三：Host Patterns</a></li><li><a href="https://sapser.github.io/ansible/2014/07/21/ansible-playbook">ansible 学习之四：Playbooks</a></li><li><a href="https://sapser.github.io/ansible/2014/07/21/ansible-roles-include">ansible 学习之五：Roles and Include Statements</a></li><li><a href="ansible%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%85%AD%EF%BC%9AVariables">https://sapser.github.io/ansible/2014/07/21/ansible-variables</a></li><li><a href="https://sapser.github.io/ansible/2014/07/21/ansible-conditionals">ansible 学习之七：条件判断</a></li><li><a href="https://sapser.github.io/ansible/2014/07/21/ansible-loops">ansible 学习之八：循环</a></li><li><a href="ansible%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B9%9D%EF%BC%9ATags">https://sapser.github.io/ansible/2014/07/22/ansible-tags</a></li><li><a href="https://sapser.github.io/ansible/2014/07/22/ansible-error-handling">ansible 学习之十：Error Handling In Playbooks</a></li><li><a href="ansible%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8D%81%E4%B8%80%EF%BC%9APrompts">https://sapser.github.io/ansible/2014/07/22/ansible-prompts</a></li><li><a href="https://sapser.github.io/ansible/2014/07/22/ansible-using-lookups">ansible 学习之十二：Using Lookups</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CI-CD流程-命令行方式与Jenkins-Blue-Ocean方式</title>
      <link href="/DevOps/CI-CD%E6%B5%81%E7%A8%8B-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E4%B8%8EJenkins-Blue-Ocean%E6%96%B9%E5%BC%8F/"/>
      <url>/DevOps/CI-CD%E6%B5%81%E7%A8%8B-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E4%B8%8EJenkins-Blue-Ocean%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/02c300ae74aa07d1b945e64f2afe3899b96a9638cc87741acd13bcd5866daee6.png" alt="CI流程图.png"></p><h3 id="命令行模式"><a href="#命令行模式" class="headerlink" title="命令行模式"></a>命令行模式</h3><blockquote><p>环境准备</p></blockquote><ol><li>克隆代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone</span><br></pre></td></tr></table></figure></li><li>启动私有docker hub<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> docker run -d -p 5000:5000 -v /data/registry:/var/lib/registry --name registry --r</span><br><span class="line">estart=always registry</span><br></pre></td></tr></table></figure></li><li>制作建置环境<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t localhost:5000/maven dockers/maven</span><br></pre></td></tr></table></figure></li></ol><p>dockers&#x2F;maven&#x2F;Dockerfile</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM </span><br><span class="line">## 安装openjdk</span><br><span class="line">## 安装Maven</span><br><span class="line">CMD [&quot;mvn&quot;]</span><br></pre></td></tr></table></figure><blockquote><p>集成、测试、验证<br>4. 进行自动化测试</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose run --rm test</span><br></pre></td></tr></table></figure><p>docker-compose.yaml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">data：</span><br><span class="line">  image: alpine</span><br><span class="line">  volumes:</span><br><span class="line">    - ~/.m2:/root/.m2</span><br><span class="line">  command: &quot;/bin/bash&quot;</span><br><span class="line"></span><br><span class="line">install:</span><br><span class="line">  image: localhost:5000/maven</span><br><span class="line">  volumes:</span><br><span class="line">    - ./:/app</span><br><span class="line">  volumes_from:</span><br><span class="line">    - data</span><br><span class="line">  working_dir: /app</span><br><span class="line">  command: &#x27;mvn test&#x27;</span><br><span class="line"></span><br><span class="line">server:</span><br><span class="line">  image: localhost:5000/maven</span><br><span class="line">  volumes:</span><br><span class="line">    - ./:/app</span><br><span class="line">    - ~/.m2:/root/.m2</span><br><span class="line">  working_dir: /app</span><br><span class="line">  ports:</span><br><span class="line">    - &quot;8000:8000&quot;</span><br><span class="line">  command: &quot;mvn spring-boot:run&quot;</span><br></pre></td></tr></table></figure><ol start="5"><li>启动 alpha server<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d server</span><br></pre></td></tr></table></figure></li><li>人员确认启动状况</li><li>关闭alpha server<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose stop server</span><br></pre></td></tr></table></figure></li><li>产出报表与封存<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose run --rm package</span><br></pre></td></tr></table></figure><blockquote><p>部署</p></blockquote></li><li>构建生产镜像<br><code>不需要maven，把额外的都去掉，保留最干净的环境，Dockerfile一般放在根目录下</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make build-docker-prod-image</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">FROM java</span><br><span class="line">COPY target/spring-boot-simple-data-rest-0.1.0.jar /app/</span><br><span class="line">EXPOSE 8000</span><br><span class="line">WORKDIR /app</span><br><span class="line">CMD /bin/bash -c &#x27;java -jar spring-boot-simple-data-rest-0.1.0.jar </span><br></pre></td></tr></table></figure></li><li>发布生产镜像<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push localhost:5000/java_simple_prod</span><br></pre></td></tr></table></figure></li><li>启动生产镜像<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make deploy-production-local</span><br></pre></td></tr></table></figure>Makefile<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">start-docker-registry:</span><br><span class="line">  - docker run -d -p 5000:5000 -v /data/registry:/var/lib/registry --name registry --r</span><br><span class="line">estart=always registry</span><br><span class="line"></span><br><span class="line">build-docker-env:</span><br><span class="line">  docker build -t localhost:5000/maven dockers/maven</span><br><span class="line"></span><br><span class="line">build-docker-prod-image:</span><br><span class="line">  docker build -t localhost:5000/java_simple_prod .</span><br><span class="line"></span><br><span class="line">deploy-production-local:</span><br><span class="line">  - docker rm -f java_simple_prod</span><br><span class="line">  - docker run -d --name java_simple_prod -p 8000:8000 localhost:5000/java_simple_prod</span><br></pre></td></tr></table></figure></li></ol><h3 id="Jenkins模式Blue-Ocean"><a href="#Jenkins模式Blue-Ocean" class="headerlink" title="Jenkins模式Blue Ocean"></a>Jenkins模式Blue Ocean</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># Jenkinsfile https://github.com/agileworks-tw/spring-boot-sample</span><br><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&#x27;checkout project&#x27;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                //git url: &#x27;https://github.com/agileworks-tw/spring-boot-sample.git&#x27;</span><br><span class="line">                checkout scm</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#x27;check docker install and build env&#x27;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;docker -v&quot;</span><br><span class="line">                sh &quot;docker-compose -v&quot;</span><br><span class="line">                sh &quot;docker ps&quot;</span><br><span class="line">            sh &quot;make start-docker-registry&quot;</span><br><span class="line">                sh &quot;make build-docker-env&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#x27;test project and serve&#x27;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;docker-compose run --rm test&quot;</span><br><span class="line">                sh &quot;docker-compose up -d server&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            post &#123;</span><br><span class="line">                always &#123;</span><br><span class="line">                    archiveArtifacts artifacts: &#x27;**/target/*.jar&#x27;, fingerprint: true</span><br><span class="line">                    junit &#x27;**/target/surefire-reports/TEST-*.xml&#x27;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#x27;wait for confirm&#x27;) &#123;</span><br><span class="line">            input &#123;</span><br><span class="line">                message &quot;Does staging at http://localhost:8000 look good?&quot;</span><br><span class="line">                ok &quot;Deploy to production&quot;</span><br><span class="line">                submitter &quot;admin&quot;</span><br><span class="line">                parameters &#123;</span><br><span class="line">                    string(name: &#x27;PERSON&#x27;, defaultValue: &#x27;Mr Jenkins&#x27;, description: &#x27;Who should I say hello to?&#x27;)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            steps &#123;</span><br><span class="line">                echo &quot;Hello, $&#123;PERSON&#125;, nice to meet you.&quot;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            post &#123; </span><br><span class="line">                always &#123; </span><br><span class="line">                    sh &quot;docker-compose stop server&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&#x27;deploy project&#x27;) &#123;</span><br><span class="line">            when &#123;</span><br><span class="line">                branch &#x27;master&#x27;</span><br><span class="line">            &#125;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &quot;docker-compose run --rm package&quot;</span><br><span class="line">                sh &quot;make build-docker-prod-image&quot;</span><br><span class="line">                sh &quot;docker push localhost:5000/java_sample_prod&quot;</span><br><span class="line">                sh &quot;make deploy-production-local&quot;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><ol><li>agent docker所有应用在指定镜像中执行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent &#123;</span><br><span class="line">        docker &#123;</span><br><span class="line">            image &#x27;maven:3-alpine&#x27;</span><br><span class="line">            args &#x27;-v /root/.m2:/root/.m2&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&#x27;Build&#x27;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                checkout scm</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>post当执行完有错误或者成功时运行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  agent any</span><br><span class="line">  stages &#123;</span><br><span class="line">     stage(&#x27;Test&#x27;) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh &#x27;mvn test&#x27;</span><br><span class="line">            &#125;</span><br><span class="line">            post &#123;</span><br><span class="line">                always &#123;</span><br><span class="line">                    junit &#x27;target/surefire-reports/*.xml&#x27;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>input parameter用户输入<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stage(&#x27;wait for input&#x27;)&#123;</span><br><span class="line">  input &#123;</span><br><span class="line">    ......</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>when condition<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stage(&#x27;deploy project&#x27;)&#123;</span><br><span class="line">  when&#123;</span><br><span class="line">    branch &#x27;master&#x27;</span><br><span class="line">  &#125;</span><br><span class="line">  steps&#123;</span><br><span class="line">    ......</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch-+-Kibana添加到Systemctl</title>
      <link href="/DevOps/Elasticsearch-+-Kibana%E6%B7%BB%E5%8A%A0%E5%88%B0Systemctl/"/>
      <url>/DevOps/Elasticsearch-+-Kibana%E6%B7%BB%E5%8A%A0%E5%88%B0Systemctl/</url>
      
        <content type="html"><![CDATA[<p>&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kibana.service</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Elasticsearch</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">PIDFile=/home/vagrant/kibana-5.1.1-linux-x86_64/kibana.pid</span><br><span class="line">ExecStart=/home/vagrant/kibana-5.1.1-linux-x86_64/bin/kibana</span><br><span class="line">User=vagrant</span><br><span class="line">Restart=always</span><br><span class="line">LimitMEMLOCK=infinity</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br></pre></td></tr></table></figure><p>&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;elasticsearch.service</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Elasticsearch</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">PIDFile=/home/vagrant/elasticsearch-rtf/elasticsearch.pid</span><br><span class="line">ExecStart=/home/vagrant/elasticsearch-rtf/bin/elasticsearch</span><br><span class="line">User=vagrant</span><br><span class="line">Restart=always</span><br><span class="line">LimitMEMLOCK=infinity</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git-+-Jenkins-提交Git-触发Jenkins-Job</title>
      <link href="/DevOps/Git-+-Jenkins-%E6%8F%90%E4%BA%A4Git-%E8%A7%A6%E5%8F%91Jenkins-Job/"/>
      <url>/DevOps/Git-+-Jenkins-%E6%8F%90%E4%BA%A4Git-%E8%A7%A6%E5%8F%91Jenkins-Job/</url>
      
        <content type="html"><![CDATA[<p>利用git的Hook机制</p><ol><li>.git&#x2F;hooks&#x2F;pre-push<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">echo ====== trigger jenkins job: maglev-verify in 10s  =======</span><br><span class="line">(sleep 10 &amp;&amp; .git/hooks/post-push) &amp;</span><br></pre></td></tr></table></figure></li><li>.git&#x2F;hooks&#x2F;post-push<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">branch=$(git rev-parse --abbrev-ref @&#123;upstream&#125;)</span><br><span class="line">curl -k --user $&#123;USER&#125;=$&#123;TOKEN&#125; http://$&#123;JENKINS_URL&#125;/job/$&#123;JOB_NAME&#125;/buildWithParameters --data-urlencode TAG=$branch</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gitea访问使用KeyCloak作为用户管理</title>
      <link href="/DevOps/Gitea%E8%AE%BF%E9%97%AE%E4%BD%BF%E7%94%A8KeyCloak%E4%BD%9C%E4%B8%BA%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/Gitea%E8%AE%BF%E9%97%AE%E4%BD%BF%E7%94%A8KeyCloak%E4%BD%9C%E4%B8%BA%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>一、安装keyCloak</p><p>二、配置KeyCloak，添加Clients<br><code>Clients</code> -&gt; <code>create</code><br>Client ID: devops-oidc<br>Enabled: true<br>Client Protocol: openid-connect<br>Access Type: confidential<br>Valid Redirect URIs: <gitea url>&#x2F;*</p><p>三、配置Gitea，添加Authentication Sources<br><code>Site Administration</code> -&gt; <code>Authentication Sources</code> -&gt; <code>Add Authentication Source</code><br>OAuth2 Provider: OpenID Connect<br>Client ID(key): devops-oidc<br>Client Secret: &lt;keycload 中 devops-oidc Credentials中查询&gt;<br>OpenID Connect Auto Discovery URL: http:&#x2F;&#x2F;<keycload url>&#x2F;auth&#x2F;realms&#x2F;master&#x2F;.well-known&#x2F;openid-configuration</p><p>gitea app.ini<br>ALLOW_ONLY_EXTERNAL_REGISTRATION &#x3D; true</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins-Pipeline触发机制</title>
      <link href="/DevOps/Jenkins-Pipeline%E8%A7%A6%E5%8F%91%E6%9C%BA%E5%88%B6/"/>
      <url>/DevOps/Jenkins-Pipeline%E8%A7%A6%E5%8F%91%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>设置好了功能强大的流水线后，接下来我们要做的就是去执行流水线，如果都靠手动去触发流水线，显然不符合带着自动化基因新一代工程师的风格，必须自动触发。<br>那么Jenkins的Pipeline支持哪些触发机制呢。一起来看一下。</p><h3 id="定时触发：cron"><a href="#定时触发：cron" class="headerlink" title="定时触发：cron"></a>定时触发：cron</h3><p>cron规则与crontab的规则是一样的</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">cron(&#x27;0 0 * * *&#x27;)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;半夜触发&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">echo &quot;凌晨执行&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="轮询代码仓库"><a href="#轮询代码仓库" class="headerlink" title="轮询代码仓库"></a>轮询代码仓库</h3><p>周期性检查代码，看代码是否有更新。这种方式需要使用</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">pollSCM(&#x27;* * * * *&#x27;)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;每分钟检查&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">echo &quot;每分钟检查代码仓库是否更新&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="由上游任务触发"><a href="#由上游任务触发" class="headerlink" title="由上游任务触发"></a>由上游任务触发</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">upstream(upstreamProjects: &#x27;job1,job2&#x27;, threshold: hudson.model.Result.SUCCESS)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;上游触发&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">echo &quot;当job1或job2执行成功时，触发该流水线&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>hudson.model.Result包括以下状态：<br>ABORTED：任务被手动中止<br>FAILURE：构建失败<br>SUCCESS：构建成功<br>UNSTABLE：存在一些错误，但构建没失败<br>NOT_BUILT：多阶段构建时，前面阶段问题导致后面阶段无法执行</p><h3 id="GitLab通知触发"><a href="#GitLab通知触发" class="headerlink" title="GitLab通知触发"></a>GitLab通知触发</h3><p>详情请在插件<a href="https://github.com/jenkinsci/gitlab-plugin">Gitlab plugin</a>的github页面上查看</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">gitlab(</span><br><span class="line">triggerOnPush: true, </span><br><span class="line">triggerOnMergeRequest: true,</span><br><span class="line">branchFilterType: &#x27;All&#x27;,</span><br><span class="line">secretToken: &quot;abcdxxxfa&quot;)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;构建&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">echo &quot;gitlab 触发&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="将构建状态信息推送到GitLab"><a href="#将构建状态信息推送到GitLab" class="headerlink" title="将构建状态信息推送到GitLab"></a>将构建状态信息推送到GitLab</h3><ol><li>在Jenkins的系统设置中，Gitlab选项下填入Gitlab信息。例Connection name设为gitlab</li><li>按提示设置Gitlab的凭证，以对话框中输入Gitlab平台获取的API token</li><li>在pipeline的post部分，将构建结果更新到Gitlab相应的commit记录下，同时还需要在options参数中加入<code>gitLabConnection</code>配置<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">gitlab(</span><br><span class="line">triggerOnPush: true, </span><br><span class="line">triggerOnMergeRequest: true,</span><br><span class="line">branchFilterType: &#x27;All&#x27;,</span><br><span class="line">secretToken: &quot;abcdxxxfa&quot;)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;构建&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">echo &quot;gitlab 触发&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">post&#123;</span><br><span class="line">failure&#123;</span><br><span class="line">updateGitlabCommitStatus name: &#x27;build&#x27;, state: &#x27;failed&#x27;</span><br><span class="line">&#125;</span><br><span class="line">success&#123;</span><br><span class="line">updateGitlabCommitStatus name: &#x27;build&#x27;, state: &#x27;success&#x27;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">options&#123;</span><br><span class="line">gitLabConnection(&#x27;gitlab&#x27;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="Generic-Webhook-Trigger插件触发"><a href="#Generic-Webhook-Trigger插件触发" class="headerlink" title="Generic Webhook Trigger插件触发"></a>Generic Webhook Trigger插件触发</h3><p><a href="https://plugins.jenkins.io/generic-webhook-trigger">Generic Webhook Trigger</a>是一个通用的通过Webhook的方式触发pipeline的插件</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">GenericTrigger(</span><br><span class="line">genericVariables: [</span><br><span class="line">key: &#x27;ref&#x27;, value: &#x27;$.ref&#x27;</span><br><span class="line">],</span><br><span class="line">token: &#x27;secret&#x27;,</span><br><span class="line"></span><br><span class="line">causeString: &#x27;Triggered on $ref&#x27;,</span><br><span class="line">printContributedVariables: true,</span><br><span class="line">printPostContent: true,</span><br><span class="line">                        regexpFilterText: &#x27;$ref&#x27;,</span><br><span class="line">                        regexpFilterExpression: &#x27;refs/heads(master|dev)&#x27;</span><br><span class="line">)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;自定义触发&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">echo &quot;Generic 触发&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后通过POST请求触发</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST -H &quot;Content-Type: application/json&quot; -d &#x27;&#123;&quot;ref&quot;: &quot;refs/heads/master&quot; &#125;&#x27; -vs http://jenkins.local:8080/jenkins/generic-webhook-trigger/invoke?token=secret</span><br></pre></td></tr></table></figure><p>触发条件依靠：<code>token</code>、<code>regexpFilterText</code>、<code>regexpFilterExpression</code>三个参数。首先token必须匹配，其次<code>regexpFilterText</code>指定的key对应的值满足<code>regexpFilterExpression</code>表达式。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>《Jenkins 2.X实践指南》</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins-Pipeline语法实例</title>
      <link href="/DevOps/Jenkins-Pipeline%E8%AF%AD%E6%B3%95%E5%AE%9E%E4%BE%8B/"/>
      <url>/DevOps/Jenkins-Pipeline%E8%AF%AD%E6%B3%95%E5%AE%9E%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="Jenkins-Pipeline支持的指令"><a href="#Jenkins-Pipeline支持的指令" class="headerlink" title="Jenkins Pipeline支持的指令"></a>Jenkins Pipeline支持的指令</h3><table><thead><tr><th>指令名</th><th>说明</th><th>作用域</th></tr></thead><tbody><tr><td>agent</td><td>定义执行任务的代理</td><td>stage 或pipeline</td></tr><tr><td>environment</td><td>设置环境变量</td><td>stage或pipeline</td></tr><tr><td>tools</td><td>自动下载并安装指定的工具，并将其加入到PATH变量中</td><td>stage或pipeline</td></tr><tr><td>input</td><td>暂停pipeline,提示输入内容</td><td>stage</td></tr><tr><td>options</td><td>配置Jenkins pipeline本身，如options{retry(3}},指pipeline失败时再重试2次</td><td>stage 或 pipeline</td></tr><tr><td>parallel</td><td>并行执行多个step</td><td>stage</td></tr><tr><td>parameters</td><td>执行pipeline前传入一些参数</td><td>pipeline</td></tr><tr><td>triggers</td><td>定义执行pipeline的触发器</td><td>pipeline</td></tr><tr><td>when</td><td>定义阶段执行的条件</td><td>stage</td></tr><tr><td>build</td><td>触发其他的job</td><td>steps</td></tr></tbody></table><h3 id="options-Jenkins-Pipeline配置参数"><a href="#options-Jenkins-Pipeline配置参数" class="headerlink" title="options Jenkins Pipeline配置参数"></a>options Jenkins Pipeline配置参数</h3><table><thead><tr><th>参数名</th><th>说明</th><th>例子</th></tr></thead><tbody><tr><td>buildDiscarder</td><td>保留最近历史构建记录的数量</td><td>buildDiscarder(logRotator(numToKeepStr: ‘10’)</td></tr><tr><td>checkoutToSubdirectory</td><td>将代码从版本控制库中拉取后，保存在工作目录的子目录</td><td>checkoutToSubdirectory(‘subdir’)</td></tr><tr><td>disableConcurrentBuilds</td><td>禁用Jenkins同时执行多次该pipeline</td><td>disableConcurrentBuilds()</td></tr><tr><td>newContainerPerStage</td><td>agent为Docker或Dockerfile时，每个stage都分别运行在一个新容器中</td><td>newContainerPerStage()</td></tr><tr><td>retry</td><td>pipeline发生失败后重试次数</td><td>retry(4)</td></tr><tr><td>timeout</td><td>pipeline运行超时时间</td><td>timeout(time:10, unit: ‘HOURS’)</td></tr></tbody></table><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">options&#123;</span><br><span class="line">buildDiscarder(logRotator(numToKeepStr: &#x27;10&#x27;)</span><br><span class="line">disableConcurrentBuilds()</span><br><span class="line">retry(4)</span><br><span class="line">timeout(time:10, unit: &#x27;HOURS&#x27;)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;demo&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">sh &#x27;echo hello&#x27;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stage间通过stash进行文件共享，即使stage不在同一个执行主机上"><a href="#stage间通过stash进行文件共享，即使stage不在同一个执行主机上" class="headerlink" title="stage间通过stash进行文件共享，即使stage不在同一个执行主机上"></a>stage间通过stash进行文件共享，即使stage不在同一个执行主机上</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent none</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;stash&#x27;)&#123;</span><br><span class="line">agent &#123; label &quot;master&quot; &#125;</span><br><span class="line">steps&#123;</span><br><span class="line">writeFile file: &quot;a.txt&quot;, text: &quot;$BUILD_NUMBER&quot;</span><br><span class="line">stash name: &quot;abc&quot;, includes: &quot;a.txt&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">stage(&#x27;unstash&#x27;)&#123;</span><br><span class="line">agent &#123; label &quot;node&quot; &#125;</span><br><span class="line">steps&#123;</span><br><span class="line">script&#123;</span><br><span class="line">unstash(&quot;abc&quot;)</span><br><span class="line">def content = readFile(&quot;a.txt&quot;)</span><br><span class="line">echo &quot;$&#123;content&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="steps中的一些操作"><a href="#steps中的一些操作" class="headerlink" title="steps中的一些操作"></a>steps中的一些操作</h3><table><thead><tr><th>命令名</th><th>说明</th></tr></thead><tbody><tr><td>error</td><td>抛出异常，中断整个pipeline</td></tr><tr><td>timeout</td><td>timeout闭包内运行的步骤超时时间</td></tr><tr><td>waitUntil</td><td>一直循环运行闭包内容，直到return true，经常与timeout同时使用</td></tr><tr><td>retry</td><td>闭包内脚本重复执行次数</td></tr><tr><td>sleep</td><td>暂停pipeline一段时间，单位为秒</td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;stash&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">timeout(50)&#123;</span><br><span class="line">waitUntil&#123;</span><br><span class="line">script&#123;</span><br><span class="line">def r = sh script: &#x27;curl http://xxx&#x27;, returnStatus: true</span><br><span class="line">return (r == 0)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">retry(10)&#123;</span><br><span class="line">script&#123;</span><br><span class="line">sh script: &#x27;curl http://xxx&#x27;, returnStatus: true</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">sleep(20)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">post&#123;</span><br><span class="line">    always&#123;</span><br><span class="line">        echo &quot;结束job&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="来一个相对复杂一点的交互式Pipeline"><a href="#来一个相对复杂一点的交互式Pipeline" class="headerlink" title="来一个相对复杂一点的交互式Pipeline"></a>来一个相对复杂一点的交互式Pipeline</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">agent any</span><br><span class="line">triggers&#123;</span><br><span class="line">upstream(upstreamProjects: &#x27;job1,job2&#x27;, threshold: hudson.model.Result.SUCCESS)</span><br><span class="line">&#125;</span><br><span class="line">stages&#123;</span><br><span class="line">stage(&#x27;pre deploy&#x27;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">script&#123;</span><br><span class="line">BRANCHES = sh  returnStdout: true, script: &#x27;git branch -r | grep -v HEAD &gt; out.txt; git tag &gt;&gt; out.txt; cat out.txt;&#x27;</span><br><span class="line">dataMap = input message: &#x27;准备发布到哪个环境&#x27;, ok: &#x27;确定&#x27;, parameters: [choice(choices: [&#x27;dev&#x27;, &#x27;sit&#x27;, &#x27;prod&#x27;], description: &#x27;部署环境&#x27;, name: &#x27;ENV&#x27;), choice(choices: &quot;$&#123;BRANCHES&#125;&quot;, description: &#x27;分支&#x27;, name: &#x27;TAG&#x27;)], submitterParameter: &#x27;APPROVER&#x27;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">stage(&quot;演示一下&quot;)&#123;</span><br><span class="line">steps&#123;</span><br><span class="line">          echo &quot;$&#123;dataMap[&#x27;APPROVER&#x27;]&#125;&quot;</span><br><span class="line">          echo &quot;$&#123;dataMap[&#x27;ENV&#x27;]&#125;&quot;</span><br><span class="line">          echo &quot;$&#123;dataMap[&#x27;TAG&#x27;]&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="共享库share-library"><a href="#共享库share-library" class="headerlink" title="共享库share library"></a>共享库share library</h3><p>解决问题： </p><ul><li>pipeline不出现方法定义，把所有类库写到library中</li><li>pipeline中重复步骤可以写到library中</li><li>规范流程过程<br>例子：<a href="https://github.com/liwei2151284/jenkins_library">https://github.com/liwei2151284/jenkins_library</a><br>参考文章：<a href="https://testerhome.com/topics/10782">https://testerhome.com/topics/10782</a></li></ul><ol><li>系统设置中设置global pipeline libraries，名字为jenkins_library，添加git地址共享库</li><li>使用：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">library &quot;jenkins_library&quot;</span><br><span class="line">node &#123;</span><br><span class="line">  stage(&quot;test&quot;)&#123;</span><br><span class="line">    sayHello()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>《Jenkins 2.X实践指南》</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jmeter简单配置使用</title>
      <link href="/DevOps/Jmeter%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8/"/>
      <url>/DevOps/Jmeter%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<ol><li>创建Test Plan <code>测试计划</code><br>File-&gt;New或者直接点击New图标</li><li>添加Thread Group <code>测试任务</code><br>右击测试计划，Add-&gt;Threads(Users)-&gt;Thread Group</li><li>添加HTTP Cookie <code>请求Cookie管理</code><br>右击Thread Group，Add-&gt;Config Element-&gt;HTTP Cookie Manager</li><li>添加HTTP Header  <code>请求头管理</code><br>右击Thread Group，Add-&gt;Config Element-&gt;HTTP Header Manager</li><li>添加HTTP Request <code>请求</code><br>右击Thread Group，Add-&gt;Sampler-&gt;HTTP Request</li><li>添加User Defined Variables <code>用户定义变量</code><br>右击Thread Group，Add-&gt;Config Element-&gt;User Defined Variable</li><li>添加报告Result Tree <code>结果树</code><br>右击Thread Group，Add-&gt;Listener-&gt;View Result Tree</li><li>添加报告Aggregate Report <code>聚合报告</code><br>右击Thread Group，Add-&gt;Listener-&gt;Aggregate Report</li></ol><h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><ol><li>添加Regular Expression Extractor <code>请求关联 </code><br>右击创建的HTTP Request，Add-&gt;Post Processors-&gt;Regular Expression Extractor<br>在第二个请求中就可以使用这个变量了。</li><li>使用Jmeter录制测试脚本<ol><li>创建一个Thread Group</li><li>创建http代理服务器</li></ol></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql瓶颈分析方法</title>
      <link href="/DevOps/Mysql%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/"/>
      <url>/DevOps/Mysql%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>数据库往往会成为应用的最终瓶颈，而Mysql是被使用得最多的开源关系型数据库。如何分析执行Mysql数据库语句的性能就非常重要。但是很多开发人员并没有相关的意识与能力，但其实掌握了一些简单的常用手段，就可以让我们自己分析出数据库语句的问题。曾经看到过有对数据库查询语句中出现7个Select的语句，当时完全被震惊到了，这根本就是往系统里注入了一个大雷呀，数据量一旦增多，数据库挂，应用挂，服务挂，客户挂，公司挂。。。。还是不做破了一个鸡蛋就想着毁了一个养鸡场的推断了。我们收集下常见的数据库的分析手段。</p><ol><li>查看当前数据库执行命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select count(*) from information_schema.processlist where COMMAND != &#x27;Sleep&#x27;;</span><br><span class="line">mysql&gt; select * from information_schema.processlist where COMMAND != &#x27;Sleep&#x27; limit 5;</span><br></pre></td></tr></table></figure></li><li>慢查询<br>查看慢查询时间定义<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &quot;long%&quot;;</span><br><span class="line">+-----------------+----------+</span><br><span class="line">| Variable_name   | Value    |</span><br><span class="line">+-----------------+----------+</span><br><span class="line">| long_query_time | 10 |</span><br><span class="line">+-----------------+----------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set long_query_time=1;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>开启“慢查询”记录功能<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &quot;slow%&quot;;</span><br><span class="line">+---------------------+------------------------------------+</span><br><span class="line">| Variable_name       | Value                              |</span><br><span class="line">+---------------------+------------------------------------+</span><br><span class="line">| slow_launch_time    | 2                                  |</span><br><span class="line">| slow_query_log      | OFF                                |</span><br><span class="line">| slow_query_log_file | /opt/mysql/data/localhost-slow.log |</span><br><span class="line">+---------------------+------------------------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global slow_query_log=ON;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br></pre></td></tr></table></figure>设置慢日志导出方式为Table或者File<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &quot;log_output&quot;;</span><br><span class="line">+---------------------+------------------------------------+</span><br><span class="line">| Variable_name       | Value                              |</span><br><span class="line">+---------------------+------------------------------------+</span><br><span class="line">| log_output         | FILE                                  |</span><br><span class="line">+---------------------+------------------------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global log_output=TABLE     </span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br></pre></td></tr></table></figure></li><li>explain输出执行计划对sql进行分析<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select uid from user where mo=132342342 limit 0,1;</span><br></pre></td></tr></table></figure>出现以下结果就需要优化了：</li></ol><ul><li>出现了Using temporary；</li><li>rows过多，或者几乎是全表的记录数；</li><li>key 是 (NULL)；</li><li>possible_keys 出现过多（待选）索引。</li></ul><ol start="4"><li><a href="https://github.com/XiaoMi/soar">soar</a>小米SQL分析工具<br>SOAR(SQL Optimizer And Rewriter)是一个对SQL进行优化和改写的自动化工具。 由小米人工智能与云平台的数据库团队开发与维护。</li></ol><h2 id=""><a href="#" class="headerlink" title=""></a><a href="https://github.com/XiaoMi/soar#%E5%8A%9F%E8%83%BD%E7%89%B9%E7%82%B9"></a></h2><ol start="5"><li>查看是否有锁表<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show engine innodb status;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx性能优化配置参考</title>
      <link href="/DevOps/Nginx%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE%E5%8F%82%E8%80%83/"/>
      <url>/DevOps/Nginx%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE%E5%8F%82%E8%80%83/</url>
      
        <content type="html"><![CDATA[<h2 id="系统优化"><a href="#系统优化" class="headerlink" title="系统优化"></a>系统优化</h2><ul><li><strong>系统内核优化参考</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/sysctl.conf</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 65536</span><br><span class="line">net.core.netdev_max_backlog =  36768</span><br><span class="line">net.core.somaxconn = 36768</span><br><span class="line"> </span><br><span class="line">net.core.wmem_default = 8588608</span><br><span class="line">net.core.rmem_default = 8588608</span><br><span class="line">net.core.rmem_max = 16877216</span><br><span class="line">net.core.wmem_max = 16877216</span><br><span class="line"> </span><br><span class="line">net.ipv4.tcp_synack_retries = 2</span><br><span class="line">net.ipv4.tcp_syn_retries = 2</span><br><span class="line"> </span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line"> </span><br><span class="line">net.ipv4.tcp_mem = 94500000 915000000 927000000</span><br><span class="line">net.ipv4.tcp_max_orphans = 3376800</span><br><span class="line">net.ipv4.ip_local_port_range = 1024  65535</span><br><span class="line"></span><br><span class="line">$ sysctl -p</span><br><span class="line">$ cat /etc/security/limit.conf</span><br><span class="line">*  hard  nofile  65535</span><br><span class="line">*  soft  nofile  65535</span><br></pre></td></tr></table></figure></li></ul><h2 id="Nginx配置优化"><a href="#Nginx配置优化" class="headerlink" title="Nginx配置优化"></a>Nginx配置优化</h2><ul><li><strong>Nginx配置参考</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">#user  nobody;</span><br><span class="line">worker_processes  4;</span><br><span class="line">worker_cpu_affinity 0001 0010 0100 1000;</span><br><span class="line">worker_rlimit_nofile 65535;</span><br><span class="line"></span><br><span class="line">#pid        logs/nginx.pid;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">        use epoll;</span><br><span class="line">        worker_connections 65535;</span><br><span class="line">        multi_accept on;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    #access_log  logs/access.log  main;</span><br><span class="line">    log_format  main  &#x27;$http_X_Real_IP $http_CLIENTIP $remote_addr $remote_user [$time_local] &quot;$request&quot; &#x27;</span><br><span class="line">                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span><br><span class="line">                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; $request_time&#x27;;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    keepalive_timeout  60;</span><br><span class="line">    keepalive_requests 10240;</span><br><span class="line">    tcp_nodelay on;</span><br><span class="line">    client_header_buffer_size 4k;</span><br><span class="line">    open_file_cache max=102400 inactive=20s;</span><br><span class="line">    open_file_cache_valid 30s;</span><br><span class="line">    open_file_cache_min_uses 1;</span><br><span class="line">    client_header_timeout 15;</span><br><span class="line">    client_body_timeout 15;</span><br><span class="line">    reset_timedout_connection on;</span><br><span class="line">    send_timeout 15;</span><br><span class="line">    server_tokens off;</span><br><span class="line">    client_max_body_size 10m;</span><br><span class="line"></span><br><span class="line">    gzip  off;</span><br><span class="line">    gzip_min_length 1k;</span><br><span class="line">    gzip_buffers 4 16k;</span><br><span class="line">    gzip_http_version 1.0;</span><br><span class="line">    gzip_comp_level 2;</span><br><span class="line">    gzip_types text/plain application/x-javascript text/css application/xml;</span><br><span class="line">    gzip_vary on;</span><br><span class="line"></span><br><span class="line">    fastcgi_connect_timeout    600;</span><br><span class="line">    fastcgi_send_timeout 600;</span><br><span class="line">    fastcgi_read_timeout 600;</span><br><span class="line">    fastcgi_buffer_size 64k;</span><br><span class="line">    fastcgi_buffers 4 64k;</span><br><span class="line">    fastcgi_busy_buffers_size 128k;</span><br><span class="line">    fastcgi_temp_file_write_size 128k;</span><br><span class="line">    fastcgi_temp_path /usr/local/nginx/fastcgi_temp;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line"></span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        access_log  /usr/local/logs/nginx/access.log  main;</span><br><span class="line">        root        html;</span><br><span class="line">        index       index.html index.htm index.php;</span><br><span class="line"></span><br><span class="line">        #图片缓存时间        </span><br><span class="line">        location ~* \.(ico|jpe?g|gif|png|bmp|swf|flv)$ &#123;</span><br><span class="line">          expires 30d;</span><br><span class="line">          #log_not_found off;</span><br><span class="line">          access_log off;</span><br><span class="line">        &#125;</span><br><span class="line">        #JS和CSS缓存时间</span><br><span class="line">        location ~* \.(js|css)$ &#123;</span><br><span class="line">          expires 7d;</span><br><span class="line">          log_not_found off;</span><br><span class="line">          access_log off;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location / &#123;</span><br><span class="line">                try_files $uri $uri/ @rewrites;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location @rewrites &#123;</span><br><span class="line">                rewrite ^ /index-development.php last;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location = /robots.txt &#123;</span><br><span class="line">                access_log off;</span><br><span class="line">                log_not_found off;</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">        location ~ \.php$ &#123;</span><br><span class="line">            root           html;</span><br><span class="line">            fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">            fastcgi_index  index.php;</span><br><span class="line">            fastcgi_param   SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line">            include        fastcgi_params;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    include conf.d/*;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong>worker_processes</strong><br>nginx运行工作进程个数，一般设置cpu的核心或者核心数x2，如：worker_processes  4;</li><li><strong>worker_cpu_affinity</strong><br>运行CPU亲和力，与worker_processes对应，如：worker_cpu_affinity 0001 0010 0100 1000;</li><li><strong>worker_rlimit_nofile</strong><br>  Nginx最多可以打开文件数，与ulimit -n保持一致，如：worker_rlimit_nofile 65535;</li><li><strong>events</strong><br>事件处理模型。如：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">events &#123;</span><br><span class="line">  use epoll;</span><br><span class="line">  worker_connections 65535;</span><br><span class="line">  multi_accept on;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><strong>use epoll</strong>：nginx采用epoll事件模型，处理效率高<br><strong>work_connections</strong>：是单个worker进程允许客户端最大连接数，这个数值一般根据服务器性能和内存来制定，实际最大值就是worker进程数乘以work_connections，实际我们填入一个65535，足够了，这些都算并发值，一个网站的并发达到这么大的数量，也算一个大站了！<br><strong>multi_accept</strong> ：告诉nginx收到一个新连接通知后接受尽可能多的连接，默认是on，设置为on后，多个worker按串行方式来处理连接，也就是一个连接只有一个worker被唤醒，其他的处于休眠状态，设置为off后，多个worker按并行方式来处理连接，也就是一个连接会唤醒所有的worker，直到连接分配完毕，没有取得连接的继续休眠。当你的服务器连接数不多时，开启这个参数会让负载有一定的降低，但是当服务器的吞吐量很大时，为了效率，可以关闭这个参数。</li><li><strong>http</strong><br>高效传输模式，如：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">include mime.types;</span><br><span class="line">default_type application/octet-stream;</span><br><span class="line">……</span><br><span class="line">sendfile on;</span><br><span class="line">tcp_nopush on;</span><br><span class="line">……</span><br></pre></td></tr></table></figure></li></ul><p><strong>Include mime.types</strong>： 媒体类型,include 只是一个在当前文件中包含另一个文件内容的指令<br><strong>default_type</strong>：默认媒体类型，如： application&#x2F;octet-stream;<br><strong>sendfile</strong> ：开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I&#x2F;O处理速度，降低系统的负载。<br><code>注意：如果图片显示不正常把这个改成off</code><br><strong>tcp_nopush</strong>：必须在sendfile开启模式才有效，防止网路阻塞，积极的减少网络报文段的数量（将响应头和正文的开始部分一起发送，而不一个接一个的发送。）</p><ul><li><strong>连接超时时间</strong><br>主要目的是保护服务器资源，CPU，内存，控制连接数，因为建立连接也是需要消耗资源的，如：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">keepalive_timeout 60;</span><br><span class="line">keepalive_requests 10240;</span><br><span class="line">tcp_nodelay on;</span><br><span class="line">client_header_buffer_size 4k;</span><br><span class="line">open_file_cache max=102400 inactive=20s;</span><br><span class="line">open_file_cache_valid 30s;</span><br><span class="line">open_file_cache_min_uses 1;</span><br><span class="line">client_header_timeout 15;</span><br><span class="line">client_body_timeout 15;</span><br><span class="line">reset_timedout_connection on;</span><br><span class="line">send_timeout 15;</span><br><span class="line">server_tokens off;</span><br><span class="line">client_max_body_size 10m;</span><br></pre></td></tr></table></figure></li></ul><p><strong>keepalived_timeout 60</strong>：客户端连接保持会话超时时间，超过这个时间，服务器断开这个链接<br><strong>keepalive_requests 10240</strong>：参数限制了一个 HTTP 长连接最多可以处理完成的最大请求数, 默认是 100。当连接处理完成的请求数达到最大请求数后，将关闭连接。<br><strong>tcp_nodelay</strong>：也是防止网络阻塞，不过要包涵在keepalived参数才有效<br><strong>client_header_buffer_size 4k</strong>：客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过 1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。<br><strong>open_file_cache max&#x3D;102400 inactive&#x3D;20s</strong>：这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。<br><strong>open_file_cache_valid 30s</strong>：这个是指多长时间检查一次缓存的有效信息。<br><strong>open_file_cache_min_uses 1</strong>：open_file_cache指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。<br><strong>client_header_timeout</strong>：设置请求头的超时时间。我们也可以把这个设置低些，如果超过这个时间没有发送任何数据，nginx将返回request time out的错误<br><strong>client_body_timeout</strong>：设置请求体的超时时间。我们也可以把这个设置低些，超过这个时间没有发送任何数据，和上面一样的错误提示<br><strong>reset_timeout_connection</strong>：告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。<br><strong>send_timeout</strong>：响应客户端超时时间，这个超时时间仅限于两个活动之间的时间，如果超过这个时间，客户端没有任何活动，nginx关闭连接<br><strong>server_tokens</strong>：并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的。<br><strong>client_max_body_size</strong>：上传文件大小限制</p><ul><li><strong>fastcgi调优</strong><br>fastcgi配置优化，如：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fastcgi_connect_timeout    600;</span><br><span class="line">fastcgi_send_timeout 600;</span><br><span class="line">fastcgi_read_timeout 600;</span><br><span class="line">fastcgi_buffer_size 64k;</span><br><span class="line">fastcgi_buffers 4 64k;</span><br><span class="line">fastcgi_busy_buffers_size 128k;</span><br><span class="line">fastcgi_temp_file_write_size 128k;</span><br><span class="line">fastcgi_temp_path/usr/local/nginx1.10/nginx_tmp;</span><br><span class="line">fastcgi_intercept_errors on;</span><br><span class="line">fastcgi_cache_path/usr/local/nginx1.10/fastcgi_cache levels=1:2 keys_zone=cache_fastcgi:128minactive=1d max_size=10g;</span><br></pre></td></tr></table></figure><strong>fastcgi_connect_timeout</strong>：指定连接到后端FastCGI的超时时间，如：600<br><strong>fastcgi_send_timeout</strong>：向FastCGI传送请求的超时时间，如：600<br><strong>fastcgi_read_timeout</strong>：指定接收FastCGI应答的超时时间，如：600<br><strong>fastcgi_buffer_size</strong>：指定读取FastCGI应答第一部分需要用多大的缓冲区，默认的缓冲区大小为fastcgi_buffers指令中的每块大小，可以将这个值设置更小，如： 64k。<br><strong>fastcgi_buffers</strong>：指定本地需要用多少和多大的缓冲区来缓冲FastCGI的应答请求，如果一个php脚本所产生的页面大小为256KB，那么会分配4个64KB的缓冲区来缓存，如果页面大小大于256KB，那么大于256KB的部分会缓存到fastcgi_temp_path指定的路径中，但是这并不是好方法，因为内存中的数据处理速度要快于磁盘。一般这个值应该为站点中php脚本所产生的页面大小的中间值，如果站点大部分脚本所产生的页面大小为256KB，那么可以把这个值设置为“8 32K”、“4 64k”等。如：4 64k<br><strong>fastcgi_busy_buffers_size</strong>：建议设置为fastcgi_buffers的两倍，繁忙时候的buffer，如：128k<br><strong>fastcgi_temp_file_write_size</strong>：在写入fastcgi_temp_path时将用多大的数据块，默认值是fastcgi_buffers的两倍，该数值设置小时若负载上来时可能报502BadGateway，如：128k<br><strong>fastcgi_temp_path</strong>：缓存临时目录<br><strong>fastcgi_intercept_errors</strong>：这个指令指定是否传递4xx和5xx错误信息到客户端，或者允许nginx使用error_page处理错误信息，如：on<br><strong>fastcgi_cache_path</strong>：如： &#x2F;usr&#x2F;local&#x2F;nginx1.10&#x2F;fastcgi_cachelevels&#x3D;1:2 <strong>keys_zone&#x3D;cache_fastcgi:128minactive&#x3D;1d max_size&#x3D;10g</strong>： fastcgi_cache缓存目录，可以设置目录层级，比如1:2会生成16*256个子目录，cache_fastcgi是这个缓存空间的名字，cache是用多少内存（这样热门的内容nginx直接放内存，提高访问速度），inactive表示默认失效时间，如果缓存数据在失效时间内没有被访问,将被删除，max_size表示最多用多少硬盘空间。<br><strong>fastcgi_cache cache_fastcgi</strong>：表示开启FastCGI缓存并为其指定一个名称。开启缓存非常有用，可以有效降低CPU的负载，并且防止502的错误放生。<strong>cache_fastcgi</strong>：为proxy_cache_path指令创建的缓存区名称</li></ul><p><strong>fastcgi_cache_valid 200 302 1h</strong>：用来指定应答代码的缓存时间，实例中的值表示将200和302应答缓存一小时，要和fastcgi_cache配合使用<br><strong>fastcgi_cache_valid 301 1d</strong>：将301应答缓存一天<br><strong>fastcgi_cache_valid any 1m</strong>：将其他应答缓存为1分钟<br><strong>fastcgi_cache_min_uses 1</strong>：该指令用于设置经过多少次请求的相同URL将被缓存。<br><strong>fastcgi_cache_key http:&#x2F;&#x2F;$host$request_uri</strong>：该指令用来设置web缓存的Key值,nginx根据Key值md5哈希存储.一般根据$host(域名)、$request_uri(请求的路径)等变量组合成proxy_cache_key 。<br><strong>fastcgi_pass</strong>：指定FastCGI服务器监听端口与地址，可以是本机或者其它</p><blockquote><p>总结：<br>nginx的缓存功能有：proxy_cache &#x2F; fastcgi_cache<br>proxy_cache的作用是缓存后端服务器的内容，可能是任何内容，包括静态的和动态。proxy_cache缓存减少了nginx与后端通信的次数，节省了传输时间和后端宽带。<br>fastcgi_cache的作用是缓存fastcgi生成的内容，很多情况是php生成的动态的内容。fastcgi_cache缓存减少了nginx与php的通信的次数，更减轻了php和数据库(mysql)的压力。</p></blockquote><ul><li><p><strong>gzip调优</strong><br>使用gzip压缩功能，可能为我们节约带宽，加快传输速度，有更好的体验，也为我们节约成本，所以说这是一个重点。Nginx启用压缩功能需要你来ngx_http_gzip_module模块，apache使用的是mod_deflate。一般我们需要压缩的内容有：文本，js，html，css，对于图片，视频，flash什么的不压缩，同时也要注意，我们使用gzip的功能是需要消耗CPU的！如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gzip on;</span><br><span class="line">gzip_min_length 2k;</span><br><span class="line">gzip_buffers    4 32k;</span><br><span class="line">gzip_http_version 1.1;</span><br><span class="line">gzip_comp_level 6;</span><br><span class="line">gzip_typestext/plain text/css text/javascriptapplication/json application/javascript application/x-javascriptapplication/xml;</span><br><span class="line">gzip_vary on;</span><br><span class="line">gzip_proxied any;</span><br></pre></td></tr></table></figure><p><strong>gzip on</strong>：开启压缩功能<br><strong>gzip_min_length 1k</strong>：设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取，默认值是0，不管页面多大都进行压缩，建议设置成大于1K，如果小与1K可能会越压越大。<br><strong>gzip_buffers 4 32k</strong>：压缩缓冲区大小，表示申请4个单位为32K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。<br><strong>gzip_http_version 1.1</strong>：压缩版本，用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可<br><strong>gzip_comp_level 6</strong>：压缩比例，用来指定GZIP压缩比，1压缩比最小，处理速度最快，9压缩比最大，传输速度快，但是处理慢，也比较消耗CPU资源。<br><strong>gzip_types text&#x2F;css text&#x2F;xml application&#x2F;javascript</strong>：用来指定压缩的类型，‘text&#x2F;html’类型总是会被压缩。默认值: gzip_types text&#x2F;html (默认不对js&#x2F;css文件进行压缩)<br><strong>gzip_vary on</strong>：varyheader支持，改选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过nginx压缩的数据</p></li><li><p><strong>expires缓存调优</strong><br>缓存，主要针对于图片，css，js等元素更改机会比较少的情况下使用，特别是图片，占用带宽大，我们完全可以设置图片在浏览器本地缓存365d，css，js，html可以缓存个10来天，这样用户第一次打开加载慢一点，第二次，就非常快了！缓存的时候，我们需要将需要缓存的拓展名列出来， Expires缓存配置在server字段里面，如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">location ~* \.(ico|jpe?g|gif|png|bmp|swf|flv)$ &#123;</span><br><span class="line">  expires 30d;</span><br><span class="line">  #log_not_found off;</span><br><span class="line">  access_log off;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location ~* \.(js|css)$ &#123;</span><br><span class="line">  expires 7d;</span><br><span class="line">  log_not_found off;</span><br><span class="line">  access_log off;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>注：log_not_found off;是否在error_log中记录不存在的错误。默认是。</p><blockquote><p> 总结：<br><strong>expire功能优点</strong><br>  expires可以降低网站购买的带宽，节约成本<br>  同时提升用户访问体验<br> 减轻服务的压力，节约服务器成本，是web服务非常重要的功能。 expire功能&gt; <strong>expire功能缺点</strong><br>被缓存的页面或数据更新了，用户看到的可能还是旧的内容，反而影响用户体验。<br><strong>解决办法</strong><br>缩短缓存时间，例如：1天，但不彻底，除非更新频率大于1天<br>对缓存的对象改名。<br><strong>网站不希望被缓存的内容</strong><br>网站流量统计工具<br>更新频繁的文件（google的logo）</p></blockquote></li><li><p><strong>防盗链</strong><br>防止别人直接从你网站引用图片等链接，消耗了你的资源和网络流量，那么我们的解决办法由几种：<br>1：水印，品牌宣传，你的带宽，服务器足够<br>2：防火墙，直接控制，前提是你知道IP来源<br>3：防盗链策略下面的方法是直接给予404的错误提示<br>如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">location ~*^.+\.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ &#123;</span><br><span class="line">    valid_referers noneblocked  www.benet.com benet.com;</span><br><span class="line">    if($invalid_referer) &#123;</span><br><span class="line">      #return 302  http://www.benet.com/img/nolink.jpg;</span><br><span class="line">      return 404;</span><br><span class="line">        break;</span><br><span class="line">    &#125;</span><br><span class="line">    access_log off;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>参数可以使如下形式：none 意思是不存在的Referer头(表示空的，也就是直接访问，<strong>比如直接在浏览器打开一个图片</strong>)blocked 意为根据防火墙伪装Referer头，如：“Referer:XXXXXXX”。server_names 为一个或多个服务器的列表，0.5.33版本以后可以在名称中<strong>使用“*”通配符</strong>。</p></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.jianshu.com/p/81445f571590">配置nginx</a><br><a href="https://github.com/jinhailang/blog/issues/37">Nginx keepalive_requests 踩坑总结</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift上使用Nginx-Pod作灰度发布</title>
      <link href="/DevOps/Openshift%E4%B8%8A%E4%BD%BF%E7%94%A8Nginx-Pod%E4%BD%9C%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/"/>
      <url>/DevOps/Openshift%E4%B8%8A%E4%BD%BF%E7%94%A8Nginx-Pod%E4%BD%9C%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<p>参考文章：<a href="https://www.hi-linux.com/posts/34319.html">使用 Nginx 实现灰度发布</a></p><h2 id="什么是灰度发布"><a href="#什么是灰度发布" class="headerlink" title="什么是灰度发布"></a>什么是灰度发布</h2><ul><li><strong>【百度百科】</strong>灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。 在其上可以进行A&#x2F;B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。</li><li>除了AB test灰度发布另一种思想是，只发布给一小部分用户，如：App在发布之前，针对性的给一小批用户测试下新版本，用小流量发布的方式来检验新版会不会有问题。</li><li>灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</li></ul><h2 id="Openshift上实现蓝绿部署"><a href="#Openshift上实现蓝绿部署" class="headerlink" title="Openshift上实现蓝绿部署"></a>Openshift上实现蓝绿部署</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/00472755cfacfe28e76746d5d43683ff92f28d60ba530b0ed064b469ae684acc.png" alt="picture 1">  </p><p>在openshift上的部署两个版本的Service：service01, service02。在创建Route的时候，可以非常简单地指定同一个Route流量访问两个service的百分比service01（25%流量）, service02（75%流量）。所有请求该Route的流量会被按指定的比例访问后service。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e191c629ec495c171cf7fd001226760317951530c0906047970f76c2311a7a12.png" alt="配置发布75%-25%">  </p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/5e94cef1338452ce703a4143346fda4b34c6bca996e748ae30564a2238d1f6dd.png" alt="Route详情展示">  </p><p>对应的Route yaml配置文件如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: grey-test</span><br><span class="line">  name: grey-test</span><br><span class="line">  namespace: grey</span><br><span class="line">spec:</span><br><span class="line">  alternateBackends:</span><br><span class="line">    - kind: Service</span><br><span class="line">      name: service_v2</span><br><span class="line">      weight: 75</span><br><span class="line">  host: grey-test.sample.com</span><br><span class="line">  port:</span><br><span class="line">    targetPort: web</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: service_v1</span><br><span class="line">    weight: 25</span><br><span class="line">  wildcardPolicy: None</span><br></pre></td></tr></table></figure><blockquote><p>金丝雀发布的不足</p></blockquote><ul><li>openshift中Route自带的金丝雀发布配置非常简单，也很实用。但是它没办法对请求的流量进行定义控制。</li><li>例如根据IP，指定IP为’202.38.12.10’的用户访问service_v2,那么Openshift中Route自带的分流就无法实现。</li><li>所以必须对特定用户访问特定版本的问题，我们需要寻求其它办法。使用传统的方法，Nginx是一个比较常见的选择。在openshift的灰度方案中，我们也尝试使用Nginx来实现对特定用户的灰度发布。</li></ul><h2 id="Nginx配置实现灰度发布"><a href="#Nginx配置实现灰度发布" class="headerlink" title="Nginx配置实现灰度发布"></a>Nginx配置实现灰度发布</h2><ol><li>创建两个upstream</li><li>针对remote_addr进行分流，默认访问default的upstream，如果ip为’202.38.12.10’，则访问api_v2的upstream。</li></ol><p>无需多解释，直接上配置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">upstream default&#123;</span><br><span class="line">    server 172.30.198.194:8080 max_fails=1 fail_timeout=60;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream api_v2&#123;</span><br><span class="line">    server 172.30.198.194:8080 max_fails=1 fail_timeout=60;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name  _;</span><br><span class="line"></span><br><span class="line">  set $group default;</span><br><span class="line">  if ($remote_addr ~ &quot;202.38.12.10&quot;) &#123;</span><br><span class="line">      set $group api_v2;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">location / &#123;                       </span><br><span class="line">    proxy_pass http://$group;</span><br><span class="line">    proxy_set_header   Host             $host;</span><br><span class="line">    proxy_set_header   X-Real-IP        $remote_addr;</span><br><span class="line">    proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    index  index.html index.htm;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="对配置作进一步优化"><a href="#对配置作进一步优化" class="headerlink" title="对配置作进一步优化"></a>对配置作进一步优化</h2><blockquote><p>怎么获取客户端IP？</p></blockquote><ul><li><p>如果直接访问Nginx服务的话，在Nginx上通过 <strong>$remote_addr</strong> 能够获得客户端IP，但是我们知道在Openshift高可用部署中，我们使用了负载均衡器。通过负载均衡器转发后，Nginx webserver获得的$remote_addr其实是负载均衡器的IP，而不是客户端真实IP。</p></li><li><p>为了能在Nginx webserver中获得客户端IP，需要在附加HTTP头字段开启客户端真实IP。同时在Nginx的配置中使用$http_x_forwarded_for来检查客户端IP.<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/5a75901d2c8871a031bf87668c7cd0cadc1c8130c79b722d4ff32a9ca536a3f9.png" alt="IaaS上创建负载均衡器">  </p></li><li><p>新的配置如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">upstream default&#123;</span><br><span class="line">    server 172.30.198.194:8080 max_fails=1 fail_timeout=60;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream api_v2&#123;</span><br><span class="line">    server 172.30.198.194:8080 max_fails=1 fail_timeout=60;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">  listen 80;</span><br><span class="line">  server_name  _;</span><br><span class="line"></span><br><span class="line">  set $group default;</span><br><span class="line">  if ($http_x_forwarded_for ~ &quot;202.38.12.10&quot;) &#123;</span><br><span class="line">      set $group api_v2;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">location / &#123;                       </span><br><span class="line">    proxy_pass http://$group;</span><br><span class="line">    proxy_set_header   Host             $host;</span><br><span class="line">    proxy_set_header   X-Real-IP        $remote_addr;</span><br><span class="line">    proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    index  index.html index.htm;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>如何实现高可用？</p></blockquote></li></ul><p>这个非常简单，只需要在Openshift上将为Nginx的DeploymentConfig增加Pod数增就可以了。</p><blockquote><p>我要有多个IP加入白名单，有没有更方便的配置方法？</p></blockquote><p>Nginx有map函数，能将IP与访问的后台服务。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">map $http_x_forwarded_for $group &#123;</span><br><span class="line">        default 172.30.198.194:8080;</span><br><span class="line">        ~202.38.12.10 172.30.198.194:8080;</span><br><span class="line">    &#125;</span><br><span class="line">server&#123;</span><br><span class="line">    listen  8080;</span><br><span class="line">    server_name _; </span><br><span class="line">    location /&#123;</span><br><span class="line">        proxy_pass http://$group;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for;</span><br><span class="line">        index index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><blockquote><p>明明有域名为啥只能是IP？</p></blockquote><ul><li>Openshift对于Service除了有固定的IP外，还有固定的域名，一般域名形式为：servername-projectname.svc。我们能否用域名代替IP,让这个配置的可读性更高，什么IP访问什么服务一目了然。</li><li>但是直接将IP更改为对应Service的域名，在启动Nginx时会报无法解析域名的错误。</li><li>Nginx需要在map配置中解析域名需要指定dns。</li><li>最终配置如下（172.30.0.1为Openshif集群默认的内部DNS，可在master的配置文件中查看）：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">resolver 172.30.0.1;</span><br><span class="line">map $http_x_forwarded_for $group &#123;</span><br><span class="line">        default api_v1.server.svc:8080;</span><br><span class="line">        ~202.38.12.10 api_v2.server.svc:8080;</span><br><span class="line">    &#125;</span><br><span class="line">server&#123;</span><br><span class="line">    listen  8080;</span><br><span class="line">    server_name _; </span><br><span class="line">    location /&#123;</span><br><span class="line">        proxy_pass http://$group;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for;</span><br><span class="line">        index index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li></ul><blockquote><p>Openshift中对于443端口的负载均衡器使用的是TCP协议，无法转发X_forward_for，那https服务要怎么弄？</p></blockquote><p>如何应用请求为Https，无法直接使用TCP负载均衡器，而Openshift部署时是通过TCP负载均衡器来作443端口的负载的。</p><ul><li>这就需要创建一个Https负载均衡器， 后台Openshift Nginx的Route设置为正常的Http。其它配置一样。既能将clientIP传给后台webserver，同时又满足了该业务请求为Http协议。</li><li>最终的流程图如下：<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e43b139ab73c0d2d49e6f29cd099dba1d464d9bccbb21ceb10ffc566f7aae849.png" alt="Nginx作负载均衡器图"></li></ul><h2 id="拓展思考"><a href="#拓展思考" class="headerlink" title="拓展思考"></a>拓展思考</h2><ul><li>是否一定要在Openshift上部署呢?【必然不需要】</li><li>Nginx实现灰度发布除了支持ip还支持啥？【对Header头信息等】</li><li>除了对页面HTTP请求实现这种灰度，那么对于TCP服务呢，比如说数据库？【也是OK的】</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOPS对配置文件数据进行加密</title>
      <link href="/DevOps/SOPS%E5%AF%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%8A%A0%E5%AF%86/"/>
      <url>/DevOps/SOPS%E5%AF%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%8A%A0%E5%AF%86/</url>
      
        <content type="html"><![CDATA[<p><strong>SOPS</strong> 是由Mozilla 开发的一款开源的文本编辑工具，它支持对YAML, JSON, ENV, INI 和BINARY 文本格式的文件进行编辑，并利用AWS KMS, GCP KMS, Azure Key Vault 或PGP 等加密方式对编辑的文件进行加密和解密。<br>在当前它还可以与heml secret作用，为Kubernetes的secret资源数据进行加密。<br>本篇主要介绍sops的基本用法，而helm secret的使用不做介绍。</p><p>##GPG进行加密</p><ol><li>生成GPG文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gpg --generate-key <span class="comment"># 根据引导生成gpg加密文件</span></span></span><br></pre></td></tr></table></figure>或者自动生成<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">gpg --batch --generate-key &lt;&lt;EOF</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash"><span class="built_in">echo</span> Generating a basic OpenPGP key <span class="keyword">for</span> HELM Secret</span></span><br><span class="line">Key-Type: RSA</span><br><span class="line">Key-Length: 4096</span><br><span class="line">Subkey-Type: RSA</span><br><span class="line">Subkey-Length: 4096</span><br><span class="line">Name-Real: Michael</span><br><span class="line">Name-Comment: Personal PGP</span><br><span class="line">Name-Email: mpan@sample.com</span><br><span class="line">Expire-Date: 0</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">no-ask-passphrase</span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">no-protection</span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">commit</span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash"><span class="built_in">echo</span> <span class="keyword">done</span></span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>查看GPG列表<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gpg -k</span></span><br><span class="line">/home/vagrant/.gnupg/pubring.kbx</span><br><span class="line">--------------------------------</span><br><span class="line">pub   rsa3072 2021-04-07 [SC] [expires: 2023-04-07]</span><br><span class="line">      FA21E3EDC58BA05535435756543DF0088828FFCC</span><br><span class="line">uid           [ultimate] Michael &lt;micael@example.com&gt;</span><br><span class="line">sub   rsa3072 2021-04-07 [E] [expires: 2023-04-07]</span><br></pre></td></tr></table></figure></li><li>使用SOPS对文件a.yaml进行加密<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;A: hello&quot;</span> &gt; a.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sops --gpg FA21E3EDC58BA05535435756543DF0088828FFCC -e file.yaml &gt; file_encode.yaml</span></span><br></pre></td></tr></table></figure></li><li>解密文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sops -d file_encode.yaml</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#或者 使用sops file_encode.yaml对加密文件直接编辑</span></span></span><br></pre></td></tr></table></figure></li><li>通过.sops.yaml来设置默认加密规则<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF &gt; .sops.yaml</span></span></span><br><span class="line">creation_rules:</span><br><span class="line">        - pgp: &#x27;FA21E3EDC58BA05535435756543DF0088828FFCC&#x27;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><strong>公钥用于加密，私钥用于解密。</strong>它们的导入与导出对于文件的传输与交流很重要。</li><li>公钥导入与导出<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"> $ </span><span class="language-bash">gpg --<span class="built_in">export</span> --armor <span class="string">&quot;mpan@sample.com&quot;</span> &gt; personal_gpg.pub</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gpg --import personal_gpg.pub</span></span><br></pre></td></tr></table></figure></li><li>私钥的导入与导出<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpg --export-secret-key -a &quot;mpan@sample.com&quot; &gt; personal_gpg</span><br><span class="line">gpg --import  personal_gpg</span><br></pre></td></tr></table></figure></li><li>删除公钥与私钥<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gpg --delete-keys FA21E3EDC58BA05535435756543DF0088828FFCC</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">gpg --delete-secret-keys FA21E3EDC58BA05535435756543DF0088828FFCC</span></span><br></pre></td></tr></table></figure></li><li>保存gpg密钥的网站（可选）<br>KeyBase：<a href="https://keybase.io/">https://keybase.io/</a><br>KeysOpenPGP<a href="https://keys.openpgp.org/">https://keys.openpgp.org/</a></li></ol><h2 id="KMS加密"><a href="#KMS加密" class="headerlink" title="KMS加密"></a>KMS加密</h2><ol><li>在aws平台的KMS服务创建一个密钥，获取它的arn ID</li><li>文件加密时使用–kms设置加密密钥。<code>前提是当前aws客户端已经设置了认证私钥，并赋予了访问该kms密钥的权限</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sops --kms <span class="string">&quot;arn:aws:kms:ap-east-1:982938942:key/f2232fa3-7678-8922-8778-f2232fa3&quot;</span> -e file.yaml &gt; file_encode.yaml</span></span><br></pre></td></tr></table></figure></li><li>解密文件方式一致<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sops -d file_encode.yaml</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="使用Age加密"><a href="#使用Age加密" class="headerlink" title="使用Age加密"></a>使用Age加密</h2><p><a href="https://github.com/FiloSottile/age">Age</a> 是一个简单，现代和安全的文件加密工具。</p><ol><li>安装<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">brew tap filippo.io/age https://filippo.io/age</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">brew install age</span></span><br></pre></td></tr></table></figure></li><li>生成密钥对<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">age-keygen -o key.txt</span></span><br><span class="line">Public key: age1st0m5a72gtlk3pz3fnvy08huq8d9llut2vnjwxzkeudejkc0fs9s6dj9ev</span><br></pre></td></tr></table></figure></li><li>使用公钥对数据进行加密<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sops -a age1st0m5a72gtlk3pz3fnvy08huq8d9llut2vnjwxzkeudejkc0fs9s6dj9ev -e secrets.yaml &gt; secrets_enc.yaml</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><ol><li>在解密时报如下错误<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-focal:~$ sops a2.yaml</span><br><span class="line">Failed to get the data key required to decrypt the SOPS file.</span><br><span class="line"></span><br><span class="line">Group 0: FAILED</span><br><span class="line">  FA21E3EDC58BA05535435756543DF0088828FFCC: FAILED</span><br><span class="line">    - | could not decrypt data key with PGP key:</span><br><span class="line">      | golang.org/x/crypto/openpgp error: Could not load secring:</span><br><span class="line">      | open /home/vagrant/.gnupg/secring.gpg: no such file or</span><br><span class="line">      | directory; GPG binary error: exit status 2</span><br></pre></td></tr></table></figure>需要设置GPG_TTY环境变量<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export GPG_TTY=$(tty)</span><br></pre></td></tr></table></figure></li></ol><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://my.oschina.net/u/3952901/blog/4409303">Helm 插件之 helm-secrets：利用 PGP 加密你的 Values 文件</a><br><a href="https://github.com/mozilla/sops/issues/304">Cannot decrypt with GPG 2.2.5 and SOPS 3.0.0 #304</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scrum敏捷开发</title>
      <link href="/DevOps/Scrum%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"/>
      <url>/DevOps/Scrum%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<h2 id="团队成员"><a href="#团队成员" class="headerlink" title="团队成员"></a>团队成员</h2><ul><li>一般情况人数在5~9个左右</li><li>团队要跨职能(包含开发人员、测试人员、用户介面设计师<br>等)</li><li>团队成员构成在Sprint内不允许变化。</li></ul><h2 id="用户故事建模"><a href="#用户故事建模" class="headerlink" title="用户故事建模"></a>用户故事建模</h2><p>为开发任务需求编写用户故事</p><table><thead><tr><th>重要性</th><th>用户故事</th><th>测试方法</th><th>预估时间</th></tr></thead><tbody><tr><td>30</td><td>做为一个会员，可以查看自己的购物清单，以便一起购买</td><td>登录，点击购买清单Tab</td><td>16h</td></tr></tbody></table><h2 id="Sprint计划会议（两周一次，4个小时）"><a href="#Sprint计划会议（两周一次，4个小时）" class="headerlink" title="Sprint计划会议（两周一次，4个小时）"></a>Sprint计划会议（两周一次，4个小时）</h2><ul><li>设定本Sprint目标及优先级</li><li>挑选本Sprint所要开发的需求（Story)</li><li>逐一将Story细分成Task</li><li>确定每日站会时间和地点</li><li>确定演示会议和回顾会议日期<br>计划会议输出：</li></ul><table><thead><tr><th>Story</th><th>Task</th><th>Hour</th></tr></thead><tbody><tr><td>A</td><td>1. 编写自动化验收测试<br>2. 设计用户界面<br>3. 编写用户界面程序代码<br> 4. 编写数据库代码<br>5. 编写单元测试<br> 6. 人工测试</td><td>3h<br>5h<br>8h<br>8h<br>8h<br>8h</td></tr><tr><td>B</td><td>1. 编写自动化验收测试<br>2. 设计用户界面<br>3. 编写用户界面程序代码<br> 4. 编写数据库代码<br>5. 编写单元测试<br> 6. 人工测试</td><td>3h<br>5h<br>8h<br>8h<br>8h<br>8h</td></tr><tr><td>第日立会为早上9：00至9：15</td><td></td><td></td></tr><tr><td>Demo演示时间为：2018-07-10 上午10：00-12：00</td><td></td><td></td></tr><tr><td>回顾会议：2018-07-10 下午3：30-4：00</td><td></td><td></td></tr></tbody></table><h2 id="每日立会（15分钟）"><a href="#每日立会（15分钟）" class="headerlink" title="每日立会（15分钟）"></a>每日立会（15分钟）</h2><ul><li>昨天做了什么</li><li>今天要做什么</li><li>遇到的问题</li><li>更新燃尽图</li></ul><h2 id="Sprint评审会（2个小时）"><a href="#Sprint评审会（2个小时）" class="headerlink" title="Sprint评审会（2个小时）"></a>Sprint评审会（2个小时）</h2><ul><li>团队展示Sprint中完成的功能</li><li>简单议程</li><li>全员参与</li><li>关闭Sprint</li></ul><h2 id="回顾会（2个小时内）"><a href="#回顾会（2个小时内）" class="headerlink" title="回顾会（2个小时内）"></a>回顾会（2个小时内）</h2><ul><li>讨论做得好的，有待改善的</li><li>就1-3个关键问题提出解决方案</li><li>对改进点分配专门人员进行跟踪，确保改进方案得到实施</li><li>全员参加<br>回顾会输出：</li><li>本次Sprint团队状况（总工时等）</li><li>记录做得好的与有待完善的点</li><li>对于有待完善的点的改进方案</li><li>对1-3个改进方案指定跟进人员</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SonarQube应用离线安装插件</title>
      <link href="/DevOps/SonarQube%E5%BA%94%E7%94%A8%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%8F%92%E4%BB%B6/"/>
      <url>/DevOps/SonarQube%E5%BA%94%E7%94%A8%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%8F%92%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p>SonarQube的插件地址为：<a href="https://binaries.sonarsource.com/Distribution/">https://binaries.sonarsource.com/Distribution/</a><br>将下载的插件文件存放在SonarQube应用的<code>/opt/sonarqube/extensions/plugins</code>目录下。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://my.oschina.net/u/1762727/blog/2878397">Sonar 离线安装插件</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vagrant常用操作</title>
      <link href="/DevOps/Vagrant%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/DevOps/Vagrant%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="查看安装的插件列表"><a href="#查看安装的插件列表" class="headerlink" title="查看安装的插件列表"></a>查看安装的插件列表</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant plugin list</span></span><br></pre></td></tr></table></figure><h2 id="安装vagrant插件"><a href="#安装vagrant插件" class="headerlink" title="安装vagrant插件"></a>安装vagrant插件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant plugin install vagrant-disksize vagrant-ignition vagrant-vbguest</span></span><br></pre></td></tr></table></figure><h2 id="查看box列表"><a href="#查看box列表" class="headerlink" title="查看box列表"></a>查看box列表</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant box list</span></span><br></pre></td></tr></table></figure><h2 id="添加一个新的box"><a href="#添加一个新的box" class="headerlink" title="添加一个新的box"></a>添加一个新的box</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant box add centos-76 centos-76.box</span></span><br></pre></td></tr></table></figure><h2 id="将一个虚拟机导出为box"><a href="#将一个虚拟机导出为box" class="headerlink" title="将一个虚拟机导出为box"></a>将一个虚拟机导出为box</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant package --output  centos-7.6.box</span></span><br></pre></td></tr></table></figure><h2 id="删除一个box"><a href="#删除一个box" class="headerlink" title="删除一个box"></a>删除一个box</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant box remove centos-76</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSL2-+-microK8s-+-K8s</title>
      <link href="/DevOps/WSL2-+-microK8s-+-K8s/"/>
      <url>/DevOps/WSL2-+-microK8s-+-K8s/</url>
      
        <content type="html"><![CDATA[<ol><li><p>Windowns 10 (WSL2) + Ubuntu 20.04 </p></li><li><p>enable systemd snapd microk8s</p></li><li><p>启动systemd，并使用snap安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$  sudo apt install daemonize</span><br><span class="line">$ sudo daemonize /usr/bin/unshare --fork --pid --mount-proc /lib/systemd/systemd --system-unit=basic.target</span><br><span class="line">$ sudo nsenter -t $(pidof systemd) -a su - $LOGNAME</span><br></pre></td></tr></table></figure></li><li><p>安装microk8s</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ snap info microk8s</span><br><span class="line">$ sudo snap install microk8s --classic</span><br></pre></td></tr></table></figure></li><li><p>使用microk8s</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ microk8s status</span><br><span class="line">$ sudo usermod -a -G microk8s mpan</span><br><span class="line">$ sudo chown -f -R mpan ~/.kube</span><br></pre></td></tr></table></figure></li><li><p>添加节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ microk8s add-node </span><br></pre></td></tr></table></figure></li></ol><p><strong>注意</strong> 每次使用microk8s时，需要先进入它的namespace</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nsenter -t $(pidof systemd) -a su - $LOGNAME</span><br></pre></td></tr></table></figure><p>K8S<br><a href="https://github.com/AliyunContainerService/k8s-for-docker-desktop">https://github.com/AliyunContainerService/k8s-for-docker-desktop</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ansible通过跳板机管理另一个网络下的主机集群</title>
      <link href="/DevOps/ansible%E9%80%9A%E8%BF%87%E8%B7%B3%E6%9D%BF%E6%9C%BA%E7%AE%A1%E7%90%86%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E4%B8%8B%E7%9A%84%E4%B8%BB%E6%9C%BA%E9%9B%86%E7%BE%A4/"/>
      <url>/DevOps/ansible%E9%80%9A%E8%BF%87%E8%B7%B3%E6%9D%BF%E6%9C%BA%E7%AE%A1%E7%90%86%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E4%B8%8B%E7%9A%84%E4%B8%BB%E6%9C%BA%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<p>原文地址：<a href="http://wooooe.com/2018/07/31/remote_forwarding/">http://wooooe.com/2018/07/31/remote_forwarding&#x2F;</a></p><p>ssh端口映射例子</p><p>因为公司的网络比较深所以经常需要跳转多次。所以这次做个记录</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/1eef3a75dc2f4c45fd229c3f112b58432a51d2383683e9f674d83b62cd8e3b04.png" alt="服务器结构">  </p><p>需求: 需要从your host跳到client中间隔了两层跳板机。</p><p>如果单纯用代理方法只能跳一层</p><p>所以如果用端口映射+代理方式就可以跳两层了</p><p>映射命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -g -f -NL 127.0.0.1:44010:172.16.3.14:22 -p 3391 jump_host1_username@222.222.222.222</span><br></pre></td></tr></table></figure><p>意思就是将172.16.3.14的22端口映射到127.0.0.1的44010端口,222.222.222.222是中间的代理机，3391是222.222.222.222的ssh端口。</p><p>映射完成之后。执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 44010 jump_host2_username@127.0.0.1</span><br></pre></td></tr></table></figure><p>就可以直接跳转到jump_host2上</p><p><strong>ssh走代理方法</strong></p><p>第一种:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -o ProxyCommand=&quot;ssh -W %h:%p -p 3391 -q jump_host1_username@222.222.222.222&quot; jump_host2_username@172.16.3.14</span><br></pre></td></tr></table></figure><p>第二种:</p><p>需要在你当前用户目录下的.ssh目录下建一个config文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Host 192.122.150.*</span><br><span class="line">    Port 22</span><br><span class="line">    User anyone</span><br><span class="line">    ProxyCommand ssh -p 3391 jump_host1_username@222.222.222.222 -W %h:%p</span><br></pre></td></tr></table></figure><p>意思就是当你在当前这个用户进行ssh连接时凡是匹配到192.122.150的ip都会使用222.222.222.222的3391端口作代理.</p><p><strong>ansible使用代理的方法</strong></p><p>当你用playbook时可以直接写在hosts文件做全局变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[web]</span><br><span class="line">172.16.3.14 ansible_ssh_user=aaaa</span><br><span class="line">[web:vars]</span><br><span class="line">ansible_ssh_common_args=&#x27;-o ProxyCommand=&quot;ssh -W %h:%p -p 3391 -q jump_host1_username@222.222.222.222&quot;&#x27;</span><br></pre></td></tr></table></figure><p>如果你想直接附加在命令行中，那么可以这么写</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--ssh-common-args=&#x27;-o ProxyCommand=&quot;ssh -W %h:%p -p 3391 -q jump_host2_username@222.222.222.222&quot;&#x27;</span><br></pre></td></tr></table></figure><p>如果你想调用ansible api走代理，那么可以这么写</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Options = namedtuple(&#x27;Options&#x27;,</span><br><span class="line">                 [&#x27;connection&#x27;,</span><br><span class="line">                  &#x27;remote_user&#x27;,</span><br><span class="line">                  &#x27;ask_sudo_pass&#x27;,</span><br><span class="line">                  &#x27;verbosity&#x27;,</span><br><span class="line">                  &#x27;ack_pass&#x27;,</span><br><span class="line">                  &#x27;module_path&#x27;,</span><br><span class="line">                  &#x27;forks&#x27;,</span><br><span class="line">                  &#x27;become&#x27;,</span><br><span class="line">                  &#x27;become_method&#x27;,</span><br><span class="line">                  &#x27;become_user&#x27;,</span><br><span class="line">                  &#x27;ssh_common_args&#x27;,</span><br><span class="line">                  &#x27;check&#x27;,</span><br><span class="line">                  &#x27;listhosts&#x27;,</span><br><span class="line">                  &#x27;listtasks&#x27;,</span><br><span class="line">                  &#x27;listtags&#x27;,</span><br><span class="line">                  &#x27;syntax&#x27;,</span><br><span class="line">                  &#x27;sudo_user&#x27;,</span><br><span class="line">                  &#x27;sudo&#x27;,</span><br><span class="line">                  &#x27;diff&#x27;])</span><br><span class="line">options = Options(connection=&#x27;smart&#x27;,</span><br><span class="line">                   remote_user=None,</span><br><span class="line">                   ack_pass=None,</span><br><span class="line">                   sudo_user=None,</span><br><span class="line">                   forks=5,</span><br><span class="line">                   sudo=None,</span><br><span class="line">                   ask_sudo_pass=False,</span><br><span class="line">                   verbosity=5,</span><br><span class="line">                   module_path=None,</span><br><span class="line">                   become=None,</span><br><span class="line">                   become_method=None,</span><br><span class="line">                   become_user=None,</span><br><span class="line">                   ssh_common_args=sshCommonArgs,</span><br><span class="line">                   check=False,</span><br><span class="line">                   diff=False,</span><br><span class="line">                   listhosts=None,</span><br><span class="line">                   listtasks=None,</span><br><span class="line">                   listtags=None,</span><br><span class="line">                   syntax=None)</span><br></pre></td></tr></table></figure><p>你需要把参数传给sshCommonArgs,例如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh_common_args=&#x27;-o ProxyCommand=&quot;ssh -W %h:%p -p 3391 jump_host1_username@222.222.222.222&#x27;</span><br></pre></td></tr></table></figure><h2 id="ansible-tower设置"><a href="#ansible-tower设置" class="headerlink" title="ansible tower设置"></a>ansible tower设置</h2><ol><li>使用这种跳转方式，必须将<code>settings</code>-&gt;<code>JOBS</code>-&gt;<code>ENABLE JOB ISOLATION</code>设置为<code>OFF</code>状态</li><li>在Credentials中添加访问的私钥</li><li>Inventories中添加Jumper server Host</li><li>Inventories中添加要访问的Host，并添加ssh访问参数<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible_ssh_common_args: &#x27;-o ProxyCommand=&quot;ssh -W %h:%p -p 22 -q 100.129.71.4&#x27;</span><br></pre></td></tr></table></figure></li><li>通过这些设置后，ansible就可以像访问普通主机一样访问目的Host了。</li></ol><p>说明：</p><ul><li>如果私钥各不一样，可以通过HOST的参数设置，其中key放在ansible tower部署机器的某个目录下。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ansible_ssh_private_key_file: key</span><br><span class="line">ansible_ssh_common_args: &#x27;-o ProxyCommand=&quot;ssh -W %h:%p -p 22 -q 100.129.71.4&#x27;</span><br></pre></td></tr></table></figure></li><li>ansible tower还有一种方式：Isolated Nodes<br>它的方式与zabbix proxy的方式有点像，可参考如下资料<br><a href="https://www.ansible.com/blog/ansible-tower-feature-spotlight-instance-groups-and-isolated-nodes">https://www.ansible.com/blog/ansible-tower-feature-spotlight-instance-groups-and-isolated-nodes</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gogs创建用户</title>
      <link href="/DevOps/gogs%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7/"/>
      <url>/DevOps/gogs%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7/</url>
      
        <content type="html"><![CDATA[<p>&#x2F;opt&#x2F;gogs&#x2F;gogs admin create-user –name&#x3D;root –password&#x3D;123456 –admin&#x3D;true --email&#x3D;<a href="mailto:&#97;&#x62;&#x63;&#x40;&#49;&#50;&#x33;&#46;&#x63;&#111;&#x6d;">&#97;&#x62;&#x63;&#x40;&#49;&#50;&#x33;&#46;&#x63;&#111;&#x6d;</a> –config&#x3D;&#x2F;etc&#x2F;gogs&#x2F;conf&#x2F;app.ini</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc project cicd &amp;&amp;</span><br><span class="line">gogspodname=$(oc get pod | grep gogs | grep -v postgresql| awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">oc rsh $gogspodname /opt/gogs/gogs admin create-user --name=root --password=123456 --admin=true --email=abc@123.com --config=/etc/gogs/conf/app.ini</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《凤凰项目—一个IT运维的传奇故事》整理</title>
      <link href="/DevOps/%E3%80%8A%E5%87%A4%E5%87%B0%E9%A1%B9%E7%9B%AE%E2%80%94%E4%B8%80%E4%B8%AAIT%E8%BF%90%E7%BB%B4%E7%9A%84%E4%BC%A0%E5%A5%87%E6%95%85%E4%BA%8B%E3%80%8B%E6%95%B4%E7%90%86/"/>
      <url>/DevOps/%E3%80%8A%E5%87%A4%E5%87%B0%E9%A1%B9%E7%9B%AE%E2%80%94%E4%B8%80%E4%B8%AAIT%E8%BF%90%E7%BB%B4%E7%9A%84%E4%BC%A0%E5%A5%87%E6%95%85%E4%BA%8B%E3%80%8B%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>###《凤凰项目》三位作者</p><ul><li>Gene Kim: Tripwire有限公司创始人，一直热衷于研究如何提高IT组织的效率</li><li>Kevin Behr：创建了信息技术流程研究院</li><li>George Spafford：行业分析师</li></ul><p>向他们致敬。</p><h3 id="故事内容"><a href="#故事内容" class="headerlink" title="故事内容"></a>故事内容</h3><p>雨前龙井整理的非常详细，可阅读它写的博客<br> <a href="http://ijyun.github.io/2016/04/23/phoenix-project.html">凤凰项目</a> <a href="http://ijyun.github.io/2016/04/23/phoenix-project.html">http://ijyun.github.io/2016/04/23/phoenix-project.html</a></p><h3 id="书中的核心概念"><a href="#书中的核心概念" class="headerlink" title="书中的核心概念"></a>书中的核心概念</h3><blockquote><p>三步工作法</p></blockquote><p>本书中阐述了一个原理：所有开发运维模式都来自“三步工作法”，可以说它是我们平台开发运维的指导思想。</p><ul><li><strong>第一工作法</strong>是关于从开发到技术运营，再到客户的整个自左向右的工作流。为了使流量最大化，我们需要小的批量规模和工作间隔，绝不让缺陷流向下游工作中心，并且不断为了整体目标（相对于开发功能完成率、测试发现&#x2F;修复比例或运维有效性等局部目标）进行优化。<br><strong>流程自动化</strong></li></ul><p>实践：持续构建、持续集成、持续部署，按需创建环境、限制半成品，构建起能够顺利变更的安全系统和组织。</p><ul><li><strong>第二工作法</strong>是关于价值流各阶段自右向左的快速持续反馈流，放大其效益以确保防止问题再次发生，或者更快地发现和修复问题。这样，我们就能在所需之处获取或嵌入知识，从源头上保证质量。<br><strong>保证上游的质量</strong></li></ul><p>实践：在部署管道中的构建和测试失败时“停止生产线”、日复一日持续的改进日常工作、创建快速的自动化测试套装软件，以确保代码总是处于可部署的状态、在开发和技术运营之间建立共同的目标和共同的解决问题的机制、建立普遍的产品遥测技术，让每个人都能知道，产品和环境是否在按设定的运行，以及是否达到了客户的目标。</p><ul><li><strong>第三工作法</strong>是关于创造公司文化，该文化可带动两中风气的形成：不断尝试，这需要承担风险并从成功和失败中吸取经验教训、理解重复和联系是熟练掌握的前提、尝试和承担风险让我们能够不懈地改进工作系统，这经常要求我们去做一些和以往做法大不相同的事。一旦出现问题，不断重复的日常操作赋予我们的技能和经验，令我们可以撤回至安全区域并恢复正常运作。<br><strong>不断试错，持续改进</strong></li></ul><p>实践：营造一种勇于创新、敢于冒险（相对于畏惧和盲目服从命令）以及高度信任（相对于低信任度和命令控制）的文化；把至少20%的开发和技术运营周期划拨给非功能性需求，并且不断鼓励进行改进。</p><blockquote><p>四种工作类型</p></blockquote><ul><li><strong>业务项目</strong><br>多数开发项目所包含的业务举措，即业务部门的所有正式项目。</li><li><strong>IT内部项目</strong><br>可能由业务项目衍生出的基础架构或IT运维项目，以及内部生成的改进项目（如创建新环境和部署自动化）。</li><li><strong>变更</strong><br>由上述两种类型的工作引起，往往在报修系统中被跟踪。在价值流的两个部分，开发和运维中应该统一管理变更。</li><li><strong>计划外工作或救火工作</strong><br>包括操作事故和操作问题，通常由以上三种类型工作导致，往往会牺牲其它计划内的工作为代码，成本往往很高。通过采用三步工作法，减少计划外工作，即使发生计划外工作，也能快速解决。</li></ul><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p><strong>总结目标</strong>:拥有一条不断改进，能够自我反馈的自动化流水线。<br>开发运维并不仅仅是简单的自动化工具的集成，虽然自动化是开发运维的很大一部分内容。更重要的是价值流导向，自始至终拥有共同的目标并共同解决问题，需要把视野放得更大一些，而不是局限在运维的主机或服务上。<br>开发运维要提升自己的价值就需要将自己的工作与最终的业务关系挂钩，了解自己运维的系统是如何影响着业务，所以开发运维需要有同公司一致的目标。<br>如书中比尔与约翰在了解到公司业务目标后，思维一下子打开了，不再局限在眼前的系统与应用，而是有了更大的视野。他们一起约谈各业务部门负责人，清楚了解到各系统在业务上的位置，从而能够更好地去分配工作的优先级。</p><blockquote><p>引用</p></blockquote><p>《凤凰项目—一个IT运维的传奇故事》<br>凤凰项目 <a href="http://ijyun.github.io/2016/04/23/phoenix-project.html">http://ijyun.github.io/2016/04/23/phoenix-project.html</a><br>DevOps 漫谈:从作坊到工厂的寓言故事 <a href="https://riboseyim.github.io/2018/04/10/DevOps-Phoenix/">https://riboseyim.github.io/2018/04/10/DevOps-Phoenix/</a></p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ea5127a287e83fb46b6f0871ee16a757e542427d7e505652f78cfdc24e8b1a55.png" alt="凤凰项目—一个IT运维的传奇故事">  </p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《启示录：打造用户喜爱的产品》读书笔记</title>
      <link href="/DevOps/%E3%80%8A%E5%90%AF%E7%A4%BA%E5%BD%95%EF%BC%9A%E6%89%93%E9%80%A0%E7%94%A8%E6%88%B7%E5%96%9C%E7%88%B1%E7%9A%84%E4%BA%A7%E5%93%81%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/DevOps/%E3%80%8A%E5%90%AF%E7%A4%BA%E5%BD%95%EF%BC%9A%E6%89%93%E9%80%A0%E7%94%A8%E6%88%B7%E5%96%9C%E7%88%B1%E7%9A%84%E4%BA%A7%E5%93%81%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7ea9c30d42e84bf4558827e28233a82fd1452743487bb525dbe6d5e64fe259a4.png" alt="启示录：打造用户喜爱的产品">  </p><p><strong>好产品具备三个基本条件：价值、可用性、可行性，三者缺一不可。产品没有价值，开发团队再优秀也无济于事。</strong></p><h2 id="第一篇：人员"><a href="#第一篇：人员" class="headerlink" title="第一篇：人员"></a>第一篇：人员</h2><p>现代软件产品团队成员</p><ol><li>产品经理<br>职责：评估产品机会；定义要开发的产品。</li><li>用户体验设计师<br>交互设计师：负责深入理解目标用户，设计有价值的，可用的功能，以及用户导航和产品使用流程。<br>视觉设计师：根据交互设计原型，制作美观的产品界面</li><li>项目管理人员<br>产品经理完成产品定义后，开发团队开始开发产品。<br>项目经理核心任务：制订计划和跟踪进度。</li><li>开发团队<br>职责：负责产品的技术开发。</li><li>运维团队<br>职责：互联网服务产品通常运行在服务器上，保证服务正常运行。</li><li>产品营销人员<br>职责：负责对外发布信息、宣传产品，为扩展市场销售渠道、组织重点营销活动、促进产品销售提供支持</li></ol><h2 id="第二篇：流程"><a href="#第二篇：流程" class="headerlink" title="第二篇：流程"></a>第二篇：流程</h2><h3 id="11-评估产品机会——确定待解决的问题"><a href="#11-评估产品机会——确定待解决的问题" class="headerlink" title="11. 评估产品机会——确定待解决的问题"></a>11. 评估产品机会——确定待解决的问题</h3><p>只讨论待解决的问题，不应涉及具体解决方案。<br>产品经理需要回答如下十个问题：</p><ul><li>产品要解决什么问题？（产品价值）</li><li>为谁解决这个问题？（目标市场）</li><li>成功的机会有多大？（市场规模）</li><li>怎样判断产品成功与否？（度量指标或收益指标）</li><li>有哪些同类产品？（竞争格局）</li><li>为什么我们最适合做这个产品？（竞争优势）</li><li>时机合适吗？（市场时机）</li><li>如何把产品推向市场？（营销组合策略）</li><li>成功的必要条件是什么？（解决方案要满足的条件）</li><li>根据以上问题，给出评估结论。（继续或放弃）</li></ul><h3 id="12-产品探索——定义正确的产品"><a href="#12-产品探索——定义正确的产品" class="headerlink" title="12. 产品探索——定义正确的产品"></a>12. 产品探索——定义正确的产品</h3><p>软件项目可以划分为两个阶段：定义正确的产品、正确地开发产品。<br>采用流水线方式并行开发产品，在开发过程中，避免大幅更改产品需求，严重影响开发团队的开发。一旦1.0版本的产品进入项目执行阶段，就开始定义2.0版本的产品。<br>产品探索的过程：</p><ol><li>评估产品机会</li><li>与交互设计师一起制作产品原型</li><li>利用产品原型展开用户测试</li><li>完成产品用例，与开发团队一起评审产品原型和说明文档</li></ol><p>定义产品的过程是产品探索，它的工作是不可预测的。产品经理应该探索是否有用户需要产品，其次探索能够解决问题的产品方案必须是有价值的、可用的、可行的。<br>利用产品原型做产品的探索，而不要孤注一掷，用实际产品探索。在产品方案达到确认是有价值的、可用的、可行的后再全面转入执行阶段。</p><h3 id="13-产品原则——确定什么最重要"><a href="#13-产品原则——确定什么最重要" class="headerlink" title="13. 产品原则——确定什么最重要"></a>13. 产品原则——确定什么最重要</h3><blockquote><p>产品原则体现了产品团队的目标与愿景，是产品战略的重要组成部分。</p></blockquote><p>形式上看，产品原则是一系列明确的、体现团队特色的产品价值准则。不仅罗列出产品原则，还需要根据重要性对其进行排序。<br>如果你所在团队还没有制定清晰的、有关产品理念的产品原则，应该花时间确定团队最看重的价值理念。<br>在作产品决策之前，应该先确定决策要解决的问题，让大家在以下几个要点上达成共识：</p><ol><li>究竟要解决什么问题？</li><li>为谁解决这个问题？</li><li>产品要达到什么目标？</li><li>每项目标的优先级是什么？</li></ol><h3 id="14-产品评审团——制定更及时、更可靠的产品决策"><a href="#14-产品评审团——制定更及时、更可靠的产品决策" class="headerlink" title="14. 产品评审团——制定更及时、更可靠的产品决策"></a>14. 产品评审团——制定更及时、更可靠的产品决策</h3><ul><li>产品评审团的目标：决定产品战略方向，宏观上监督产品的研发流程，合理配置资源。产品战略需要在已定的商业战略的条件下。</li><li>产品评审团的成员：CEO&#x2F;COO&#x2F;部门总监理&#x2F;产品总监&#x2F;用户体验设计总监&#x2F;市场总监&#x2F;开发总监&#x2F;网站运营总监&#x2F;客服总监</li><li>产品评审团的职责：<ul><li>启动产品评估工作–&gt;产品经理开始评估产品机会</li><li>根据产品评估机会的结果，<strong>宣称要解决的问题是否有价值</strong>，决定是否开始定义产品的解决方案–&gt;开始定义产品解决方案，制作原型、用户测试、成本估算</li><li>根据<strong>产品原型</strong>、<strong>用户测试结果</strong>、<strong>成本估算明细</strong>，决定是否开发产品–&gt;开始开发产品</li><li>评审最终产品、产品质量、发布计划、社会效益，决定是否发布产品</li></ul></li></ul><p>成本评估分两个阶段进行：评估产品机会时做粗略估算，根据最终产品说明文档做详细估算。</p><h3 id="15-特约用户——产品开发伙伴"><a href="#15-特约用户——产品开发伙伴" class="headerlink" title="15. 特约用户——产品开发伙伴"></a>15. 特约用户——产品开发伙伴</h3><p>拥有一群忠实的、乐于推荐产品的用户会对产品的发布起到很大的促进作用。平台产品，最好提供一批起示范作用的应用程序。</p><blockquote><p>产品经理要深入了解目标用户，明确产品需要解决的问题，定义出满足用户需求的产品。</p></blockquote><ul><li>特约用户数量：8-10人，互联网服务可以是10-15人</li><li>特约用户注意事项：<ul><li>不要向特约用户收取参与费用。</li><li>人数不要超过10人，为满足大批心急用户，可发布预览版</li><li>如果寻找特约用户遇到困难，很可能产品机会价值不足，可以重新考虑产品计划</li><li>确保特约用户是产品的潜在目标用户</li><li>产品经理向特约用户承诺产品会持续开发</li><li>产品经理把特约用户当成开发伙伴，互相帮助</li><li>产品经理与特约用户的合作贯穿产品研发的每个环节：向他们展示产品原型，请他们参加测试，请教产品细节等</li><li>正式发布前，一定邀请特约用户试用，确保人人满意</li><li>产品经理还要和产品营销团队合作，帮忙物色特约用户，同时帮助提高特约用户的受关注度</li><li>平台产品的话，特约用户要换成特约应用，与特约应用的开发者紧密合作。</li></ul></li></ul><p>特约用户是确保产品不偏离用户需求最简单有效的办法。</p><h3 id="16-市场调研——理解市场调研的作用与局限性"><a href="#16-市场调研——理解市场调研的作用与局限性" class="headerlink" title="16. 市场调研——理解市场调研的作用与局限性"></a>16. 市场调研——理解市场调研的作用与局限性</h3><ul><li>市场调研的方法<ul><li>用户调查</li><li>产品使用分析</li><li>数据挖掘</li><li>拜访用户</li><li>人物角色</li><li>可用性测试</li><li>同类产品分析</li></ul></li><li>好的市场调研可以得到以下答案<ul><li>谁是目标用户？</li><li>用户会怎样使用产品？</li><li>用户能想明白怎样使用产品吗？障碍在哪里？</li><li>用户为什么选用你的产品？</li><li>用户喜欢产品的那些特点？</li><li>用户希望如何改进产品，增加哪些功能？</li></ul></li></ul><p>市场调研只能作为研发产品的依据和参考，不能决定产品研发的方向。可以用于完善现有产品，但不能用来定义新产品。<br>成功的产品基于：深入理解用户需求，以及明白怎样的解决方案在现阶段是可行的。</p><h3 id="17-产品人物角色——理解目标用户"><a href="#17-产品人物角色——理解目标用户" class="headerlink" title="17. 产品人物角色——理解目标用户"></a>17. 产品人物角色——理解目标用户</h3><ul><li>人物角色：又称为用户特征记录，指通过与用户沟通交流，确定典型的目标用户类型，在理解各类目标用户特征的基础上建立的人物原型。</li><li>产品经理必须深入参与创建人物角色的工作，尤其是参与用户交流和用户调查。</li><li>人物角色的用途<ul><li>用来筛选重要的产品功能。</li><li>可以帮助避免产品团队把自己的需求当成用户的需求</li><li>有助于对用户类型的优先级进行排序，识别重点需求</li><li>方便向团队描述产品的目标用户就谁，他们怎么使用产品，他们的关注点在哪里</li><li>帮助团队成员达成共识</li></ul></li></ul><h3 id="18-重新定义产品说明文档——安息吧，纸质说明文档"><a href="#18-重新定义产品说明文档——安息吧，纸质说明文档" class="headerlink" title="18.重新定义产品说明文档——安息吧，纸质说明文档"></a>18.重新定义产品说明文档——安息吧，纸质说明文档</h3><ul><li>主体：高保真产品原型</li><li>补充：用例描述重要的产品行为</li></ul><h3 id="19-用户体验设计与实现——先定义用户体验在动手开发"><a href="#19-用户体验设计与实现——先定义用户体验在动手开发" class="headerlink" title="19. 用户体验设计与实现——先定义用户体验在动手开发"></a>19. 用户体验设计与实现——先定义用户体验在动手开发</h3><ul><li>需求调研和产品设计（用户体验设计）应该同步开展。</li><li>用户体验设计与软件开发<strong>不能</strong>放在一起进行。</li><li>正确的做法是用户体验设计师做好设计后再开始开发，除非开发有大量后台基础软件需要开发。</li></ul><h3 id="20-基本产品——削减功能还是延长工期"><a href="#20-基本产品——削减功能还是延长工期" class="headerlink" title="20. 基本产品——削减功能还是延长工期"></a>20. 基本产品——削减功能还是延长工期</h3><blockquote><p>推荐的产品设计方式</p></blockquote><ol><li>产品经理和设计师合作设计产品的高保真原型，它只具备商业目标的最基本功能要求，及良好的用户体验和吸引力。</li><li>邀请一位开发人员参与原型设计。帮助估算成本，指出设计上的误区，分析、评估可行性。</li><li>请真实用户验证产品原型。在产品全力开发前，产品经理和设计师必须确信产品是用户需要的，这就需要用户测试来验证。</li></ol><p>设计产品时一定要分清最重要功能，争取设计出只满足基本要求的，不可删减的产品。</p><h3 id="21-产品验证——证明产品的价值、可用性、可行性"><a href="#21-产品验证——证明产品的价值、可用性、可行性" class="headerlink" title="21. 产品验证——证明产品的价值、可用性、可行性"></a>21. 产品验证——证明产品的价值、可用性、可行性</h3><ol><li>可行性测试<br>邀请架构师和开发人员深度参与技术调研，寻找可行的方案。有些产品的技术风险较大，如果产品存在可行性风险，一定要提前解决这些问题。</li><li>可用性测试<br>请真实用户来试用可用性原型。为了测试可用性，即使要模拟复杂的后台处理过程也是值得的，关键是要评估用户体验的实际效果。</li><li>价值测试<br>可用性测试与价值测试同时进行。可用性测试重在观察用户如何设法完成必要的操作，而价值测试重在观察用户是否喜欢这些功能，是否满意具体的实现方式。</li></ol><h3 id="22-原型测试——把产品创意呈现给真实用户"><a href="#22-原型测试——把产品创意呈现给真实用户" class="headerlink" title="22. 原型测试——把产品创意呈现给真实用户"></a>22. 原型测试——把产品创意呈现给真实用户</h3><p>让真实用户验证产品创意是必不可少的环节。</p><ol><li>物色测试者<ul><li>特约用户</li><li>同类产品展销会寻找目标用户</li><li>分类信息网站上发布广告征集测试者</li><li>邀请亲朋好友参加测试</li><li>从邮箱列表中筛选测试者</li><li>公司网站征集志愿者</li><li>大型公司定期开展测试活动（两周一次，每次10~20位测试者参加）</li><li>到产品对应用户群聚集地寻找测试者</li><li>测试前一天致电测试者</li></ul></li><li>准备测试<ul><li>事先拟好测试内容，测试主要功能。</li><li>在开始测试前，观察用户在不知道产品的情况下，如何解决问题</li><li>观察测试者是否从原型首页看出产品要解决的问题，哪些地方最能吸引他们</li><li>待测试完成，了解了产品功能的，通过聊天进一步收集信息。比如是否使用过同类产品，原型是否比他常用的产品好？是否会推荐给朋友使用。了解测试者对产品的评价</li><li>为每个问题的答案打分</li><li>可以先测试主要项目，向客户了解接下来希望有什么功能，获取宝贵意见</li></ul></li><li>测试环境<ul><li>测试者放松的环境，回答问题更坦诚和开放</li><li>用户的办公室</li><li>尽量面对面测试</li><li>产品经理应亲自参加每次原型测试，了解客户需求</li><li>产品经理要明白自己的产品设计不完美，获取用户反馈信息是完善产品设计的最佳途径</li><li>安排一个人主持测试，另一个人记录</li><li>可以邀请开发人员、交互设计师、视觉设计师等参加</li></ul></li><li>测试原型<ul><li>测试前不宜与测试者交谈过多</li><li>务必告诉测试者：这只是产品原型，不是最终产品，可以尽情说出问题</li><li>尽量让测试者保持平和情绪。<strong>测试重点是看测试者能否轻松完成测试任务，以及是否喜欢产品功能，多观察测试者的操作，少在意测试者的抱怨</strong>，如果测试者提出界面上的元素美观问题就跑题了</li><li>尽量保持安静，不要给测试者提示</li><li>通常有三种结果：顺利完成任务、艰难完成任务、放弃任务</li><li>尽量不要提示测试者，可以问测试者的困惑</li><li>主持人可以通过口述他们在做的事，尽量不要用感性语句，比如“好极了”，以免诱导测试者</li><li>测试的作用是理解目标用户如何看待产品要解决的问题，发现用户的期待，为后面的优化提供参考</li><li>观察测试者的表情与动作</li></ul></li><li>更新原型<ul><li>只要两三个测试者反馈同一个问题，就可以动手解决了。如果有连续六位测试者理解和欣赏产品的价值，而且顺利完成关键任务，就算测试原型任务完成</li><li>如果发现没法让测试者对原型产生兴趣，或者无法让原型变得足够简单易用，就应该立马收手，放弃这个产品创意。</li></ul></li></ol><h3 id="23-改进再有产品——不是一味地添加功能"><a href="#23-改进再有产品——不是一味地添加功能" class="headerlink" title="23. 改进再有产品——不是一味地添加功能"></a>23. 改进再有产品——不是一味地添加功能</h3><p>开发新产品的第一步是要明确目标。<br>改进产品不是简单地满足个别用户的要求，能<strong>提高指标的功能</strong>才是关注的重点</p><h3 id="24-平滑部署——避免更新产品导致用户反感"><a href="#24-平滑部署——避免更新产品导致用户反感" class="headerlink" title="24. 平滑部署——避免更新产品导致用户反感"></a>24. 平滑部署——避免更新产品导致用户反感</h3><p>通常情况下，用户不喜欢变化。为了将版本更新带来的负面影响降到最低，可以采取以下措施：</p><ol><li>通过公告、群发邮件、在线教育等方式提前通知用户</li><li>加倍做好测试工作，避免新版本存在影响正常使用的隐患</li><li>采用并行部署或者增量部署的方式来降低风险</li></ol><p>平滑部署的方式很多：</p><ol><li>部署两个版本，邀请部分用户试用新版本。待大部分用户习惯新版本后，再将新版本设为默认版本，同时保留旧版本一段时间，确定旧版本提供支持的最后期限</li><li>区域性逐步部署</li><li>将新功能分割成几个较小的部分逐步发布</li></ol><h3 id="25-快速响应阶段——产品出炉后切莫虎头蛇尾"><a href="#25-快速响应阶段——产品出炉后切莫虎头蛇尾" class="headerlink" title="25. 快速响应阶段——产品出炉后切莫虎头蛇尾"></a>25. 快速响应阶段——产品出炉后切莫虎头蛇尾</h3><ul><li>交付产品后，要留一周左右时间，快速响应处理产品发布后的用户反馈。</li><li>关键不在于是否会出现问题，在于能多快解决问题</li><li>给指标分出轻重缓急，并保持关注。页面访问量、注册用户数、访问停留时间、会员转换率、广告收益？</li><li>追踪用户的使用情况，使用追踪工具，如谷歌分析工具</li><li>上门向客户收集反馈</li><li>一旦问题反馈回来，产品团队应该至少每天召开一次简短会议，讨论问题的轻重缓急，确定最佳解决方案</li></ul><h3 id="26-合理运用敏捷方法——十大秘诀"><a href="#26-合理运用敏捷方法——十大秘诀" class="headerlink" title="26. 合理运用敏捷方法——十大秘诀"></a>26. 合理运用敏捷方法——十大秘诀</h3><ol><li>产品经理即是产品负责人，为产品负责</li><li>产品经理要明白产品的方向和目标，设定衡量产品成功与否的标准</li><li>产品经理与设计师的进度应该比开发团队领先一两个迭代周期，另外，让开发人员参与评估产品设计和产品原型及时反馈可行性、成本、解决方案的建议</li><li>产品设计目标是设计出符合基本要求的产品</li><li>产品经理的主要任务是定义有价值、可用的产品原型和用户故事，作为开发基础。</li><li>让开发人员自主划分迭代周期</li><li>产品经理、交互设计师必须出席每天的晨会</li><li>一定要等产品满足产品经理的要求，才能够进行发布</li><li>每次迭代完成后，产品经理应该向团队展示产品现状，及下次迭代的产品原型</li><li>团队展开敏捷培训</li></ol><h3 id="27-合理运用瀑布式开发方法——扬长避短"><a href="#27-合理运用瀑布式开发方法——扬长避短" class="headerlink" title="27. 合理运用瀑布式开发方法——扬长避短"></a>27. 合理运用瀑布式开发方法——扬长避短</h3><p>瀑布式开发的优点：一开始确定了产品的需求，变动很少，可以制定精确的开发计划<br>瀑布式开发的缺点：</p><ol><li>产品验证严重滞后</li><li>变更计划代价高</li><li>无法适应快速的市场变化</li></ol><h3 id="28-创业型公司的产品管理——关键在于产品探索"><a href="#28-创业型公司的产品管理——关键在于产品探索" class="headerlink" title="28. 创业型公司的产品管理——关键在于产品探索"></a>28. 创业型公司的产品管理——关键在于产品探索</h3><blockquote><p><strong>推荐一种新的产品设计方式，提高产品的成功率，还能大幅节约创业成本。</strong></p></blockquote><ul><li>创业初期只设三个职位：产品经理、交互设计师和原型开发人员。只要有人负责这三项工作即可。这个团队可以快速展开产品设计，迭代修改</li><li>创建体现用户体验的高保真原型，邀请真实的目标用户验证产品原型</li><li>产品原型不断迭代，产品会渐趋完善。这个过程需要几周到两个月时间</li><li>确定产品原型后，再招聘程序员进行开发</li></ul><h3 id="29-大公司如何创新——有困难，但值得一试"><a href="#29-大公司如何创新——有困难，但值得一试" class="headerlink" title="29. 大公司如何创新——有困难，但值得一试"></a>29. 大公司如何创新——有困难，但值得一试</h3><ul><li>20%法则</li><li>臭鼬工程，受限制的条件下，利用自己的时间，低调地进行创新研究</li><li>观察用户使用公司产品或同类产品的一举一动</li><li>改善用户体验</li><li>收购小公司</li></ul><h3 id="30-在大公司施展拳脚——十大秘诀"><a href="#30-在大公司施展拳脚——十大秘诀" class="headerlink" title="30. 在大公司施展拳脚——十大秘诀"></a>30. 在大公司施展拳脚——十大秘诀</h3><ol><li>了解公司制定决策的方式</li><li>建立人脉网络</li><li>臭鼬工程，三五个志趣相投的同事在工作之余做出产品原型</li><li>自己顶上，一切为了推出产品，不计较个人得失</li><li>有选择地据理力争</li><li>会前沟通，形成默契</li><li>合理分配时间</li><li>分享信息</li><li>向上司借力</li><li>传播你的产品理念</li></ol><p>大公司的优点：产品会获得媒体和用户的高度关注。<br>“大部分人游荡在黑暗里，他们只知道抱怨，却从不想办法寻找电灯开关”</p><h2 id="第三篇：产品"><a href="#第三篇：产品" class="headerlink" title="第三篇：产品"></a>第三篇：产品</h2><p>富有创意的产品应该具有一些鲜明特性</p><h3 id="31-苹果公司"><a href="#31-苹果公司" class="headerlink" title="31. 苹果公司"></a>31. 苹果公司</h3><p>苹果公司很多值得觉得的经验，作者认为最重要的是以下四点：</p><ol><li>硬件为软件服务：硬件是配合软件满足用户需求</li><li>软件为用户体验服务：把用户体验放在心里，所有工作围绕着产品的可用性、交互设计、视觉设计、工业设计展开</li><li>用户体验为情感服务：抓位用户的情感需求</li><li>产品为真正的需求服务：逐一改善用户痛点</li></ol><h3 id="32-提防有特殊要求的产品"><a href="#32-提防有特殊要求的产品" class="headerlink" title="32. 提防有特殊要求的产品"></a>32. 提防有特殊要求的产品</h3><p>客户说：产品需要增加以下七项功能，否则拒绝购买。say Yes or No?</p><ul><li>特殊要求混淆了客户需求和产品需求，必然会使公司偏离正轨。</li><li>产品需求不能用户说了算。<ol><li>在看到具体产品之前，用户很难知道自己需要什么</li><li>用户不知道什么样的产品是可行的</li><li>用户之间缺少沟通，需求很难统一</li></ol></li><li>产品经理的任务是满足大众需求——这是产品公司和定制软件公司的区别</li></ul><p>公司应该怎样回避特殊要求的产品带来的危害？</p><ul><li>与客户沟通，一起梳理需求，找到问题的本质，提供更合理的解决方案</li><li>看能否在保持产品能用用途的前提下，设法满足客户定制要求</li></ul><h3 id="新瓶装老酒"><a href="#新瓶装老酒" class="headerlink" title="新瓶装老酒"></a>新瓶装老酒</h3><p>成功的产品往往不是什么新鲜事物，只是新瓶装老酒，“新瓶”做得更好、更方便、更便宜，改变了消费者对“老酒”的印象</p><ul><li>对目标市场了如指掌，对现有产品的缺陷洞若观火。产品的可用性测试掌握产品情况（包括自己的和竞争对手的产品）</li><li>跟踪最新的技术趋势。用新技术解决用户的老问题。</li></ul><h3 id="34-恐惧、贪婪、欲望"><a href="#34-恐惧、贪婪、欲望" class="headerlink" title="34. 恐惧、贪婪、欲望"></a>34. 恐惧、贪婪、欲望</h3><p>企业级消费者出于恐惧和贪婪购买产品<br>大众消费者购买产品原因多样化，有可能是交友的欲望、满足自豪感等<br>只有从情感的角度重新观察市场上的产品和服务，才能体会用户的真实感受。</p><h3 id="35-情感接纳曲线"><a href="#35-情感接纳曲线" class="headerlink" title="35. 情感接纳曲线"></a>35. 情感接纳曲线</h3><p>愤怒的用户决定着产品未来的发展方向。<br>不要一味从技术角度看待产品，从用户的角度考虑问题。</p><ul><li>技术爱好者，他们的需求与普通大众不同，购买产品是对技术本身的痴迷</li><li>非理性消费者，情感需求与大众相同，但更强烈。产品经理应该着重关注他们</li><li>普通大众，和非理性消费者情感需求一样，但不那么强烈，随着产品完善，会加入消耗队伍</li><li>理性消费者，只购买他们认为实用、成熟的产品，只购买性价比合适的产品</li><li>超理性消费者，情感需求很弱，只要产品有半点不满意，就不会购买</li><li>观望者，他们有同样的需求，只购买公认好用的产品</li></ul><p>非理性消费者的情感需求是推动产品跨越鸿沟的动力。</p><blockquote><p><strong>带着新生的感觉去发掘每天折磨着大众的情感——孤独、恐惧、挫折、不满，你离发现新产品的日子就不远了。</strong></p></blockquote><h3 id="36-可用性与美感"><a href="#36-可用性与美感" class="headerlink" title="36. 可用性与美感"></a>36. 可用性与美感</h3><p>交互设计与视觉设计缺一不可。</p><h3 id="37-大众网络服务产品"><a href="#37-大众网络服务产品" class="headerlink" title="37. 大众网络服务产品"></a>37. 大众网络服务产品</h3><p>作者总结了十条管理大众网络服务产品的要点：</p><ol><li>可用性：产品必须具备良好的用户体验</li><li>人物角色：抽象出有代表性的用户类型，加以分析</li><li>扩展性：系统支持动态扩展，应对激增的用户访问</li><li>持续可用性：保证网络服务高可用性</li><li>客户服务：维持良好的用户体验</li><li>保护用户隐私：树立保护用户隐私的意识，设置用户资料保护机制</li><li>口碑营销：为用户提供便利，方便他们向熟人推荐产品</li><li>全球化：设计时支持本地化</li><li>平滑部署：尽量减少不必要的更新</li><li>用户社区管理：多与用户交流，了解用户的想法</li></ol><h3 id="38-打造企业级产品的经验"><a href="#38-打造企业级产品的经验" class="headerlink" title="38. 打造企业级产品的经验"></a>38. 打造企业级产品的经验</h3><p>企业级产品的十大要点</p><ol><li>可用性：也要做交互设计、视觉设计、可用性测试</li><li>产品正常工作：保证产品按设计的方式运行</li><li>特例产品：必须坚持原则，开发满足广大用户需求的产品始终是首要任务</li><li>特约用户：配合产品团队验证产品设计，体验产品。必须保证特约用户满意，才能发布产品</li><li>销售渠道的需求：按照销售与分销渠道的需求来设计产品</li><li>客户和用户的需求：参考用户的需求设计产品</li><li>产品安装：安装过程尽量简单</li><li>产品的配置、自定义、集成</li><li>产品升级：简化升级技术和流程</li><li>销售策略：传统靠的是销售人员的才智、魅力与关系，现在可以考虑网络推广策略</li></ol><h3 id="39-打造平台产品的经验"><a href="#39-打造平台产品的经验" class="headerlink" title="39. 打造平台产品的经验"></a>39. 打造平台产品的经验</h3><p>面向三种不同客户：应用软件供应商、开发人员、终端用户<br>与平台产品接触最多的是开发人员，为平台买单的软件供应商，往往最终用户离平台最远。经常会<strong>被错误地</strong>把开发人员排在第一位，而把最终用户排在最后一们。</p><blockquote><p>必须认识到，只有最终客户满意，平台产品才是成功的。</p></blockquote><h3 id="40-最佳实践经验"><a href="#40-最佳实践经验" class="headerlink" title="40. 最佳实践经验"></a>40. 最佳实践经验</h3><blockquote><p>产品经理的主要职责是定义有价值的、可用的，可行的产品</p></blockquote><ol><li>产品管理的职责：产品经理要专注在产品管理的工作上，设计出有价值、可用性、可行性的好产品</li><li>用户体验：用户体验是产品的生命</li><li>机会评估：动手设计前，先明确产品要解决什么问题，为谁解决问题，以及评估产品的标准</li><li>特约用户：要请用户反复试用产品，不断改进</li><li>产品原则：确定产品的价值标准</li><li>人物角色：把目标用户按特征分类，逐一分析，理解其情感与行为，作为决策的依据</li><li>定义产品：产品经理的主要职责是定义有价值的、可用的，可行的产品</li><li>使用原型：使用高保真原型。迫使产品经理深入定义解决方案、可以让真实用户参与测试及验证产品创意、可向直观地团队展示产品的设计思路</li><li>用户参与原型测试：获取用户反馈</li><li>根据数据改进产品：根据数据分析，不断提高产品的各项指标，完善产品</li></ol><h3 id="41-产品经理反省清单"><a href="#41-产品经理反省清单" class="headerlink" title="41. 产品经理反省清单"></a>41. 产品经理反省清单</h3><p>作为产品经理每天问自己这十个问题</p><ol><li>产品对目标消费者有吸引力吗？</li><li>产品的体验如何？</li><li>产品有哪些竞争力？</li><li>我了解目标用户吗？产品是否能得到他们的认可？</li><li>产品与竞品相比较有啥差别？能用2分钟解决清楚差别点吗？</li><li>产品能正常运行吗？</li><li>产品完整吗？用户对它的印象如何？销售业绩如何？</li><li>产品特色是否与目标用户的需求一致？是否鲜明？</li><li>产品价格是否合理？</li><li>我了解团队其他成员对产品的看法吗？他们怎么看待这个产品？</li></ol><h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><p><a href="https://www.jianshu.com/p/475034543945">《启示录-打造用户喜爱的产品》</a></p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《持续交付发布可靠软件的系统方法》读书笔记</title>
      <link href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="基础篇"><a href="#基础篇" class="headerlink" title="基础篇"></a>基础篇</h2><p><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E8%BD%AF%E4%BB%B6%E4%BA%A4%E4%BB%98%E7%9A%84%E9%97%AE%E9%A2%98/">第一章：软件交付的问题</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86">第二章：配置管理</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90">第三章：持续集成</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E6%B5%8B%E8%AF%95%E7%AD%96%E7%95%A5%E7%9A%84%E5%AE%9E%E7%8E%B0">第四章：测试策略的实现</a></p><h2 id="部署流水线"><a href="#部署流水线" class="headerlink" title="部署流水线"></a>部署流水线</h2><p><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%A7%A3%E6%9E%90">第五章：部署流水线解析</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%83%A8%E7%BD%B2%E7%9A%84%E8%84%9A%E6%9C%AC%E5%8C%96">第六章：构建与部署的脚本化</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E6%8F%90%E4%BA%A4%E9%98%B6%E6%AE%B5">第七章：提交阶段</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%8A%A8%E5%8C%96%E9%AA%8C%E6%94%B6%E6%B5%8B%E8%AF%95">第八章：自动化验收测试</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%B9%9D%E7%AB%A0%EF%BC%9A%E9%9D%9E%E5%8A%9F%E8%83%BD%E9%9C%80%E6%B1%82%E7%9A%84%E6%B5%8B%E8%AF%95">第九章：非功能需求的测试</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8F%91%E5%B8%83">第十章：应用程序的部署与发布</a></p><h2 id="交付生态圈"><a href="#交付生态圈" class="headerlink" title="交付生态圈"></a>交付生态圈</h2><p><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%92%8C%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86">第十一章：基础设施与环境管理</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86">第十二章：数据管理</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%EF%BC%9A%E7%BB%84%E4%BB%B6%E5%92%8C%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86">第十三章：组件和依赖管理</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%EF%BC%9A%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%BF%9B%E9%98%B6">第十四章：版本控制进阶</a><br><a href="/devops/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88_%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E7%AE%A1%E7%90%86">第十五章：持续交付管理</a></p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/9aceae35b4b34c39894b12d393be17b9ed54961d4bfee66801c81a7302460e69.png" alt="持续交付发布可靠软件的系统方法"></p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为啥新环境的Kafka性能这么差？</title>
      <link href="/DevOps/%E4%B8%BA%E5%95%A5%E6%96%B0%E7%8E%AF%E5%A2%83%E7%9A%84Kafka%E6%80%A7%E8%83%BD%E8%BF%99%E4%B9%88%E5%B7%AE%EF%BC%9F/"/>
      <url>/DevOps/%E4%B8%BA%E5%95%A5%E6%96%B0%E7%8E%AF%E5%A2%83%E7%9A%84Kafka%E6%80%A7%E8%83%BD%E8%BF%99%E4%B9%88%E5%B7%AE%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<p><strong>本故事纯属虚构，如有雷同，纯属巧合，一笑了之。</strong><br>公司分配给了A和B一个任务，测试容器化Kafka集群的性能。之前B在老机器上已经测试过一个版本，并写了完整的报告，算是有经验的老鸟了。<br>现在到了一批新机器，需要在它们上面重新测试一下Kafka的性能，A主动承担这个该任务，要知道新机器不管从cpu核数还是内存大小都是老机器的两倍，而且新机器用的是SSD盘，而老机器用的是机械盘。<br>A信心满满，认认真真地按照之前B写的文档操作。可测试结果让他大吃一惊，新机器的性能竟然不到老机器的一半。</p><blockquote><p>网络问题？</p></blockquote><p>A：这个Kafka集群压测数据怎么这么差？会不会是网络问题呢？<br>B：之前我们用的是万M网卡，你这个是多少？<br>A：网卡速度怎么看？<br>B：<strong>用ethtool命令，后面加对应的网络接口名，看Speed值，就能知道是万M还是千M网卡了。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ethtool eth0</span></span><br><span class="line">Settings for em0:</span><br><span class="line">Supported ports: [ TP ]</span><br><span class="line">...</span><br><span class="line">Speed: 1000Mb/s</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>A：这是千M网卡，怪不得性能会这么差呢。<br>B：你确定是网卡的问题吗？你压测的时候用nload命令查看一下网络的带宽有没有跑满。<br>A：nload?这个怎么用？<br>B：<strong>nload命令使用非常简单，后面加对应网络接口名就能查看网卡的出入流量了。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nload eth0</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f40fce0c8c2a75bf13878de6b64200d2b51082c19b23904b4f41ff60c1de3d1c.png" alt="nload命令结果">  </p><p>A：离跑满还远着呢。那应该不是网卡带宽的问题了。</p><blockquote><p>容器问题</p></blockquote><p>A：我想会不会跟容器相关呀？容器的SDN什么的那么复杂，又加包头，解包头，会不会对Kafka有影响了呀？<br>B：<strong>你直接搭一个单机版的Kafka运行在一台主机上，不做容器化，就在那台机器上测试，不走网络看下性能如何。</strong><br>A：Good Idea！<br>半小时后<br>A：性能还是没上去，看来可以排除容器和网络的因素了。</p><blockquote><p>磁盘问题？</p></blockquote><p>A：那磁盘呢，Kafka数据可是会落盘的，压测时磁盘的IO应该比较大吧？<br>B：我们之前测的时候使用的是机械盘接SAS口，8k的写能达到200M&#x2F;s。你测下你的IO是多少。<br>A：怎么测？<br>B：<strong>磁盘的IO简单测试使用dd命令就可以，测试写时记得添加oflag&#x3D;direct，要更仔细测试就使用用fio命令。</strong></p><p>dd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">time <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=test.dbf bs=8k count=300000 oflag=direct <span class="comment">#测试写性能</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">dd</span> <span class="keyword">if</span>=test.dbf bs=8k count=300000 of=/dev/null  <span class="comment">#测试读性能</span></span></span><br></pre></td></tr></table></figure><p>fio</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#4k顺序写</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> dep <span class="keyword">in</span> &#123;1,2,4,8,16,32,64,128&#125;;<span class="keyword">do</span> fio -filename=/dev/vdb --ioengine=libaio -direct=1 -rw=write -bs=4k -size=50G -iodepth=<span class="variable">$dep</span> -group_reporting -ramp_time=10 -runtime=60 -name=model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_seq_write --output=/home/model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_seq_write.<span class="built_in">log</span> -numjobs=1; <span class="keyword">done</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#4k顺序读</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> dep <span class="keyword">in</span> &#123;1,2,4,8,16,32,64,128&#125;;<span class="keyword">do</span> fio -filename=/dev/vdb --ioengine=libaio -direct=1 -rw=<span class="built_in">read</span> -bs=4k -size=50G -iodepth=<span class="variable">$dep</span> -group_reporting -ramp_time=10 -runtime=60 -name=model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_seq_read --output=/home/model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_seq_read.<span class="built_in">log</span> -numjobs=1; <span class="keyword">done</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#4k随机写</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> dep <span class="keyword">in</span> &#123;1,2,4,8,16,32,64,128&#125;;<span class="keyword">do</span> fio -filename=/dev/vdb --ioengine=libaio -direct=1 -rw=randwrite -bs=4k -size=50G -iodepth=<span class="variable">$dep</span> -group_reporting -ramp_time=10 -runtime=60 -name=model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_rand_write --output=/home/model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_rand_write.<span class="built_in">log</span> -numjobs=1; <span class="keyword">done</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#4k随机读</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> dep <span class="keyword">in</span> &#123;1,2,4,8,16,32,64,128&#125;;<span class="keyword">do</span> fio -filename=/dev/vdb --ioengine=libaio -direct=1 -rw=randread -bs=4k -size=50G -iodepth=<span class="variable">$dep</span> -group_reporting -ramp_time=10 -runtime=60 -name=model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_rand_read --output=/home/model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_rand_read.<span class="built_in">log</span> -numjobs=1; <span class="keyword">done</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#4k混合顺序读写</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> dep <span class="keyword">in</span> &#123;1,2,4,8,16,32&#125;;<span class="keyword">do</span> fio -filename=/dev/vdb --ioengine=psync -direct=1 -rw=readwrite -bs=4k -size=100G -iodepth=<span class="variable">$dep</span> -group_reporting -ramp_time=30 -runtime=120 -name=model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_seq_read_write --output=/home/model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_seq_read_write.<span class="built_in">log</span> -numjobs=1; <span class="keyword">done</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#4k混合随机读写</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> dep <span class="keyword">in</span> &#123;1,2,4,8,16,32&#125;;<span class="keyword">do</span> fio -filename=/dev/vdb --ioengine=psync -direct=1 -rw=randrw -bs=4k -size=100G -iodepth=<span class="variable">$dep</span> -group_reporting -ramp_time=30 -runtime=120 -name=model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_rand_read_write --output=/home/model_4K_<span class="variable">$&#123;dep&#125;</span>_100SAS_rand_read_write.<span class="built_in">log</span> -numjobs=1; <span class="keyword">done</span></span></span><br></pre></td></tr></table></figure><p>A：结果出来了，性能好差，写才70M&#x2F;s，算下来IOPS才8000左右，之前环境IOPS有20000多呢。看来这个磁盘性能真的有问题呀。<br>B：你确认下它是不是SSD盘，部署机器的C跟我说挂载的是SSD盘。<br>A：肯定不是呀，这么差。我到机房去看一看吧。<br>B：不用去机房，<strong>你查看下系统的磁盘参数&#x2F;sys&#x2F;block&#x2F;*&#x2F;queue&#x2F;rotational，如果是0的话就是SSD。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep ^ /sys/block/*/queue/rotational</span></span><br></pre></td></tr></table></figure><p>A：竟然值是0，那这么差的盘竟然是SSD！别当我无知就好欺负呀。我去机房拔下来看。<br>半小时后<br>A：上面挂载的还真是SSD盘，但接的是SATA口。<br>B：<strong>磁盘性能并不只跟磁盘有关，跟接口的关系也非常大，PCIE卡&gt;SAS&gt;SATA，如果有做Raid的话，性能也会有不一样。PCIE卡不能做Raid。</strong><br>A：怪不得，那现在是磁盘有问题？<br>B：你可以在压测的时候看下磁盘的实时IOPS是多少。<br>A：怎么看？<br>B：<strong>用iostat命令，后面可以接需要观察的盘符名，看结果中的w&#x2F;s，与r&#x2F;s值就能知道实时的IOPS了。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iostat /dev/vdb -x 1</span></span><br></pre></td></tr></table></figure><p>A：结果显示这两个值都很低呀，最高不到1000，有的时候才几十，远远没有到瓶颈呀。<br>B：要排除磁盘问题，你还可以不用磁盘，直接把内存挂载到对应的目录下，再压测，看结果有没有变化。<br>A：把内存挂载到对应目录？这个又是么高科技？（抓头）<br>B：不算什么高科技，其实很简单啦。<strong>linux系统的目录&#x2F;dev&#x2F;shm是在内存上，你把kafka的数据目录指向这个目录下就好了。</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">linux系统的目录/dev/shm是在内存上</span><br></pre></td></tr></table></figure><p>A：这样呀，我测试下。。。性能还是很低呀。<br>B：嗯，又排除了磁盘的影响。</p><blockquote><p>系统问题？</p></blockquote><p>A：我想会不会是系统的配置问题？之前环境用的是rh 7.3，而这次我们装的是rh 7.5。<br>B：那给现在这台机器重装下系统，使用同样的rh 7.3，再压测下试试。<br>A：好，就这么干。<br>半个小时后<br>A：测试结果出来了，还是很低呀。并没有任何改进。<br>B：看来跟系统也没有关系。</p><blockquote><p>CPU问题？</p></blockquote><p>B：我们看下CPU的信息。<strong>查看&#x2F;proc&#x2F;cpuinfo能查看cpu的详情。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /proc/cpuinfo</span></span><br><span class="line">......</span><br><span class="line">model name: Intel(R) Xeon(R) Gold 6138 CPU @ 2.00GHZ</span><br><span class="line">cpu MHz: 1995.381</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>A：原先主机的CPU频率我也查到了，3.00GHZ，整整大了50%<br>B：现在两个环境系统是完全一样的，我们可以使用计算圆周率的办法测下单核cpu的能力。<br>A：计算圆周率，我要去研究下算法了。（抓头）<br>B：不用，<strong>使用bc命令直接计算圆周率。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">time <span class="built_in">echo</span> <span class="string">&quot;scale=5000;4*a(1)&quot;</span> | bc -l -q</span></span><br></pre></td></tr></table></figure><p>A：好吧。（一会后）新机器计算花了80s，而老机器才18s，差距这么大！<br>B：最后我们用unixbench工具对主机性能做下全面测试，看看结果如何。<br>A：unixbench？怎么又来了个新工具。。。这个怎么测？<br>B：<strong>unixbench测试非常简单，它不仅能测试单核性能，还可以测试多核性能。代码在<a href="https://github.com/kdlucas/byte-unixbench">https://github.com/kdlucas/byte-unixbench</a>，直接运行<code>Run</code>就可以了。</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">Run</span></span><br><span class="line">......</span><br><span class="line">80 CPUs in system; running 1 parallel copies of tests</span><br><span class="line"></span><br><span class="line">System Benchmarks Index Score                                        4678.5</span><br><span class="line">......</span><br><span class="line">80 CPUs in system; running 80 parallel copies of tests</span><br><span class="line"></span><br><span class="line">System Benchmarks Index Score                                        8820.4</span><br></pre></td></tr></table></figure><p>一个小时后<br>A：终于运行好了，新的机器测试的分数连之前机器分数的一半都不到。这不是逗我吗，测的可是新机器呀！<br>……<br>A：到底是哪有问题呀？！我找厂商去。</p><p>评价：把问题死磕到底，你会有非常多的收获。</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>创建自签证书步骤</title>
      <link href="/DevOps/%E5%88%9B%E5%BB%BA%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E6%AD%A5%E9%AA%A4/"/>
      <url>/DevOps/%E5%88%9B%E5%BB%BA%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E6%AD%A5%E9%AA%A4/</url>
      
        <content type="html"><![CDATA[<ol><li><p>根证书创建</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out ca.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -x509 -days 36500 -key ca.key -out ca.crt -subj <span class="string">&quot;/C=CN/ST=shanxi/L=taiyuan/O=cn/OU=test/CN=example.com&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#或者 openssl req -new -x509 -days 36500 -key ca.key -out ca.crt 手动输入配置</span></span></span><br></pre></td></tr></table></figure></li><li><p>创建证书并使用根证书签发</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out app.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -key app.key -out app.csr</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -req -<span class="keyword">in</span> app.csr -CA ca.crt -CAkey ca.key -out app.crt -days 3650  -CAcreateserial</span></span><br></pre></td></tr></table></figure></li><li><p>使用 Openssl 工具查看证书信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> app.crt -noout -dates</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> app.crt -noout -subject</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> app.crt -noout -text</span></span><br></pre></td></tr></table></figure></li><li><p>nginx的配置中的证书使用中，ca与crt证书的保存顺序如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">CRT</span><br><span class="line">-----END CERTIFICATE-----</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">CA</span><br><span class="line">-----END CERTIFICATE-----</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>将字符串进行压缩后保存该如何做？</title>
      <link href="/DevOps/%E5%B0%86%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E5%90%8E%E4%BF%9D%E5%AD%98%E8%AF%A5%E5%A6%82%E4%BD%95%E5%81%9A%EF%BC%9F/"/>
      <url>/DevOps/%E5%B0%86%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9%E5%90%8E%E4%BF%9D%E5%AD%98%E8%AF%A5%E5%A6%82%E4%BD%95%E5%81%9A%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<p>如何将zip文件挂载到容器Pod中呢？<br>Prometheus operator中看到的一个特殊玩法。它将prometheus.yml进行压缩成.gz后再保存到secret中。可参考它来实现对数据的压缩与加密。<br>具体的操作如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;abc&quot;</span> | gzip | <span class="built_in">base64</span></span></span><br><span class="line">H4sIAAAAAAAAA0tMSuYCAE6BiEcEAAAA</span><br></pre></td></tr></table></figure><p>解密操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;H4sIAAAAAAAAA0tMSuYCAE6BiEcEAAAA&quot;</span> | <span class="built_in">base64</span> -d | gunzip</span></span><br></pre></td></tr></table></figure><p>大家可以尝试下。另外需要注意的是，将该数据挂载到POD的文件中，文件是压缩后的gz文件。</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>性能测试方案设计与测试过程</title>
      <link href="/DevOps/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B/"/>
      <url>/DevOps/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-160a4afa34f8adfc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="性能测试 - 来自网站"></p><h2 id="性能测试过程"><a href="#性能测试过程" class="headerlink" title="性能测试过程"></a>性能测试过程</h2><ol><li>性能测试计划</li></ol><ul><li>按照模板生成性能测试计划<blockquote><p>指标设计（并发数、在线数、TPS、请求超时）<br>挑选典型交易（20%交易，覆盖80%流量）<br>环境、数据准备（与生产环境尽量一致）<br>场景设计（基础场景、专项场景）<br>测试进度安排</p></blockquote></li></ul><ol start="2"><li>需求分析、调研</li></ol><ul><li>了解业务需求</li></ul><ol start="3"><li>环境、数据准备：</li></ol><ul><li>系统部署</li><li>真实含义的业务数据</li><li>数据量为生产数据量三年以后的数据量。</li></ul><ol start="4"><li>场景分析设计</li></ol><ul><li>挑选交易，典型交易：高频交易，逻辑复杂的交易，集中时间段的场景</li><li>单交易运行——&gt;单交易负载场景</li><li>混合场景设计：混合容量设计，浪涌设计（20-&gt;100,100-&gt;20）</li><li>稳定性场景设计（48小时、72小时持续压力验证）</li></ul><ol start="5"><li>场景执行、应用监控</li></ol><ul><li>执行测试场景</li></ul><ol start="6"><li>问题定位、分析优化</li></ol><ul><li>分析问题</li><li>回归验证</li></ul><ol start="7"><li>性能测试报告</li></ol><ul><li>测试结果汇总形成报告</li></ul><h2 id="性能测试方案扩展"><a href="#性能测试方案扩展" class="headerlink" title="性能测试方案扩展"></a>性能测试方案扩展</h2><p>引入多样化的性能监控工具（prometheus&#x2F;JVM&#x2F;pinpoint&#x2F;skywalking）<br>丰富性能场景设计（扩展性场景、可靠性场景、网络异常等情况）<br>可持续性能压测(Jmeter进行自动化性能测试)</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-ded4e503842f5a83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="性能测试"></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（_交付生态圈）第十五章：持续交付管理</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88_%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88_%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%EF%BC%9A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>实现持续交付不仅仅是搭建一些工具，做一些自动化的工作，它依赖于交付过程中的每个人的协作。通过持续交付实践，可以快速且可靠地交付新版本。</p><h2 id="配置与发布管理成熟模型"><a href="#配置与发布管理成熟模型" class="headerlink" title="配置与发布管理成熟模型"></a>配置与发布管理成熟模型</h2><p><img src="https://upload-images.jianshu.io/upload_images/5793257-55fb9f67ead6d76f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="成熟度模型"></p><p>这个模型的最终目标：</p><ul><li>缩短生产周期</li><li>减少缺陷</li><li>提高软件交付生命周期的可预测性</li><li>规范合规</li><li>有效发现和管理软件交付相关风险</li><li>交付更少缺陷的软件，降低成本</li></ul><p>模型指导组织推进持续交付变革，使用戴明环，即计划——执行——检查——处理。</p><ol><li>使用模型来分析所在部门的配置与发布管理模式</li><li>选择一个领域集中发力，该领域是你的薄弱环节，痛点所在</li><li>实施变革。先创建一个实施计划，选择真正感到痛苦的那部分人</li><li>一旦发生了变化，使用之前创建的验收条件来衡量这些变化是否达到了预期效果。组织所有相关人员召开回顾会议，找出改进点及潜在改进领域</li><li>重复上述步骤，积累知识，增量改进，推广到整个部门</li></ol><h2 id="项目生命周期"><a href="#项目生命周期" class="headerlink" title="项目生命周期"></a>项目生命周期</h2><p>团队的组建与磨合常常有以下五个阶段：创建期、风暴期、规范期、运转期、调整重组期。软件也有五个阶段：立项阶段、启动阶段、初始阶段、开发部署阶段、运维阶段。</p><ul><li>立项阶段：业务分析、业务负责人及涉及部门有关人确立</li><li>启动阶段：需求收集和分析，规范项目范围和计划。输出有，商务分析报告、概括性的功能与非功能需求列表、发布计划、测试策略、发布策略、架构评估报告 、风险和问题列表、开发生命周期描述、执行上述内容计划描述。包括足以启用项目的细节和最多几个月需交付目标，最合理周期为3个月。</li><li>初始阶段：一到二周，确保软硬件到位；确保网络、白板、笔纸、打印机、食品等到位；建立好版本控制库；建立一个基本的持续集成环境；角色、职责、工作时间、会议时间上达成一致；为第一周做准备，目标上达成一致；创建简单的测试环境与测试数据；更详细研究预定的系统设计 ；调研识别和缓解分析、开发、测试风险；开发用户故事与需求的待办列表；创建项目结构及构建脚本和一些测试，以验证持续集成环境正常工作</li><li>开发部署阶段：迭代开发是最基本要求。软件应该一直处于可工作状态；每个迭代都能将软件部署到一个类生产环境中向用户演示；迭代长度不超过两周</li><li>运维阶段：项目开发部署阶段结束后，一般项目还会继续开发下去，此过程与开发部署阶段差不多</li></ul><h2 id="风险管理流程"><a href="#风险管理流程" class="headerlink" title="风险管理流程"></a>风险管理流程</h2><p>在项目的各个阶段都要做到风险的识别与预防</p><ul><li>启动阶段结束时：验证发布策略在关于“创建发布策略”一节（10.2）节讨论过的方面都考虑到了；做好初始阶段的计划</li><li>初始阶段结束时：确保团队已经准备好开始开发软件了，持续集成环境正常工作，并且有一个类生产环境用于产品代码的部署</li><li>开发部署风险的缓解：识别、跟踪和管理风险，及时调整。查看部署计划，每次演示后做简单的回顾会议，每日立会作为风险识别的一部分。</li></ul><h2 id="常见交付问题和原因"><a href="#常见交付问题和原因" class="headerlink" title="常见交付问题和原因"></a>常见交付问题和原因</h2><ol><li>构建某个版本花很长时间，而且经常失败。<br>可能原因：部署过程非自动化；没有足够的硬件；硬件和操作系统配置没有正确管理 ；部署过程依赖于团队无法掌控的系统；没有足够多的人员理解构建和部署过程；测试、开发、分析和运营人员没有充分协作；开发人员没有遵守纪律，通过小步增量的方式的修改保证应用程序一直处于可工作状态</li><li>缺陷数量持续增加，产品质量下降<br>可能原因：开发期间，测试与开发没有协作；用户故事在没有全面测试，被测试人员验收，并在类生产环境下给用户演示的情况下标记为“完成”；开发与测试在自动化测试套件开发方面缺少经验；团队不了解哪种类型的测试有效；没有足够的测试覆盖率；系统原来就是一个不可靠的原型。</li><li>集成周期长，迭代速度慢<br>可能原因：自动化测试运行时间太长；提交阶段运行时间太长；自动化测试有间歇性失败，还是误报；没人得到许可就回滚别人的提交；没有足够多的人理解持续集成过程</li><li>环境不一致，导致生产故障<br>可能原因：UAT和生产环境有差异；没有对生产环境或试运行环境的变更管理流程；在运营、数据管理团队和交付团队间协作不畅；生产环境和试运行环境中的缺陷事件的监管不够有效；应用程序中的指南和日志不充分；应用程序非功能需求测试不充分</li></ol><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（交付生态圈）第十一章：基础设施和环境管理</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%92%8C%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%92%8C%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>基础设施与环境管理的目标是让所有测试环境（包括持续集成环境）都要与生产环境相似，特别是它们的管理方式。<br><strong>环境</strong>是指应用程序运行所需的所有资源和它们的配置信息。有如下这些属性：组成运行环境的服务器的硬件配置信息：如CPU类型和数量、内存大小、硬盘和网卡等；应用程序运行所需要的操作系统和中间件：如消息队列、应用服务器、web服务器及数据库服务器等的配置信息。<br><strong>基础设施</strong>代表了所在组织中的所有环境以及支持运行的所有服务，如DNS服务器、防火墙、路由器、版本控制库、存储、监控、邮件服务、日志服务等。<br><strong>准备部署环境及管理它，要基于以下原理</strong>，用一个整体方法来管理所有基础设施：</p><ul><li>使用保存于版本控制库中的配置信息来指定基础设施所处的状态</li><li>基础设施应该具有自治特性，即它应该自动地将自己设定为所需状态</li><li>通过测试设备和监控手段，应该时时都能掌握基础设施的实时状况</li><li>基础设施还应该具有非常容易重新搭建的特性</li></ul><p>为了减少在类生产环境中的部署风险，需要精心管理以下内容:</p><ul><li>操作系统及其配置信息，包括各个环境</li><li>中间件软件栈及其配置信息，包括应用服务器、消息系统和数据库</li><li>基础设施软件，如版本控制库、目录服务器及监控</li><li>外部集成点，比如外部系统和服务</li><li>网络基础设施，包括路由器、防火墙、交换机、DNS和DHCP等</li><li>应用程序开发团队与运维团队间的关系</li></ul><h2 id="理解运维团队的需要"><a href="#理解运维团队的需要" class="headerlink" title="理解运维团队的需要"></a>理解运维团队的需要</h2><p>开发团队往往需要尽可能快地交付软件，而运维团队的目标是稳定性。所有人的共识是：让发布有价值的软件成为一件低风险的事情。做这件事的最好方法是频繁发布，每次发布的变更很小。<br>运维团队使用熟悉的技术，在各个环境统一部署技术栈。开发人员是最开始部署环境的，所以一开始运维团队也需要在最开始写脚本的时候就加入其中。<br>对应用程序配置、中间件配置、操作系统配置、数据库配置等都需要进行统一管理。将它们像源代码一样加入版本控制库中，同时它们的配置也是部署流水线的一部分。</p><h2 id="基础设施的建模和管理"><a href="#基础设施的建模和管理" class="headerlink" title="基础设施的建模和管理"></a>基础设施的建模和管理</h2><p>如果项目处于开始阶段，这是制定基础设施配置管理策略的好时机。如果是一个遗留系统，并且没有好的控制规范的话，就要找出让它处于受控状态的方法。</p><ul><li>在没有批准的情况下，不允许他人修改基础设施</li><li>制定一个对基础设施进行变更的自动化过程</li><li>对基础设施进行监控，一旦发生问题，迟早发现。</li></ul><p>对基础设施的修改是一个严肃的问题，在个问题上对测试环境与对生产环境同等重要。如果无法通过一个自动化过程从头重新创建基础设施的话，首先要实现访问控制，没有审批，不得对基础设施做任何修改；接下来在不关闭访问控制的情况下，创建自动化过程来管理基础设施。当然对测试环境的变更审核可以比生产环境的变更审核更容易些。<br>对基础设施进行修改的关键特征</p><ul><li>无论做哪类变更，如防火墙等都要走同样的变更管理流程</li><li>流程使用一个所有人都需要登录的工单系统来管理</li><li>变更应该有详细的记录</li><li>能够看到每个环境进行的变更历史，包括部署活动</li><li>生产环境变更前，必须先在类生产环境中测试通过，自动化测试也已经运行完成</li><li>对每次修改都应该做版本控制，并通过自动化流程对基础设施进行变更</li><li>需要有一个测试来验证变更是否成功</li></ul><h2 id="服务器的准备及其配置的管理"><a href="#服务器的准备及其配置的管理" class="headerlink" title="服务器的准备及其配置的管理"></a>服务器的准备及其配置的管理</h2><p>服务器可以使用PXE来做自动化的远程安装，或者使用虚拟化技术。同时服务器的配置需要添加到版本控制库中进行统一管理。一旦安装好操作系统后，就必须保证任何配置的修改都是以受控方式进行。除了运维团队外，任何人不能登录到服务器上，同时所有的变更都使用自动化系统来执行。</p><h2 id="中间件的配置管理"><a href="#中间件的配置管理" class="headerlink" title="中间件的配置管理"></a>中间件的配置管理</h2><p>中间件如果是系统标准安装的部分，直接使用配置管理工具进行部署；而如果不是系统标准安装的部分，可以将中间件打包，并将它放在包管理服务器上，然后使用同样的方式对其进行管理；最后对于没有考虑脚本化或者后台安装的产品，需要对其进行改造，并将配置相关的文件进行版本控制。</p><h2 id="基础设施服务的管理"><a href="#基础设施服务的管理" class="headerlink" title="基础设施服务的管理"></a>基础设施服务的管理</h2><p>经常会出现已经成功完成部署流水线并在生产环境中运行的软件因为基础设施问题而不同正常工作。如DNS服务问题等。这种问题一般会比较难以诊断。有以下几个建议：</p><ul><li>对网络基础设施的每个部分都应该进行版本控制，使用Ansible类似的工具将配置文件从版本控制库中取出放在系统中运行，实现自动化</li><li>安装一个好用的网络监控系统</li><li>应用程序中对网络连接出现问题时，日志记录</li><li>确保冒烟测试在部署时检查所有的连接</li><li>确保集成测试环境的网络拓扑尽可能与生产相似</li><li>出现问题时，可以使用tcpdump和wireshark进行排查</li></ul><h2 id="多宿主系统"><a href="#多宿主系统" class="headerlink" title="多宿主系统"></a>多宿主系统</h2><p>生产系统中一个重要的增强部分是不同类型的流量使用多个隔离网络，并与多宿主服务器结合使用。多宿主服务器多个网络，一个用于运行备份，一个用于服务器的监控与管理，一个用做服务器间数据传输。</p><h2 id="基础设施和应用程序的监控"><a href="#基础设施和应用程序的监控" class="headerlink" title="基础设施和应用程序的监控"></a>基础设施和应用程序的监控</h2><p>创建监控策略时，需要考虑以下四点：</p><ul><li>对应用程序和基础设施进行监测，以便可以收集必要的数据</li><li>存储数据，以便拿来分析</li><li>创建一个信息Dashboard，将数据聚合在一起图表的形式展现出来</li><li>建立通知机制，便于及时关注关心的事件</li></ul><p>监控数据类型</p><ul><li>硬件，通过带外监控服务器的电压、温度、系统风扇速度、peripheral health等。</li><li>构成基础设施的那些服务器上的操作系统，比如内存使用、CPU使用情况、交换分区、磁盘、IO、带宽等使用情况。</li><li>中间件，如内存、数据库连接池、线程池、连接数、响应时间等。</li><li>应用程序，设计一些数据监控的hook，比如业务交易数量、价格、转换率等。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（交付生态圈）第十三章：组件和依赖管理</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%EF%BC%9A%E7%BB%84%E4%BB%B6%E5%92%8C%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%EF%BC%9A%E7%BB%84%E4%BB%B6%E5%92%8C%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>持续交付让应用程序处于随时可发布的状态。在大型重构或添加复杂功能时，要继续保持应用的可发布状态，需要对大型应用组件化。<br>组件是指应用程序中的一个规模相当大的代码结构，它具有一套定义良好的API，而且可以被另一种实现方式代替。一个基于组件的软件系统，通常其代码库被分成多个相互分离的部分，每个部分通过有限的定义良好的接口提供一些服务与其他组件进行有限的交互。有人把组件称为模块。<br>基于组件的设计是一种良好的架构，具有松耦合性。</p><h2 id="保持应用程序可发布"><a href="#保持应用程序可发布" class="headerlink" title="保持应用程序可发布"></a>保持应用程序可发布</h2><p>团队不断地增加新特性，可以给每次新特性创建新的分支，当新特性完成后，再将它合并到主分支。这将会导致合并周期变长，无法做到持续集成，这种方法不是最好的。<strong>提倡每个人都应该提交到主干</strong>。可是这样又该如何保证主干一直保持可发布状态呢？有如下四种策略：</p><ul><li>将新功能隐藏起来，直到它完成为止。一种方法是把新功能直接放进主干，但对用户不可见，比如通过单独的URL来访问，通过Web服务器配置不允许访问其入口；另一种方法是通过配置项开关来管理。把功能半成品与系统其他部分一同发布是一个好实践。</li><li>将所有的变更都变成一系列的增量小修改，而每次小修改都是可发布的。首先需要用各种方式将一个需求分解成较小的任务，然后将这些任务再划分成更小的增量修改。</li><li>使用通过抽象来模拟分支的方式对代码库进行大范围的变更。在要修改的那部分代码上创建一个抽象层，然后在当前实现方法存在的同时，开发一种新的实现方式，当完成时再把原始的实现和抽象层删除。</li><li>使用组件，根据不同部分修改的频率对应用程序解耦。</li></ul><h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>库是团队除了选择权以外，没有控制权的软件包，它们很少更新。组件是应用程序所依赖的代码块，它一般由团队自己开发的，更新频繁。<br>构建时的依赖会与运行时依赖不同，管理依赖遇到问题。</p><ul><li>依赖地狱。应用程序的依赖版本与实际部署的版本不一致。</li><li>库管理。一种方法是将库文件提交到代码版本控制库中，但时间久了后会导致版本库变大且乱，同时库文件的状态难以管理。另一种方法是使用显示声明的库管理工具，如Maven。</li></ul><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>只有一个系统达到一定的复杂度时，才会考虑将它分成多个组件。组件的目的是为了提交团队的效率。</p><ul><li>它将问题分成更小更达意的代码块</li><li>组件常常表示出系统不同部分代码的变化率不同，且有不同的生命周期</li><li>将代码划分，也便于分析系统的职责描述和维护，并且提交了对代码的理解</li><li>提供了额外的自由度来优化构建和部署过程</li></ul><p>当我们遇到以下情况时，可以考虑将组件代码从代码库中独立出来</p><ul><li>代码库的一部分需要独立部署</li><li>打算将系统分成一个内核和一系列组件，以便用另一种实现代替当前系统的某部分或者支持用户自扩展</li><li>组件为其他系统提供了一个接口（如API接口）</li><li>代码的编译和链接时间太长</li><li>在开发环境中打开项目时间太长</li><li>对一个团队来说，代码库太大</li></ul><p>大多数情况下，我们建议整个应用程序使用一个构建流水线，每次提交修改时，就应该构建并测试整个应用。只有当效率太低而无法忍受时，才使用并行流水线方式。</p><h2 id="二进制包管理"><a href="#二进制包管理" class="headerlink" title="二进制包管理"></a>二进制包管理</h2><p>使用制品库来管理二进制包，如Artifactory，Nexus。制品库不应该包含那些无法重现的产物，即便删除整个制品库，也可以方便地将二进制包恢复出来，一般通过重新构建对应的代码。<br>最简单的制品库是磁盘上的一个目录，最重要的是它应该将一个二进制文件关联到版本控制库中生成该文件的某个源码版本对应上。<br>流水线与制品库相结合</p><ul><li>编译阶段会创建需要放到制品库的二进制文件</li><li>单元测试和验收测试阶段会从制品库中取出这些二进制文件，将生成的测试报告放在制品库中</li><li>用户验收测试阶段将二进制文件部署到UAT环境，用于手工测试</li><li>发布阶段从制品库中取出二进制文件，将它部署到生产环境</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（交付生态圈）第十二章：数据管理</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>应用程序可以通过删除前一个版本，使用新版本替换旧版本的方式部署，但是大多数系统，数据无法使用这种方式进行变更，一旦某个系统发布到了生产环境中，关联的数据将不断增加。数据往往是系统中最有价值的部分。当我们需要对数据系统进行结构修改或者内容修改时，就需要相关的策略。<br>对数据的修改是不可避免的，关键在于将数据迁移过程自动化。目前有一些工具对数据迁移提供了较多支持，它们还允许对数据库进行版本化管理。<br>另一个重要部分是测试数据的管理。</p><h2 id="数据库脚本化"><a href="#数据库脚本化" class="headerlink" title="数据库脚本化"></a>数据库脚本化</h2><p>任何数据库的修改都应该通过自动化过程来管理。包括<code>数据库的初始化</code>，<code>数据库所有的迁移</code>都需要脚本化，并将脚本提交到版本控制库中。<br>几乎所有的数据管理系统都支持通过自动化脚本进行数据存储的初始化工作。</p><ul><li>清除原有的数据库</li><li>创建数据库结构、数据弯路实例以及模式等</li><li>向数据库加载数据</li></ul><p>在大多数据项目中，数据库的使用要复杂得多。</p><h2 id="增量式修改"><a href="#增量式修改" class="headerlink" title="增量式修改"></a>增量式修改</h2><p>绝大多数据系统，对数据库更新时，要保留它们的数据。由于在部署时需要保留数据库中的已有数据，所以需要有回滚策略，以便部署失败时使用。这就需要对数据库进行版本控制。</p><ul><li>在数据库中创建一个数据，用来保存版本号</li><li>每次数据库进行修改时，需要创建两个脚本：升级脚本、回滚脚本</li><li>有一个配置项来设置数据库与应用版本对应关系</li></ul><p>在很多项目中，多个程序共用一套数据库存储。虽然这种方式并不推荐，最好是让程序直接交互，但是这种情况却是常见的。这种环境下对数据库变更，就需要对程序做完全的集成测试，确保数据库变更对相关影响到的程序都能测试到。同时对<strong>哪个应用使用了数据库哪个对象</strong>做登记也是可以的。</p><h2 id="数据库回滚和无停机发布"><a href="#数据库回滚和无停机发布" class="headerlink" title="数据库回滚和无停机发布"></a>数据库回滚和无停机发布</h2><p>生产环境部署有两个需求会成为数据库回滚的约束。</p><ul><li>回滚时需要保留本次升级后产生的数据</li><li>保持应用程序的可用状态</li></ul><ol><li>保留数据的回滚<br>回滚脚本要满足以下条件</li></ol><ul><li>包括模式修改，即不迁移任何数据</li><li>只删除新版本使用的那些数据，即使这些数据丢失了也没问题</li></ul><p>对于以下情况</p><ul><li>涉及从临时表中将数据导回来</li><li>删除那些旧版本系统无法接受的数据</li></ul><p>第一种方法是将那些不想丢失的数据库事务缓存，一旦应用程序被成功地重新部署，这些事件就可以重新播放一遍。<br>第三种方法是使用蓝绿部署，发布时对生产数据库（蓝环境）做一个备份，将备份放在绿环境中应用，迁移数据，将用户切换到绿环境中。回滚时，将用户切回蓝环境，再把绿环境的数据库上发生的新事务回收，在下一次更新之前重新应用这些事务到蓝数据库上。<br>2. 应用程序部署与数据库迁移解耦</p><p>第三种方法是将应用程序部署过程与数据迁移过程解耦，分别执行，这种可用于管理热部署。<br>开发应用程序升级的中间版本，它既与数据库上个版本兼容，也与数据库下个版本兼容。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-d600fa2f0d2946ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="将应用程序部署与数据库迁移解耦"></p><h2 id="测试数据的管理"><a href="#测试数据的管理" class="headerlink" title="测试数据的管理"></a>测试数据的管理</h2><ol><li>为单元测试进行数据库模拟<br>单元测试不使用真正的数据库，通常它会使用测试替身对象来取代与数据库打交道的服务。如果做不到的话：</li></ol><ul><li>用测试替身对象来替代那些访问数据库的代码，通常使用repository模式</li><li>使用假的数据库，如H2&#x2F;SQLite&#x2F;JavaDB。单元测试运行在一个内存数据库上，让验收测试运行在平时使用的磁盘的数据库上。</li></ul><ol start="2"><li>管理测试与数据之间的耦合<br>以下三种方法可以用来做测试设计，便于管理好数据的状态：</li></ol><ul><li>测试的独立性**[推荐]**，合理组织测试，让每个测试的数据只对该测试可见</li><li>适应性测试，运行时先对数据环境进行检查，用检查的数据作为数据基础进行测试</li><li>测试的顺序，按某种已知的序列运行，每次测试输入依赖于前一个输出</li></ul><p>保持测试的独立性最简单的方法是确保在测试结束时，总是把数据库中的数据状态恢复到测试之前。<br>对于支持事务的数据库来说，测试开始时创建一个事务，在事务内执行所需的数据库操作与交互，测试结束后，将该事务进行回滚。<br>不建议创建一个连贯的“故事”进行顺序执行，这个有序的测试无法真正地代表测试的目的和内容。</p><h2 id="数据管理和部署流水线"><a href="#数据管理和部署流水线" class="headerlink" title="数据管理和部署流水线"></a>数据管理和部署流水线</h2><ul><li>提交阶段的测试数据，避免复杂的数据准备。</li><li>验收测试的数据，尽可能减少测试对大型复杂数据结构的依赖。测试专属数据、测试引用数据、应用程序引用数据</li><li>容量测试的数据，为测试提供足够的输入数据，准备适当的引用数据支持测试中的用例</li><li>其他测试阶段的数据，推荐利用生产数据的一个子集或者运行一些自动化验收测试或者容量测试之后产生的数据库，为其他测试阶段提供数据。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（交付生态圈）第十四章：版本控制进阶</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%EF%BC%9A%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%BF%9B%E9%98%B6/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E4%BA%A4%E4%BB%98%E7%94%9F%E6%80%81%E5%9C%88%EF%BC%89%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%EF%BC%9A%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>版本控制用来维护应用程序每次修改的完整历史，包括源代码、文档、数据库定义、构建脚本和测试等。团队可以在一个代码版本控制库上一起开发应用程序的不同部分。一旦团队人数超过一定数量，就需要规划版本控制库的使用，让开发更加高效。</p><h2 id="分支与合并"><a href="#分支与合并" class="headerlink" title="分支与合并"></a>分支与合并</h2><p>分支，即为选择的基线创建一个副本，该副本与原基线相互独立，开发者能在两个工作流上同时开发。<br>团队为什么使用分支？</p><ul><li>物理上：系统物理配置而分支，即为文件、组件和子系统而分支</li><li>功能上【最常见】：系统功能配置而分支，即为特性、逻辑修改、缺陷修复和功能增加，以及其他可交付的功能而分支</li><li>环境上：系统运行环境而分支，即由构建平台和运行时平台的不同而分支</li><li>组织上：团队的工作量而分支，即为活动&#x2F;任务、子项目、角色和群组而分支</li><li>流程上：团队的工作行为而分支，支持不同规章政策、流程和状态而分支</li></ul><p>在开发中，经常会遇到分支合并的情况，除非那些为了发布或者技术预研而创建的分支。两次合并时间间隔越长，每个分支上工作的人越多，合并发生冲突的可能性就越大。以下两种方法来减小冲突：</p><ul><li>创建更多的分支来减少在每个分支上的修改。这只是将痛苦延后而已。</li><li>很谨慎地创建分支，可能每个发布才创建一个分支。为了尽量减少合并的痛苦就经常做合并。<br>一个强烈推荐的分支策略是：只为发布创建长期的分支。这种模式下，新开发的代码总是被提交到主干上，只有在发布分支上修改缺陷时才需要合并，而这具合并是从分支合并回主干。只有非常严重的缺陷修复才会从主干合并到发布分支上。</li></ul><h2 id="分布式版本控制系统（Git）"><a href="#分布式版本控制系统（Git）" class="headerlink" title="分布式版本控制系统（Git）"></a>分布式版本控制系统（Git）</h2><p>分布式版本控制系统就是每个使用者本地都有一个完整的代码仓库。它有了很多新特性：</p><ul><li>在几秒内就能开始使用分布式版本控制系统</li><li>可以单独从别人那里拿到他们的最新更新，不需要提交到中央代码库</li><li>可以将自己修改推送到一组人的代码库中，而不需要他们每个人来取你的修改</li><li>补丁可以通过网络用户更高效地传播</li><li>没有网络的时候，也可以对修改的代码版本控制</li><li>可以频繁地提交未完成的功能到本地代码库，而不影响其他人</li><li>将修改发送给其他人之前，可以很容易地在本地对这些提交进行修改，重排它们的顺序或者将多次提交打包成一个，这个叫‘rebasing’</li><li>很容易用本地代码库来尝试各种解决方案或想法</li><li>能在本地把多次提交打包</li><li>在本地建立和同步多个代理库很容易，有更高的可用性</li><li>全量代码有很多份副本，有更好的容错性</li></ul><h2 id="主干开发"><a href="#主干开发" class="headerlink" title="主干开发"></a>主干开发</h2><p>开发人员总是提交代码到主干，而使用很少使用分支。这有以下三个好处：</p><ol><li>确保所有代码被持续集成</li><li>确保开发人员及时获得他人的修改</li><li>避免项目后期的“合并地狱”和“集成地狱”</li></ol><p>开发人员在主干上工作，每天至少提交一次代码。当需要做复杂的修改时，修改会被分成一系列小的增量步骤有计划地实现，而每个步骤都会通过测试且不会破坏已有的功能。<br>主干开发并不排斥分支，只有当不需要合并回主干时，才创建分支。如发布分支，技术预研分支。<br>如果开发人员很多，且有多个版本发布的大型团队，软件需要良好的组件化、增量式开发和特性隐藏。要做的是持续频繁地向主干分支提交代码，每天至少一次提交。</p><h2 id="按发布创建分支"><a href="#按发布创建分支" class="headerlink" title="按发布创建分支"></a>按发布创建分支</h2><p>在某个版本即将发布之前，创建发布分支。该分支一旦创建，该发布版本的测试和验证全部在该分支上进行，而最新的开发工作仍然在旧的主干分支上进行。发布分支上只做严重缺陷的修复。遵循如下规则：</p><ol><li>一直在主干上开发新功能</li><li>当待分布版本的所有功能完成，且希望继续开发新功能时才创建一个分支</li><li>在分支上只允许提交修复严重缺陷的代码，且这些修改必须立即合并到主干</li><li>执行实际的发布时，这个分支可以选择性地打个标签</li></ol><p>不要在已有的发布分支上再创建更多的分支，所有后续分支都应该从主干上创建。<br>一旦发布频率达到一定的频率（比如一周一次），就没必要创建分支了，在这种情况下，发布一个新版本要比在已发布的分支上打补丁更容易，成本更低。而且部署流水线机制可能为你保留了一份记录，包括发布的软件在版本控制库中对应的修订版本号。</p><h2 id="按功能特性分支"><a href="#按功能特性分支" class="headerlink" title="按功能特性分支"></a>按功能特性分支</h2><p>为了让开发团队更容易在“特性”层次上并行工作，并保持主干为可发布状态，这时使用特性分支。<br>使用特性分支，需要遵循以下规则：</p><ol><li>每天都要把主干上的所有变更合并到每个分支上</li><li>每个特性分支都应该是短生命周期的，理想情况只有几天</li><li>活跃分支的数量随时都应该少于或等于开在开发当中的用户故事的数量。只有在已经把开发的用户故事合并回主干，才允许创建新的特性分支</li><li>在合并回主干之前，该用户故事应该已经由测试人员验收通过</li><li>重构必须即时合并，从而将合并冲突最小化</li><li>技术负责人的一部分职责就是保证主干的可发布状态</li></ol><h2 id="按团队分支"><a href="#按团队分支" class="headerlink" title="按团队分支"></a>按团队分支</h2><p>团队分支模式的工作流：<br>多个开发人员同时工作在多个工作流上，还要保证主干随时可发布状态</p><ol><li>创建多个小团队，每个团队自己有对应的分支</li><li>一旦某个特性或用户故事完成，让该分支稳定下来，合并到主干</li><li>每天都将主干上的变更合并到每个分支上</li><li>对于每个分支，每次提交代码都要运行单元测试和验收测试</li><li>每次分支合并回主干时，主干上也要运行所有的测试，包括集成测试</li></ol><p>在有几个比较小而且相对独立的团队，同时各团队负责该软件系统中功能相对独立的情况下，该模式才有效。<br>从持续集成的角度说，该策略有一些缺点，根本问题是该模式下的工作单元是一个分支，而不是一次特定的修改。<br>这种模式与特性分支模式很类似。它的优点是：分支较少，所以集成工作会频繁一些。缺点是：各分支很快会变得差异很多，在合并操作时会更复杂。团队分支很快会和主干变得很不一样，差异很大，合并冲突可能很快就变得极其痛苦。<br>推荐使用“功能隐藏”的方式进行增量开发，从而做到应用程序随时可发布。即使某个功能特性正在开发中，也把它隐藏起来，这种方法需要更多的纪律性，但风险小，避免了分支的不断合并带来的复杂性，而且可以快速得到某次提交对整个应用的影响的反馈，这正是真正的持续集成可以提供的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（基础篇）第一章：软件交付的问题</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E8%BD%AF%E4%BB%B6%E4%BA%A4%E4%BB%98%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E8%BD%AF%E4%BB%B6%E4%BA%A4%E4%BB%98%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><h3 id="软件构成部分：可执行的代码、配置信息、运行环境、数据"><a href="#软件构成部分：可执行的代码、配置信息、运行环境、数据" class="headerlink" title="软件构成部分：可执行的代码、配置信息、运行环境、数据"></a>软件构成部分：可执行的代码、配置信息、运行环境、数据</h3><ul><li>不同环境下只进行一次编译</li><li>对环境的任何修改都应该作为配置信息管理，配置信息的更改都需要经过测试</li><li>如果运行环境需要修改，则修改后的环境也需要进行测试。环境包括：操作系统配置、应用程序依赖的软件集、网络配置及任何基础设置、外部系统</li><li>数据结构发生变化，同样需要经过测试</li></ul><h3 id="反馈流程：指完全以自动化的方式尽可能地测试每一次变更"><a href="#反馈流程：指完全以自动化的方式尽可能地测试每一次变更" class="headerlink" title="反馈流程：指完全以自动化的方式尽可能地测试每一次变更"></a>反馈流程：指完全以自动化的方式尽可能地测试每一次变更</h3><ul><li>创建可执行代码的流程</li><li>单元测试</li><li>质量检测：测试覆盖率以及其他与技术相关的度量项</li><li>功能测试验收</li><li>性能、有效性、安全性等非功能测试</li><li>探索性测试，给客户&#x2F;最终应用演示</li></ul><h3 id="自动化测试反馈"><a href="#自动化测试反馈" class="headerlink" title="自动化测试反馈"></a>自动化测试反馈</h3><p>【commit阶段】</p><ul><li>运行速度快</li><li>尽可能全面，75%代码库覆盖率</li><li>环境中立，相对生产环境简单廉价</li><li>如果出现问题，绝不发布<br>【commit之后测试】</li><li>运行速度慢一些，适合并行执行</li><li>即使有些测试问题，也可以发布应用程序</li><li>运行环境尽可能与生产相同</li></ul><h3 id="不同版本、不同环境的配置放在版本控制中"><a href="#不同版本、不同环境的配置放在版本控制中" class="headerlink" title="不同版本、不同环境的配置放在版本控制中"></a>不同版本、不同环境的配置放在版本控制中</h3><ul><li>开发人员都拥有自己的专属开发环境</li><li>无论部署在什么目标环境都应采用同一种部署方法</li><li>开发环境是特例，可以有多变性部署方法</li></ul><h3 id="软件的交付原则"><a href="#软件的交付原则" class="headerlink" title="软件的交付原则"></a>软件的交付原则</h3><ul><li>为软件的发布创建一个可重复且可靠的过程</li><li>将几乎所有的事情自动化（构建、部署、测试、发布）</li><li>把所有的东西都纳入版本控制（需求文档、测试脚本、自动化测试用例、网络配置脚本、部署脚本、数据库创建、升级、回滚和初始化脚本、库文件、应用程序依赖的软件集、工具链及技术文档等)</li><li>找到流程中最痛苦的事情，并提交频繁地进行：如果集成最痛苦，那应在开始阶段就不断进行集成、测试；如果发布痛苦，每次提交并通过自动化测试后就进行发布</li><li>用户故事只有到了已发布才算完成，交付成果属于每个成员，交付前每个成员都为其负责</li><li>持续改进，交付过程中，整个团队召开回顾会议，提出改进方向及方法，每个改进点应该同一个人负责跟踪，确保改进被执行，下一次回顾会议，汇报结果。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（基础篇）第三章：持续集成</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>持续集成要求每当有人提交代码时，就对整个应用进行构建，并对其执行全面的自动化测试集合，一旦出现问题，开发团队应停下手中的工作，修复问题。<br>持续集成的目标是：让正在研发的软件一直处于可工作的状态。</p><h2 id="实施持续集成的先决条件"><a href="#实施持续集成的先决条件" class="headerlink" title="实施持续集成的先决条件"></a>实施持续集成的先决条件</h2><ul><li>版本控制，与项目相关的所有内容都必须提交到一个版本控制库中（产品代码、测试代码、数据库脚本、构建与部署脚本、以及所有用于创建安装运行和测试该应用的程序的东西）</li><li>自动化构建：必须满足人和计算机都能通过命令行自动执行应用的构建、测试以及部署过程</li><li>团队共识：持续集成是一种实践，需要团队所有成员都遵循规则</li></ul><h2 id="一个基本持续集成系统"><a href="#一个基本持续集成系统" class="headerlink" title="一个基本持续集成系统"></a>一个基本持续集成系统</h2><ul><li>第一次在持续集成工具上执行构建时，可能会缺少一些必须的软件及配置，请将所操作的工作记录下来，并放在自己项目的知识共享库中，应花一些时间将应用程序所依赖的所有软件和配置项提交到版本控制系统中，并将重建全新环境的整个活动变成一个自动化的过程</li><li>查看一下是否有构建正在运行，如果有，等它运行完。如果它失败了，则与团队其他人一起将它修复，后再提交自己的代码</li><li>一量构建完成且测试全部通过，就从版本控制库中将该版本的代码更新到自己的开发环境上</li><li>在自己的开发机上执行构建脚本、运行测试，以确保所有代码在本地工作正常</li><li>如果本地构建成功，就将代码提交到版本控制库中，然后等待包含本次提交的构建结果</li><li>如果构建失败，就停下手中的工作，立即修复这个问题，本地测试通过后，再次提交代码到版本控制库中</li><li>如果构建成功，开始下一项任务</li></ul><h2 id="持续集成的前提条件"><a href="#持续集成的前提条件" class="headerlink" title="持续集成的前提条件"></a>持续集成的前提条件</h2><ul><li>频繁提交，开发始终在主干上提交代码</li><li>创建全面的自动化测试套件【单元测试（10m），组件测试（较长），验收测试（长）】</li></ul><p>理想情况下，提交前的预编译和测试过程与持续集成服务器上的编译和测试过程都应在几分钟内结束，10m是极限，90s内完成最理想。<br>如果测试过程太久，则需要找出那些运行较慢的测试，优化它，缩短测试时间。<br>测试分为两个阶段：提交阶段、提交后阶段</p><ul><li>提交阶段：运行所有类别的单元测试，并构建部署的二进制文件。提交前运行一次，通过后再提交到持续集成环境再运行一次</li><li>提交后阶段：进行验收测试、集成测试，一旦提交测试通过，立马运行验收测试。如果超过30m，就要考虑采用高性能多进程机器缩短测试时间</li></ul><h2 id="使用持续集成软件"><a href="#使用持续集成软件" class="headerlink" title="使用持续集成软件"></a>使用持续集成软件</h2><ul><li>触发Job或轮询版本控制系统，如果有更新，运行构建脚本及测试</li><li>提供展示这个流程运行结果的视图，并通知报告 ，拿到生成它的安装文件等</li></ul><h2 id="必不可少的实践"><a href="#必不可少的实践" class="headerlink" title="必不可少的实践"></a>必不可少的实践</h2><ul><li>构建失败之后不要提交新代码</li><li>提交前在本地运行所有的提交测试或让持续集成服务器完成此事</li><li>等提交测试通过后再继续工作</li><li>回家之前，构建必须处于成功状态</li><li>时刻准备着回滚到前一个版本</li><li>在回滚之前需要规定一个修复时间</li><li>不要将失败的测试注释掉</li><li>为自己导致的问题负责</li><li>测试驱动的开发</li></ul><h2 id="推荐的实践"><a href="#推荐的实践" class="headerlink" title="推荐的实践"></a>推荐的实践</h2><ul><li>极限编程开发实践</li><li>若违背架构原则，就让构建失败</li><li>若测试运行变慢，就让测试失败（2s)</li><li>若有编译警告或代码风格问题，就让构建失败</li></ul><h2 id="在持续集成系统之上的扩展"><a href="#在持续集成系统之上的扩展" class="headerlink" title="在持续集成系统之上的扩展"></a>在持续集成系统之上的扩展</h2><p>持续集成的实施迫使你遵循两个重要的实践：</p><ul><li>良好的配置管理</li><li>创建并维护一个自动化构建和测试流程</li></ul><p>一个好的持续集成系统是基石，在此之上你可以构建更多的基础设置：</p><ul><li>一个巨大的可视化指示器，用于显示构建系统所收集的信息，以提供高质量的反馈</li><li>结果报告系统，以及针对自己测试团队的安装包</li><li>为项目经理提供关于应用程序质量的数据的提供程序</li><li>使用部署流水线，可以将其延展到生产环境，为测试人员和运维团队提供一键式部署系统</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（基础篇）第二章：配置管理</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>配置管理指一个过程，通过该过程，所有与项目有关的产物，以及它们之间的关系都被唯一定义、修改、存储与检索。</p><h2 id="使用版本控制"><a href="#使用版本控制" class="headerlink" title="使用版本控制"></a>使用版本控制</h2><ul><li>对所有内容进行版本控制（所需的支撑软件配置信息，操作系统配置信息、DNS区域文件和防火墙配置等）</li></ul><p>配置管理是持续集成交付过程的基础。</p><h3 id="软件配置管理"><a href="#软件配置管理" class="headerlink" title="软件配置管理"></a>软件配置管理</h3><h4 id="灵活性：先专注于提供具有高价值且可配置程度低的功能，冒烟测试就是一种缓解配置验证问题的方法"><a href="#灵活性：先专注于提供具有高价值且可配置程度低的功能，冒烟测试就是一种缓解配置验证问题的方法" class="headerlink" title="灵活性：先专注于提供具有高价值且可配置程度低的功能，冒烟测试就是一种缓解配置验证问题的方法"></a>灵活性：先专注于提供具有高价值且可配置程度低的功能，冒烟测试就是一种缓解配置验证问题的方法</h4><h4 id="配置分类"><a href="#配置分类" class="headerlink" title="配置分类"></a>配置分类</h4><ul><li>推荐应使构建打包生成的包，面向所有环境，并不植入配置信息</li></ul><h4 id="应用程序的配置管理"><a href="#应用程序的配置管理" class="headerlink" title="应用程序的配置管理"></a>应用程序的配置管理</h4><ul><li>将特定于测试环境或生产环境的实际配置信息存放于与源代码分离的单独代码库，需要注意配置信息的版本，一定要与相应的应用软件的版本相切尔西</li><li>不要把密码放在版本控制系统中</li><li>获取配置信息：文件系统、从某个中心仓库中获取配置信息</li><li>配置信息：区分应用、版本、环境，都需要满足以下：<ul><li>新增一个环境，能为这个配置应用的新环境指定一套新的配置信息</li><li>新建应用程序的一个新版本，确保在部署新版本时，使用新的配置，但是一量需要回滚时，还能够使用旧版本的配置</li><li>将新版本从一个环境移到另一个环境，确保新环境上的新配置里有效</li><li>重定向到一个数据库服务器，只需要简单更改一个配置项</li><li>通过虚拟化技术管理环境</li></ul></li><li>一种方法是把预生产环境的配置信息作为默认配置，其它环境通过适当的方式覆盖这些默认值，尽量减少配置项</li></ul><h4 id="跨应用的配置管理"><a href="#跨应用的配置管理" class="headerlink" title="跨应用的配置管理"></a>跨应用的配置管理</h4><p>每个应用程序的配置项管理都应该作为项目启动阶段的一个议题，且应维护一份应用程序配置选项索引表，记录配置项的功能，位置及生命周期，如何修改。</p><ul><li>在应用程序的生命周期中，我们应该在什么时候注入哪类配置信息，要与系统运维和支持团队一同讨论。</li><li>将应用程序的配置项与源代码保存在一个仓库中，但要把配置项的值保存在别处，另外像用户密码这类敏感信息不应该放在版本控制库中</li><li>应该总是通过自动化的过程将配置项从保存配置信息的存储库中取出并设置好，这样就能很容易掌握不同环境中的配置信息了</li><li>配置系统应该能依据应用、版本、环境为打包、安装以及部署脚本提供不同的配置值。</li><li>对每个配置项都应用明确的命名习惯，避免使用难懂的名称。</li><li>确保配置信息是模块化且封闭的，使得对某处配置项的修改不会影响到那些与其无关的配置项。</li><li>DRY原则。定义好配置中的每个元素，使每个配置元素在整个系统中都是唯一的，其含义绝不与其他元素重叠。</li><li>最少化，即配置信息应尽可能简单且集中。</li><li>避免对配置信息的过分设计，应该尽可能简单。</li><li>确保测试已覆盖到部署或安装时的配置操作。</li></ul><h4 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h4><ul><li>环境中各种各样的操作系统，包括其版本、补丁级别及配置设置</li><li>应用程序所依赖的需要安装到每个环境中的软件包，以及这些软件包的具体版本及配置</li><li>应用程序正常工作所需的网络拓扑结构</li><li>应用程序所依赖的所有外部服务，以及这些服务的版本和配置信息</li><li>现有的数据以及其他相关信息</li></ul><p>当评估第三方产品或服务时，应该问自己以下问题：</p><ul><li>我们可以自行部署它吗？</li><li>我们能对它的配置做有效的版本控制吗？</li><li>如何使它适应我们的自动化部署策略？</li></ul><p>对环境的变更过程进行管理，严格控制生产环境，未经组织内部正式的变更管理过程，任何人不得对其进行修改。<br>应该像对待生产环境一样对待测试环境，其配置管理应该与生产环境中的配置管理一样的策略。</p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（基础篇）第四章：测试策略的实现</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E6%B5%8B%E8%AF%95%E7%AD%96%E7%95%A5%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E7%A1%80%E7%AF%87%EF%BC%89%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E6%B5%8B%E8%AF%95%E7%AD%96%E7%95%A5%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>项目在一开始阶段，测试人员就会与开发人员及客户一起写自动化测试。这些测试应该在开发前就写好。<br>以上这些测试仅仅是系统进行功能测试，容量、安全性及其非功能性试也应尽早建立，为它们写自动化测试套件。确保不符合需求的问题尽早暴露。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-94ada21d67f8c7dd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="测试象限图"></p><h3 id="业务导向且支持开发过程的测试"><a href="#业务导向且支持开发过程的测试" class="headerlink" title="业务导向且支持开发过程的测试"></a>业务导向且支持开发过程的测试</h3><p>在开发一个用户故事之前，应写好验收测试，采取完美的自动化形式。<br>系统的验收测试应运行在类生产环境（UAT)<br>验收测试有价值的特性：</p><ul><li>它加快了反馈速度 </li><li>减少了测试人员的工作负荷</li><li>让测试人员集中精力做探索性测试和高价值的活动</li><li>这些验收测试也是一组回归测试套件</li><li>行为驱动开发，可以以这些测试中自动生成需求说明文档</li></ul><p>并不是所有的东西都需要自动化。我们倾向于将自动化验收测试限于完全覆盖Happy Path的行为，并仅覆盖其它一些极其重要的部分。每一种测试都应该覆盖应用程序的80%<br>验收测试一般都是端对端测试，但是这样很多时候验收测试的失败并不是因为真正的缺陷，而是因为界面的变更，这将导致增大了验收测试脚本的维护。有两种方法解决这个问题：</p><ul><li>在测试与用户界面之间增加一个抽象层，以便减少因用户界面变更而导致的问题</li><li>通过公共API来运行这些验收测试，用户界面会使用这些公共API来执行真正的操作</li></ul><p>###技术导向且支持开发过程的测试<br>单元测试：不应该访问数据库，不应该使用文件系统，不与外部系统交互<br>组件测试：涉及更多的准备工作并执行更多的IO，需要连接数据库，文件系统，与外部系统交互<br>部署测试：用于检查部署过程是否正确</p><h3 id="业务导向且评价项目的测试"><a href="#业务导向且评价项目的测试" class="headerlink" title="业务导向且评价项目的测试"></a>业务导向且评价项目的测试</h3><p>其中非常tgsvr一种测试是：演示<br>探索性测试，并不只是发现缺陷，它还会致使创建新的自动化集合<br>易用性测试，为了验证用户是否能很容易使用该应用软件完成工作<br>Beta测试，金丝雀发布，多个版本同时运行在生产环境，收集不同版本的数据，如果分析证明新功能无法带来足够的价值，就删除它</p><h3 id="技术导向且评价项目的测试"><a href="#技术导向且评价项目的测试" class="headerlink" title="技术导向且评价项目的测试"></a>技术导向且评价项目的测试</h3><p>验收测试分两类：功能性测试，非功能性测试</p><h3 id="测试替身"><a href="#测试替身" class="headerlink" title="测试替身"></a>测试替身</h3><ul><li>哑对象：那些被传递但不被真正使用的对象</li><li>假对象：可以真正使用的实现，但通常会利用一些捷径</li><li>桩：在测试中为每个调用提供一个封装好的响应，它通常不会对测试之外的请求进行响应，只用于测试</li><li>SPY：一种可记录一些关于它们如何被调用的信息的桩</li><li>模拟对象：一种在编程时就设定了它的预期要接收的调用</li></ul><h3 id="现实中的情况与应对策略"><a href="#现实中的情况与应对策略" class="headerlink" title="现实中的情况与应对策略"></a>现实中的情况与应对策略</h3><h4 id="新项目：一开始就要写自动化验收测试"><a href="#新项目：一开始就要写自动化验收测试" class="headerlink" title="新项目：一开始就要写自动化验收测试"></a>新项目：一开始就要写自动化验收测试</h4><ul><li>选择技术平台和测试工具</li><li>建立一个简单的自动化构建</li><li>制定遵守INVEST原则【独立的，可协商的，有价值的，可估计的，小的，可测试的】用户故事及考虑其验收条件</li><li>客户、分析师和测试人员定义验收条件</li><li>测试人员与研发人员一起基于验收条件实现验收测试的自动化</li><li>开发人员编码来满足验收条件</li><li>只要有自动化测试失败，开发人员优先修复问题</li></ul><h4 id="项目进行中"><a href="#项目进行中" class="headerlink" title="项目进行中"></a>项目进行中</h4><ul><li>引入自动化测试最好的方式是选择应用程序中那些最常见，最重要且高价值的用例为起点。</li><li>让测试覆盖的范围稍稍宽于通常的用户故事级别的验收测试。</li><li>如果发现对同一个功能重复进行了多次的手工测试，就判断该功能是否还会个性。如果不会，就将这个测试自动化，否则，说明这个测试覆盖的功能一直变化，可以与客户和开发确认后，把它从测试集合中先忽略掉，并尽可能详细地写注释</li><li>如果时间紧，最好利用各种各样的测试数据来确保一定的覆盖率</li></ul><h4 id="遗留系统"><a href="#遗留系统" class="headerlink" title="遗留系统"></a>遗留系统</h4><ul><li>如果没有自动构建流程，最高优先级是创建一个自动构建流程，然后创建更多的自动化功能测试来丰富它</li><li>识别系统中高价值的功能，聚焦于系统中高价值的功能</li><li>基于高价值功能，创建一套广泛的自动化测试</li><li>逐渐为新增功能添加相应的测试</li><li>只写那些有价值的自动化测试，如果只是新增功能，而不需要修改提供支撑的框架代码时这部分代码不需要写全面的测试</li></ul><h4 id="集成测试"><a href="#集成测试" class="headerlink" title="集成测试"></a>集成测试</h4><p>集成测试：那些确保系统的每个独立部分都能够正确作用于其依赖的那些服务的测试<br>集成测试应该在两种上下文中运行：</p><ul><li>被测试的应用程序使用其真正依赖的外部系统来运行时，或使用由外部服务供应商所提供的替代系统</li><li>应用程序运行于你自己创建的一个测试用具之上<br>确保在正式部署生产环境之前，应用程序不要与真实的外部系统进行交互，否则就要想办法告诉外部系统，应用所发送的数据只用于测试</li><li>在测试环境中使用“防火墙”，将该应用程序与外部系统隔离开来</li><li>在应用程序中用一组配置信息，让其与外部系统的模拟版本交互<br>把关于集成的活动放到发布计划中是非常必要的。与外部系统的集成总是比较复杂，需要花时间并制定计划。每当增加一个外部系统集成点时，项目风险就会增，集成风险：</li><li>测试服务是否准备好了？它是否能正常运行？</li><li>外部服务供应商是否有足够的资源与人力来回答我们遇到的问题，修改缺陷，添加我们提出的一些定制功能?</li><li>我们是否能直接访问真实的生产环境，以便验证外部系统是否满足我们的容量要求或可用性要求？</li><li>外部服务提供的API是否很容易与我们自己开发应用软件时所采用的技术进行集成，我们团队是否需要某些专业技能才能使用这些API?</li><li>是否需要编写并维护我们的测试服务？</li><li>当外部系统的响应与我们所期望的行为不一致时，我们自己的应用程序是否能够正确地处理？</li><li>还需要构建与维护这个集成层及相关的运行时配置，测试服务与测试策略。</li></ul><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><ul><li>找出最高优先级的测试场景</li><li>代码让这些验收条件变成可执行的测试</li><li>测试人员与研发人员在开发前应尽早一起讨论验收测试</li></ul><h3 id="管理待修复的缺陷列表"><a href="#管理待修复的缺陷列表" class="headerlink" title="管理待修复的缺陷列表"></a>管理待修复的缺陷列表</h3><ul><li>将待修复缺陷列表可视化</li><li>一种零缺陷，关注缺陷问题，并修复</li><li>像对待功能一样对待缺陷，将功能与缺陷一起做优先级排序，让开发按优先级进行开发</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（部署流水线）第七章：提交阶段</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E6%8F%90%E4%BA%A4%E9%98%B6%E6%AE%B5/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E6%8F%90%E4%BA%A4%E9%98%B6%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>提交阶段的运行应该少于5分钟，一定不要超过10分钏<br>提交阶段的首要目标是创建可部署的产物</p><h1 id="提交阶段的原则与实践"><a href="#提交阶段的原则与实践" class="headerlink" title="提交阶段的原则与实践"></a>提交阶段的原则与实践</h1><ul><li>提供快速有用的反馈</li><li>何时令提交阶段失败<ul><li>编译错误</li><li>测试失败（包括单元覆盖率低于60%）</li></ul></li><li>精心对待提交阶段<ul><li>提交阶段中有构建用的脚本和运行单元测试、静态分析等脚本。</li><li>随着项目的进行，不断改进提交阶段的脚本的质量、设计和性能</li><li>确保将脚本做成模块化，将那些经常使用且很少变化的常见任务与需要修改的任务分开</li><li>将部署流水线中不同阶段所用的代码分别写在不同脚本中</li><li>不要写出与具体环境相关的脚本，即要把具体环境配置与构建脚本分离</li></ul></li><li>让开发人员也拥有所有权<br>如果必要的话，即使是很普通的变更也都应该由开发人员和运维人员来执行</li><li>在超大项目团队中指定一个构建负责人<ul><li>监督和指导对构建的维护</li><li>鼓励和加强构建纪律</li><li>在团队开始接触持续集成时，构建纪律还没建立起来时，提醒作用  </li><li>团队成员轮流当，比如每星期轮换一次</li></ul></li></ul><h1 id="提交阶段结果"><a href="#提交阶段结果" class="headerlink" title="提交阶段结果"></a>提交阶段结果</h1><p>提交阶段的输入是源代码，输出是二进制包和报告（测试结果和代码分析报告）</p><h3 id="制品库"><a href="#制品库" class="headerlink" title="制品库"></a>制品库</h3><ul><li>制品库仅保存某些版本，而不是全部。如果在部署流水线某个阶段失败，就可以删除该版本</li><li>制品库中的二进制包能够追溯到具体的代码版本控制库中的版本</li><li>良好的配置管理策略，二进制文件的构建过程应该是可重复的</li></ul><h1 id="提交测试套件的原则与实践"><a href="#提交测试套件的原则与实践" class="headerlink" title="提交测试套件的原则与实践"></a>提交测试套件的原则与实践</h1><ul><li>提交阶段，测试绝大部分应由单元测试组成</li><li>设计 能够快速运行的提交测试策略</li><li>运行的单元测试不应该与文件系统、数据库、库文件、框架或外部系统等交互</li></ul><h3 id="提交测试实践"><a href="#提交测试实践" class="headerlink" title="提交测试实践"></a>提交测试实践</h3><ul><li>避免用户界面</li><li>使用依赖注入</li><li>避免使用数据库<br>单元测试不应该依赖于数据库，需要把测试的代码与其存储分离开来。这就要求代码实现良好的分层，也需要使用依赖注入。如果实在无法做到，使用内存数据库</li><li>避免异步</li><li>使用测试替身<br>模拟技术工具集：Mockito、Rhino、EasyMock、JMock、NMock、Mocha等</li><li>最少化测试中的状态<br>降低要构造的测试环境的复杂性</li><li>时间的伪装<br>对于那些需要确保一定延时或者定时的行为，需要对其中的时间系统进行控制。作者团队的经验是，只要代码中需要使用时间，就会抽象到对系统时间服务的请求，而不是直接在业务逻辑中调用它们</li><li>蛮力（测试阶段运行应该少于5分钟）<ul><li>将提交测试分成多个套件，在多台机器上并行执行（构建网格）</li><li>作为构建优化过程的一部分，将那些运行时间长，且不经常失败的测试放在验收测试阶段</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（部署流水线）第九章：非功能需求的测试</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%B9%9D%E7%AB%A0%EF%BC%9A%E9%9D%9E%E5%8A%9F%E8%83%BD%E9%9C%80%E6%B1%82%E7%9A%84%E6%B5%8B%E8%AF%95/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%B9%9D%E7%AB%A0%EF%BC%9A%E9%9D%9E%E5%8A%9F%E8%83%BD%E9%9C%80%E6%B1%82%E7%9A%84%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><h3 id="性能、吞吐量、容量概念"><a href="#性能、吞吐量、容量概念" class="headerlink" title="性能、吞吐量、容量概念"></a>性能、吞吐量、容量概念</h3><p>性能：对处理单一事务所花时间的一种度量，既可以单独衡量，也可以在一定的负载下衡量。<br>吞吐量：系统在一定时间内处理事务的数量，通常它受限于系统中的某个瓶颈<br>容量：一定的负载下，当每个单独请求的响应时间维持在可接受范围内时，系统所能承担的最大吞吐量。<br>非功能性：有效性、容量、安全性、可维护性等。</p><h3 id="非功能需求管理"><a href="#非功能需求管理" class="headerlink" title="非功能需求管理"></a>非功能需求管理</h3><p>将非功能需求与功能需求一样对待。</p><ul><li>创建一些具体任务来管理非功能需求</li><li>有必要的话，向功能需求中加入非功能需求的验收条件</li></ul><h3 id="如何为容量编程"><a href="#如何为容量编程" class="headerlink" title="如何为容量编程"></a>如何为容量编程</h3><ol><li>为何要做容量测试<br>高德纳著名格言：<br><code>在97%的时间里，我们都应该忘记那种小的效率提升：过早优化是所有罪恶之根。然而，我们也不能让另外非常关键的3%的机会与我们擦肩而过。一个优秀程序员不会因为这个原则而对其置之不理，他们非常聪明，只会在识别出那段关键代码后，才会非常细心地去查看。</code><br>在找到解决方案之前，必须先找出问题的根源。容量测试会告诉我们是否存在问题，以便我们可以修复它。不要枉自猜测，而要先进行度量。</li><li>解决容量问题<br>现代软件系统中，最昂贵的是网络通信或磁盘存储，在性能和应用程序的稳定性方面，跨进程或网络边界的通信是昂贵的，所以这类通信应该尽量最小化。<br>让业务干系人决定系统的容量特性极其重要，以免方案过度设计 。<br>为解决容量问题，可采取的策略：</li></ol><ul><li>为应用程序决定一种架构。通常要特别注意进程、网络边界和I&#x2F;O。</li><li>了解并使用正确的模式，避免使用那些影响系统容量和稳定性的反模式。</li><li>确保团队在已经明确的应用架构下进行开发，不要为容量做无谓的优化。在没有明确测试结果表明有容量问题时，坚决不能在代码可读性上让步。</li><li>注意在数据结构和算法方面的选择，确保它们的属性与应用程序相吻合。</li><li>处理线程时要特别注意。</li><li>创建一些自动化测试来断言所期望的容量级别。当这些测试失败时，用它们作为向导来修复这些问题。</li><li>使用调测工具主要关注测试中发现的问题，并修复它。</li><li>只要有可能，就使用真实的容量数据来做度量。</li></ul><h3 id="容量度量"><a href="#容量度量" class="headerlink" title="容量度量"></a>容量度量</h3><ul><li>扩展性测试：随着服务器数、服务等的增加，单个请求的响应时间和并发用户数的支持会如何变化。</li><li>持久性测试：长时间运行应用程序，是否有性能上的变化。</li><li>吞吐量测试：系统每秒能处理多少事务、消息或页面点击。</li><li>负载测试：当系统负载增加到类似生产环境大小时，系统的容量如何。</li></ul><p>容量度量测试遵行有两种策略</p><ul><li>把目标设定为得到稳定、可重现的结果。专为容量测试准备一个环境。</li><li>一旦某个测试通过了最低验收标准，就把验收标准提高一点，调整该测试的成功门槛</li><li>每个测试都必须体现一个具体的场景，并且只有达到某个标准门槛时，才能认为该测试通过</li></ul><h3 id="容量测试环境"><a href="#容量测试环境" class="headerlink" title="容量测试环境"></a>容量测试环境</h3><ul><li>容量测试环境与生产环境一致。</li><li>如果无法提供与生产环境相似的环境，可以把容量测试作为金丝雀发布策略的一部分来执行。更频繁的发布可以减小影响应用程序容量的修改所带来的风险</li><li>容量测试环境尽可能与生产环境相似。这样虽然无法满足容量目标，但是可以把那些严重的问题突显出来</li><li>不要依据硬件的某种特定参数对程序的扩展性作出线性推论</li><li>复制应用程序一小部分的服务器进行容量测试，是一个既可以降低环境成本又能提供适当准确度量的策略</li></ul><h3 id="自动化容量测试"><a href="#自动化容量测试" class="headerlink" title="自动化容量测试"></a>自动化容量测试</h3><ul><li>一般我们都是把容量测试当作一项独立的工作，但是当容量非常重要时，那么就暂且忽视这些时间成本 。这时需要在部署流水线中加入容量测试阶段。</li><li>创建一个自动化容量测试套件，且每次对应用程序进行修改后，通过了提交测试和验收测试就应该执行容量测试。</li><li>容量测试要达到如下6个目标</li></ul><ol><li>测试具体的现实场景</li><li>预先设定成功的门槛</li><li>尽可能让测试运行时间短一些</li><li>在变更面前要更健壮一些</li><li>组合成大规模的复杂场景</li><li>可重复的，并且既能串行执行，也能并行执行</li></ol><h3 id="容量测试系统的附加价值"><a href="#容量测试系统的附加价值" class="headerlink" title="容量测试系统的附加价值"></a>容量测试系统的附加价值</h3><p>容量测试系统是一个试验场所，可以根据需要有效地控制时间，设计和执行所有的试验场景来帮助诊断问题、预测问题并找到触发问题办法。</p><ul><li>重现生产环境中发现的复杂缺陷</li><li>探测并调试内存泄漏</li><li>持久性测试</li><li>评估垃圾回收的影响</li><li>垃圾回收的调优</li><li>应用程序参数的调优</li><li>第三方应用程序配置的调优，如操作系统</li><li>模拟非正常、最糟糕的情况</li><li>评估一些复杂问题的不同解决方案</li><li>模拟集成失败的情况</li><li>度量应用程序在不同硬件配置下的可扩展性</li><li>与外部系统进行交互的负载测试</li><li>复杂部署的回滚演练</li><li>有选择地使系统部分或全部瘫痪，从而评估服务优雅降级</li><li>在短期可用的生产硬件上执行真实世界的容量基准，以便计算出长期且低配的容量测试环境中更准确的扩展因素。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（部署流水线）第五章：部署流水线解析</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%A7%A3%E6%9E%90/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><h2 id="什么是部署流水线"><a href="#什么是部署流水线" class="headerlink" title="什么是部署流水线"></a>什么是部署流水线</h2><p>部署流水线是指软件从版本控制到用户手中这一过程的自动化表现形式。<br>价值流图</p><table><thead><tr><th>产品可行性评估</th><th></th><th>产品探索</th><th></th><th>产品计划与评估</th><th></th><th>开发</th><th></th><th>最后测试与审核</th><th></th><th>发布</th></tr></thead><tbody><tr><td>3天</td><td>1周</td><td>7天</td><td>10天</td><td>10天</td><td>10天</td><td>3天</td><td>7周</td><td>1周</td><td>2天</td><td>2小时</td></tr></tbody></table><ul><li>开发到发布的流水线：会有很多次构建通过这一流程走向最后的发布</li><li>流水线各个阶段：<br>交付团队-&gt;版本控制库-&gt;构建和单元测试-&gt;自动化验收测试-&gt;用户验收测试-&gt;发布</li><li>一般而言，只要某个构建使这个流程任一阶段失败，都会停止，不会进入下一个阶段。<ul><li>提交阶段【自动化测试（主要是单元测试），代码分析】</li></ul></li><li>自动化验收测试阶段【功能与非功能测试】</li><li>手工测试阶段【对自动化测试的补充，探索性测试，集成测试等】</li><li>发布阶段【部署到生产环境或试运行环境】</li></ul><h2 id="最基本的部署流水线"><a href="#最基本的部署流水线" class="headerlink" title="最基本的部署流水线"></a>最基本的部署流水线</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2e569d364b917a6e3bae9dec84669000ee66a661f3c936c4856d030eda792800.png" alt="基本的部署流水线">  </p><h2 id="部署流水线的相关实践"><a href="#部署流水线的相关实践" class="headerlink" title="部署流水线的相关实践"></a>部署流水线的相关实践</h2><ul><li>只生成一次二进制包。对于不需要编译的语言，二制包指的是所有源文件的集合。这些二进制包应保存在文件系统的某个位置，让流水线后续阶段能够轻松访问到，但不要放在版本控制库中。二进制包应与环境无关。</li><li>对不同环境采用同一部署方式<ul><li>使用属性文件保存配置信息。比如分别为每个环境保存一个属性文件，并将其放在版本控制库中，部署时，通过本地服务器的主机名来查找到正确的配置，如果环境中有多台服务器，可以将环境变量提供给部署脚本</li><li>将配置放在一个目录服务中（LDAP或ActiveDiretory）或数据库中</li></ul></li><li>对部署进行冒烟测试<br>当应用程序部署时，应用一个自动化脚本做下冒烟测试。这个测试的流程是：<ul><li>启动用户程序</li><li>检查主页面</li><li>检查应用程序所依赖的服务，比如数据库，消息队列等</li></ul></li><li>向生产环境的副本中部署<br> 如果预算充足，可以建立与生产环境一样的环境</li><li>每次变更都要立即在流水线中传递<br>对于一些特殊情况，验收测试是比较耗时的，版本在验收测试时可能会产生冲突，这时可以在单元测试结束时，将最近还没构建的所有变更全部拿来进行构建</li><li>只要有环节失败，就停止整个流水线</li></ul><h2 id="提交阶段"><a href="#提交阶段" class="headerlink" title="提交阶段"></a>提交阶段</h2><ul><li>编译代码</li><li>运行一套提交测试【单元测试，容易失败的特定测试】</li><li>为后续阶段创建二进制包</li><li>执行代码分析检查代码的健康状况</li><li>为后续阶段准备工作，比如准备后续测试所用的数据库</li></ul><h2 id="自动化验收测试之门"><a href="#自动化验收测试之门" class="headerlink" title="自动化验收测试之门"></a>自动化验收测试之门</h2><ul><li>每次提交后，应立即运行提交测试，提交阶段完成后，立即做验收测试，简单的验收测试为：运行代码，查看主页</li><li>尽管验收测试非常有价值，但它们的创建与维护成本也非常高，所以牢记不要把所有验收测试条件盲目的自动化</li></ul><h2 id="后续的测试阶段"><a href="#后续的测试阶段" class="headerlink" title="后续的测试阶段"></a>后续的测试阶段</h2><p>部署流水线应支持测试人员根据自己的需求将任意一个版本部署到自己的测试环境</p><ul><li>手工测试</li><li>非功能测试</li></ul><h2 id="发布准备"><a href="#发布准备" class="headerlink" title="发布准备"></a>发布准备</h2><p>把发布环节视为部署流水线的一个自然结果</p><ul><li>让参与项目交付过程的人共同创建维护一个发布计划</li><li>通过尽可能多的自动化过程最小化人的错误发生的可能性</li><li>在类生产环境中经常做发布流程演练</li><li>如果事情并没有按计划执行，要有撤销本次发布的能力</li><li>作为升级和撤销过程的一部分，制定配置迁移和数据迁移策略</li></ul><p>自动部署与发布</p><ul><li>在具有代表性环境上执行自动化验收测试套件</li><li>对生产环境的任何修改都应该通过自动化过程完成【程序的部署，配置，软件栈，网络拓扑，状态的所有修改）</li><li>管理生产环境的流程，也应用于测试环境</li><li>使用虚拟化技术，最佳配置管理降低成本</li></ul><p>变更的撤销策略</p><ul><li>让旧版本仍旧处于可用状态，保持一段时间</li><li>从头部署旧版本</li></ul><h2 id="实现一个部署流水线"><a href="#实现一个部署流水线" class="headerlink" title="实现一个部署流水线"></a>实现一个部署流水线</h2><ul><li>对价值流建模，创建一个可工作的简单框架</li><li>将构建和部署流程自动化</li><li>将单元测试和代码分析自动化</li><li>将验收测试自动化</li><li>将发布自动化<br>注意以下几点：</li><li>增量实现整个流水线，如果有手工操作部分，记录开始结束时间，想办法把它自动化</li><li>部署流水线是构建、部署、测试和发布整个流程中有效，也是最重要的统计数据来源</li><li>不断改进部署流水线</li></ul><h2 id="度量"><a href="#度量" class="headerlink" title="度量"></a>度量</h2><p>最重要的全局度量指标是流水线周期时间。用约束理论来对流水线进行优化：</p><ul><li>识别系统中的约束</li><li>确保最大限度地提高流程中这部分的产出</li><li>根据这一约束调整其他环节的产出</li><li>为约束环节扩容，增加资源</li><li>理顺约束环节，找到下一个约束点</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（部署流水线）第八章：自动化验收测试</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%8A%A8%E5%8C%96%E9%AA%8C%E6%94%B6%E6%B5%8B%E8%AF%95/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E8%87%AA%E5%8A%A8%E5%8C%96%E9%AA%8C%E6%94%B6%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>验收测试通常是在每一个通过提交测试的软件版本上执行的。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-ffed8499ec5c9f60.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="验收测试阶段"></p><ul><li>验收测试的目的：对于一个单独的验收测试，它的目的是验证一个用户故事或需求的验收条件是否被满足。如功能验收条件和非功能验收条件。</li><li>如果每次提交测试后都在该版本上运行自动化验收测试，会有如下效果：<ul><li>反馈环大大缩短，能够更快地定位问题</li><li>测试、开发人员和客户需要紧密合作才能创建一个良好的自动化测试套件，这会促进他们之间的良好合作</li><li>有助于让每个人更关注业务的价值</li></ul></li><li>验收测试与单元测试的区别：验收测试是针对业务的，单元测试是面向开发的。</li></ul><h2 id="创建验收测试"><a href="#创建验收测试" class="headerlink" title="创建验收测试"></a>创建验收测试</h2><ul><li><ol><li>分析人员与测试人员和客户紧密合作，定义验收条件</li></ol></li><li><ol start="2"><li>分析人员向开发人员讲解需求，以及它的业务上下文，并检查一遍验收条件</li></ol></li><li><ol start="3"><li>测试人员与开发人员讨论，并就“哪些自动化验收测试来证明验收条件被满足”达成一致</li></ol></li><li><ol start="4"><li>开发人员认为工作完成是指所有单元测试和组件测试通过，验收测试全部实现，并证明系统满足需求。此时可以向分析人员、测试人员和客户进行演示</li></ol></li></ul><h2 id="应用程序驱动层"><a href="#应用程序驱动层" class="headerlink" title="应用程序驱动层"></a>应用程序驱动层</h2><p>应用程序驱动层是一个知道如何与应用程序打交道的层次。它所用的API是以某种领域语言表达的，可以认为是一种针对它自己的领域专属语言。</p><h2 id="实现验收测试"><a href="#实现验收测试" class="headerlink" title="实现验收测试"></a>实现验收测试</h2><ul><li><ol><li>让测试对复杂状态的依赖最小</li></ol></li><li><ol start="2"><li>不要使用生产数据的备份作为验收测试的测试数据，要维护一个受控的数据最小集</li></ol></li><li><ol start="3"><li>满足原子性，测试的执行顺序无关紧要，可以并行执行，他创建它需要的一切，并在运行后清理干净</li></ol></li><li><ol start="4"><li>自动化验收测试不应该运行在包含所有外部系统集成点的环境中，应该为自动验收测试提供一个受控环境，并且被测系统应该能在这个环境下运行。使用替身对象取代外部系统，可以使系统与外部系统耦合最小。</li></ol></li></ul><h2 id="验收测试阶段"><a href="#验收测试阶段" class="headerlink" title="验收测试阶段"></a>验收测试阶段</h2><p>把验收测试套件作为部署流水线的一个组成部分来运行。提交测试一旦成功，就应该开始在通过提交测试的版本上运行验收测试套件。</p><ul><li>验收测试失败的版本不能用于部署</li><li>确保验收测试一直处于通过状态</li></ul><h2 id="验收测试的性能"><a href="#验收测试的性能" class="headerlink" title="验收测试的性能"></a>验收测试的性能</h2><p>验收测试没有把它放在提交测试阶段，主要是因为验收测试运行时间太长。但是我们认为自动化验收测试的全面性比测试在10分钟内运行完成更重要。然而一旦开始实现部署流水线，快速失败体系和迅速反馈环将更快地帮助发现问题，一般验收测试花费几个小时完成也是可以接受的。但是仍然有办法来提高验收测试的效率。</p><ul><li>重构通用任务</li><li>共享昂贵资源</li><li>并行测试</li><li>使用计算网格（如：Selenium Grid、 Zalenium）</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（部署流水线）第六章：构建与部署的脚本化</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%83%A8%E7%BD%B2%E7%9A%84%E8%84%9A%E6%9C%AC%E5%8C%96/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%9E%84%E5%BB%BA%E4%B8%8E%E9%83%A8%E7%BD%B2%E7%9A%84%E8%84%9A%E6%9C%AC%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><p>##构建工具概览</p><ul><li>Make</li><li>Ant</li><li>NAnt与MSBuild</li><li>Maven</li><li>Rake</li><li>Buildr</li><li>Psake</li></ul><h2 id="构建部署脚本化的原则与实践"><a href="#构建部署脚本化的原则与实践" class="headerlink" title="构建部署脚本化的原则与实践"></a>构建部署脚本化的原则与实践</h2><ul><li>为部署流水线的每个阶段创建脚本</li><li>使用恰当的技术部署应用程序</li><li>使用同样的脚本向所有环境部署</li><li>使用操作系统自带的包管理工具</li><li>确保部署流程是幂等的</li><li>部署系统的增量式演进</li></ul><h2 id="部署脚本化"><a href="#部署脚本化" class="headerlink" title="部署脚本化"></a>部署脚本化</h2><ul><li>多层的部署和测试<table><thead><tr><th>层</th><th>配置</th></tr></thead><tbody><tr><td>应用／服务／组件</td><td>应用配置</td></tr><tr><td>中间件</td><td>中间件配置</td></tr><tr><td>操作系统</td><td>操作系统配置</td></tr><tr><td>硬件</td><td>硬件</td></tr></tbody></table></li><li>测试环境配置<br> 部署前对基础设施做标准冒烟测试，如果发现问题，就让环境配置流程快速失败，并给出测试结果<ul><li>确认能从数据库中拿到一条记录</li><li>确认能连上网站</li><li>断言消息代理中的已注册的消息集合是正确的</li><li>透过防火墙发送ping，证明线路通畅</li></ul></li></ul><h2 id="推荐策略"><a href="#推荐策略" class="headerlink" title="推荐策略"></a>推荐策略</h2><ul><li>总是使用相对路径</li><li>消除手工步骤</li><li>从二进制包到版本控制库的内建可追溯性<br>二进制包记录版本信息，如Java应用可以在MANIFEST中包含元数据，另外可以将构建流程生成的每个二进制包的MD5值及名字和版本标识符一起放在数据库中</li><li>不要把二进制包作为构建的一部分放到版本控制库中</li><li>“test”不应该让构建失败<br>  在构建时如果有一个test任务失败，应该设置一个标记，继续构建，当生成更多的结果报告或者更完整的测试集后再令构建失败</li><li>用集成冒烟测试来限制应用程序</li><li>.NET项目中确保bin和obj这两个目录被完全删除</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>持续交付发布可靠软件的系统方法（部署流水线）第十章：应用程序的部署与发布</title>
      <link href="/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8F%91%E5%B8%83/"/>
      <url>/DevOps/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%88%E9%83%A8%E7%BD%B2%E6%B5%81%E6%B0%B4%E7%BA%BF%EF%BC%89%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8F%91%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<p><a href="/DevOps/%E3%80%8A%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%8F%91%E5%B8%83%E5%8F%AF%E9%9D%A0%E8%BD%AF%E4%BB%B6%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%96%B9%E6%B3%95%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《持续交付发布可靠软件的系统方法》读书笔记</a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>发布到生产环境和部署到测试环境的差异应该被封装在一组配置文件中，遵循一样的部署过程。启动自动部署系统，将要部署的软件版本与环境名称告诉它，点击开始，后缀部署与发布使用相同的流程。<br>我们需要有一个列表，其中包含能够部署到每个环境的所有构建，并且只要通过点击就可以选择一个软件版本向某个环境进行自动部署。同时这种方式是对环境修改的唯一途径（包括对操作系统和第三方软件配置的修改）。</p><h2 id="创建发布策略（文档）"><a href="#创建发布策略（文档）" class="headerlink" title="创建发布策略（文档）"></a>创建发布策略（文档）</h2><ul><li>每个环境的部署由发布由谁负责</li><li>创建一个资产和配置管理策略</li><li>部署时所用的技术的描述。运维团队与开发团队应对其达成共识</li><li>实现部署流水线的计划</li><li>枚举所有的环境，包括用于验收测试、容量测试、集成测试、用户验收测试的环境，以及每个构建在这些环境中的移动过程</li><li>描述在测试和生产环境中部署时应该遵循的流程，比如一个变更申请，及申请授权等</li><li>对应用程序的监控需求，包括用于通知运维团队关于应用程序相关状态的API和服务</li><li>讨论部署时和运行时的配置方法如何管理，以及它们与自动化部署流程是如何关联在一起的</li><li>描述应用程序如何与所有外部系统集成</li><li>如何记录日志详情，以便运维人员能够确定应用程序的状态，识别出错原因</li><li>制定灾难恢复计划，以便在灾难发生后，恢复应用程序的状态</li><li>对软件的服务级别达成一致</li><li>生产环境的数量大小 及容量计划：应用程序会创建多少数据，需要多少个日志文件或数据库，需要多少带宽或磁盘空间，用户对响应延迟的容忍度是什么？</li><li>制定一个归档策略，以便不必为了审计或技术支持而保留生产数据</li><li>如何对生产环境进行首次部署</li><li>如何修复生产环境中出现的缺陷，并为其打补丁</li><li>如何升级生产环境中的应用程序以及迁移数据</li><li>如何做应用程序生产服务与技术支持</li></ul><p>随着项目的进行，这个策略文档也会改变</p><h2 id="应用程序的部署与晋级"><a href="#应用程序的部署与晋级" class="headerlink" title="应用程序的部署与晋级"></a>应用程序的部署与晋级</h2><p>每次部署时都使用同样的方法，使用相同的流程向每个环境部署，包括生产环境。在首次向测试环境部署时就应该使用自动化部署。</p><h4 id="首次部署"><a href="#首次部署" class="headerlink" title="首次部署"></a>首次部署</h4><p>在第一个迭代里，选择一至两个具有高优先级但非常简单的用户故事或需求，让部署流水线的前几个阶段可以运行，且能够部署并展示一些成果。把它看作实现部署流水线的“抽水泵”<br>这个启动迭代结束后，应该已经完成了以下内容：</p><ul><li>部署流水线线的提交阶段</li><li>一个用于部署的类生产环境</li><li>通过一个自动化过程获取在提交阶段中生成的二进制包，并将其部署到这个类生产环境（UAT）中</li><li>一个简单的冒烟测试，用于验证本次部署的正确性</li></ul><h4 id="对发布过程进行建模并让构建晋级"><a href="#对发布过程进行建模并让构建晋级" class="headerlink" title="对发布过程进行建模并让构建晋级"></a>对发布过程进行建模并让构建晋级</h4><p>在构建中重点注意以下内容</p><ul><li>为了达到发布质量，一个构建版本要通过哪些测试阶段</li><li>每个阶段需要设置怎样的晋级门槛或者需要怎样的签字许可</li><li>对每个晋级门槛来说，谁有权批准让该构建通过该阶段</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-1e1564ff34c0b0cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="测试与发布流程"></p><h4 id="配置的晋级"><a href="#配置的晋级" class="headerlink" title="配置的晋级"></a>配置的晋级</h4><p>除了二进制需要晋级，环境与应用程序的配置信息也需要晋级。但是并不是所有的配置都需要晋级，这就需要对配置信息进行晋级管理。</p><ul><li>用冒烟测试来验证配置信息的正确性。</li><li>对于中间件的配置，利用像Nagios这样工具来监控这些设置。</li><li>写一些对基础设置的测试，用于检查关键设置，并将其返回给监控软件。</li></ul><h4 id="联合环境"><a href="#联合环境" class="headerlink" title="联合环境"></a>联合环境</h4><p>SIT环境中更多的工作是部署每个应用程序的新版本，直到所有应用程序可以互相联通。</p><h4 id="部署到试运行环境"><a href="#部署到试运行环境" class="headerlink" title="部署到试运行环境"></a>部署到试运行环境</h4><p>项目开始时就需要计划以下事情：</p><ul><li>确保生产环境、容量测试环境和试运行环境已准备好</li><li>准备好一个自动化过程，对环境进行配置，包括网络配置、外部服务和基础设置</li><li>确保部署流程是经过充分冒烟测试的</li><li>度量应用程序的“预热”时长。如果应用程序使用了缓存，这一点就尤其重要，将它也纳入到部署计划中</li><li>与外部系统进行测试集成</li><li>如果可能，发布之前就把应用程序放在生产环境上部署。蓝绿部署</li><li>如果可能，把应用程序发布给所有人之前，将它发布给一小部分用户群。金丝雀发布</li><li>将每次已通过验收测试的变更版本部署在试运行环境中</li></ul><h2 id="部署回滚和零停机发布"><a href="#部署回滚和零停机发布" class="headerlink" title="部署回滚和零停机发布"></a>部署回滚和零停机发布</h2><p>制定回滚计划时，需要遵循两个原则：</p><ul><li>发布前，确保生产系统的状态（数据库和保存在文件系统中的状态）已备份</li><li>每次发布之前都练习一下回滚计划，包括从备份中恢复或把数据库备份迁移回来</li></ul><h4 id="通过重新部署历史版本进行回滚"><a href="#通过重新部署历史版本进行回滚" class="headerlink" title="通过重新部署历史版本进行回滚"></a>通过重新部署历史版本进行回滚</h4><p>优点：可预知时间内恢复，且风险较低；部署操作经过运行，而回滚频率低，所以回滚脚本更不稳定<br>缺点：部署需要时间，业务有中断；覆盖部署，难以查找问题原因；新版本运行时产生的数据丢失。</p><h4 id="零停机部署"><a href="#零停机部署" class="headerlink" title="零停机部署"></a>零停机部署</h4><p>将用户从一个版本几乎瞬间转移到另一个版本，如果出问题，可以瞬间将用户转到碑的版本上。不同版本应用独立部署。</p><h4 id="蓝绿部署"><a href="#蓝绿部署" class="headerlink" title="蓝绿部署"></a>蓝绿部署</h4><p>保留两个相同的生产环境版本，“蓝环境”、“绿环境”。<br>将新版本部署在“蓝环境”下，在蓝环境下测试完成后，将路由配置到蓝环境。如果出现问题，把路由器切回到绿环境上即可，此时蓝环境用于查找问题。<br>#####蓝绿部署要小心管理数据库。解决办法如下：<br>在切换之前暂时将应用程序变成只读状态一小段时间，将绿数据库复制一份，并恢复到蓝数据库中，执行迁移操作，再将用户切换到蓝系统。如果一切正常，再把应用程序切换到读写方式，如果出现问题，只要把它切回绿数据库就可以了。<br>如果问题出现时，应用程序中已经写入了一些数据到蓝系统，那么切回去之前需要将新记录迁回到绿数据库中<br>还可以找个办法让应用程序的新版本把数据库事务同时发向新旧两个数据库</p><p>如果只有一个生产环境，也可以使用蓝录部署。让应用程序两个副本一起运行在同一个环境中。</p><h4 id="金丝雀发布"><a href="#金丝雀发布" class="headerlink" title="金丝雀发布"></a>金丝雀发布</h4><p>金丝雀发布：把应用程序的某个新版本部署到生产环境中的部署服务器中，从而快速得到反馈。</p><ol><li>部署新版本到一部分服务器上，对新版本上做冒烟测试，容量测试。</li><li>选择一部分用户，把他们引到新版本上</li><li>还可以部署多个版本，将不同组用户引导到不同版本上</li></ol><p>好处：</p><ul><li>非常容易回滚，只要不把用户引到有问题的版本</li><li>将用记引致新旧版本，从而作A&#x2F;B测试</li><li>可以通过逐渐增加负载，慢慢地把用户引到新版本，检验应用程序是否满足容量需求</li></ul><h2 id="紧急修复"><a href="#紧急修复" class="headerlink" title="紧急修复"></a>紧急修复</h2><p>牢记：任何情况下，都不能破坏流程。紧急修复版本也需要走构建、部署、测试和发布流程。<br>让每个紧急修复都走完标准的部署流水线。<br>紧急修复的另一个做法是回滚到旧的好版本上。<br>处理生产环境的缺陷时应用考虑以下因素：</p><ul><li>别加班到深夜来做，应该与别人一起结对做</li><li>确保有一个已经测试过的紧急修复流程</li><li>对于应用程序的变更，避免绕过标准的流程，除非在极端情况下</li><li>确保在试运行环境上对紧急修复版本做过测试</li><li>有时候回滚比部署新的修复版本更划算</li></ul><h2 id="持续部署"><a href="#持续部署" class="headerlink" title="持续部署"></a>持续部署</h2><p>使用部署流水线、让部署到生产也自动化。如果某次提交的代码通过了所有的自动化测试，就直接部署到生产环境中。<br>持续部署可以与金丝雀发布结合，先通过自动过程发布给一小部分用户，如果没有问题，就发布给所有用户。</p><h2 id="小贴士"><a href="#小贴士" class="headerlink" title="小贴士"></a>小贴士</h2><ul><li>真正执行部署操作的人应该参与部署过程的创建</li><li>记录部署活动</li><li>不要删除旧文件，而是移动到别的位置</li><li>部署是整个团队的责任</li><li>服务器应用程序不应该有GUI</li><li>为新部署留预热期</li><li>快速失败</li><li>不要直接对生产环境进行修改</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>测试工具汇总</title>
      <link href="/DevOps/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/"/>
      <url>/DevOps/%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h2><h4 id="Jmeter"><a href="#Jmeter" class="headerlink" title="Jmeter"></a><a href="https://jmeter.apache.org/">Jmeter</a></h4><p><a href="https://blog.csdn.net/bigsec/article/details/78029989">Jmeter简单介绍与搭配Jenkins实现自动化测试实践</a><br><a href="http://www.importnew.com/13876.html">使用JMeter进行负载测试——终极指南</a></p><h4 id="Locust"><a href="#Locust" class="headerlink" title="Locust"></a><a href="https://www.locust.io/">Locust</a></h4><p><a href="http://www.cnblogs.com/walker-dead-cave/p/5770200.html">Locust学习总结分享</a><br><a href="http://www.cnblogs.com/fnng/p/6081798.html">性能测试工具Locust</a><br><a href="http://www.testclass.net/locust/introduce/">Locust 系列教程</a></p><h4 id="LoadRunner"><a href="#LoadRunner" class="headerlink" title="LoadRunner"></a><a href="https://ssl.www8.hp.com/sg/en/ad/load-runner/load-runner.html">LoadRunner</a></h4><p><a href="http://www.trustiv.co.uk/2017/02/using-loadrunner-jenkins">Using LoadRunner with Jenkins</a></p><h2 id="接口测试"><a href="#接口测试" class="headerlink" title="接口测试"></a>接口测试</h2><h4 id="Robot-Framework"><a href="#Robot-Framework" class="headerlink" title="Robot Framework"></a><a href="http://robotframework.org/">Robot Framework</a></h4><p><a href="https://blog.csdn.net/aotou126/article/details/40111365">Robot Framework 在 Jenkins 上的自动化测试</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统僵尸进程管理</title>
      <link href="/DevOps/%E7%B3%BB%E7%BB%9F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
      <url>/DevOps/%E7%B3%BB%E7%BB%9F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<ol><li><p>查看系统僵尸进程数<br>top<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c4d6b38a2b3d2493a87000deedba11ca1b63bb19538577adfe94e4108a6292ae.png" alt="image.png">  </p></li><li><p>查看僵尸进程详情<br>ps -ef|grep defunct<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/fa1df78a5c205ca2fb28c01021fdc16164b7c514c81ef9b43e88bbfd880b3c15.png" alt="image.png">  </p></li><li><p>停止僵尸进程<br>kill -9 $Parent PID</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>系统性能测试与监测工具汇总</title>
      <link href="/DevOps/%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%8E%E7%9B%91%E6%B5%8B%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/"/>
      <url>/DevOps/%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%B8%8E%E7%9B%91%E6%B5%8B%E5%B7%A5%E5%85%B7%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="综合能力"><a href="#综合能力" class="headerlink" title="综合能力"></a>综合能力</h1><h2 id="性能测试（Unixbench）"><a href="#性能测试（Unixbench）" class="headerlink" title="性能测试（Unixbench）"></a>性能测试（<a href="https://github.com/kdlucas/byte-unixbench">Unixbench</a>）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ ./Run</span><br></pre></td></tr></table></figure><h1 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h1><h2 id="查看当前CPU负载（uptime）"><a href="#查看当前CPU负载（uptime）" class="headerlink" title="查看当前CPU负载（uptime）"></a>查看当前CPU负载（uptime）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ uptime</span><br></pre></td></tr></table></figure><h2 id="测试单cpu计算能力（bc）"><a href="#测试单cpu计算能力（bc）" class="headerlink" title="测试单cpu计算能力（bc）"></a>测试单cpu计算能力（bc）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ time echo &quot;scale=5000;4*a(1)&quot; | bc -l -q</span><br></pre></td></tr></table></figure><h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1><h2 id="查看当前内存使用的情况的状态（free）"><a href="#查看当前内存使用的情况的状态（free）" class="headerlink" title="查看当前内存使用的情况的状态（free）"></a>查看当前内存使用的情况的状态（free）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ free -m</span><br></pre></td></tr></table></figure><h2 id="进程对内存的占用情况（pmap）"><a href="#进程对内存的占用情况（pmap）" class="headerlink" title="进程对内存的占用情况（pmap）"></a>进程对内存的占用情况（pmap）</h2> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ pmap -d 35713 # 查看进程35713占用内存的情况</span><br></pre></td></tr></table></figure><h1 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h1><h2 id="磁盘IO测试（dd）"><a href="#磁盘IO测试（dd）" class="headerlink" title="磁盘IO测试（dd）"></a>磁盘IO测试（dd）</h2><p>测试磁盘的IO写速度</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">time <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=test.dbf bs=8k count=300000 oflag=direct</span></span><br></pre></td></tr></table></figure><p>测试磁盘的IO读速度</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">dd</span> <span class="keyword">if</span>=test.dbf bs=8k count=300000 of=/dev/null</span> </span><br></pre></td></tr></table></figure><p>表示每次写入&#x2F;读取8k的数据，执行300000次</p><h2 id="实时查看各磁盘的io（iostat）"><a href="#实时查看各磁盘的io（iostat）" class="headerlink" title="实时查看各磁盘的io（iostat）"></a>实时查看各磁盘的io（iostat）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install sysstat</span><br><span class="line">[root@localhost] $ iostat -x 1 100</span><br></pre></td></tr></table></figure><h2 id="对磁盘iops的测试（fio）"><a href="#对磁盘iops的测试（fio）" class="headerlink" title="对磁盘iops的测试（fio）"></a>对磁盘iops的测试（fio）</h2><p>安装fio</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install fio</span><br></pre></td></tr></table></figure><p>ioengine: 负载引擎，我们一般使用libaio，发起异步IO请求。<br>bs: IO大小<br>direct: 直写，绕过操作系统Cache。因为我们测试的是硬盘，而不是操作系统的Cache，所以设置为1。<br>rw: 读写模式，有顺序写write、顺序读read、随机写randwrite、随机读randread等。<br>size: 寻址空间，IO会落在 [0, size)这个区间的硬盘空间上。这是一个可以影响IOPS的参数。一般设置为硬盘的大小。<br>filename: 测试对象<br>iodepth: 队列深度，只有使用libaio时才有意义。这是一个可以影响IOPS的参数。<br>runtime: 测试时长</p><p>4K随机写测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=100G -filename=/dev/vdb </span><br><span class="line">-name=&quot;EBS 4KB randwrite test&quot; -iodepth=32 -runtime=60</span><br></pre></td></tr></table></figure><p>4K随机读测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randread -size=100G -filename=/dev/vdb </span><br><span class="line">-name=&quot;EBS 4KB randread test&quot; -iodepth=8 -runtime=60</span><br></pre></td></tr></table></figure><p>512KB顺序写测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ fio -ioengine=libaio -bs=512k -direct=1 -thread -rw=write -size=100G -filename=/dev/vdb </span><br><span class="line">-name=&quot;EBS 512KB seqwrite test&quot; -iodepth=64 -runtime=60</span><br></pre></td></tr></table></figure><h2 id="进程对磁盘的读写情况（iotop）"><a href="#进程对磁盘的读写情况（iotop）" class="headerlink" title="进程对磁盘的读写情况（iotop）"></a>进程对磁盘的读写情况（iotop）</h2><p>安装iotop</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install iotop</span><br></pre></td></tr></table></figure><p>运行iotop查看进程对磁盘的读写</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ iotop   #查看全部进程的磁盘读写情况</span><br><span class="line">[root@localhost] $ iotop -o   #实时查看当前进程对磁盘的读写（推荐）</span><br><span class="line">[root@localhost] $ iotop -p 34323   #查看进程号为34323对磁盘的读写情况</span><br></pre></td></tr></table></figure><p>监控告警可以使用如下命令获取io的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ iotop -botqqq --iter=3</span><br></pre></td></tr></table></figure><h1 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h1><h2 id="网络测试（iperf"><a href="#网络测试（iperf" class="headerlink" title="网络测试（iperf)"></a>网络测试（iperf)</h2><p>启动服务端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install iperf3 -y</span><br><span class="line">[root@localhost] $ iperf3 -s</span><br></pre></td></tr></table></figure><p>客户端进行测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install iperf3 -y</span><br><span class="line">[root@localhost] $ iperf3 -c 10.2.2.2 -P 5</span><br></pre></td></tr></table></figure><p>以上默认为作TCP测试，如果要UDP测试，服务端启动与客户端测试都需要加上-u</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 服务端</span></span></span><br><span class="line">iperf3 -s -u</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 客户端</span></span></span><br><span class="line">iperf3 -c 10.2.2.2 -P 5 -u</span><br></pre></td></tr></table></figure><h2 id="网络测试（qperf"><a href="#网络测试（qperf" class="headerlink" title="网络测试（qperf)"></a>网络测试（qperf)</h2><p>启动服务端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install qperf -y</span><br><span class="line">[root@localhost] $ qperf</span><br></pre></td></tr></table></figure><p>客户端进行测试网络延时</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install qperf -y</span><br><span class="line">[root@localhost] $ qperf 10.2.2.2 -t 100 -oo msg_size:8:256K:*2 tcp_lat</span><br></pre></td></tr></table></figure><p>客户端进行测试网络带宽</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install qperf -y</span><br><span class="line">[root@localhost] $ qperf 10.2.2.2 -t 100 -oo msg_size:8:256K:*2 tcp_bw</span><br></pre></td></tr></table></figure><p>延时与带宽可以一起测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ qperf 10.2.2.2 -t 100 -oo msg_size:8:256K:*2 tcp_bw tcp_lat</span><br></pre></td></tr></table></figure><h2 id="网卡流量监测（nload）"><a href="#网卡流量监测（nload）" class="headerlink" title="网卡流量监测（nload）"></a>网卡流量监测（nload）</h2><p>安装nload</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install nload</span><br></pre></td></tr></table></figure><p>监测网卡流量输入及输出</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ nload eth0 eth1</span><br></pre></td></tr></table></figure><h2 id="DNS服务压测工具（queryperf）"><a href="#DNS服务压测工具（queryperf）" class="headerlink" title="DNS服务压测工具（queryperf）"></a>DNS服务压测工具（queryperf）</h2><p>queryperf [-d datafile] [-s server_addr] [-p port] [-q num_queries]<br>-d: 后面接上一个文件，文件的内容是用户对DNS的请求，一行为一条请求，所以为了测试，我们可以在里面写上几千几万条。<br>-s: DNS服务器地址<br>-p: DNS服务器端口<br>-q: 请求多少次</p><p>使用vim命令先创建一个请求文件：vim querytest.txt</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">www.example.com A</span><br><span class="line">example.com NS</span><br><span class="line">tftp.example.com CNAME</span><br><span class="line">blog.example.com A</span><br><span class="line">....</span><br><span class="line"># 600万行</span><br></pre></td></tr></table></figure><p>执行测试命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ queryperf -d querytest.txt -s 192.168.0.6</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过跳板机代理将本地文件传输到远端服务器</title>
      <link href="/DevOps/%E9%80%9A%E8%BF%87%E8%B7%B3%E6%9D%BF%E6%9C%BA%E4%BB%A3%E7%90%86%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%88%B0%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
      <url>/DevOps/%E9%80%9A%E8%BF%87%E8%B7%B3%E6%9D%BF%E6%9C%BA%E4%BB%A3%E7%90%86%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%88%B0%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<ol><li>通过-J参数指定跳板机<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -J user@&lt;bastion:port&gt; &lt;user@remote:port&gt;</span><br><span class="line">// scp</span><br><span class="line">$ scp -J user@&lt;bastion:port&gt; sourcefile &lt;user@remote:port&gt;:</span><br></pre></td></tr></table></figure></li><li>在.ssh&#x2F;config中配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## The Bastion Host</span></span></span><br><span class="line">Host jump</span><br><span class="line">  HostName 10.2.3.2</span><br><span class="line">  Port 3022</span><br><span class="line">  User jump</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## The Remote Host</span></span></span><br><span class="line">Host remote</span><br><span class="line">  HostName 172.32.2.7</span><br><span class="line">  Port 22</span><br><span class="line">  User root</span><br><span class="line">  ProxyJump jump</span><br></pre></td></tr></table></figure>使用普通参数就可以实现跳转<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ssh remote</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">scp &lt;sourcefile&gt; remote:/data/</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>项目的通用结构</title>
      <link href="/DevOps/%E9%A1%B9%E7%9B%AE%E7%9A%84%E9%80%9A%E7%94%A8%E7%BB%93%E6%9E%84/"/>
      <url>/DevOps/%E9%A1%B9%E7%9B%AE%E7%9A%84%E9%80%9A%E7%94%A8%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>项目的通用结构，可根据真实情况进行删减</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">- src #代码</span><br><span class="line">- data #需要保存的文件，如安装包、镜像等</span><br><span class="line">- docs # 说明文档</span><br><span class="line">- scripts #相关的脚本文件</span><br><span class="line">- hack</span><br><span class="line">  - build</span><br><span class="line">    - Dockerfile  # 构建镜像</span><br><span class="line">  - Vagrantfile #Vagrant配置</span><br><span class="line">  - ansible/    # ansible构建部署脚本</span><br><span class="line">    - site.yml</span><br><span class="line">    - hosts</span><br><span class="line">    - roles/</span><br><span class="line">    - group_vars/</span><br><span class="line">    - host_vars/</span><br><span class="line">    - library/</span><br><span class="line">  - kubernetes/  # Openshift平台构建部署脚本</span><br><span class="line">  - docker-compose # Docker compose部署</span><br><span class="line">    - conf</span><br><span class="line">    - docker-compose.yaml</span><br><span class="line">- Makefile # 不同环境构统一构建入口</span><br><span class="line">- Jenkinsfile # Jenkins构建流水线，可调用ansible脚本或Dockerfile脚本</span><br><span class="line">- README.md</span><br><span class="line">- CHANGELOG.md</span><br><span class="line">- LICENSE</span><br><span class="line">- .travis.yml</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible的k8s模块完全兼容OpenShift资源</title>
      <link href="/openshift/Ansible%E7%9A%84k8s%E6%A8%A1%E5%9D%97%E5%AE%8C%E5%85%A8%E5%85%BC%E5%AE%B9OpenShift%E8%B5%84%E6%BA%90/"/>
      <url>/openshift/Ansible%E7%9A%84k8s%E6%A8%A1%E5%9D%97%E5%AE%8C%E5%85%A8%E5%85%BC%E5%AE%B9OpenShift%E8%B5%84%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<p>Ansible 的 k8s 模块完全兼容 openshift 资源</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><blockquote><p>使用 k8s 模块需要安装 openshift 的 python 扩展</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install --ignore-installed openshift</span><br></pre></td></tr></table></figure><p>安装过程中报如下错误<br><code>TypeError: find_packages() got an unexpected keyword argument include</code><br>需要升级 setuptools</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install -U setuptools</span></span><br></pre></td></tr></table></figure><blockquote><p>在执行 k8s 命令的主机上登录 kubernetes&#x2F;openshift 平台</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc login https://master.example.com:8443 -u admin -p</span><br><span class="line">password</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><blockquote><p>使用 ansible k8s 模块创建 namespace</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc -i hosts all -m k8s -a <span class="string">&#x27;state=present name=testproject kind=Project&#x27;</span></span></span><br></pre></td></tr></table></figure><blockquote><p>使用 ansible k8s 模块基于 dc.yaml 文件创建 dc</p></blockquote><ol><li>创建 dc.yaml 文件</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc run nginx --image=nginx -n testproject --dry-run -o yaml</span></span><br></pre></td></tr></table></figure><p>将内容输入到 nginx-dc.yaml 文件中,去掉些默认值，添加 namespace</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ cat nginx-dc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    run: nginx</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: testproject</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    run: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br></pre></td></tr></table></figure><ol start="2"><li>使用 ansible 创建</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible -i hosts all -m k8s -a <span class="string">&#x27;state=present src=/root/sample/nginx-dc.yaml&#x27;</span></span></span><br></pre></td></tr></table></figure><blockquote><p>使用 ansible k8s 模块基于模板文件创建 dc</p></blockquote><ol><li>创建 playbook 文件</li></ol><figure class="highlight plaintext"><figcaption><span><< EOF >> playbook.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">- hosts: all</span><br><span class="line">  tasks:</span><br><span class="line">  - name: create nginx yaml</span><br><span class="line">    k8s:</span><br><span class="line">      state: present</span><br><span class="line">      definition: &quot;&#123;&#123; lookup(&#x27;template&#x27;, &#x27;/root/sample/dc.yaml&#x27;) | from_yaml &#125;&#125;&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ol start="2"><li>使用 ansible-playbook 创建 nginx 应用</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook -i hosts playbook.yaml</span></span><br></pre></td></tr></table></figure><blockquote><p>删除 nginx DeploymentConfig</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible -i hosts all -m k8s -a <span class="string">&#x27;state=absent kind=DeploymentConfig namespace=testproject name=nginx&#x27;</span></span></span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>k8s 插件不支持 kind: List。kind: List 并不是 K8S&#x2F;OpenShift 中的资源对象，而是客户端将它解析为单独的资源对象</li><li>k8s 插件不支持 definition 中使用<code>---</code>来创建多个资源对象。</li><li>使用 k8s 插件得一个个地创建资源对象，利用 Ansible 的 with_items。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Calico-BGP集群外部与集群网络打通</title>
      <link href="/openshift/Calico-BGP%E9%9B%86%E7%BE%A4%E5%A4%96%E9%83%A8%E4%B8%8E%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E6%89%93%E9%80%9A/"/>
      <url>/openshift/Calico-BGP%E9%9B%86%E7%BE%A4%E5%A4%96%E9%83%A8%E4%B8%8E%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E6%89%93%E9%80%9A/</url>
      
        <content type="html"><![CDATA[<p>把这几个路由规则加入到路由器或者客户端机器上</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">route add -net 10.233.55.64 netmask 255.255.255.192 gw 10.21.21.76</span><br><span class="line">route add -net 10.233.119.0 netmask 255.255.255.192 gw 10.21.21.74</span><br><span class="line">route add -net 10.233.183.64 netmask 255.255.255.192 gw 10.21.21.75</span><br></pre></td></tr></table></figure><p>Win10客户端机器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">route add -p 10.233.97.128 mask  255.255.255.192 192.168.1.225</span><br><span class="line">route add -p 10.233.75.0  mask  255.255.255.192 192.168.1.226</span><br><span class="line">route add -p 10.233.100.128 mask 255.255.255.192 192.168.1.227</span><br><span class="line">route add -p 10.233.90.0 mask 255.255.255.192 192.168.1.228</span><br><span class="line">route add -p 10.233.75.64 mask 255.255.255.192 192.168.1.42</span><br><span class="line">route add -p 10.233.71.0 mask 255.255.255.192 192.168.1.43</span><br><span class="line">route add -p 10.233.74.64 mask 255.255.255.192 192.168.1.44</span><br><span class="line">route add -p 10.233.102.128 mask 255.255.255.192 192.168.1.41</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS上OpenLDAP-Server使用cn=config方式配置</title>
      <link href="/openshift/CentOS%E4%B8%8AOpenLDAP-Server%E4%BD%BF%E7%94%A8cn=config%E6%96%B9%E5%BC%8F%E9%85%8D%E7%BD%AE/"/>
      <url>/openshift/CentOS%E4%B8%8AOpenLDAP-Server%E4%BD%BF%E7%94%A8cn=config%E6%96%B9%E5%BC%8F%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>翻译自<a href="https://access.redhat.com/solutions/2484371">How to Configure OpenLDAP server in Red Hat Enterprise Linux 7 using cn&#x3D;config method ? </a></p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul><li>CentOS 7</li><li>openldap-2.4</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li>使用slapd工具在CentOS上安装与配置OpenLDAP Server</li><li>使用olc方式如何配置OpenLDAP Server</li></ul><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><ol><li>安装openldap包<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y openldap openldap-clients openldap-servers</span><br></pre></td></tr></table></figure>LDAP默认的配置目录是&#x2F;etc&#x2F;openldap&#x2F;slapd.d<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 ~]# cd /etc/openldap/slapd.d/</span><br><span class="line">[root@rhel7 slapd.d]# ls -l</span><br><span class="line">drwxr-x---. 4 ldap ldap 4096 Aug  3 22:49 cn=config</span><br><span class="line">-rw-------. 1 ldap ldap  589 Aug  2 23:39 cn=config.ldif</span><br><span class="line">[root@rhel7 slapd.d]# cd cn\=config</span><br><span class="line">[root@rhel7 cn=config]# ls -l</span><br><span class="line">drwxr-x---. 2 ldap ldap 4096 Aug  3 22:11 cn=schema</span><br><span class="line">-rw-------. 1 ldap ldap  378 Aug  2 22:21 cn=schema.ldif</span><br><span class="line">-rw-------. 1 ldap ldap  552 Aug  3 20:42 olcDatabase=&#123;0&#125;config.ldif</span><br><span class="line">-rw-------. 1 ldap ldap  443 Aug  2 22:21 olcDatabase=&#123;-1&#125;frontend.ldif</span><br><span class="line">-rw-------. 1 ldap ldap  562 Aug  2 22:21 olcDatabase=&#123;1&#125;monitor.ldif</span><br><span class="line">drwxr-x---. 2 ldap ldap   65 Aug  3 22:53 olcDatabase=&#123;2&#125;hdb.ldif</span><br></pre></td></tr></table></figure></li><li>设置olcSuffix,设置domain。只需要更新下文件olcDatabase&#x3D;{2}hdb.ldif中的olcSuffix<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 cn=config]# vi /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;2\&#125;hdb.ldif</span><br><span class="line">olcSuffix: dc=example,dc=com</span><br></pre></td></tr></table></figure></li><li>推荐先创建一个专用的具有所有权限的账号，用它来更新LDAP的数据库。需要更新文件olcDatabase&#x3D;{2}hdb.ldif中的olcRootDN和olcRootPW<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 cn=config]# vi /etc/openldap/slapd.d/cn\=config/olcDatabase\=\&#123;2\&#125;hdb.ldif</span><br><span class="line">olcRootDN: cn=Manager,dc=example,dc=com</span><br><span class="line">olcRootPW: redhat</span><br></pre></td></tr></table></figure></li><li>同时设置config数据库的管理员账号<br><code>这里设置的密码很简单，请在生产环境下将密码设置复杂些</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 cn=config]# vi olcDatabase\=\&#123;0\&#125;config.ldif</span><br><span class="line">olcRootDN: cn=config</span><br><span class="line">olcRootPW: secret</span><br></pre></td></tr></table></figure></li><li>使用slaptest命令去验证配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 cn=config]# slaptest -u</span><br><span class="line">config file testing succeeded</span><br></pre></td></tr></table></figure>如果报<code>ldif_read_file: checksum error</code>这样的错误，是因为计算文件的CRC32码来自动校验（文件中前两行中带有校验码），需要更新校验码</li></ol><ul><li>删除掉报错的文件的前两行 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify.</span><br><span class="line"># CRC32 3e515b74</span><br></pre></td></tr></table></figure></li><li>安装crc32工具（perl-Archive-Zip）<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 cn=config]# yum install perl-Archive-Zip -y</span><br></pre></td></tr></table></figure></li><li>计算新文件的CRC32码  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@rhel7 cn=config]# crc32 &lt;(cat olcDatabase\=\&#123;2\&#125;hdb.ldif)</span><br><span class="line">509f92c7</span><br></pre></td></tr></table></figure></li><li>将计算的CRC32码更新到文件中，添加到文件的前两行  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify.</span><br><span class="line"># CRC32 509f92c7</span><br></pre></td></tr></table></figure></li></ul><ol start="6"><li>如果配置验证成功，启动openldap server<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start slapd</span></span><br></pre></td></tr></table></figure></li><li>创建ldap server的基础结构<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> base.ldif</span></span><br><span class="line">dn: dc=example,dc=com</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: example.com</span><br><span class="line"></span><br><span class="line">dn: ou=users,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: users</span><br><span class="line"></span><br><span class="line">dn: ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: groups       </span><br></pre></td></tr></table></figure></li><li>使用ldapadd命令向LDAP目录导入基础结构<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -x -D <span class="string">&quot;cn=Manager,dc=example,dc=com&quot;</span> -w redhat -f base.ldif</span></span><br><span class="line">adding new entry &quot;dc=example,dc=com&quot;</span><br><span class="line">adding new entry &quot;ou=users,dc=example,dc=com&quot;</span><br><span class="line">adding new entry &quot;ou=groups,dc=example,dc=com&quot;</span><br></pre></td></tr></table></figure></li><li>使用ldapsearch命令验证基础结构是否成功导入<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapsearch -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -b dc=example,dc=com -w redhat</span></span><br></pre></td></tr></table></figure></li><li>在向ldap结构中添加users和groups之前，先使用ldapadd导入schema，以免出现“object class not defined”的报错<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -Y EXTERNAL -H ldapi:// -f /etc/openldap/schema/cosine.ldif</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -Y EXTERNAL -H ldapi:// -f /etc/openldap/schema/nis.ldif</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -Y EXTERNAL -H ldapi:// -f /etc/openldap/schema/inetorgperson.ldif</span></span><br></pre></td></tr></table></figure></li><li>向ldap结构中添加users和groups</li></ol><ul><li>Users<ul><li>使用slappasswd命令获取需要的密码<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">slappasswd -s <span class="built_in">test</span></span></span><br><span class="line">&#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br></pre></td></tr></table></figure></li><li>使用ldif文件和上面的hashed密码创建users.ldif<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> users.ldif</span></span><br><span class="line">dn: uid=testuser,ou=users,dc=example,dc=com</span><br><span class="line">uid: testuser</span><br><span class="line">cn: testuser</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: person</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">userPassword: &#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br><span class="line">shadowLastChange: 17016</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">uidNumber: 1000</span><br><span class="line">gidNumber: 1000</span><br><span class="line">homeDirectory: /home/testuser</span><br><span class="line">sn: testuser</span><br><span class="line">mail: testuser@example.com</span><br><span class="line"></span><br><span class="line">dn: uid=testuser1,ou=users,dc=example,dc=com</span><br><span class="line">uid: testuser1</span><br><span class="line">cn: testuser1</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: person</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">userPassword: &#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br><span class="line">shadowLastChange: 17016</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">uidNumber: 1001</span><br><span class="line">gidNumber: 1001</span><br><span class="line">homeDirectory: /home/testuser1</span><br><span class="line">sn: testuser1</span><br><span class="line">mail: testuser1@example.com</span><br></pre></td></tr></table></figure></li></ul></li><li>Groups<br>  创建groups.ldif<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> groups.ldif</span></span><br><span class="line">dn: cn=testuser,ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line">cn: testuser</span><br><span class="line">userPassword: &#123;crypt&#125;x</span><br><span class="line">gidNumber: 1000</span><br><span class="line"></span><br><span class="line">dn: cn=testuser1,ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line">cn: testuser1</span><br><span class="line">userPassword: &#123;crypt&#125;x</span><br><span class="line">gidNumber: 1001</span><br></pre></td></tr></table></figure></li></ul><ol start="12"><li>使用ldapadd命令添加users和groups<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -x -D cn=Manager,dc=example,dc=com -f users.ldif -w redhat</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -x -D cn=Manager,dc=example,dc=com -f groups.ldif -w redhat</span></span><br></pre></td></tr></table></figure></li><li>使用ldapsearch命令来验证users和groups创建是否成功<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ldapsearch -x -D cn=Manager,dc=example,dc=com -b dc=example,dc=com -w redhat</span><br></pre></td></tr></table></figure></li></ol><h2 id="OpenLDAP的操作"><a href="#OpenLDAP的操作" class="headerlink" title="OpenLDAP的操作"></a>OpenLDAP的操作</h2><ol><li>添加数据<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"> $ </span><span class="language-bash"><span class="built_in">cat</span> user3.ldif</span></span><br><span class="line">dn: uid=testuser3,ou=users,dc=example,dc=com</span><br><span class="line">uid: testuser3</span><br><span class="line">cn: testuser3</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: person</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">userPassword: &#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br><span class="line">shadowLastChange: 17016</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">uidNumber: 1000</span><br><span class="line">gidNumber: 1000</span><br><span class="line">homeDirectory: /home/testuser</span><br><span class="line">sn: testuser3</span><br><span class="line">mail: testuser@example.com</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -w redhat -f user3.ldif</span></span><br></pre></td></tr></table></figure></li><li>查询数据<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapsearch -x -b <span class="string">&#x27;dc=example,dc=com&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapsearch -x -b <span class="string">&#x27;dc=example,dc=com&#x27;</span> <span class="string">&#x27;sn=testuser3&#x27;</span></span></span><br></pre></td></tr></table></figure></li><li>修改数据<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方法一：交互式</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapmodify -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -w redhat</span></span><br><span class="line">dn: uid=testuser3,ou=users,dc=example,dc=com</span><br><span class="line">changetype: modify</span><br><span class="line">replace: sn</span><br><span class="line">sn: Test User 3</span><br><span class="line">-</span><br><span class="line">add: description</span><br><span class="line">description: add attribute</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方法二：配置文件式</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> modify.ldif</span></span><br><span class="line">dn: uid=testuser3,ou=users,dc=example,dc=com</span><br><span class="line">changetype: modify</span><br><span class="line">replace: sn</span><br><span class="line">sn: Test User 3</span><br><span class="line">-</span><br><span class="line">delete: description</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapmodify -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -w redhat -f modify.ldif</span></span><br></pre></td></tr></table></figure></li><li>删除数据<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapdelete -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -w redhat uid=testuser3,ou=<span class="built_in">users</span>,dc=example,dc=com</span></span><br></pre></td></tr></table></figure></li><li>数据导出<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方法一：用查询导出</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapsearch -x -b <span class="string">&#x27;dc=example,dc=com&#x27;</span> &gt; export.ldif</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">方法二：导出命令</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">slapcat -l export.ldif</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="打开OpenLDAP日志"><a href="#打开OpenLDAP日志" class="headerlink" title="打开OpenLDAP日志"></a>打开OpenLDAP日志</h2><ol><li>更新日志级别<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> loglevel.ldif</span> </span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcLogLevel</span><br><span class="line">olcLogLevel: stats</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapmodify -Y EXTERNAL -H ldapi:/// -f loglevel.ldif</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart slapd</span></span><br></pre></td></tr></table></figure></li><li>修改rsyslog配置文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">touch</span> /var/log/slapd.log</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> local4.* /var/log/slapd.log &gt;&gt; /etc/rsyslog.conf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart rsyslog</span></span><br></pre></td></tr></table></figure></li><li>查看openldap日志<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">tail</span> -f /var/log/slapd.log</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="容器化部署"><a href="#容器化部署" class="headerlink" title="容器化部署"></a>容器化部署</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --name ldap_core -p 389:389 -p 636:636 --<span class="built_in">env</span> LDAP_ORGANISATION=<span class="string">&quot;example.com&quot;</span> --<span class="built_in">env</span> LDAP_DOMAIN=<span class="string">&quot;example.com&quot;</span> --<span class="built_in">env</span> LDAP_ADMIN_PASSWORD=<span class="string">&quot;redhat&quot;</span> --detach osixia/openldap</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run --name ldap_web -p 80:80 -p 443:443 --<span class="built_in">link</span> ldap_core:ldap_core --<span class="built_in">env</span> PHPLDAPADMIN_LDAP_HOSTS=ldap_core --detach osixia/phpldapadmin</span></span><br></pre></td></tr></table></figure><p>同时还有Openshift的openldap容器<a href="https://hub.docker.com/r/openshift/openldap-2441-centos7">openshift&#x2F;openldap-2441-centos7</a></p><h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><ol><li>浏览ldap目录列表的工具<a href="http://www.ldapbrowserwindows.com/">ldapbrowser</a></li><li><a href="https://blog.csdn.net/Laputa_SKY/article/details/80363398">LDAPSearch命令参数详情</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS上搭建双主高可用OpenLDAP-Server</title>
      <link href="/openshift/CentOS%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%8F%8C%E4%B8%BB%E9%AB%98%E5%8F%AF%E7%94%A8OpenLDAP-Server/"/>
      <url>/openshift/CentOS%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%8F%8C%E4%B8%BB%E9%AB%98%E5%8F%AF%E7%94%A8OpenLDAP-Server/</url>
      
        <content type="html"><![CDATA[<p>OpenLDAP单机搭建手册参考：<a href="https://www.jianshu.com/p/b5df1eb1f4de">CentOS上OpenLDAP Server使用cn&#x3D;config方式配置</a></p><h2 id="配置双主高可用OpenLDAP"><a href="#配置双主高可用OpenLDAP" class="headerlink" title="配置双主高可用OpenLDAP"></a>配置双主高可用OpenLDAP</h2><ol><li>准备两台centos 7服务器，作为两台OpenLDAP Server的运行主机</li></ol><table><thead><tr><th>Server ID</th><th>系统版本</th><th>IP</th></tr></thead><tbody><tr><td>1</td><td>centos 7</td><td>192.168.1.2</td></tr><tr><td>2</td><td>centos 7</td><td>192.168.1.3</td></tr></tbody></table><ol start="2"><li>按照<a href="https://www.jianshu.com/p/b5df1eb1f4de">CentOS上OpenLDAP Server使用cn&#x3D;config方式配置</a>的方式在两台主机上部署好OpenLDAP Server。做到第6步即可，即<code>启动openldap server</code></li><li>在两台主机上启动syncprov模块<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> syncprov_mod.ldif</span></span><br><span class="line">dn: cn=module,cn=config</span><br><span class="line">objectClass: olcModuleList</span><br><span class="line">cn: module</span><br><span class="line">olcModulePath: /usr/lib64/openldap</span><br><span class="line">olcModuleLoad: syncprov.la</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -Y EXTERNAL -H ldapi:/// -f syncprov_mod.ldif</span></span><br><span class="line">SASL/EXTERNAL authentication started</span><br><span class="line">SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth</span><br><span class="line">SASL SSF: 0</span><br><span class="line">adding new entry &quot;cn=module,cn=config&quot;</span><br></pre></td></tr></table></figure></li><li>启动OpenLDAP主主同步<br>在两台机器上创建configrep.ldif文件，并执行配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> configrep.ldif</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## Update Server ID with LDAP URL ###</span></span></span><br><span class="line"></span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcServerID</span><br><span class="line">olcServerID: 1 ldap://192.168.1.2</span><br><span class="line">olcServerID: 2 ldap://192.168.1.3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## Enable replication ###</span></span></span><br><span class="line"></span><br><span class="line">dn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: add</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcSyncProvConfig</span><br><span class="line">olcOverlay: syncprov</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## Adding details for replication ###</span></span></span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcSyncRepl</span><br><span class="line">olcSyncRepl:</span><br><span class="line">  rid=001</span><br><span class="line">  provider=ldap://192.168.1.2</span><br><span class="line">  binddn=&quot;cn=Manager,dc=example,dc=com&quot;</span><br><span class="line">  bindmethod=simple</span><br><span class="line">  credentials=redhat</span><br><span class="line">  searchbase=&quot;dc=example,dc=com&quot;</span><br><span class="line">  type=refreshAndPersist</span><br><span class="line">  retry=&quot;5 5 300 5&quot;</span><br><span class="line">  timeout=1</span><br><span class="line">olcSyncRepl:</span><br><span class="line">  rid=002</span><br><span class="line">  provider=ldap://192.168.1.3</span><br><span class="line">  binddn=&quot;cn=Manager,dc=example,dc=com&quot;</span><br><span class="line">  bindmethod=simple</span><br><span class="line">  credentials=redhat</span><br><span class="line">  searchbase=&quot;dc=example,dc=com&quot;</span><br><span class="line">  type=refreshAndPersist</span><br><span class="line">  retry=&quot;5 5 300 5&quot;</span><br><span class="line">  timeout=1</span><br><span class="line">-</span><br><span class="line">add: olcMirrorMode</span><br><span class="line">olcMirrorMode: TRUE</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapmodify -Y EXTERNAL -H ldapi:/// -f configrep.ldif</span></span><br></pre></td></tr></table></figure></li><li>配置ldap启动host，更新<code>/etc/sysconfig/slapd</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/sysconfig/slapd</span></span><br><span class="line">SLAPD_URLS=&quot;ldapi:/// ldap://192.168.1.2&quot;</span><br></pre></td></tr></table></figure><code>192.168.1.2</code>、<code>192.168.1.3</code>根据主机ip确定。</li><li>重启slapd<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart slapd</span></span><br></pre></td></tr></table></figure>至此，dc&#x3D;example,dc&#x3D;com 下的内容便可以在两个服务器上同步了。</li></ol><h2 id="实践测试"><a href="#实践测试" class="headerlink" title="实践测试"></a>实践测试</h2><ol><li>在ldap1服务器192.168.1.2中创建ldap server的基础结构<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> base.ldif</span></span><br><span class="line">dn: dc=example,dc=com</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: example.com</span><br><span class="line"></span><br><span class="line">dn: ou=users,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: users</span><br><span class="line"></span><br><span class="line">dn: ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">objectClass: top</span><br><span class="line">ou: groups       </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd -h 192.168.1.2 -x -D <span class="string">&quot;cn=Manager,dc=example,dc=com&quot;</span> -w redhat -f base.ldif</span></span><br></pre></td></tr></table></figure></li><li>检查ldap1和ldap2中的数据对比<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 检查ldap1 192.168.1.2中的数据</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapsearch -h 192.168.1.2 -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -b dc=example,dc=com -w redhat</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">extended LDIF</span>                                                                                                                                                                                                   </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span>                                                                                                                                                                                                               </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">LDAPv3</span>                                                                                                                                                                                                          </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">base &lt;dc=example,dc=com&gt; with scope subtree</span>                                                                                                                                                                     </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">filter: (objectclass=*) 19L, 623C</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">requesting: ALL</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example.com</span></span><br><span class="line">dn: dc=example,dc=com</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: example.com</span><br><span class="line">dc: example</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">users</span>, example.com</span></span><br><span class="line">dn: ou=users,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: users</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">groups</span>, example.com</span></span><br><span class="line">dn: ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: groups</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">search result</span></span><br><span class="line">search: 2</span><br><span class="line">result: 0 Success</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">numResponses: 4</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">numEntries: 3</span></span><br></pre></td></tr></table></figure>与ldap2 192.168.1.3中的数据进行对比<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 检查ldap2 192.168.1.3中的数据</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapsearch -h 192.168.1.3 -x -D <span class="string">&#x27;cn=Manager,dc=example,dc=com&#x27;</span> -b dc=example,dc=com -w redhat</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">extended LDIF</span>                                                                                                                                                                                                   </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> </span>                                                                                                                                                                                                               </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">LDAPv3</span>                                                                                                                                                                                                          </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">base &lt;dc=example,dc=com&gt; with scope subtree</span>                                                                                                                                                                     </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">filter: (objectclass=*) 19L, 623C</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">requesting: ALL</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example.com</span></span><br><span class="line">dn: dc=example,dc=com</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: example.com</span><br><span class="line">dc: example</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">users</span>, example.com</span></span><br><span class="line">dn: ou=users,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: users</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">groups</span>, example.com</span></span><br><span class="line">dn: ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: groups</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">search result</span></span><br><span class="line">search: 2</span><br><span class="line">result: 0 Success</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">numResponses: 4</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">numEntries: 3</span></span><br></pre></td></tr></table></figure>数据是一样的，注意：ldap2 192.168.1.3服务器的数据是从192.168.1.2中同步过来的。</li><li>可以对ldap2 192.168.1.3中进行数据更新，再查看ldap1 192.168.1.2中的数据。确认互为主<br>在ldap2中添加用户</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> users.ldif</span></span><br><span class="line">dn: uid=testuser,ou=users,dc=example,dc=com</span><br><span class="line">uid: testuser</span><br><span class="line">cn: testuser</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: person</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">userPassword: &#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br><span class="line">shadowLastChange: 17016</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">uidNumber: 1000</span><br><span class="line">gidNumber: 1000</span><br><span class="line">homeDirectory: /home/testuser</span><br><span class="line">sn: testuser</span><br><span class="line">mail: testuser@example.com</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ldapadd  -h 192.168.1.3 -x -D cn=Manager,dc=example,dc=com -f users.ldif -w redhat</span></span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://v.colinlee.fish/posts/openldap-speedy-tutorial-replication.html">OpenLDAP 极速搭建：双主同步</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph的搭建流程及openshift上使用ceph-rbd实现动态存储</title>
      <link href="/openshift/Ceph%E7%9A%84%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%8F%8Aopenshift%E4%B8%8A%E4%BD%BF%E7%94%A8ceph-rbd%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8/"/>
      <url>/openshift/Ceph%E7%9A%84%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%8F%8Aopenshift%E4%B8%8A%E4%BD%BF%E7%94%A8ceph-rbd%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Ceph分布式块存储部署机器列表"><a href="#Ceph分布式块存储部署机器列表" class="headerlink" title="Ceph分布式块存储部署机器列表"></a>Ceph分布式块存储部署机器列表</h2><table><thead><tr><th>名称</th><th>核数</th><th>内存</th><th>ip</th><th>hostname</th><th>外挂磁盘大小（G）</th></tr></thead><tbody><tr><td>管理节点admin</td><td>2</td><td>4</td><td>192.168.1.2</td><td>admin.ceph.com</td><td></td></tr><tr><td>监控节点monitor</td><td>2</td><td>4</td><td>192.168.1.3</td><td>monitor.ceph.com</td><td></td></tr><tr><td>存储节点node1</td><td>2</td><td>4</td><td>192.168.1.4</td><td>node1.ceph.com</td><td>100G</td></tr><tr><td>存储节点node2</td><td>2</td><td>4</td><td>192.168.1.5</td><td>node2.ceph.com</td><td>100G</td></tr></tbody></table><h2 id="部署Ceph-RBD"><a href="#部署Ceph-RBD" class="headerlink" title="部署Ceph RBD"></a>部署Ceph RBD</h2><blockquote><p>1、给每台机器设置hostname</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 设置hostname </span><br><span class="line"> hostnamectl --static set-hostname admin.ceph.com   #192.168.1.2</span><br><span class="line"> hostnamectl --static set-hostname monitor.ceph.com #192.168.1.3</span><br><span class="line"> hostnamectl --static set-hostname node1.ceph.com   #192.168.1.4</span><br><span class="line"> hostnamectl --static set-hostname node2.ceph.com   #192.168.1.5</span><br></pre></td></tr></table></figure><blockquote><p>2、给每个服务器创建用户ceph</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 添加用户ceph </span><br><span class="line">ansible -i hosts all -m user -a &quot;name=ceph&quot;</span><br><span class="line"># 登录每台机器使用passwd命令给每个用户创建密码ceph</span><br><span class="line"># 创建ceph用户密码 </span><br><span class="line">[root@admin ~]# passwd ceph</span><br><span class="line">Changing password for user ceph.</span><br><span class="line">New password: ceph</span><br><span class="line">BAD PASSWORD: The password is shorter than 8 characters</span><br><span class="line">Retype new password: ceph</span><br><span class="line">passwd: all authentication tokens updated successfully.</span><br><span class="line"># 为每台服务器上的ceph用户添加root权限(用root用户登录)</span><br><span class="line"># 为用户添加root权限 </span><br><span class="line">ansible -i hosts all -m shell -a &#x27;echo &quot;ceph ALL=(root) NOPASSWD:ALL&quot; | sudo tee /etc/sudoers.d/ceph&#x27;</span><br><span class="line">ansible -i hosts all -m shell -a &#x27;chmod 0440 /etc/sudoers.d/ceph&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>为admin节点设置访问其它服务器免密码登录</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[ceph@admin ~]$ ssh-keygen </span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/ceph/.ssh/id_rsa): </span><br><span class="line">Created directory &#x27;/home/ceph/.ssh&#x27;.</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /home/ceph/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/ceph/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:rH/HNUPm4HPtxOXzbndOwGzpy6bwA1frhW9S5cywl2Q ceph@admin.ceph.com</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|       .    .o=Eo|</span><br><span class="line">|        S  . *O%+|</span><br><span class="line">|       .  . +oX+%|</span><br><span class="line">|      .   .+ =.X+|</span><br><span class="line">|       .  .o+.+oO|</span><br><span class="line">|        .. .o+o*=|</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line">[ceph@admin ~]$ ssh-copy-id ceph@monitor.ceph.com</span><br><span class="line">[ceph@admin ~]$ ssh-copy-id ceph@node1.ceph.com</span><br><span class="line">[ceph@admin ~]$ ssh-copy-id ceph@node2.ceph.com</span><br></pre></td></tr></table></figure><ol start="4"><li>创建集群<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"># admin.ceph.com创建my-cluster文件夹 </span><br><span class="line">$ ssh ceph@admin</span><br><span class="line">$ mkdir my-cluster</span><br><span class="line">$ cd my-cluster</span><br><span class="line"># 安装ceph-deploy</span><br><span class="line"># 安装ceph-deploy </span><br><span class="line">yum install ceph-deploy</span><br><span class="line"># 清除之前的配置数据</span><br><span class="line"># 清除之前的数据 </span><br><span class="line">ceph-deploy uninstall admin.ceph.com monitor.ceph.com node1.ceph.com node2.ceph.com</span><br><span class="line"># 清除远程主机/var/lib/ceph /etc/ceph中的包和数据</span><br><span class="line"># 清除远程主机/var/lib/ceph /etc/ceph中的包和数据 </span><br><span class="line">ceph-deploy purge admin.ceph.com monitor.ceph.com node1.ceph.com node2.ceph.com</span><br><span class="line"># 清除/var/lib/ceph及/etc/ceph下ceph目录及以下内容全部</span><br><span class="line"># 清除/var/lib/ceph及/etc/ceph下ceph目录及以下内容全部： </span><br><span class="line">ceph-deploy purgedata admin.ceph.com monitor.ceph.com node1.ceph.com node2.ceph.com</span><br><span class="line"># 清除my-cluster目录中的认证密钥文件</span><br><span class="line"># 清除my-cluster目录中的认证密钥文件 </span><br><span class="line">ceph-deploy forgetkeys</span><br><span class="line"># 关闭所有节点的防火墙及安全防护项（青云平台机器默认是不开启的，这步可以不用做）</span><br><span class="line"># 关闭所有节点的防火墙及安全防护项 </span><br><span class="line">ansible -i ceph-hosts all -m service -a &#x27;name=iptables state=stopped&#x27;</span><br><span class="line">ansible -i ceph-hosts all -m shell -a &#x27;setenforce 0&#x27;</span><br><span class="line"></span><br><span class="line"># 创建集群 </span><br><span class="line">$ ceph-deploy new monitor.ceph.com</span><br><span class="line"># 在~/my-cluster下会生成三个文件</span><br><span class="line"># ~/my-cluster下会生成三个文件 </span><br><span class="line">$ ll</span><br><span class="line">total 24</span><br><span class="line">-rw-rw-r-- 1 ceph ceph   251 Jan 12 16:34 ceph.conf</span><br><span class="line">-rw-rw-r-- 1 ceph ceph 15886 Jan 12 16:30 ceph.log</span><br><span class="line">-rw------- 1 ceph ceph    73 Jan 12 16:30 ceph.mon.keyring</span><br><span class="line"></span><br><span class="line"># 系统默认的osd pool为3，目前osd为2，需要修改默认值</span><br><span class="line"># 修改osd默认值为2 </span><br><span class="line">[ceph@admin my-cluster]$ cat ceph.conf </span><br><span class="line">[global]</span><br><span class="line">fsid = 25c13add-967e-4912-bb33-ebbc2cb9376d</span><br><span class="line">mon_initial_members = monitor</span><br><span class="line">mon_host = 192.168.1.3</span><br><span class="line">auth_cluster_required = cephx</span><br><span class="line">auth_service_required = cephx</span><br><span class="line">auth_client_required = cephx</span><br><span class="line">filestore_xattr_use_omap = true</span><br><span class="line">osd pool default size=2</span><br><span class="line"></span><br><span class="line"># 部署安装ceph </span><br><span class="line">ceph-deploy install admin.ceph.com monitor.ceph.com node1.ceph.com node2.ceph.com</span><br><span class="line"># 创建Ceph Monitor</span><br><span class="line"> $ ceph-deploy mon create monitor.ceph.com</span><br><span class="line"> $ ceph-deploy gatherkeys monitor.ceph.com</span><br><span class="line"># 创建ceph osd</span><br><span class="line"># 切到node1.ceph.com</span><br><span class="line">给node1数据节点挂载磁盘/dev/sdc</span><br><span class="line"># 挂载磁盘 </span><br><span class="line">$ sudo mkfs.xfs -f /dev/sdc</span><br><span class="line">$ mkdir /var/lib/ceph/osd/osd-0</span><br><span class="line">$ sudo mount /dev/sdc /var/lib/ceph/osd/osd-0</span><br><span class="line">$ sudo chown ceph:ceph /var/lib/ceph/osd/osd-0</span><br><span class="line"># 同样的方法把node2.ceph.com的磁盘挂载到/var/lib/ceph/osd/osd-1</span><br><span class="line"># 挂载磁盘 </span><br><span class="line">$ sudo mkfs.xfs -f /dev/sdc</span><br><span class="line">$ mkdir /var/lib/ceph/osd/osd-1</span><br><span class="line">$ sudo mount /dev/sdc /var/lib/ceph/osd/osd-1</span><br><span class="line">$ sudo chown ceph:ceph /var/lib/ceph/osd/osd-1</span><br><span class="line"># 准备并激活osd，返回到admin管理节点</span><br><span class="line"># 准备并激活ceph osd </span><br><span class="line">$ ceph-deploy osd prepare node1.ceph.com:/var/lib/ceph/osd/osd-0 node2.ceph.com:/var/lib/ceph/osd/osd-1</span><br><span class="line">$ ceph-deploy osd activate node1.ceph.com:/var/lib/ceph/osd/osd-0 node2.ceph.com:/var/lib/ceph/osd/osd-1</span><br><span class="line"># 拷贝配置文件及key文件</span><br><span class="line">$ ceph-deploy admin admin.ceph.com monitor.ceph.com node1.ceph.com node2.ceph.com</span><br><span class="line"># 为ceph.clinet.admin.keyring添加可读权限（admin节点与monitor节点都添加）</span><br><span class="line"># 添加读取权限 </span><br><span class="line"> $ sudo chmod +r /etc/ceph/ceph.client.admin.keyring</span><br><span class="line"># 查看集群状态</span><br><span class="line">$ ceph health</span><br><span class="line">$ ceph osd tree #查看当前节点</span><br><span class="line"># 完成！！！</span><br></pre></td></tr></table></figure></li></ol><h1 id="Openshift上创建RBD-Storageclass"><a href="#Openshift上创建RBD-Storageclass" class="headerlink" title="Openshift上创建RBD Storageclass"></a>Openshift上创建RBD Storageclass</h1><blockquote><ol><li>首先查看my-cluster文件夹下的ceph.client.admin.keyring文件</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cat ceph.client.admin.keyring </span><br><span class="line">[client.admin]</span><br><span class="line">key = AQBUilha86ufLhAA2BxJn7sG8qVYndokVwtvyA==</span><br><span class="line">caps mds = &quot;allow *&quot;</span><br><span class="line">caps mon = &quot;allow *&quot;</span><br><span class="line">caps osd = &quot;allow *&quot;</span><br><span class="line"># 使用admin的key在openshift上创建secret</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>创建secret私钥</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc  create secret generic ceph-secret --type=&quot;kubernetes.io/rbd&quot; --from-literal=key=&#x27;AQBUilha86ufLhAA2BxJn7sG8qVYndokVwtvyA==&#x27; --namespace=kube-system</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>在需要使用ceph-rbd的project也需要添加secret</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc  create secret generic ceph-secret --type=&quot;kubernetes.io/rbd&quot; --from-literal=key=&#x27;AQBUilha86ufLhAA2BxJn7sG8qVYndokVwtvyA==&#x27; --namespace=project</span><br></pre></td></tr></table></figure><blockquote><ol start="4"><li>创建storageclass</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># storageclass.yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-rbd-sc</span><br><span class="line">provisioner: kubernetes.io/rbd</span><br><span class="line">parameters:</span><br><span class="line">  monitors: 192.168.1.3:6789</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretName: ceph-secret</span><br><span class="line">  adminSecretNamespace: kube-system</span><br><span class="line">  pool: rbd</span><br><span class="line">  userId: admin</span><br><span class="line">  userSecretName: ceph-secret</span><br><span class="line"># oc create -f storageclass.yaml</span><br></pre></td></tr></table></figure><p><code>说明:adminId默认值为admin,pool默认值为rbd, userId默认值与adminId一样.所以这三个值可以不填写。</code></p><blockquote><ol start="5"><li>创建PVC(可通过yaml创建也可以在openshift的webconsole中选择对应的storageclass创建)</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># ceph-rbd-pvc.yaml </span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: myclaim</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 8Gi</span><br><span class="line">  storageClassName: ceph-rbd-sc</span><br><span class="line"># oc create -f ceph-rbd-pvc.yaml -n project</span><br></pre></td></tr></table></figure><p>结果展示</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-dfa6717e23b9c3e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Ceph存储PVC.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ceph集群监控Prometheus+Grafana</title>
      <link href="/openshift/Ceph%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7Prometheus+Grafana/"/>
      <url>/openshift/Ceph%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7Prometheus+Grafana/</url>
      
        <content type="html"><![CDATA[<ul><li>Ceph是一个分布式存储系统。同时Ceph除了能提供块存储，还可以提供文件存储、对象存储。</li><li>这里不介绍如何搭建Ceph及原理，只记录使用Ceph_exporter + Prometheus + Grafana 来对Ceph集群作监控的部署过程</li><li>Ceph集群有三种节点：Admin + Monitor + Node</li></ul><h3 id="Admin节点上部署Ceph-exporter"><a href="#Admin节点上部署Ceph-exporter" class="headerlink" title="Admin节点上部署Ceph_exporter"></a>Admin节点上部署Ceph_exporter</h3><blockquote><p>安装需要的软件golang</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install golang git librados2-devel librbd1-devel -y</span><br></pre></td></tr></table></figure><blockquote><p>设置go的环境变量</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># /etc/profile.d/go.sh</span><br><span class="line">export GOROOT=/usr/lib/golang</span><br><span class="line">export GOBIN=$GOROOT/bin</span><br><span class="line">export GOPATH=/home/golang</span><br><span class="line">export PATH=$PATH:$GOROOT/bin:$GOPATH/bin</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile.d/go.sh</span><br></pre></td></tr></table></figure><blockquote><p>安装ceph_exporter</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go get -u github.com/digitalocean/ceph_exporter</span><br></pre></td></tr></table></figure><blockquote><p>运行ceph_exporter</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/lib/golang/bin/</span><br><span class="line">nohup ./ceph_exporter &amp;</span><br></pre></td></tr></table></figure><blockquote><p> 检验结果</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl 127.0.0.1:9128</span><br></pre></td></tr></table></figure><h3 id="Prometheus上添加ceph-exporter的job"><a href="#Prometheus上添加ceph-exporter的job" class="headerlink" title="Prometheus上添加ceph_exporter的job"></a>Prometheus上添加ceph_exporter的job</h3><blockquote><p>添加scraper的job</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># prometheus.yml</span><br><span class="line">...</span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;ceph&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;ceph_host:9128&#x27;]</span><br><span class="line">        labels:</span><br><span class="line">          instance: ceph</span><br></pre></td></tr></table></figure><blockquote><p>重启prometheus</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pkill -9 prometheus</span><br><span class="line">nohup ./prometheus &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><blockquote><p>检验结果</p></blockquote><p>检查prometheus的status-&gt;targets中Ceph(1&#x2F;1up)</p><h3 id="Grafana中添加Ceph监控展示"><a href="#Grafana中添加Ceph监控展示" class="headerlink" title="Grafana中添加Ceph监控展示"></a>Grafana中添加Ceph监控展示</h3><blockquote><p>下载Ceph集群监控配置json：<a href="https://grafana.com/dashboards/917">Ceph-Cluster Dashboard</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Revisions -&gt; Download</span><br></pre></td></tr></table></figure><blockquote><p>展示最终效果图</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/38268682852617e4117c827bf3c30a367675017fefdc227971fab9682485a15d.png" alt="ceph-cluster.JPG">  </p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Confluence容器化-+-Openshift-Confluence模板创建</title>
      <link href="/openshift/Confluence%E5%AE%B9%E5%99%A8%E5%8C%96-+-Openshift-Confluence%E6%A8%A1%E6%9D%BF%E5%88%9B%E5%BB%BA/"/>
      <url>/openshift/Confluence%E5%AE%B9%E5%99%A8%E5%8C%96-+-Openshift-Confluence%E6%A8%A1%E6%9D%BF%E5%88%9B%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p>因为应用容器化部署已经是标准化的流程，无需再详篇介绍具体的部署流程。所以本文只提供相关的配置文档。如果对部署过程不了解的同学，请先自学容器基础。<br>镜像已经创建好了，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker.io/xhuaustc/confluence:6.7.1</span><br><span class="line">docker.io/xhuaustc/atlassian-mysql:5.7</span><br></pre></td></tr></table></figure><h2 id="镜像构建配置"><a href="#镜像构建配置" class="headerlink" title="镜像构建配置"></a>镜像构建配置</h2><h2 id="mysql镜像"><a href="#mysql镜像" class="headerlink" title="mysql镜像"></a>mysql镜像</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># my.cnf</span><br><span class="line">[mysqld]</span><br><span class="line"></span><br><span class="line"># Disabling symbolic-links is recommended to prevent assorted security risks</span><br><span class="line">symbolic-links = 0</span><br><span class="line"></span><br><span class="line"># http://www.percona.com/blog/2008/05/31/dns-achilles-heel-mysql-installation/</span><br><span class="line">skip_name_resolve</span><br><span class="line"></span><br><span class="line"># http://www.chriscalender.com/ignoring-the-lostfound-directory-in-your-datadir/</span><br><span class="line">ignore-db-dir=lost+found</span><br><span class="line"></span><br><span class="line">character_set_server=utf8</span><br><span class="line">init_connect=&#x27;SET NAMES utf8&#x27;</span><br><span class="line">collation_server=utf8_bin</span><br><span class="line">transaction_isolation=&#x27;read-committed&#x27;</span><br><span class="line"></span><br><span class="line">!includedir /etc/my.cnf.d</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">FROM centos/mysql-57-centos7</span><br><span class="line">COPY my.cnf /etc/my.cnf</span><br></pre></td></tr></table></figure><h2 id="confluence镜像"><a href="#confluence镜像" class="headerlink" title="confluence镜像"></a>confluence镜像</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/cptactionhank/docker-atlassian-confluence</span><br></pre></td></tr></table></figure><p>在Dockerfile目录下添加server.xml, setenv.sh与atlassian-extras-decoder-v2-3.3.0.jar</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"># server.xml</span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;Server port=&quot;8000&quot; shutdown=&quot;SHUTDOWN&quot;&gt;</span><br><span class="line">  &lt;Service name=&quot;Tomcat-Standalone&quot;&gt;</span><br><span class="line">    &lt;Connector port=&quot;8090&quot; connectionTimeout=&quot;300000&quot; redirectPort=&quot;8443&quot; maxThreads=&quot;400&quot; minSpareThreads=&quot;10&quot; enableLookups=&quot;false&quot; acceptCount=&quot;100&quot; URIEncoding=&quot;UTF-8&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;/&gt;</span><br><span class="line">    &lt;Engine name=&quot;Standalone&quot; defaultHost=&quot;localhost&quot;&gt;</span><br><span class="line">      &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;false&quot; startStopThreads=&quot;4&quot;&gt;</span><br><span class="line">        &lt;Context path=&quot;&quot; docBase=&quot;../confluence&quot; reloadable=&quot;false&quot; useHttpOnly=&quot;true&quot;&gt;</span><br><span class="line">          &lt;!-- Logger is deprecated in Tomcat 5.5. Logging configuration for Confluence is specified in confluence/WEB-INF/classes/log4j.properties --&gt;</span><br><span class="line">          &lt;Manager pathname=&quot;&quot;/&gt;</span><br><span class="line">          &lt;Valve className=&quot;org.apache.catalina.valves.StuckThreadDetectionValve&quot; threshold=&quot;600&quot;/&gt;</span><br><span class="line">        &lt;/Context&gt;</span><br><span class="line">        &lt;Context path=&quot;$&#123;confluence.context.path&#125;/synchrony-proxy&quot; docBase=&quot;../synchrony-proxy&quot; reloadable=&quot;false&quot; useHttpOnly=&quot;true&quot;&gt;</span><br><span class="line">          &lt;Valve className=&quot;org.apache.catalina.valves.StuckThreadDetectionValve&quot; threshold=&quot;600&quot;/&gt;</span><br><span class="line">        &lt;/Context&gt;</span><br><span class="line">      &lt;/Host&gt;</span><br><span class="line">    &lt;/Engine&gt;</span><br><span class="line">    &lt;!--</span><br><span class="line">            To run Confluence via HTTPS:</span><br><span class="line">             * Uncomment the Connector below</span><br><span class="line">             * Execute:</span><br><span class="line">                 %JAVA_HOME%\bin\keytool -genkey -alias tomcat -keyalg RSA (Windows)</span><br><span class="line">                 $JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA  (Unix)</span><br><span class="line">               with a password value of &quot;changeit&quot; for both the certificate and the keystore itself.</span><br><span class="line">             * Restart and visit https://localhost:8443/</span><br><span class="line"></span><br><span class="line">             For more info, see https://confluence.atlassian.com/display/DOC/Running+Confluence+Over+SSL+or+HTTPS</span><br><span class="line">        --&gt;</span><br><span class="line">    &lt;!--</span><br><span class="line">        &lt;Connector port=&quot;8443&quot; maxHttpHeaderSize=&quot;8192&quot;</span><br><span class="line">                   maxThreads=&quot;150&quot; minSpareThreads=&quot;25&quot;</span><br><span class="line">                   protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;</span><br><span class="line">                   enableLookups=&quot;false&quot; disableUploadTimeout=&quot;true&quot;</span><br><span class="line">                   acceptCount=&quot;100&quot; scheme=&quot;https&quot; secure=&quot;true&quot;</span><br><span class="line">                   clientAuth=&quot;false&quot; sslProtocols=&quot;TLSv1,TLSv1.1,TLSv1.2&quot; sslEnabledProtocols=&quot;TLSv1,TLSv1.1,TLSv1.2&quot; SSLEnabled=&quot;true&quot;</span><br><span class="line">                   URIEncoding=&quot;UTF-8&quot; keystorePass=&quot;&lt;MY_CERTIFICATE_PASSWORD&gt;&quot;/&gt;</span><br><span class="line">--&gt;</span><br><span class="line">  &lt;/Service&gt;</span><br><span class="line">&lt;/Server&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"># setenv.sh</span><br><span class="line"># See the CATALINA_OPTS below for tuning the JVM arguments used to start Confluence.</span><br><span class="line"></span><br><span class="line">echo &quot;If you encounter issues starting up Confluence, please see the Installation guide at http://confluence.atlassian.com/display/DOC/Confluence+Installation+Guide&quot;</span><br><span class="line"></span><br><span class="line"># set the location of the pid file</span><br><span class="line">if [ -z &quot;$CATALINA_PID&quot; ] ; then</span><br><span class="line">    if [ -n &quot;$CATALINA_BASE&quot; ] ; then</span><br><span class="line">        CATALINA_PID=&quot;$CATALINA_BASE&quot;/work/catalina.pid</span><br><span class="line">    elif [ -n &quot;$CATALINA_HOME&quot; ] ; then</span><br><span class="line">        CATALINA_PID=&quot;$CATALINA_HOME&quot;/work/catalina.pid</span><br><span class="line">    fi</span><br><span class="line">fi</span><br><span class="line">export CATALINA_PID</span><br><span class="line"></span><br><span class="line">PRGDIR=`dirname &quot;$0&quot;`</span><br><span class="line">if [ -z &quot;$CATALINA_BASE&quot; ]; then</span><br><span class="line">  if [ -z &quot;$CATALINA_HOME&quot; ]; then</span><br><span class="line">    LOGBASE=$PRGDIR</span><br><span class="line">    LOGTAIL=..</span><br><span class="line">  else</span><br><span class="line">    LOGBASE=$CATALINA_HOME</span><br><span class="line">    LOGTAIL=.</span><br><span class="line">  fi</span><br><span class="line">else</span><br><span class="line">  LOGBASE=$CATALINA_BASE</span><br><span class="line">  LOGTAIL=.</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">PUSHED_DIR=`pwd`</span><br><span class="line">cd $LOGBASE</span><br><span class="line">cd $LOGTAIL</span><br><span class="line">LOGBASEABS=`pwd`</span><br><span class="line">cd $PUSHED_DIR</span><br><span class="line"></span><br><span class="line">echo &quot;&quot;</span><br><span class="line">echo &quot;Server startup logs are located in $LOGBASEABS/logs/catalina.out&quot;</span><br><span class="line"># IMPORTANT NOTE: Only set JAVA_HOME or JRE_HOME above this line</span><br><span class="line"># Get standard Java environment variables</span><br><span class="line">if $os400; then</span><br><span class="line">  # -r will Only work on the os400 if the files are:</span><br><span class="line">  # 1. owned by the user</span><br><span class="line">  # 2. owned by the PRIMARY group of the user</span><br><span class="line">  # this will not work if the user belongs in secondary groups</span><br><span class="line">  . &quot;$CATALINA_HOME&quot;/bin/setjre.sh</span><br><span class="line">else</span><br><span class="line">  if [ -r &quot;$CATALINA_HOME&quot;/bin/setjre.sh ]; then</span><br><span class="line">    . &quot;$CATALINA_HOME&quot;/bin/setjre.sh</span><br><span class="line">  else</span><br><span class="line">    echo &quot;Cannot find $CATALINA_HOME/bin/setjre.sh&quot;</span><br><span class="line">    echo &quot;This file is needed to run this program&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo &quot;---------------------------------------------------------------------------&quot;</span><br><span class="line">echo &quot;Using Java: $JRE_HOME/bin/java&quot;</span><br><span class="line">CONFLUENCE_CONTEXT_PATH=`$JRE_HOME/bin/java -jar $CATALINA_HOME/bin/confluence-context-path-extractor.jar $CATALINA_HOME`</span><br><span class="line">export CONFLUENCE_CONTEXT_PATH</span><br><span class="line">$JRE_HOME/bin/java -jar $CATALINA_HOME/bin/synchrony-proxy-watchdog.jar $CATALINA_HOME</span><br><span class="line">echo &quot;---------------------------------------------------------------------------&quot;</span><br><span class="line">JVM_MINIMUM_MEMORY=$&#123;JVM_XMS:-384m&#125;</span><br><span class="line">JVM_MAXIMUM_MEMORY=$&#123;JVM_XMX:-768m&#125;</span><br><span class="line"></span><br><span class="line"># Set the JVM arguments used to start Confluence. For a description of the options, see</span><br><span class="line"># http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html</span><br><span class="line">CATALINA_OPTS=&quot;-Xms$&#123;JVM_MINIMUM_MEMORY&#125; -Xmx$&#123;JVM_MAXIMUM_MEMORY&#125; -XX:-PrintGCDetails -XX:+PrintGCDateStamps -XX:-PrintTenuringDistribution $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-Xloggc:$LOGBASEABS/logs/gc-`date +%F_%H-%M-%S`.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=2M $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-XX:G1ReservePercent=20 $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-Djava.awt.headless=true $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-Datlassian.plugins.enable.wait=300 $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-Dsynchrony.enable.xhr.fallback=true $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-Dorg.apache.tomcat.websocket.DEFAULT_BUFFER_SIZE=32768 $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;$&#123;START_CONFLUENCE_JAVA_OPTS&#125; $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">CATALINA_OPTS=&quot;-Dconfluence.context.path=$&#123;CONFLUENCE_CONTEXT_PATH&#125; $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export CATALINA_OPTS</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改Dockerfile</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">FROM openjdk:8-alpine</span><br><span class="line"></span><br><span class="line"># Setup useful environment variables</span><br><span class="line">ENV CONF_HOME     /var/atlassian/confluence</span><br><span class="line">ENV CONF_INSTALL  /opt/atlassian/confluence</span><br><span class="line">ENV CONF_VERSION  6.7.1</span><br><span class="line"></span><br><span class="line">ENV JAVA_CACERTS  $JAVA_HOME/jre/lib/security/cacerts</span><br><span class="line">ENV CERTIFICATE   $CONF_HOME/certificate</span><br><span class="line"></span><br><span class="line"># Install Atlassian Confluence and helper tools and setup initial home</span><br><span class="line"># directory structure.</span><br><span class="line">RUN set -x \</span><br><span class="line">    &amp;&amp; apk --no-cache add curl xmlstarlet bash ttf-dejavu libc6-compat \</span><br><span class="line">    &amp;&amp; mkdir -p                &quot;$&#123;CONF_HOME&#125;&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;CONF_HOME&#125;&quot; \</span><br><span class="line">    &amp;&amp; mkdir -p                &quot;$&#123;CONF_INSTALL&#125;/conf&quot; \</span><br><span class="line">    &amp;&amp; curl -Ls                &quot;https://www.atlassian.com/software/confluence/downloads/binary/atlassian-confluence-$&#123;CONF_VERSION&#125;.tar.gz&quot; | tar -xz --directory &quot;$&#123;CONF_INSTALL&#125;&quot; --strip-components=1 --no-same-owner \</span><br><span class="line">    &amp;&amp; curl -Ls                &quot;https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.44.tar.gz&quot; | tar -xz --directory &quot;$&#123;CONF_INSTALL&#125;/confluence/WEB-INF/lib&quot; --strip-components=1 --no-same-owner &quot;mysql-connector-java-5.1.44/mysql-connector-java-5.1.44-bin.jar&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;CONF_INSTALL&#125;/conf&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;CONF_INSTALL&#125;/temp&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;CONF_INSTALL&#125;/logs&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;CONF_INSTALL&#125;/work&quot; \</span><br><span class="line">    &amp;&amp; echo -e                 &quot;\nconfluence.home=$CONF_HOME&quot; &gt;&gt; &quot;$&#123;CONF_INSTALL&#125;/confluence/WEB-INF/classes/confluence-init.properties&quot; \</span><br><span class="line">    &amp;&amp; xmlstarlet              ed --inplace \</span><br><span class="line">        --delete               &quot;Server/@debug&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Connector/@debug&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Connector/@useURIValidationHack&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Connector/@minProcessors&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Connector/@maxProcessors&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Engine/@debug&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Engine/Host/@debug&quot; \</span><br><span class="line">        --delete               &quot;Server/Service/Engine/Host/Context/@debug&quot; \</span><br><span class="line">                               &quot;$&#123;CONF_INSTALL&#125;/conf/server.xml&quot; \</span><br><span class="line">    &amp;&amp; touch -d &quot;@0&quot;           &quot;$&#123;CONF_INSTALL&#125;/conf/server.xml&quot; </span><br><span class="line"></span><br><span class="line"># Use the default unprivileged account. This could be considered bad practice</span><br><span class="line"># on systems where multiple processes end up being executed by &#x27;daemon&#x27; but</span><br><span class="line"># here we only ever run one process anyway.</span><br><span class="line"></span><br><span class="line"># Expose default HTTP connector port.</span><br><span class="line">EXPOSE 8090 8091</span><br><span class="line"></span><br><span class="line"># Set volume mount points for installation and home directory. Changes to the</span><br><span class="line"># home directory needs to be persisted as well as parts of the installation</span><br><span class="line"># directory due to eg. logs.</span><br><span class="line">VOLUME [&quot;/var/atlassian/confluence&quot;, &quot;/opt/atlassian/confluence/logs&quot;]</span><br><span class="line"></span><br><span class="line"># Set the default working directory as the Confluence home directory.</span><br><span class="line">WORKDIR /var/atlassian/confluence</span><br><span class="line"></span><br><span class="line">COPY docker-entrypoint.sh /</span><br><span class="line">COPY atlassian-extras-decoder-v2-3.3.0.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.3.0.jar</span><br><span class="line">COPY server.xml /opt/atlassian/confluence/conf/server.xml</span><br><span class="line">ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]</span><br><span class="line"></span><br><span class="line"># Run Atlassian Confluence as a foreground process by default.</span><br><span class="line">CMD [&quot;/opt/atlassian/confluence/bin/start-confluence.sh&quot;, &quot;-fg&quot;]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="docker-compose配置"><a href="#docker-compose配置" class="headerlink" title="docker-compose配置"></a>docker-compose配置</h2><p>因为mysql用mysql用户启动的，需要把data&#x2F;mysql权限改为777<br><code>chmod 777 data/mysql -R</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">wiki:</span><br><span class="line">  image: xhuaustc/confluence:6.7.1</span><br><span class="line">  restart: always</span><br><span class="line">  environment:</span><br><span class="line">    - JVM_XMX=1024m</span><br><span class="line">    - JVM_XMS=512m</span><br><span class="line">  ports:</span><br><span class="line">    - &#x27;10380:8090&#x27;</span><br><span class="line">  links:</span><br><span class="line">    - db</span><br><span class="line">  volumes:</span><br><span class="line">    - ./data/confluence:/var/atlassian/confluence</span><br><span class="line">    - ./data/logs:/opt/atlassian/confluence/logs</span><br><span class="line"></span><br><span class="line">db:</span><br><span class="line">  image: xhuaustc/atlassian-mysql:5.7</span><br><span class="line">  restart: always</span><br><span class="line">  environment:</span><br><span class="line">    - MYSQL_USER=confluence</span><br><span class="line">    - MYSQL_PASSWORD=conflence</span><br><span class="line">    - MYSQL_DATABASE=confluence</span><br><span class="line">    - MYSQL_ROOT_PASSWORD=confluence</span><br><span class="line">  volumes:</span><br><span class="line">    - ./data/mysql:/var/lib/mysql</span><br></pre></td></tr></table></figure><h2 id="Openshfit-confluence模板"><a href="#Openshfit-confluence模板" class="headerlink" title="Openshfit confluence模板"></a>Openshfit confluence模板</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Template</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  name: confluence</span><br><span class="line">objects:</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: DeploymentConfig</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: confluence</span><br><span class="line">    name: confluence</span><br><span class="line">  spec:</span><br><span class="line">    replicas: 1</span><br><span class="line">    selector:</span><br><span class="line">      run: confluence</span><br><span class="line">    strategy:</span><br><span class="line">      type: Recreate</span><br><span class="line">    template:</span><br><span class="line">      metadata:</span><br><span class="line">        labels:</span><br><span class="line">          run: confluence</span><br><span class="line">      spec:</span><br><span class="line">        containers:</span><br><span class="line">        - env:</span><br><span class="line">            - name: JVM_XMX</span><br><span class="line">              value: &#x27;2048m&#x27;</span><br><span class="line">            - name: JVM_XMS</span><br><span class="line">              value: &#x27;1024m&#x27;</span><br><span class="line">          image: docker.io/xhuaustc/confluence:6.7.1</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: confluence</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /var/atlassian/confluence</span><br><span class="line">            name: volume-7iy6x</span><br><span class="line">          - mountPath: /opt/atlassian/confluence/logs</span><br><span class="line">            name: volume-zsyly</span><br><span class="line">        volumes:</span><br><span class="line">        - name: volume-7iy6x</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: confluence</span><br><span class="line">        - name: volume-zsyly</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: log</span><br><span class="line">    triggers:</span><br><span class="line">    - type: ConfigChange</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: DeploymentConfig</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: mysql</span><br><span class="line">    name: mysql</span><br><span class="line">  spec:</span><br><span class="line">    replicas: 1</span><br><span class="line">    selector:</span><br><span class="line">      run: mysql</span><br><span class="line">    strategy:</span><br><span class="line">      type: Recreate</span><br><span class="line">    template:</span><br><span class="line">      metadata:</span><br><span class="line">        labels:</span><br><span class="line">          run: mysql</span><br><span class="line">      spec:</span><br><span class="line">        containers:</span><br><span class="line">        - env:</span><br><span class="line">          - name: MYSQL_USER</span><br><span class="line">            value: confluence</span><br><span class="line">          - name: MYSQL_PASSWORD</span><br><span class="line">            value: confluence</span><br><span class="line">          - name: MYSQL_DATABASE</span><br><span class="line">            value: confluence</span><br><span class="line">          - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">            value: confluence</span><br><span class="line">          image: docker.io/xhuaustc/atlassian-mysql:5.7</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: mysql</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /var/lib/mysql</span><br><span class="line">            name: volume-uiwfa</span><br><span class="line">         volumes:</span><br><span class="line">          - name: volume-uiwfa</span><br><span class="line">            persistentVolumeClaim:</span><br><span class="line">              claimName: mysql-data</span><br><span class="line">    triggers:</span><br><span class="line">    - type: ConfigChange</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: confluence</span><br><span class="line">    name: confluence</span><br><span class="line">  spec:</span><br><span class="line">    ports:</span><br><span class="line">    - port: 8090</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8090</span><br><span class="line">    selector:</span><br><span class="line">      run: confluence</span><br><span class="line">    type: ClusterIP</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: mysql</span><br><span class="line">    name: mysql</span><br><span class="line">  spec:</span><br><span class="line">    ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 3306</span><br><span class="line">    selector:</span><br><span class="line">      run: mysql</span><br><span class="line">    type: ClusterIP</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Route</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      haproxy.router.openshift.io/timeout: 3000s</span><br><span class="line">    labels:</span><br><span class="line">      run: confluence</span><br><span class="line">    name: confluence</span><br><span class="line">  spec:</span><br><span class="line">    port:</span><br><span class="line">      targetPort: 8090</span><br><span class="line">    to:</span><br><span class="line">      kind: Service</span><br><span class="line">      name: confluence</span><br><span class="line">      weight: 100</span><br><span class="line">    wildcardPolicy: None</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolumeClaim</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      volume.beta.kubernetes.io/storage-class: ceph-rbd-sc</span><br><span class="line">      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/rbd</span><br><span class="line">    name: confluence</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 20Gi</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolumeClaim</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      volume.beta.kubernetes.io/storage-class: ceph-rbd-sc</span><br><span class="line">      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/rbd</span><br><span class="line">    name: log</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 10Gi</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolumeClaim</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      volume.beta.kubernetes.io/storage-class: ceph-rbd-sc</span><br><span class="line">      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/rbd</span><br><span class="line">    name: mysql-data</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 10Gi</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker中使用命令COPY-ADD导入文件对权限的影响</title>
      <link href="/openshift/Docker%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4COPY-ADD%E5%AF%BC%E5%85%A5%E6%96%87%E4%BB%B6%E5%AF%B9%E6%9D%83%E9%99%90%E7%9A%84%E5%BD%B1%E5%93%8D/"/>
      <url>/openshift/Docker%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4COPY-ADD%E5%AF%BC%E5%85%A5%E6%96%87%E4%BB%B6%E5%AF%B9%E6%9D%83%E9%99%90%E7%9A%84%E5%BD%B1%E5%93%8D/</url>
      
        <content type="html"><![CDATA[<p>1、文件<br>保留权限原文件的权限<br>所属用户与组为镜像中的用户<br>可以使用<code>--chown=jenkins:jenkins</code>来指定用户所属</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">COPY --chown=1001:1001 sample.txt sample.txt</span><br></pre></td></tr></table></figure><p>2、压缩包（ADD）<br>保留权限原文件的权限<br>保留压缩包内文件的用户与组</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker安装镜像仓库的三种方法</title>
      <link href="/openshift/Docker%E5%AE%89%E8%A3%85%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
      <url>/openshift/Docker%E5%AE%89%E8%A3%85%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="一、docker-distribution"><a href="#一、docker-distribution" class="headerlink" title="一、docker-distribution"></a>一、docker-distribution</h2><ol><li>安装docker-distribution软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-distribution</span><br></pre></td></tr></table></figure></li><li>配置registry&#x2F;config.yml文件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># /etc/docker-distribution/registry/config.yml</span><br><span class="line">version: 0.1</span><br><span class="line">log:</span><br><span class="line">fields:</span><br><span class="line">service: registry</span><br><span class="line">storage:</span><br><span class="line">cache:</span><br><span class="line">layerinfo: inmemory</span><br><span class="line">filesystem:</span><br><span class="line">rootdirectory: /var/lib/registry</span><br><span class="line">http:</span><br><span class="line">addr: :5000</span><br></pre></td></tr></table></figure></li><li>启动docker-distribution服务<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker-distribution</span><br><span class="line">systemctl enable docker-distribution</span><br></pre></td></tr></table></figure>运维</li></ol><h2 id="二、运行容器registry"><a href="#二、运行容器registry" class="headerlink" title="二、运行容器registry"></a>二、运行容器registry</h2><p>直接运行docker run</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 5000:5000 -v /data/registry:/var/lib/registry --name registry --r</span><br><span class="line">estart=always registry</span><br></pre></td></tr></table></figure><p>Docker安装镜像仓库的三种方法</p><h2 id="三、搭建Harbor"><a href="#三、搭建Harbor" class="headerlink" title="三、搭建Harbor"></a>三、搭建Harbor</h2><p>Harbor部署在主机上<br>部署相关资料地址：Harbor 地址<br>下载offline部署文件：Harbor offline installer<br>部署手册：Harbor部署手册</p><ol><li>安装必要软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-1.12.6 docker-compose -y</span><br></pre></td></tr></table></figure></li><li>在 &#x2F;etc&#x2F;hosts 添加harbor地址<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/hosts</span><br><span class="line">192.168.2.3 harbor.openshift</span><br></pre></td></tr></table></figure></li><li>在 harbor&#x2F;harbor.cfg 修改hostname<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># harbor/harbor.cfg</span><br><span class="line">hostname = harbor.openshift:1080</span><br></pre></td></tr></table></figure>Harbor默认镜像存储在 <code>/data/ </code>目录下</li><li>更新Harbor对外服务端口号<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># harbor/docker-compose.yml 123行</span><br><span class="line">- 1080:80</span><br><span class="line">- 1443:443</span><br><span class="line">- 4443:4443</span><br><span class="line"># harbor/harbor.cfg</span><br><span class="line">hostname = harbor.openshift:1080</span><br></pre></td></tr></table></figure></li><li>启动docker<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 执行之前请确认/var/lib/docker文件夹是否单独挂盘</span><br><span class="line"># 更新 /etc/sysconfig/docker 配置</span><br><span class="line"># 添加</span><br><span class="line">OPTIONS=&#x27;--selinux-enabled --log-driver=journald --signature-verification=false</span><br><span class="line">--insecure-registry=0.0.0.0/0 --registry-mirror=https://docker.mirrors.ustc.ed</span><br><span class="line">u.cn&#x27;</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure></li><li>安装Harbor<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./install.sh</span><br></pre></td></tr></table></figure></li><li>测试Harbor<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login harbor.openshift</span><br></pre></td></tr></table></figure></li><li>维护Harbor<br>a. 暂停<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose stop</span><br></pre></td></tr></table></figure>b. 暂停后重新启动<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose start</span><br></pre></td></tr></table></figure>c. 更新harbor.cfg后启动<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker-compose down -v</span><br><span class="line">./prepare</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>d. 删除Harbor<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker-compose down -v</span><br><span class="line">rm -r /data/database</span><br><span class="line">rm -r /data/registry</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jira容器化-+-Openshift-Jira模板创建</title>
      <link href="/openshift/Jira%E5%AE%B9%E5%99%A8%E5%8C%96-+-Openshift-Jira%E6%A8%A1%E6%9D%BF%E5%88%9B%E5%BB%BA/"/>
      <url>/openshift/Jira%E5%AE%B9%E5%99%A8%E5%8C%96-+-Openshift-Jira%E6%A8%A1%E6%9D%BF%E5%88%9B%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p>因为应用容器化部署已经是标准化的流程，无需再详篇介绍具体的部署流程。所以本文只提供相关的配置文档。如果对部署过程不了解的同学，请先自学容器基础。<br>镜像已经创建好了，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker.io/xhuaustc/jira-software:7.11.0</span><br><span class="line">docker.io/xhuaustc/atlassian-mysql:5.7</span><br></pre></td></tr></table></figure><h2 id="镜像构建配置"><a href="#镜像构建配置" class="headerlink" title="镜像构建配置"></a>镜像构建配置</h2><p>Jira容器构建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/cptactionhank/docker-atlassian-jira-software</span><br></pre></td></tr></table></figure><p>将setenv.sh与atlassian-extras-3.2.jar拷贝到docker-atlassian-jira-software</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"># setenv.sh</span><br><span class="line">#</span><br><span class="line"># One way to set the JIRA HOME path is here via this variable.  Simply uncomment it and set a valid path like /jira/home.  You can of course set it outside in the command terminal.  That will also work.</span><br><span class="line">#</span><br><span class="line">#JIRA_HOME=&quot;&quot;</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line">#  Occasionally Atlassian Support may recommend that you set some specific JVM arguments.  You can use this variable below to do that.</span><br><span class="line">#</span><br><span class="line">JVM_SUPPORT_RECOMMENDED_ARGS=&quot;&quot;</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># The following 2 settings control the minimum and maximum given to the JIRA Java virtual machine.  In larger JIRA instances, the maximum amount will need to be increased.</span><br><span class="line">#</span><br><span class="line">JVM_MINIMUM_MEMORY=$&#123;JVM_XMS:-384m&#125;</span><br><span class="line">JVM_MAXIMUM_MEMORY=$&#123;JVM_XMX:-768m&#125;</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># The following are the required arguments for JIRA.</span><br><span class="line">#</span><br><span class="line">JVM_REQUIRED_ARGS=&#x27;-Djava.awt.headless=true -Datlassian.standalone=JIRA -Dorg.apache.jasper.runtime.BodyContentImpl.LIMIT_BUFFER=true -Dmail.mime.decodeparameters=true -Dorg.dom4j.factory=com.atlassian.core.xml.InterningDocumentFactory&#x27;</span><br><span class="line"></span><br><span class="line"># Uncomment this setting if you want to import data without notifications</span><br><span class="line">#</span><br><span class="line">#DISABLE_NOTIFICATIONS=&quot; -Datlassian.mail.senddisabled=true -Datlassian.mail.fetchdisabled=true -Datlassian.mail.popdisabled=true&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#-----------------------------------------------------------------------------------</span><br><span class="line">#</span><br><span class="line"># In general don&#x27;t make changes below here</span><br><span class="line">#</span><br><span class="line">#-----------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">#-----------------------------------------------------------------------------------</span><br><span class="line"># Prevents the JVM from suppressing stack traces if a given type of exception</span><br><span class="line"># occurs frequently, which could make it harder for support to diagnose a problem.</span><br><span class="line">#-----------------------------------------------------------------------------------</span><br><span class="line">JVM_EXTRA_ARGS=&quot;-XX:-OmitStackTraceInFastThrow&quot;</span><br><span class="line"></span><br><span class="line">PRGDIR=`dirname &quot;$0&quot;`</span><br><span class="line">cat &quot;$&#123;PRGDIR&#125;&quot;/jirabanner.txt</span><br><span class="line"></span><br><span class="line">JIRA_HOME_MINUSD=&quot;&quot;</span><br><span class="line">if [ &quot;$JIRA_HOME&quot; != &quot;&quot; ]; then</span><br><span class="line">    echo $JIRA_HOME | grep -q &quot; &quot;</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">    echo &quot;&quot;</span><br><span class="line">    echo &quot;--------------------------------------------------------------------------------------------------------------------&quot;</span><br><span class="line">echo &quot;   WARNING : You cannot have a JIRA_HOME environment variable set with spaces in it.  This variable is being ignored&quot;</span><br><span class="line">    echo &quot;--------------------------------------------------------------------------------------------------------------------&quot;</span><br><span class="line">    else</span><br><span class="line">JIRA_HOME_MINUSD=-Djira.home=$JIRA_HOME</span><br><span class="line">    fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">JAVA_OPTS=&quot;-Xms$&#123;JVM_MINIMUM_MEMORY&#125; -Xmx$&#123;JVM_MAXIMUM_MEMORY&#125; $&#123;JAVA_OPTS&#125; $&#123;JVM_REQUIRED_ARGS&#125; $&#123;DISABLE_NOTIFICATIONS&#125; $&#123;JVM_SUPPORT_RECOMMENDED_ARGS&#125; $&#123;JVM_EXTRA_ARGS&#125; $&#123;JIRA_HOME_MINUSD&#125; $&#123;START_JIRA_JAVA_OPTS&#125;&quot;</span><br><span class="line"></span><br><span class="line">export JAVA_OPTS</span><br><span class="line"></span><br><span class="line"># DO NOT remove the following line</span><br><span class="line"># !INSTALLER SET JAVA_HOME</span><br><span class="line"></span><br><span class="line">echo &quot;&quot;</span><br><span class="line">echo &quot;If you encounter issues starting or stopping JIRA, please see the Troubleshooting guide at http://confluence.atlassian.com/display/JIRA/Installation+Troubleshooting+Guide&quot;</span><br><span class="line">echo &quot;&quot;</span><br><span class="line">if [ &quot;$JIRA_HOME_MINUSD&quot; != &quot;&quot; ]; then</span><br><span class="line">    echo &quot;Using JIRA_HOME:       $JIRA_HOME&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># set the location of the pid file</span><br><span class="line">if [ -z &quot;$CATALINA_PID&quot; ] ; then</span><br><span class="line">    if [ -n &quot;$CATALINA_BASE&quot; ] ; then</span><br><span class="line">        CATALINA_PID=&quot;$CATALINA_BASE&quot;/work/catalina.pid</span><br><span class="line">    elif [ -n &quot;$CATALINA_HOME&quot; ] ; then</span><br><span class="line">        CATALINA_PID=&quot;$CATALINA_HOME&quot;/work/catalina.pid</span><br><span class="line">    fi</span><br><span class="line">fi</span><br><span class="line">export CATALINA_PID</span><br><span class="line"></span><br><span class="line">if [ -z &quot;$CATALINA_BASE&quot; ]; then</span><br><span class="line">  if [ -z &quot;$CATALINA_HOME&quot; ]; then</span><br><span class="line">    LOGBASE=$PRGDIR</span><br><span class="line">    LOGTAIL=..</span><br><span class="line">  else</span><br><span class="line">    LOGBASE=$CATALINA_HOME</span><br><span class="line">    LOGTAIL=.</span><br><span class="line">  fi</span><br><span class="line">else</span><br><span class="line">  LOGBASE=$CATALINA_BASE</span><br><span class="line">  LOGTAIL=.</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">PUSHED_DIR=`pwd`</span><br><span class="line">cd $LOGBASE</span><br><span class="line">cd $LOGTAIL</span><br><span class="line">LOGBASEABS=`pwd`</span><br><span class="line">cd $PUSHED_DIR</span><br><span class="line"></span><br><span class="line">echo &quot;&quot;</span><br><span class="line">echo &quot;Server startup logs are located in $LOGBASEABS/logs/catalina.out&quot;</span><br><span class="line"></span><br><span class="line"># Set the JVM arguments used to start JIRA. For a description of the options, see</span><br><span class="line"># http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html</span><br><span class="line"></span><br><span class="line">#-----------------------------------------------------------------------------------</span><br><span class="line"># This allows us to actually debug GC related issues by correlating timestamps</span><br><span class="line"># with other parts of the application logs.</span><br><span class="line">#-----------------------------------------------------------------------------------</span><br><span class="line">GC_JVM_PARAMETERS=&quot;&quot;</span><br><span class="line">GC_JVM_PARAMETERS=&quot;-XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause $&#123;GC_JVM_PARAMETERS&#125;&quot;</span><br><span class="line">GC_JVM_PARAMETERS=&quot;-Xloggc:$LOGBASEABS/logs/atlassian-jira-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M $&#123;GC_JVM_PARAMETERS&#125;&quot;</span><br><span class="line"></span><br><span class="line">CATALINA_OPTS=&quot;$&#123;GC_JVM_PARAMETERS&#125; $&#123;CATALINA_OPTS&#125;&quot;</span><br><span class="line">export CATALINA_OPTS</span><br></pre></td></tr></table></figure><p>构建Dockerfile</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#Dockerfile</span><br><span class="line">FROM openjdk:8-alpine</span><br><span class="line"></span><br><span class="line"># Configuration variables.</span><br><span class="line">ENV JIRA_HOME     /var/atlassian/jira</span><br><span class="line">ENV JIRA_INSTALL  /opt/atlassian/jira</span><br><span class="line">ENV JIRA_VERSION  7.11.0</span><br><span class="line"></span><br><span class="line"># Install Atlassian JIRA and helper tools and setup initial home</span><br><span class="line"># directory structure.</span><br><span class="line">RUN set -x \</span><br><span class="line">    &amp;&amp; apk add --no-cache curl xmlstarlet bash ttf-dejavu libc6-compat \</span><br><span class="line">    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_HOME&#125;&quot; \</span><br><span class="line">    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_HOME&#125;/caches/indexes&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;JIRA_HOME&#125;&quot; \</span><br><span class="line">    &amp;&amp; mkdir -p                &quot;$&#123;JIRA_INSTALL&#125;/conf/Catalina&quot; \</span><br><span class="line">    &amp;&amp; curl -Ls                &quot;https://www.atlassian.com/software/jira/downloads/binary/atlassian-jira-software-7.11.0.tar.gz&quot; | tar -xz --directory &quot;$&#123;JIRA_INSTALL&#125;&quot; --strip-components=1 --no-same-owner \</span><br><span class="line">    &amp;&amp; curl -Ls                &quot;https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.38.tar.gz&quot; | tar -xz --directory &quot;$&#123;JIRA_INSTALL&#125;/lib&quot; --strip-components=1 --no-same-owner &quot;mysql-connector-java-5.1.38/mysql-connector-java-5.1.38-bin.jar&quot; \</span><br><span class="line">    &amp;&amp; rm -f                   &quot;$&#123;JIRA_INSTALL&#125;/lib/postgresql-9.1-903.jdbc4-atlassian-hosted.jar&quot; \</span><br><span class="line">    &amp;&amp; curl -Ls                &quot;https://jdbc.postgresql.org/download/postgresql-42.2.1.jar&quot; -o &quot;$&#123;JIRA_INSTALL&#125;/lib/postgresql-42.2.1.jar&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;JIRA_INSTALL&#125;/conf&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;JIRA_INSTALL&#125;/logs&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;JIRA_INSTALL&#125;/temp&quot; \</span><br><span class="line">    &amp;&amp; chmod -R 777            &quot;$&#123;JIRA_INSTALL&#125;/work&quot; \</span><br><span class="line">    &amp;&amp; sed --in-place          &quot;s/java version/openjdk version/g&quot; &quot;$&#123;JIRA_INSTALL&#125;/bin/check-java.sh&quot; \</span><br><span class="line">    &amp;&amp; echo -e                 &quot;\njira.home=$JIRA_HOME&quot; &gt;&gt; &quot;$&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/classes/jira-application.properties&quot; \</span><br><span class="line">    &amp;&amp; touch -d &quot;@0&quot;           &quot;$&#123;JIRA_INSTALL&#125;/conf/server.xml&quot;</span><br><span class="line"></span><br><span class="line"># Use the default unprivileged account. This could be considered bad practice</span><br><span class="line"># on systems where multiple processes end up being executed by &#x27;daemon&#x27; but</span><br><span class="line"># here we only ever run one process anyway.</span><br><span class="line"></span><br><span class="line"># Expose default HTTP connector port.</span><br><span class="line">EXPOSE 8080</span><br><span class="line"></span><br><span class="line"># Set volume mount points for installation and home directory. Changes to the</span><br><span class="line"># home directory needs to be persisted as well as parts of the installation</span><br><span class="line"># directory due to eg. logs.</span><br><span class="line">VOLUME [&quot;/var/atlassian/jira&quot;, &quot;/opt/atlassian/jira/logs&quot;]</span><br><span class="line"></span><br><span class="line"># Set the default working directory as the installation directory.</span><br><span class="line">WORKDIR /var/atlassian/jira</span><br><span class="line"></span><br><span class="line">COPY &quot;docker-entrypoint.sh&quot; &quot;/&quot;</span><br><span class="line">COPY atlassian-extras-3.2.jar $&#123;JIRA_INSTALL&#125;/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar</span><br><span class="line">COPY setenv.sh $&#123;JIRA_INSTALL&#125;/bin/setenv.sh</span><br><span class="line">ENTRYPOINT [&quot;/docker-entrypoint.sh&quot;]</span><br><span class="line"></span><br><span class="line"># Run Atlassian JIRA as a foreground process by default.</span><br><span class="line">CMD [&quot;/opt/atlassian/jira/bin/start-jira.sh&quot;, &quot;-fg&quot;]</span><br></pre></td></tr></table></figure><p>构建对应的Mysql镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># my.cnf</span><br><span class="line">[mysqld]</span><br><span class="line">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class="line">socket          = /var/run/mysqld/mysqld.sock</span><br><span class="line">datadir         = /var/lib/mysql</span><br><span class="line">secure-file-priv= NULL</span><br><span class="line"># Disabling symbolic-links is recommended to prevent assorted security risks</span><br><span class="line">symbolic-links=0</span><br><span class="line">character_set_server=utf8</span><br><span class="line">init_connect=&#x27;SET NAMES utf8&#x27;</span><br><span class="line">collation_server=utf8_bin</span><br><span class="line">transaction_isolation=&#x27;read-committed&#x27;</span><br><span class="line"></span><br><span class="line"># Custom config should go here</span><br><span class="line">!includedir /etc/mysql/conf.d/</span><br></pre></td></tr></table></figure><p>Dockerfile文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM mysql:5.7</span><br><span class="line">COPY my.cnf /etc/mysql/my.cnf</span><br></pre></td></tr></table></figure><h2 id="部署镜像"><a href="#部署镜像" class="headerlink" title="部署镜像"></a>部署镜像</h2><p>构建docker-compose.yml</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">jira:</span><br><span class="line">  image: xhuaustc/jira-software:7.11.0</span><br><span class="line">  restart: always</span><br><span class="line">  environment:</span><br><span class="line">    - JVM_XMX=2048m</span><br><span class="line">    - JVM_XMS=1024m</span><br><span class="line">  ports:</span><br><span class="line">    - &#x27;8080:8080&#x27;</span><br><span class="line">  links:</span><br><span class="line">    - db</span><br><span class="line">  volumes:</span><br><span class="line">    - ./data/jira:/var/atlassian/jira</span><br><span class="line">    - ./data/logs:/opt/atlassian/jira/logs</span><br><span class="line"></span><br><span class="line">db:</span><br><span class="line">  image: xhuaustc/atlassian-mysql:5.7</span><br><span class="line">  restart: always</span><br><span class="line">  environment:</span><br><span class="line">    - MYSQL_USER=jira</span><br><span class="line">    - MYSQL_PASSWORD=jira</span><br><span class="line">    - MYSQL_DATABASE=jira</span><br><span class="line">    - MYSQL_ROOT_PASSWORD=jira</span><br><span class="line">  volumes:</span><br><span class="line">    - ./data/mysql:/var/lib/mysql</span><br></pre></td></tr></table></figure><h2 id="Openshift-Jira模板"><a href="#Openshift-Jira模板" class="headerlink" title="Openshift Jira模板"></a>Openshift Jira模板</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Template</span><br><span class="line">metadata:</span><br><span class="line">  name: jira</span><br><span class="line">objects:</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: DeploymentConfig</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: jira</span><br><span class="line">    name: jira</span><br><span class="line">  spec:</span><br><span class="line">    replicas: 1</span><br><span class="line">    selector:</span><br><span class="line">      run: jira</span><br><span class="line">    strategy:</span><br><span class="line">      type: Recreate</span><br><span class="line">    template:</span><br><span class="line">      metadata:</span><br><span class="line">        labels:</span><br><span class="line">          run: jira</span><br><span class="line">      spec:</span><br><span class="line">        containers:</span><br><span class="line">        - env:</span><br><span class="line">          - name: JVM_XMX</span><br><span class="line">            value: 2048m</span><br><span class="line">          - name: JVM_XMS</span><br><span class="line">            value: 1024m</span><br><span class="line">          image: docker.io/xhuaustc/jira-software:7.11.0</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: jira</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /var/atlassian/jira</span><br><span class="line">            name: volume-7iy6x</span><br><span class="line">          - mountPath: /opt/atlassian/jira/logs</span><br><span class="line">            name: volume-zsyly</span><br><span class="line">        volumes:</span><br><span class="line">        - name: volume-7iy6x</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: jira</span><br><span class="line">        - name: volume-zsyly</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: jira-log</span><br><span class="line">    triggers:</span><br><span class="line">    - type: ConfigChange</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: DeploymentConfig</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: mysql-jira</span><br><span class="line">    name: mysql-jira</span><br><span class="line">  spec:</span><br><span class="line">    replicas: 1</span><br><span class="line">    selector:</span><br><span class="line">      run: mysql-jira</span><br><span class="line">    strategy:</span><br><span class="line">      type: Recreate</span><br><span class="line">    template:</span><br><span class="line">      metadata:</span><br><span class="line">        labels:</span><br><span class="line">          run: mysql-jira</span><br><span class="line">      spec:</span><br><span class="line">        containers:</span><br><span class="line">        - env:</span><br><span class="line">          - name: MYSQL_USER</span><br><span class="line">            value: jira</span><br><span class="line">          - name: MYSQL_PASSWORD</span><br><span class="line">            value: jira</span><br><span class="line">          - name: MYSQL_DATABASE</span><br><span class="line">            value: jira</span><br><span class="line">          - name: MYSQL_ROOT_PASSWORD</span><br><span class="line">            value: jira</span><br><span class="line">          image: docker.io/xhuaustc/atlassian-mysql:5.7</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: mysql-jira</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /var/lib/mysql</span><br><span class="line">            name: volume-uiwfa</span><br><span class="line">        volumes:</span><br><span class="line">        - name: volume-uiwfa</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: mysql-jira-data</span><br><span class="line">    triggers:</span><br><span class="line">    - type: ConfigChange</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: jira</span><br><span class="line">    name: jira</span><br><span class="line">  spec:</span><br><span class="line">    ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8080</span><br><span class="line">    selector:</span><br><span class="line">      run: jira</span><br><span class="line">    type: ClusterIP</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      run: mysql-jira</span><br><span class="line">    name: mysql-jira</span><br><span class="line">  spec:</span><br><span class="line">    ports:</span><br><span class="line">    - port: 3306</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 3306</span><br><span class="line">    selector:</span><br><span class="line">      run: mysql-jira</span><br><span class="line">    type: ClusterIP</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Route</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      haproxy.router.openshift.io/timeout: 3000s</span><br><span class="line">    labels:</span><br><span class="line">      run: jira</span><br><span class="line">    name: jira</span><br><span class="line">  spec:</span><br><span class="line">    port:</span><br><span class="line">      targetPort: 8080</span><br><span class="line">    to:</span><br><span class="line">      kind: Service</span><br><span class="line">      name: jira</span><br><span class="line">      weight: 100</span><br><span class="line">    wildcardPolicy: None</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolumeClaim</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      volume.beta.kubernetes.io/storage-class: ceph-rbd-sc</span><br><span class="line">      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/rbd</span><br><span class="line">    name: jira</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 20Gi</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolumeClaim</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      volume.beta.kubernetes.io/storage-class: ceph-rbd-sc</span><br><span class="line">      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/rbd</span><br><span class="line">    name: jira-log</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 10Gi</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolumeClaim</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      volume.beta.kubernetes.io/storage-class: ceph-rbd-sc</span><br><span class="line">      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/rbd</span><br><span class="line">    name: mysql-jira-data</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        storage: 10Gi</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8S-JFrog-DevOps实战训练营</title>
      <link href="/openshift/K8S-JFrog-DevOps%E5%AE%9E%E6%88%98%E8%AE%AD%E7%BB%83%E8%90%A5/"/>
      <url>/openshift/K8S-JFrog-DevOps%E5%AE%9E%E6%88%98%E8%AE%AD%E7%BB%83%E8%90%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="DevOps-CAMS模型"><a href="#DevOps-CAMS模型" class="headerlink" title="DevOps CAMS模型"></a>DevOps CAMS模型</h2><p>C 文化 Culture<br>A 自动化 Automation<br>M 指标维度 Measurement<br>S 分享 Sharing</p><h2 id="DevOps-Five-Stages"><a href="#DevOps-Five-Stages" class="headerlink" title="DevOps Five Stages"></a>DevOps Five Stages</h2><ol><li>规范化技术栈</li><li>推进标准化 &amp; 降低不一致性因素</li><li>扩展DevOps实践，开始从一个团队，再到第二个第三个，最后到整个公司</li><li>自动化基础框架交付（PaaS平台）</li><li>提供自服务能力（自定义编排）</li></ol><p>DevOps三步落地法</p><ol><li>基于价值流的自动化持续交付，有六个实践，分别是：可视化、限制在制品、减少规模、减少交接数量、持续识别和拓展约束，以及在价值流中消除浪费。<ul><li>每种架构一套标准化流水线<br>   gitlab &#x2F; jenkins &#x2F; nexus &#x2F; ansible</li><li>Kanban 或 Sprint计划板实现可视化工作，价值流交付可视化</li></ul></li><li>快速反馈，PaaS监控、应用监控<br>prometheus &#x2F; grafana<br>持续反馈，交付之前快速反馈<br>jmeter &#x2F; redmood &#x2F; senium</li><li>DevOps度量<br><a href="https://github.com/Hygieia/Hygieia">Hygieia</a></li></ol><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>跨主机网络</p><ol><li>大二层网络<br>vxlan, flannel<br>Mac in UDP</li><li>三层路由<br>calico<br>必须有三层路由转发能力设备支持</li></ol><h2 id="流水线反模式"><a href="#流水线反模式" class="headerlink" title="流水线反模式"></a>流水线反模式</h2><blockquote><p>Docker镜像多次构建，不做升级</p></blockquote><p>问题：你发布的并不是你测试的<br>解决：一次构建，多次升级<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/53f3998a9f5e70c9191b9f97b2fa070a3ab84064a1af4941727fabb35aaf118e.png" alt="镜像仓库">  </p><blockquote><p> 缺乏质量关卡</p></blockquote><blockquote><p>Docker镜像不进行安全漏洞扫描</p></blockquote><p>问题：</p><ol><li>30%镜像包含已知漏洞</li><li>14% npm package 包含已知漏洞</li><li>59% maven已知漏洞未修复</li></ol><p>解决：DevSecOps<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/67b0fa1ad862ac4a2e23e8e30538e203f10dbf59c033e240518255f433962834.png" alt="DevSecOps">  </p><blockquote><p>工具碎片化</p></blockquote><p>问题： 缺少可追溯性，定位问题难<br>解决：流水线全系统记录，静态扫描结果、测试阶段<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c7a679e0f7bca84bd6bd62b42a91028137b6b9e16b3a86ba66fe60026826735c.png" alt="全系统记录">  </p><blockquote><p>交付物或部署文件无版本化</p></blockquote><p>问题：</p><ol><li>部署回滚流程缺少规范及标准，管理复杂，易出错</li><li>可读性差，易出错，风险高</li><li>历史链混乱，追溯性差，定位问题难<br>解决：<br>Helm——Kubernetes官方包管理工具<br>配置与应用分离</li></ol><h2 id="持续交付流水线设计"><a href="#持续交付流水线设计" class="headerlink" title="持续交付流水线设计"></a>持续交付流水线设计</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/3da634cc4b813d9ab21bda949aca69cdf732119d7b5670613714b03fa59b377c.png" alt="持续交付流水线设计">  </p><p>基础镜像也会有单独的流水线、并且会漏洞扫描、做测试，并将它放在公共生产镜像仓库</p><h2 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h2><blockquote><p>痛点</p></blockquote><ol><li><p>开发语言、运行环境多</p></li><li><p>应用部署、管理难</p></li><li><p>依赖关系复杂、服务治理</p></li><li><p>配置管理</p><blockquote><p>解决</p></blockquote></li><li><p>容器</p></li><li><p>容器编排</p></li><li><p>Istio服务网格</p></li><li><p>ConfigMap &amp; Secret</p></li></ol><blockquote><p>容器云优势</p></blockquote><ol><li>打包运行环境</li><li>集群管理，扩容伸缩</li><li>集群管理，扩容伸缩</li><li>降低运维成本</li><li>降低运维成本</li><li>DevOps(20%)</li></ol><blockquote><p>使用Pod</p></blockquote><ol><li>方便管理</li><li>资源共享和通信</li><li>灵活</li></ol><blockquote><p>安全</p></blockquote><p>configmap或者secret在应用启动前注入环境变量，然后在应用启动后，将环境变量去掉。</p><blockquote><p>Kubernetes最佳实践</p></blockquote><ul><li>配置与应用分离</li><li>计算与存储分离</li><li>服务透明访问</li><li>善用调度特性</li></ul><p>Kubernetes添加节点前Token忘了怎么办？<br>两种办法，1：找回；2：生成新的加入命令</p><ol><li>找回忘记的Token<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;</span><br><span class="line">cda2299d203e26b6499e8283937ffbb6489421ff761569fdf8172d03d9a889d6</span><br><span class="line"></span><br><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# kubeadm token list</span><br><span class="line">TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS</span><br><span class="line">qyg3si.njhyhixcqd18by2g   23h       2019-07-27T15:13:15+08:00   authentication,signing   The default bootstrap token generated by &#x27;kubeadm init&#x27;.   system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"></span><br><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# #kubeadm join 172.17.3.226:6443 --token qyg3si.njhyhixcqd18by2g --discovery-token-ca-cert-hash sha256:cda2299d203e26b6499e8283937ffbb6489421ff761569fdf8172d03d9a889d6</span><br></pre></td></tr></table></figure></li><li>生成新的命令<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><blockquote><p>Helm</p></blockquote></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes安装手册</title>
      <link href="/openshift/Kubernetes%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C/"/>
      <url>/openshift/Kubernetes%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<p>Kubernetes在2014年开源后，很快便占据了容器编排的主导地位，成为容器编排的事实标准。那么Kubernetes的安装是了解它的第一步。目前有非常多的工具方法来实现Kubernetes的安装，收集了一些如下。</p><ul><li>kubeadm：<a href="https://github.com/kubernetes/kubeadm">https://github.com/kubernetes/kubeadm</a><br>kubeadm是官方提供的最为通用的一种部署方案。</li><li>kops：<a href="https://github.com/kubernetes/kops">https://github.com/kubernetes/kops</a><br>kops通过命令行创建，销毁，升级和维护生产级，高可用性的Kubernetes集群。目前正式支持AWS（Amazon Web Services），其中GCE和OpenStack处于beta测试阶段，而VMware vSphere处于alpha阶段。</li><li>kubespray：<a href="https://github.com/kubernetes-sigs/kubespray">https://github.com/kubernetes-sigs/kubespray</a><br>kubespray通过 Ansible Playbook 来定义系统与 Kubernetes 集群部署的任务。</li><li>KubeOperator: <a href="https://github.com/KubeOperator/KubeOperator">https://github.com/KubeOperator/KubeOperator</a><br>KubeOperator 是一个Fit2Cloud开源项目，在离线网络环境下，通过可视化 Web UI 在 VMware、Openstack 或者物理机上规划、部署和运营生产级别的 Kubernetes 集群。</li><li>ansible-install-k8s：<a href="https://github.com/lizhenliang/ansible-install-k8s">https://github.com/lizhenliang/ansible-install-k8s</a><br>ansible-install-k8s支持离线安装，是属于个人开发的ansible部署脚本</li><li>kind：<a href="https://github.com/kubernetes-sigs/kind">https://github.com/kubernetes-sigs/kind</a><br>Kind（Kubernetes in Docker） 是一个 Kubernetes 孵化项目，Kind 是一套开箱即用的 Kubernetes 环境搭建方案。顾名思义，就是将 Kubernetes 所需要的所有组件，全部部署在一个 Docker 容器中，可以很方便的搭建 Kubernetes 集群。</li><li>sealos：<a href="https://github.com/fanux/sealos">https://github.com/fanux/sealos</a><br>Sealos 是一个 Go 语言开发的简单干净且轻量的 Kubernetes 集群部署工具，Sealos 能很好的支持在生产环境中部署高可用的 Kubernetes 集群。</li></ul><h2 id="使用kubeadm部署单机版k8s"><a href="#使用kubeadm部署单机版k8s" class="headerlink" title="使用kubeadm部署单机版k8s"></a>使用kubeadm部署单机版k8s</h2><h3 id="Master节点安装"><a href="#Master节点安装" class="headerlink" title="Master节点安装"></a>Master节点安装</h3><ol><li>机器准备</li></ol><ul><li>虚机配置2核4G以上</li><li>可访问外网</li><li>操作系统CentOS 7.6</li></ul><ol start="2"><li><p>准备工作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl stop firewalld</span><br><span class="line">$ systemctl disable firewalld</span><br><span class="line">$ setenforce 0</span><br><span class="line">$cat /etc/selinux/config</span><br><span class="line">...</span><br><span class="line">SELINUX=disabled</span><br><span class="line">...</span><br><span class="line">$ hostnamectl set-hostname master1</span><br></pre></td></tr></table></figure></li><li><p>添加k8s yum源</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[k8s]</span><br><span class="line">name=k8s</span><br><span class="line">baseurl=https://mirrors.tuna.tsinghua.edu.cn/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure></li><li><p>确保 iptables 工具不使用 nftables 后端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ update-alternatives --set iptables /usr/sbin/iptables-legacy</span><br></pre></td></tr></table></figure></li><li><p>安装软件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y docker kubelet kubeadm kubectl kubernetes-cni</span><br><span class="line">$ echo &quot;KUBELET_EXTRA_ARGS=--cgroup-driver=systemd&quot; &gt; /etc/sysconfig/kubelet</span><br></pre></td></tr></table></figure></li><li><p>关闭系统的Swap</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ swapoff -a</span><br><span class="line">$ # 将/etc/fstab文件中的Swap注释掉</span><br><span class="line">$ cat /etc/fstab</span><br><span class="line">/dev/mapper/VolGroup00-LogVol00 /                       xfs     defaults        0 0</span><br><span class="line">UUID=1539acb0-0589-4eae-a0a4-24566186e425 /boot                   xfs     defaults        0 0</span><br><span class="line">#/dev/mapper/VolGroup00-LogVol01 swap                    swap    defaults        0 0</span><br></pre></td></tr></table></figure></li><li><p>创建&#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf文件，添加如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">vm.swappiness=0</span><br></pre></td></tr></table></figure></li><li><p>启动docker与配置kubelet服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br><span class="line">systemctl enable docker</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure></li><li><p>对docker进行加速，在&#x2F;etc&#x2F;sysconfig&#x2F;docker配置项中添加如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--registry-mirror=https://r03u9tep.mirror.aliyuncs.com</span><br></pre></td></tr></table></figure></li><li><p>使用hub.docker.com中的镜像，例如：<code>docker.io/aiotceo/kube-apiserver</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ # 下载aiotceo镜像</span><br><span class="line">$ kubeadm config images list | sed -e &#x27;s/^/docker pull /g&#x27; -e &#x27;s/k8s.gcr.io/docker.io\/aiotceo/g&#x27; -e &#x27;s/-0//g&#x27; | sh -x</span><br><span class="line">$ #将aiotceo重新tag到k8s.gcr.io</span><br><span class="line">$ docker images | grep aiotceo | awk &#x27;&#123;print &quot;docker tag &quot; $1&quot;:&quot;$2,$1&quot;:&quot;$2&#125;&#x27; | sed -e &quot;s#docker.io/aiotceo#k8s.gcr.io#2&quot; -e &quot;s#3.4.3#3.4.3-0#2&quot; | sh -x</span><br><span class="line">$ #删除aiotceo镜像</span><br><span class="line">$ docker images |grep aiotceo |awk &#x27;&#123;print &quot;docker rmi &quot;, $1&quot;:&quot;$2&#125;&#x27; |sh -x </span><br></pre></td></tr></table></figure></li><li><p>初始化kube集群</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm init</span><br><span class="line">...</span><br><span class="line">kubeadm join 10.0.2.15:6443 --token 8o8yv2.tv836s1jncmrwgsp \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:d9d15b5905e8defc0ef6de294be5eff08d720ed9d98b8d6cb99d153bc7332e8e</span><br></pre></td></tr></table></figure></li><li><p>创建管理员访问文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p $HOME/.kube</span><br><span class="line">$ cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br></pre></td></tr></table></figure></li><li><p>安装网络插件，例如calico</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f https://kuboard.cn/install-script/calico/calico-3.13.1.yaml</span><br></pre></td></tr></table></figure></li><li><p>查看k8s状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node</span><br><span class="line">NAME    STATUS   ROLES    AGE   VERSION</span><br><span class="line">node1   Ready    master   14m   v1.18.2</span><br></pre></td></tr></table></figure></li></ol><h3 id="添加计算节点"><a href="#添加计算节点" class="headerlink" title="添加计算节点"></a>添加计算节点</h3><p>重复 0-9 步，完成环境准备，安装软件及下载镜像。<br>10. kubeadm将计算节点加入集群</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 10.0.2.15:6443 --token 8o8yv2.tv836s1jncmrwgsp \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:d9d15b5905e8defc0ef6de294be5eff08d720ed9d98b8d6cb99d153bc7332e8e</span><br></pre></td></tr></table></figure><ol start="11"><li>查看k8s状态<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get node</span><br><span class="line">NAME    STATUS   ROLES    AGE   VERSION</span><br><span class="line">node1   Ready    master   14m   v1.18.2</span><br><span class="line">node2   Ready    &lt;none&gt;   30m   v1.18.2</span><br></pre></td></tr></table></figure></li></ol><h3 id="补充说明："><a href="#补充说明：" class="headerlink" title="补充说明："></a>补充说明：</h3><ol><li>安装时可以通过<code>kubeadm config print init-defaults</code>查看默认配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm config print init-defaults</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 1.2.3.4</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  name: master1</span><br><span class="line">  taints:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns:</span><br><span class="line">  type: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: k8s.gcr.io</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.18.0</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure></li><li>使用<code>kubeadm init --config</code>可以指定kubeadm配置文件</li></ol><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://kuboard.cn/install/install-k8s.html#%E6%96%87%E6%A1%A3%E7%89%B9%E7%82%B9">使用kubeadm安装kubernetes_v1.18.x</a><br><a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/high-availability/">利用 kubeadm 创建高可用集群</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes工具集（持续收集------）</title>
      <link href="/openshift/Kubernetes%E5%B7%A5%E5%85%B7%E9%9B%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%94%B6%E9%9B%86------%EF%BC%89/"/>
      <url>/openshift/Kubernetes%E5%B7%A5%E5%85%B7%E9%9B%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%94%B6%E9%9B%86------%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="Kubescope-cli"><a href="#Kubescope-cli" class="headerlink" title="Kubescope cli"></a>Kubescope cli</h2><p><a href="https://github.com/hharnisc/kubescope-cli">Kubescope cli</a> 是一个可以运行在本地或 Kubernetes 中的工具，可直接从 Docker Daemon 中收集容器指标并可视化。和 <code>cAdvisor</code> 等其他集群指标收集服务一样， <code>kubescope cli</code> 收集指标的周期是 1 秒（而不是 10-15 秒）。如果周期是 10-15 秒，你可能会在测试期间错过一些引发性能瓶颈的问题。如果你使用 cAdvisor 进行测试，每次都要使用新的 Pod 作为测试对象，因为 Kubernetes 在超过资源限制时就会将 Pod 杀死，然后重新启动一个全新的 Pod。而 <code>kubescope cli</code> 就没有这方面的忧虑，它直接从 Docker Daemon 中收集容器指标（你可以自定义收集指标的时间间隔），并使用正则表达式来选择和过滤你想要显示的容器。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-27566fb3d2a4d92b.gif?imageMogr2/auto-orient/strip" alt="kubescope-cli"></p><h2 id="KubeMark"><a href="#KubeMark" class="headerlink" title="KubeMark"></a>KubeMark</h2><p><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/kubemark-guide.md">Kubemark</a>是K8s官方提供的一个对K8s集群进行性能测试的工具。它可以模拟出一个K8s cluster（Kubemark cluster），不受资源限制，从而能够测试的集群规模比真实集群大的多。这个cluster中master是真实的机器，所有的nodes是Hollow nodes。Hollow nodes执行的还是真实的K8s程序，只是不会调用Docker，因此测试会走一套K8s API调用的完整流程，但是不会真正创建pod。</p><h2 id="Kubefwd"><a href="#Kubefwd" class="headerlink" title="Kubefwd"></a>Kubefwd</h2><p><a href="https://github.com/txn2/kubefwd/blob/master/README_CN.md">kubefwd</a> 是一个用于端口转发Kubernetes中指定namespace下的全部或者部分pod的命令行工具。 kubefwd 使用本地的环回IP地址转发需要访问的service，并且使用与service相同的端口。 kubefwd 会临时将service的域条目添加到 &#x2F;etc&#x2F;hosts 文件中。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/131045874b5f63548f32c7206962fc25048b4931bf29c615c539e2fa5904f3bd.png" alt="kubefwd">  </p><h2 id="kubectl-debug"><a href="#kubectl-debug" class="headerlink" title="kubectl-debug"></a>kubectl-debug</h2><p><a href="https://github.com/aylei/kubectl-debug">kubectl-debug</a> 是一个简单的 kubectl 插件, 能够帮助你便捷地进行 Kubernetes 上的 Pod 排障诊断. 背后做的事情很简单: 在运行中的 Pod 上额外起一个新容器, 并将新容器加入到目标容器的 pid, network, user 以及 ipc namespace 中, 这时我们就可以在新容器中直接用 netstat, tcpdump 这些熟悉的工具来解决问题了, 而旧容器可以保持最小化, 不需要预装任何额外的排障工具.</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-be51ec5e0f312a8d.gif?imageMogr2/auto-orient/strip" alt="kubectl-debug"></p><h2 id="nsenter命令"><a href="#nsenter命令" class="headerlink" title="nsenter命令"></a>nsenter命令</h2><p><a href="https://staight.github.io/2019/09/23/nsenter%E5%91%BD%E4%BB%A4%E7%AE%80%E4%BB%8B/">nsenter</a> 命令是一个可以在指定进程的命令空间下运行指定程序的命令。它位于util-linux包中。<br>它的命令语法如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">nsenter [options] [program [arguments]]</span><br><span class="line"></span><br><span class="line">options:</span><br><span class="line">-t, --target pid：指定被进入命名空间的目标进程的pid</span><br><span class="line">-m, --mount[=file]：进入mount命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-u, --uts[=file]：进入uts命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-i, --ipc[=file]：进入ipc命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-n, --net[=file]：进入net命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-p, --pid[=file]：进入pid命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-U, --user[=file]：进入user命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-G, --setgid gid：设置运行程序的gid</span><br><span class="line">-S, --setuid uid：设置运行程序的uid</span><br><span class="line">-r, --root[=directory]：设置根目录</span><br><span class="line">-w, --wd[=directory]：设置工作目录</span><br><span class="line"></span><br><span class="line">如果没有给出program，则默认执行$SHELL。</span><br></pre></td></tr></table></figure><p>具体使用实例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker inspect -f &#123;&#123;.State.Pid&#125;&#125; nginx <span class="comment">## 其中nginx为需要查看的容器名，也可以使用用Container ID</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nsenter --target 3326 --mount --uts --ipc --net --pid</span></span><br></pre></td></tr></table></figure><h2 id="kt-connect"><a href="#kt-connect" class="headerlink" title="kt-connect"></a>kt-connect</h2><p><a href="https://alibaba.github.io/kt-connect/#/zh-cn/">kt-connect</a> 是一个可以让开发环境访问K8S集群下应用的工具</p><h2 id="Lens"><a href="#Lens" class="headerlink" title="Lens"></a>Lens</h2><p>Kubernetes可视化管理工具</p><h2 id="Container-diff"><a href="#Container-diff" class="headerlink" title="Container-diff"></a>Container-diff</h2><p><a href="https://github.com/GoogleContainerTools/container-diff">container-diff</a><br>这是一个可对两个镜像进行内容对比的工具。比较本地镜像使用<code>daemon://</code>。例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">container-diff diff daemon://modified_debian:latest remote://gcr.io/google-appengine/debian8:latest</span></span><br></pre></td></tr></table></figure><h2 id="kube-score"><a href="#kube-score" class="headerlink" title="kube-score"></a>kube-score</h2><p><a href="https://github.com/zegl/kube-score/releases">Kube-Score</a>是一款针对Kubernetes的性能及安全分析工具，该工具能够对Kubernetes对象定义进行静态代码分析，并给出提升Kubernetes性能和安全性方面的建议。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-37f5373c17bbfcc5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Kube-Score"></p><h2 id="kubectx、kubens"><a href="#kubectx、kubens" class="headerlink" title="kubectx、kubens"></a>kubectx、kubens</h2><p><a href="https://github.com/ahmetb/kubectx">kubectx</a>快速切换管理k8s的集群<br><a href="https://github.com/ahmetb/kubectx">kubens</a>快速切换K8s集群的namespace<br>将多个kubectl config配置文件进行合并</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">KUBECONFIG=a.conf:b.conf:c.conf kubectl config view --flatten &gt; .kube/config</span></span><br></pre></td></tr></table></figure><p><img src="https://upload-images.jianshu.io/upload_images/5793257-ec72dadfc5c1927e.gif?imageMogr2/auto-orient/strip" alt="kubectx"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-110880b8459302a0.gif?imageMogr2/auto-orient/strip" alt="kubens"></p><h2 id="kubecm"><a href="#kubecm" class="headerlink" title="kubecm"></a>kubecm</h2><p><a href="https://github.com/sunny0826/kubecm">kubecm</a> : Manage your kubeconfig more easily.<br><a href="https://kubecm.cloud/">doc</a></p><h2 id="webkubectl"><a href="#webkubectl" class="headerlink" title="webkubectl"></a>webkubectl</h2><p><a href="https://github.com/KubeOperator/webkubectl">webkubectl</a>: 页面版k9s&#x2F;kubectl</p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p><a href="https://supereagle.github.io/2017/03/09/kubemark/">Kubernetes集群性能测试</a><br><a href="https://www.jianshu.com/p/32e6794cda0e">kubemark 搭建测试集群和性能测试</a><br><a href="https://juejin.im/post/5cf2905de51d4577614760ea">简化 Pod 故障诊断: kubectl-debug 介绍</a><br><a href="https://karlkfi.medium.com/a-select-list-of-kubernetes-tools-38249fc27155">A Select List of Kubernetes Tools</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes更新etcd证书</title>
      <link href="/openshift/Kubernetes%E6%9B%B4%E6%96%B0etcd%E8%AF%81%E4%B9%A6/"/>
      <url>/openshift/Kubernetes%E6%9B%B4%E6%96%B0etcd%E8%AF%81%E4%B9%A6/</url>
      
        <content type="html"><![CDATA[<p>在三台etcd所在的主机上执行以下操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /etc/kubernetes/pki</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> etcd etcd.bak</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> apiserver-etcd-client</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> apiserver-etcd-client.* apiserver-etcd-client/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm alpha phase certs etcd-ca</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm alpha phase certs etcd-server --config=/etc/kubernetes/kubeadmcfg.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm alpha phase certs etcd-peer --config=/etc/kubernetes/kubeadmcfg.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm alpha phase certs etcd-healthcheck-client --config=/etc/kubernetes/kubeadmcfg.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm alpha phase certs apiserver-etcd-client --config=/etc/kubernetes/kubeadmcfg.yaml</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubespray安装Kubernates过程</title>
      <link href="/openshift/Kubespray%E5%AE%89%E8%A3%85Kubernates%E8%BF%87%E7%A8%8B/"/>
      <url>/openshift/Kubespray%E5%AE%89%E8%A3%85Kubernates%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<ol><li><p>准备机器，绑定好IP（请关闭ipv6功能），关闭防火墙，并配置好hostname</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>在bation机器上设置免密码登录，并下载好kubespray安装脚本</p></li><li><p>先安装python3与python3-pip，并将pip进行升级</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install python3 python3-pip -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip3 install --upgrade pip</span></span><br></pre></td></tr></table></figure></li><li><p>安装python依赖包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install -r requirements.txt  -i https://pypi.douban.com/simple</span></span><br></pre></td></tr></table></figure></li><li><p>更改镜像地址，特别是国内网络安装时</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vim roles/download/defaults/main.yml</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-3升级Docker服务</title>
      <link href="/openshift/OpenShift-3%E5%8D%87%E7%BA%A7Docker%E6%9C%8D%E5%8A%A1/"/>
      <url>/openshift/OpenShift-3%E5%8D%87%E7%BA%A7Docker%E6%9C%8D%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>OpenShift是一个开源产品，自2015年3.0版本开始，它使用Kubernetes作为底层的编排引擎，已经有将近5年了。同时它也有企业级版本，服务了众多大中小企业。经过这些年生产上的实践，OpenShift 3不断完善，已经非常稳定了，但是它依赖组件多，不断增加新的功能，使用量不断增多，一些漏洞和问题会被发现。在生产环境中，运行着大量的生产级应用，我们该如何升级Docker等组件，把业务影响降到最小，这是每个企业都无法绕过的问题。<br>Docker作为OpenShift 3默认的容器运行，它的可靠性也尤为重要。本篇就以Docker升级为例介绍如何对OpenShift组件进行升级。<br>升级不同OpenShift组件的思路是一样，主要是如下两条。</p><ol><li>逐个节点升级</li><li>升级前将业务应用迁走</li></ol><h2 id="升级Docker实操"><a href="#升级Docker实操" class="headerlink" title="升级Docker实操"></a>升级Docker实操</h2><ol><li>更新yum源中的docker包<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp docker-rpm/* ./extras/Packages/d/</span><br><span class="line">$ createrepo --update extras</span><br></pre></td></tr></table></figure></li><li>迁移节点上的POD并将它设置为不可调度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm drain &lt;node_name&gt; --force --delete-local-data --ignore-daemonsets </span><br></pre></td></tr></table></figure></li><li>排除不需要升级的软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ atomic-openshift-docker-excluder exclude </span><br><span class="line">$ atomic-openshift-excluder exclude </span><br></pre></td></tr></table></figure></li><li>升级docker<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum clean all</span><br><span class="line">$ yum update docker</span><br></pre></td></tr></table></figure></li><li>重启服务或者重启主机</li></ol><p>Master节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart docker</span><br><span class="line">$ master-restart api</span><br><span class="line">$ master-restart controllers </span><br><span class="line">$ systemctl restart origin-node</span><br></pre></td></tr></table></figure><p>Node节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart docker</span><br><span class="line">$ systemctl restart origin-node</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ reboot</span><br></pre></td></tr></table></figure><ol start="5"><li>将节点设置为可调度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm uncordon &lt;node_name&gt; </span><br></pre></td></tr></table></figure></li></ol><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://access.redhat.com/solutions/3874691">https://access.redhat.com/solutions/3874691</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-4-3部署安装（国内需要使用科学上网支持）</title>
      <link href="/openshift/OpenShift-4-3%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85%EF%BC%88%E5%9B%BD%E5%86%85%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%94%AF%E6%8C%81%EF%BC%89/"/>
      <url>/openshift/OpenShift-4-3%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85%EF%BC%88%E5%9B%BD%E5%86%85%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%94%AF%E6%8C%81%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="准备好本机访问科学上网环境"><a href="#准备好本机访问科学上网环境" class="headerlink" title="准备好本机访问科学上网环境"></a>准备好本机访问科学上网环境</h2><ol><li>安装pip软件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install python2-pip</span><br></pre></td></tr></table></figure></li><li>安装shadowsocks包<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install shadowsocks -i https://pypi.douban.com/simple</span><br></pre></td></tr></table></figure></li><li>编辑文件&#x2F;etc&#x2F;shadowsocks.json<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; /etc/shadowsocks.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;server&quot;:&quot;shadowsocks的IP&quot;,</span><br><span class="line">    &quot;server_port&quot;:8388,</span><br><span class="line">    &quot;local_address&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">    &quot;local_port&quot;:1080,</span><br><span class="line">    &quot;password&quot;:&quot;fuuuuuuuuuuuuckgfw&quot;,</span><br><span class="line">    &quot;timeout&quot;:300,</span><br><span class="line">    &quot;method&quot;:&quot;rc4-md5&quot;,</span><br><span class="line">    &quot;fast_open&quot;: false</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>启动shadowsocks客户端<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sslocal -c /etc/shadowsocks.json -d start</span><br></pre></td></tr></table></figure>如果需要暂停，执行以下命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo sslocal -c /etc/shadowsocks.json -d stop</span><br></pre></td></tr></table></figure></li><li>安装privoxy软件将sockets5转为http协议<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ yum install privoxy</span><br><span class="line">$ cat &gt;/etc/privoxy/config &lt;&lt;EOF</span><br><span class="line">forward-socks5t   /               127.0.0.1:1080 .</span><br><span class="line">listen-address  localhost:8118</span><br><span class="line">EOF</span><br><span class="line">$ systemctl start privoxy</span><br></pre></td></tr></table></figure></li><li>设置本机的http代理服务<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ export http_proxy=http://localhost:8118</span><br><span class="line">$ export https_proxy=http://localhost:8118</span><br><span class="line">$ export no_proxy=&quot;registry.example.com,127.0.0.1,192.168.1.21&quot;</span><br></pre></td></tr></table></figure>其中<code>no_proxy</code>为本地镜像仓库，将会用来接收OpenShift 4的官方镜像。</li></ol><h2 id="同步镜像"><a href="#同步镜像" class="headerlink" title="同步镜像"></a>同步镜像</h2><p>镜像同步完成后的提示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@registry ~]# oc adm -a $&#123;LOCAL_SECRET_JSON&#125; release mirror      --from=quay.io/$&#123;PRODUCT_REPO&#125;/$&#123;RELEASE_NAME&#125;:$&#123;OCP_RELEASE&#125;      --to=$&#123;LOCAL_REGISTRY&#125;/$&#123;LOCAL_REPOSITORY&#125;      --to-release-image=$&#123;LOCAL_REGISTRY&#125;/$&#123;LOCAL_REPOSITORY&#125;:$&#123;OCP_RELEASE&#125;</span><br><span class="line">info: Mirroring 109 images to registry.fcloudy.com:5000/ocp4/openshift4 ...</span><br><span class="line">registry.fcloudy.com:5000/</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">info: Mirroring completed in 4m46.5s (3.265MB/s)</span><br><span class="line">Success</span><br><span class="line">Update image:  registry.fcloudy.com:5000/ocp4/openshift4:4.4.3-x86_64</span><br><span class="line">Mirror prefix: registry.fcloudy.com:5000/ocp4/openshift4</span><br><span class="line"></span><br><span class="line">To use the new mirrored repository to install, add the following section to the install-config.yaml:</span><br><span class="line"></span><br><span class="line">imageContentSources:</span><br><span class="line">- mirrors:</span><br><span class="line">  - registry.fcloudy.com:5000/ocp4/openshift4</span><br><span class="line">  source: quay.io/openshift-release-dev/ocp-release</span><br><span class="line">- mirrors:</span><br><span class="line">  - registry.fcloudy.com:5000/ocp4/openshift4</span><br><span class="line">  source: quay.io/openshift-release-dev/ocp-v4.0-art-dev</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">To use the new mirrored repository for upgrades, use the following to create an ImageContentSourcePolicy:</span><br><span class="line"></span><br><span class="line">apiVersion: operator.openshift.io/v1alpha1</span><br><span class="line">kind: ImageContentSourcePolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: example</span><br><span class="line">spec:</span><br><span class="line">  repositoryDigestMirrors:</span><br><span class="line">  - mirrors:</span><br><span class="line">    - registry.fcloudy.com:5000/ocp4/openshift4</span><br><span class="line">    source: quay.io/openshift-release-dev/ocp-release</span><br><span class="line">  - mirrors:</span><br><span class="line">    - registry.fcloudy.com:5000/ocp4/openshift4</span><br><span class="line">    source: quay.io/openshift-release-dev/ocp-v4.0-art-dev</span><br></pre></td></tr></table></figure><h2 id="检查本地镜像仓库状态"><a href="#检查本地镜像仓库状态" class="headerlink" title="检查本地镜像仓库状态"></a>检查本地镜像仓库状态</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -u admin:admin -k https://registry.fcloudy.com:5000/v2/_catalog</span><br></pre></td></tr></table></figure><h2 id="下载相关的coreos文件"><a href="#下载相关的coreos文件" class="headerlink" title="下载相关的coreos文件"></a>下载相关的coreos文件</h2><p>文件列表可参考 <a href="https://github.com/RedHatOfficial/ocp4-helpernode/blob/master/vars/main.yml">https://github.com/RedHatOfficial/ocp4-helpernode/blob/master/vars/main.yml</a><br>列表如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/4.4/latest/rhcos-4.4.3-x86_64-metal.x86_64.raw.gz</span><br><span class="line">https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/4.4/latest/rhcos-4.4.3-x86_64-installer-kernel-x86_64</span><br><span class="line">https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/4.4/latest/rhcos-4.4.3-x86_64-installer-initramfs.x86_64.img</span><br><span class="line">https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.4.3/openshift-client-linux-4.4.3.tar.gz</span><br><span class="line">https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.4.3/openshift-install-linux-4.4.3.tar.gz</span><br></pre></td></tr></table></figure><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>1、安装master与node节点时，需要关闭helper机器的selinux</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ setenforce 0</span><br></pre></td></tr></table></figure><p>2、Vmware 节点引导使用BIOS<br>3、</p><h2 id="创建机器"><a href="#创建机器" class="headerlink" title="创建机器"></a>创建机器</h2><p>下载rhcos镜像地址 <a href="https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/4.4/latest/">https://mirror.openshift.com/pub/openshift-v4/x86_64&#x2F;dependencies&#x2F;rhcos&#x2F;4.4&#x2F;latest&#x2F;</a><br>通过vmware导入创建rhcos服务器，分别作为bootstrap、master、node机器。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-ImageStream指向的镜像是否为内部镜像仓库</title>
      <link href="/openshift/OpenShift-ImageStream%E6%8C%87%E5%90%91%E7%9A%84%E9%95%9C%E5%83%8F%E6%98%AF%E5%90%A6%E4%B8%BA%E5%86%85%E9%83%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"/>
      <url>/openshift/OpenShift-ImageStream%E6%8C%87%E5%90%91%E7%9A%84%E9%95%9C%E5%83%8F%E6%98%AF%E5%90%A6%E4%B8%BA%E5%86%85%E9%83%A8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-318a5527b792d665.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Openshift内部镜像仓库"></p><p>ImageStream是OpenShift中的一个特有的资源。在DeploymentConfig&#x2F;BuildConfig中使用ImageStream和ImageStreamTag时经常会有这样的疑惑：究竟它指向的镜像有没有pull到OpenShift内部的镜像仓库呢？我们使用DeploymentConfig发布应用时，集群会从内部镜像仓库中pull镜像，还是从指向的外部镜像仓库中拉取？<br>大家来看一下下面这个例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc import-image openshift/jenkins:v3.10 --from=docker.io/openshift/jenkins-2-centos7:v3.10 --confirm</span><br></pre></td></tr></table></figure><p>猜一猜，以上这条命令是否会将镜像拉取到内部镜像仓库？<br>答案是否定的，内部镜像仓库并<code>不会</code>拉取镜像本身，只是获取镜像的元数据，将创建的ImageStreamTag <code>openshift/jenkins:v3.10</code>指向镜像<code>docker.io/openshift/jenkins-2-centos7:v3.10</code>。这里的关键就是ImageStream[Tag]的一个配置项：referencePolicy.type。导入镜像时，referencePolicy.type默认为source。<br>所以如果需要将导入镜像到ImageStream[Tag]，并将它自动拉取到内部镜像仓库，需要设置referencePolicy.type为local，在DeploymentConfig第一次部署拉取镜像时，镜像也会导入到私有镜像仓库中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ImageStream</span><br><span class="line">metadata:</span><br><span class="line">  ...</span><br><span class="line">  tags:</span><br><span class="line">    - ...</span><br><span class="line">      referencePolicy:</span><br><span class="line">        type: Local</span><br></pre></td></tr></table></figure><p>在使用<code>oc import-image</code>时需要添加参数<code>--reference-policy=&#39;local&#39;</code>，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc import-image openshift/jenkins:v3.10 --reference-policy=&#x27;local&#x27; --from=docker.io/openshift/jenkins-2-centos7:v3.10 --confirm</span><br></pre></td></tr></table></figure><p>或者是通过<code>docker push</code>将镜像推送到镜像仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull docker.io/openshift/jenkins-2-centos7:v3.10 </span><br><span class="line">$ docker tag docker.io/openshift/jenkins-2-centos7:v3.10 docker-registry-default.example.com/openshift/jenkins-2-centos7:v3.10 </span><br><span class="line">$ docker login -p `oc whoami -t`  -e unused -u unused docker-registry-default.example.com</span><br><span class="line">$ docker push docker-registry-default.example.com/openshift/jenkins-2-centos7:v3.10</span><br></pre></td></tr></table></figure><p>参考文章：<br><a href="https://austindewey.com/2018/12/09/a-word-about-openshift-imagestreams/">https://austindewey.com/2018/12/09/a-word-about-openshift-imagestreams/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Kafka-Operator测试报告</title>
      <link href="/openshift/OpenShift-Kafka-Operator%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/"/>
      <url>/openshift/OpenShift-Kafka-Operator%E6%B5%8B%E8%AF%95%E6%8A%A5%E5%91%8A/</url>
      
        <content type="html"><![CDATA[<h1 id="1-测试环境"><a href="#1-测试环境" class="headerlink" title="1. 测试环境"></a>1. 测试环境</h1><p>物理机设备：集群（3 master 2 infra 3 node）<br>  管理（1manager 部署LB+外部镜像仓库+DNS）<br>物理机配置：40c 378G<br>Openshift：v3.11.0+1a90c5c-83<br>Kubernetes：v1.11.0+d4cacc0<br>Kafka Operator：amq-streams-1.1.0<br>Kafka：2.1.1</p><h1 id="2-测试要求和内容"><a href="#2-测试要求和内容" class="headerlink" title="2. 测试要求和内容"></a>2. 测试要求和内容</h1><p>根据测试要求，本次具体测试的功能点如下：</p><table><thead><tr><th>序号</th><th>测试项目</th><th>测试项</th><th>优先级</th></tr></thead><tbody><tr><td>1</td><td>Kafka Operator部署</td><td>Kafka Operator部署</td><td>高</td></tr><tr><td></td><td></td><td>Kafka集群创建</td><td>高</td></tr><tr><td></td><td></td><td>Kafka监控部署</td><td>高</td></tr><tr><td>2</td><td>Kafka功能测试</td><td>Kafka创建Topic</td><td>高</td></tr><tr><td></td><td></td><td>Openshift集群内部Kafka producer与consumer测试</td><td>高</td></tr><tr><td></td><td></td><td>Openshift集群外部Kafka producer与consumer测试（NodePort方案）</td><td>高</td></tr><tr><td></td><td></td><td>Openshift集群外部Kafka producer与consumer测试（Router方案）</td><td>高</td></tr><tr><td>3</td><td>Kafka性能测试</td><td>Kafka写入消息压力测试[集群内部]</td><td>高</td></tr><tr><td></td><td></td><td>Kafka 消费消息压力测试[集群内部]</td><td>高</td></tr><tr><td></td><td></td><td>Kafka写入消息压力测试[集群外部NodePort方案]</td><td>高</td></tr><tr><td></td><td></td><td>Kafka 消费消息压力测试[集群外部NodePort方案]</td><td>高</td></tr><tr><td></td><td></td><td>Kafka写入消息压力测试[集群外部Router方案]</td><td>中</td></tr><tr><td></td><td></td><td>Kafka 消费消息压力测试[集群外部Router方案]</td><td>中</td></tr><tr><td>4</td><td>高可用性测试</td><td>Broker异常，恢复时长</td><td>中</td></tr><tr><td></td><td></td><td>磁盘故障，数据影响</td><td>中</td></tr></tbody></table><h1 id="3-测试方法和结果"><a href="#3-测试方法和结果" class="headerlink" title="3. 测试方法和结果"></a>3. 测试方法和结果</h1><h2 id="3-1-Kafka-Operator部署"><a href="#3-1-Kafka-Operator部署" class="headerlink" title="3.1 Kafka Operator部署"></a>3.1 Kafka Operator部署</h2><h3 id="3-1-1-Kafka-Operator部署"><a href="#3-1-1-Kafka-Operator部署" class="headerlink" title="3.1.1 Kafka Operator部署"></a>3.1.1 Kafka Operator部署</h3><h4 id="3-1-1-1-测试方法和步骤"><a href="#3-1-1-1-测试方法和步骤" class="headerlink" title="3.1.1.1 测试方法和步骤"></a>3.1.1.1 测试方法和步骤</h4><p><strong>测试准备</strong></p><p>步骤一：拉取需要镜像，并将它们导入内部镜像仓库</p><p>步骤二：下载部署脚本，并解压服务器上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget http://sha.stor.mbcloud.com/openshift-deploy-material/amq-streams-1.1.0-ocp-install-examples.zip</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">unzip amq-streams-1.1.0-ocp-install-examples.zip</span></span><br></pre></td></tr></table></figure><p>步骤三：将脚本中访问外网镜像仓库地址，改成内网镜像地址<br>将install&#x2F;cluster-operator&#x2F;050-Deployment-strimzi-cluster-operator.yaml中的registry.access.redhat.com更改为harbor.apps.it.mbcloud.com</p><p><strong>测试过程</strong></p><p>步骤一：创建项目myproject</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc new-project myproject</span><br></pre></td></tr></table></figure><p>步骤二：安装部署Operator</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc apply -f install/cluster-operator</span><br></pre></td></tr></table></figure><h4 id="3-1-1-2-测试结果"><a href="#3-1-1-2-测试结果" class="headerlink" title="3.1.1.2 测试结果"></a>3.1.1.2 <strong>测试结果</strong></h4><p>完成Kafka Operator部署<br><img src="https://upload-images.jianshu.io/upload_images/5793257-5b379016e3a0f845.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="kafka operator部署"></p><h3 id="3-1-2-Kafka集群创建"><a href="#3-1-2-Kafka集群创建" class="headerlink" title="3.1.2  Kafka集群创建"></a>3.1.2  Kafka集群创建</h3><h4 id="3-1-2-1-测试方法和步骤"><a href="#3-1-2-1-测试方法和步骤" class="headerlink" title="3.1.2.1 测试方法和步骤"></a>3.1.2.1 <strong>测试方法和步骤</strong></h4><p>步骤一：进入myproject项目</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc project myproject</span><br></pre></td></tr></table></figure><p>步骤二：创建Kafka集群my-cluster,三副本，存储无持久化</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ cat &lt;&lt; EOF | oc create -f -</span><br><span class="line">apiVersion: kafka.strimzi.io/v1alpha1</span><br><span class="line">kind: Kafka</span><br><span class="line">metadata:</span><br><span class="line">  name: my-cluster</span><br><span class="line">spec:</span><br><span class="line">  kafka:</span><br><span class="line">    version: 2.1.1</span><br><span class="line">    replicas: 3</span><br><span class="line">    listeners:</span><br><span class="line">      plain: &#123;&#125;</span><br><span class="line">      tls: &#123;&#125;</span><br><span class="line">      external:</span><br><span class="line">        type: route</span><br><span class="line">    config:</span><br><span class="line">      offsets.topic.replication.factor: 3</span><br><span class="line">      transaction.state.log.replication.factor: 3</span><br><span class="line">      transaction.state.log.min.isr: 2</span><br><span class="line">      log.message.format.version: &quot;2.1&quot;</span><br><span class="line">    storage:</span><br><span class="line">      type: ephemeral</span><br><span class="line">  zookeeper:</span><br><span class="line">    replicas: 3</span><br><span class="line">    storage:</span><br><span class="line">      type: ephemeral</span><br><span class="line">  entityOperator:</span><br><span class="line">    topicOperator: &#123;&#125;</span><br><span class="line">    userOperator: &#123;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>步骤三：查看部署结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ oc get pod</span><br><span class="line">NAME                                              READY     STATUS    RESTARTS   AGE</span><br><span class="line">my-cluster-entity-operator-78dc68cc86-9ghmw       3/3       Running   0          6d</span><br><span class="line">my-cluster-kafka-0                                2/2       Running   0          6d</span><br><span class="line">my-cluster-kafka-1                                2/2       Running   0          6d</span><br><span class="line">my-cluster-kafka-2                                2/2       Running   0          6d</span><br><span class="line">my-cluster-zookeeper-0                            2/2       Running   0          6d</span><br><span class="line">my-cluster-zookeeper-1                            2/2       Running   0          6d</span><br><span class="line">my-cluster-zookeeper-2                            2/2       Running   0          6d</span><br><span class="line">strimzi-cluster-operator-7f46bcb9c6-s8x5r         1/1       Running   0          6d</span><br></pre></td></tr></table></figure><h4 id="3-1-2-2-测试结果"><a href="#3-1-2-2-测试结果" class="headerlink" title="3.1.2.2 测试结果"></a>3.1.2.2 <strong>测试结果</strong></h4><p>部署Kafka集群my-cluster。3 zookeeper + 3 kafka</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-4110354afaaed944.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Kafka集群部署"></p><h3 id="3-1-3-Kafka监控部署"><a href="#3-1-3-Kafka监控部署" class="headerlink" title="3.1.3 Kafka监控部署"></a>3.1.3 Kafka监控部署</h3><h4 id="3-1-3-1-测试方法和步骤"><a href="#3-1-3-1-测试方法和步骤" class="headerlink" title="3.1.3.1 测试方法和步骤"></a>3.1.3.1 <strong>测试方法和步骤</strong></h4><p>步骤一：在kafka my-cluster的配置中添加metrics设置，</p><p>参考example&#x2F;metrics&#x2F;kafka-metrics.yaml文件中metrics的属性</p><p>步骤二：给prometheus添加查看myproject权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc policy add-role-to-user view system:serviceaccount:openshift-monitoring:prometheus-k8s -n myproject</span><br></pre></td></tr></table></figure><p>步骤三：在openshift-monitoring下新建servicemonitor</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ cat &lt;&lt; EOF | oc create -f -</span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: prometheus</span><br><span class="line">  name: my-cluster-kafka</span><br><span class="line">  namespace: openshift-monitoring</span><br><span class="line">spec:</span><br><span class="line">  endpoints:</span><br><span class="line">  - port: metrics</span><br><span class="line">  namespaceSelector:</span><br><span class="line">    matchNames:</span><br><span class="line">    - myproject</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      strimzi.io/name: my-cluster-kafka-bootstrap</span><br></pre></td></tr></table></figure><p>步骤四：在grafana中添加Kafka的监控Dashboard</p><p>Dashboard配置参考examples&#x2F;metrics&#x2F;grafana-dashboards&#x2F;strimzi-kafka.json</p><h4 id="3-1-3-2-测试结果"><a href="#3-1-3-2-测试结果" class="headerlink" title="3.1.3.2 测试结果"></a>3.1.3.2 <strong>测试结果</strong></h4><p>在grafana上查看Kafka的监控图表</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-ed22de273ffd7c4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="grafana kafka监控.png"></p><h2 id="3-2-Kafka功能测试"><a href="#3-2-Kafka功能测试" class="headerlink" title="3.2.Kafka功能测试"></a>3.2.Kafka功能测试</h2><h3 id="3-2-1-Kafka创建Topic"><a href="#3-2-1-Kafka创建Topic" class="headerlink" title="3.2.1 Kafka创建Topic"></a>3.2.1 <strong>Kafka创建Topic</strong></h3><h4 id="3-2-1-1-测试方法和步骤"><a href="#3-2-1-1-测试方法和步骤" class="headerlink" title="3.2.1.1 测试方法和步骤"></a>3.2.1.1 <strong>测试方法和步骤</strong></h4><p>步骤一：进入myproject项目</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc project myproject</span><br></pre></td></tr></table></figure><p>步骤二：创建Topic</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ cat &lt;&lt; EOF | oc create -f -</span><br><span class="line">apiVersion: kafka.strimzi.io/v1alpha1</span><br><span class="line">kind: KafkaTopic</span><br><span class="line">metadata:</span><br><span class="line">  name: my-topic</span><br><span class="line">  labels:</span><br><span class="line">    strimzi.io/cluster: my-cluster</span><br><span class="line">spec:</span><br><span class="line">  partitions: 3</span><br><span class="line">  replicas: 3</span><br><span class="line">  config:</span><br><span class="line">    retention.ms: 7200000</span><br><span class="line">    segment.bytes: 1073741824</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>步骤三：验证Topic状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec -c zookeeper  my-cluster-zookeeper-0 --  bin/kafka-topics.sh --zookeeper 127.0.0.1:21810 --topic my-topic --describe</span><br><span class="line">OpenJDK 64-Bit Server VM warning: If the number of processors is expected to increase from one, then you should configure the number of parallel GC threads appropriately using -XX:ParallelGCThreads=N</span><br><span class="line">Topic:my-topic  PartitionCount:3  ReplicationFactor:3  Configs:message.format.version=2.1-IV2</span><br><span class="line">Topic: my-topic  Partition: 0  Leader: 0  Replicas: 0,1,2  Isr: 0,1,2</span><br><span class="line">Topic: my-topic  Partition: 1  Leader: 1  Replicas: 1,2,0  Isr: 0,1,2</span><br><span class="line">Topic: my-topic  Partition: 2  Leader: 2  Replicas: 2,0,1  Isr: 0,1,2</span><br></pre></td></tr></table></figure><h4 id="3-2-1-2-测试结果"><a href="#3-2-1-2-测试结果" class="headerlink" title="3.2.1.2 测试结果"></a>3.2.1.2 <strong>测试结果</strong></h4><p>my-topic Topic创建成功。为3分区3复本。</p><h3 id="3-2-2-Openshift集群内部Kafka-producer与consumer测试"><a href="#3-2-2-Openshift集群内部Kafka-producer与consumer测试" class="headerlink" title="3.2.2 Openshift集群内部Kafka producer与consumer测试"></a>3.2.2 <strong>Openshift集群内部Kafka producer与consumer测试</strong></h3><h4 id="3-2-2-1-测试方法和步骤"><a href="#3-2-2-1-测试方法和步骤" class="headerlink" title="3.2.2.1 测试方法和步骤"></a>3.2.2.1 <strong>测试方法和步骤</strong></h4><p>步骤一：运行consumer端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc run kafka-consumer -ti --image=amq7/amq-streams-kafka:1.1.0-kafka-2.1.1 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic</span><br></pre></td></tr></table></figure><p>步骤二：运行producer端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc run kafka-producer -ti --image=amq7/amq-streams-kafka:1.1.0-kafka-2.1.1 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9092 --topic my-topic</span><br></pre></td></tr></table></figure><p>步骤三：在producer端发送数据，在consumer端显示发送的数据</p><h4 id="3-2-2-2-测试结果"><a href="#3-2-2-2-测试结果" class="headerlink" title="3.2.2.2 测试结果"></a>3.2.2.2 <strong>测试结果</strong></h4><p>通过my-topic Topic，producer端产生数据，consumer端消费数据</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-7d09a3a383dddd4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="生产压测.png"></p><h3 id="3-2-3-Openshift集群外部Kafka-producer与consumer测试（NodePort方案）"><a href="#3-2-3-Openshift集群外部Kafka-producer与consumer测试（NodePort方案）" class="headerlink" title="3.2.3 Openshift集群外部Kafka producer与consumer测试（NodePort方案）"></a>3.2.3 <strong>Openshift集群外部Kafka producer与consumer测试（NodePort方案）</strong></h3><h4 id="3-2-3-1-测试方法和步骤"><a href="#3-2-3-1-测试方法和步骤" class="headerlink" title="3.2.3.1 测试方法和步骤"></a>3.2.3.1 <strong>测试方法和步骤</strong></h4><p><strong>TLS设置为False</strong></p><p>步骤一：将Kafka的配置项中添加external为nodeport，并固定nodeport为32678</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">listeners:</span><br><span class="line">      external:</span><br><span class="line">        tls: false</span><br><span class="line">        type: nodeport</span><br><span class="line">        overrides:</span><br><span class="line">          bootstrap:</span><br><span class="line">            nodePort: 32678</span><br></pre></td></tr></table></figure><p>步骤二：集群外网环境创建Kafka Producer，连接Kafka</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from kafka import KafkaProducer</span><br><span class="line">producer = KafkaProducer(bootstrap_servers=[&#x27;99.248.81.70:32678&#x27;])</span><br><span class="line">producer.send(&#x27;my-topic&#x27;, &#x27;hello world&#x27;)</span><br><span class="line">producer.close()</span><br></pre></td></tr></table></figure><p>步骤三：集群外网环境新建Kafka Consumer，消费Kafka中my-topic主题的数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from kafka import KafkaConsumer</span><br><span class="line">consumer = KafkaConsumer(&#x27;my-topic&#x27;, bootstrap_servers=[&#x27;99.248.81.70:32678&#x27;])</span><br><span class="line">for msg in consumer:</span><br><span class="line">    print(msg)</span><br></pre></td></tr></table></figure><p><strong>TLS设置为True</strong></p><p>步骤一：将Kafka的配置项中添加external为nodeport，并固定nodeport为32678</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">listeners:</span><br><span class="line">      external:</span><br><span class="line">        type: nodeport</span><br><span class="line">        overrides:</span><br><span class="line">          bootstrap:</span><br><span class="line">            nodePort: 32678</span><br></pre></td></tr></table></figure><p>步骤二：获得secret&#x2F;my-cluster-clients-ca&#x2F;ca.key与secret&#x2F;my-cluster-clients-ca-cert&#x2F;ca.crt</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc extract secret/my-cluster-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</span><br><span class="line">$ oc extract secret/my-cluster-clients-ca --keys=ca.key --to=- &gt; ca.key</span><br></pre></td></tr></table></figure><p>步骤三：集群外网环境创建Kafka Producer，连接Kafka</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from kafka import KafkaProducer</span><br><span class="line">producer = KafkaProducer(bootstrap_servers=[&#x27;99.248.81.70:32678&#x27;], ssl_check_hostname=False, ssl_cafile=&#x27;ca.crt&#x27;, ssl_certfile=&#x27;ca.key&#x27;, security_protocol=&#x27;SSL&#x27;)</span><br><span class="line">producer.send(&#x27;my-topic&#x27;, &#x27;hello world&#x27;)</span><br><span class="line">producer.close()</span><br></pre></td></tr></table></figure><p>步骤三：集群外网环境新建Kafka Consumer，消费Kafka中my-topic主题的数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from kafka import KafkaConsumer</span><br><span class="line">consumer = KafkaConsumer(&#x27;my-topic&#x27;, bootstrap_servers=[&#x27;99.248.81.70:32678&#x27;], ssl_check_hostname=False, ssl_cafile=&#x27;ca.crt&#x27;, ssl_certfile=&#x27;ca.key&#x27;, security_protocol=&#x27;SSL&#x27;)</span><br><span class="line">for msg in consumer:</span><br><span class="line">    print(msg)</span><br></pre></td></tr></table></figure><h4 id="3-2-3-2-测试结果"><a href="#3-2-3-2-测试结果" class="headerlink" title="3.2.3.2 测试结果"></a>3.2.3.2 <strong>测试结果</strong></h4><p>与TLS设置为False一样</p><p>通过nodePort连接到Kafka集群，Producer将会往Topic my-topic发送一条“hello world”的消息，Consumer将会将消息输出到console端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Python27\python.exe D:/workspace/mb_autopf/utils/kafka-test/consumer.py</span><br><span class="line">ConsumerRecord(topic=u&#x27;my-topic&#x27;, partition=0, offset=333338, timestamp=1558511698388L, timestamp_type=0, key=None, value=&#x27;hello world&#x27;, checksum=-1265845277, serialized_key_size=-1, serialized_value_size=11)</span><br></pre></td></tr></table></figure><h3 id="3-2-4-Openshift集群外部Kafka-producer与consumer测试（Router方案）"><a href="#3-2-4-Openshift集群外部Kafka-producer与consumer测试（Router方案）" class="headerlink" title="3.2.4 Openshift集群外部Kafka producer与consumer测试（Router方案）"></a>3.2.4 <strong>Openshift集群外部Kafka producer与consumer测试（Router方案）</strong></h3><h4 id="3-2-4-1-测试方法和步骤"><a href="#3-2-4-1-测试方法和步骤" class="headerlink" title="3.2.4.1 测试方法和步骤"></a>3.2.4.1 <strong>测试方法和步骤</strong></h4><p>步骤一：将Kafka的配置项中添加external为nodeport，并固定nodeport为32678</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">listeners:</span><br><span class="line">      external:</span><br><span class="line">        type: route</span><br></pre></td></tr></table></figure><p>步骤二：获得secret&#x2F;my-cluster-clients-ca&#x2F;ca.key与secret&#x2F;my-cluster-clients-ca-cert&#x2F;ca.crt</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc extract secret/my-cluster-cluster-ca-cert --keys=ca.crt --to=- &gt; ca.crt</span><br><span class="line">$ oc extract secret/my-cluster-clients-ca --keys=ca.key --to=- &gt; ca.key</span><br></pre></td></tr></table></figure><p>步骤三：获取对外的router域名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get route my-cluster-kafka-bootstrap --template=&#123;&#123;range.status.ingress&#125;&#125;&#123;&#123;.host&#125;&#125;&#123;&#123;println&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line">my-cluster-kafka-bootstrap-myproject.apps.paas1.mbcloud.com</span><br></pre></td></tr></table></figure><p>步骤四：集群外网环境创建Kafka Producer，连接Kafka</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from kafka import KafkaProducer</span><br><span class="line">producer = KafkaProducer(bootstrap_servers=[&#x27;my-cluster-kafka-bootstrap-myproject.apps.paas1.mbcloud.com:443&#x27;], ssl_check_hostname=False, ssl_cafile=&#x27;ca.crt&#x27;, ssl_certfile=&#x27;ca.key&#x27;, security_protocol=&#x27;SSL&#x27;)</span><br><span class="line">producer.send(&#x27;my-topic&#x27;, &#x27;hello world&#x27;)</span><br><span class="line">producer.close()</span><br></pre></td></tr></table></figure><p>步骤三：集群外网环境新建Kafka Consumer，消费Kafka中my-topic主题的数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from kafka import KafkaConsumer</span><br><span class="line">consumer = KafkaConsumer(&#x27;my-topic&#x27;, bootstrap_servers=[&#x27;my-cluster-kafka-bootstrap-myproject.apps.paas1.mbcloud.com:443&#x27;], ssl_check_hostname=False, ssl_cafile=&#x27;ca.crt&#x27;, ssl_certfile=&#x27;ca.key&#x27;, security_protocol=&#x27;SSL&#x27;)</span><br><span class="line">for msg in consumer:</span><br><span class="line">    print(msg)</span><br></pre></td></tr></table></figure><h4 id="3-2-4-2-测试结果"><a href="#3-2-4-2-测试结果" class="headerlink" title="3.2.4.2 测试结果"></a>3.2.4.2 <strong>测试结果</strong></h4><p>通过Route域名连接到Kafka集群，Producer将会往Topic my-topic发送一条“hello world”的消息，Consumer将会将消息输出到console端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Python27\python.exe D:/workspace/mb_autopf/utils/kafka-test/consumer.py</span><br><span class="line">ConsumerRecord(topic=u&#x27;my-topic&#x27;, partition=0, offset=333340, timestamp=1558514729435L, timestamp_type=0, key=None, value=&#x27;hello world&#x27;, checksum=-459554926, serialized_key_size=-1, serialized_value_size=11)</span><br></pre></td></tr></table></figure><h2 id="3-3-Kafka性能测试"><a href="#3-3-Kafka性能测试" class="headerlink" title="3.3 Kafka性能测试"></a>3.3 <strong>Kafka性能测试</strong></h2><h3 id="3-3-1-测试工具：Kafka自带的压测脚本"><a href="#3-3-1-测试工具：Kafka自带的压测脚本" class="headerlink" title="3.3.1 测试工具：Kafka自带的压测脚本"></a>3.3.1 <strong>测试工具：Kafka自带的压测脚本</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh</span><br><span class="line">bin/kafka-consumer-perf-test.sh</span><br></pre></td></tr></table></figure><h4 id="3-3-1-1-参数说明"><a href="#3-3-1-1-参数说明" class="headerlink" title="3.3.1.1 参数说明:"></a>3.3.1.1 <strong>参数说明:</strong></h4><p><strong>bin&#x2F;kafka-producer-perf-test.sh</strong><br>–num-records：发送的总的消息数  –record-size：消息大小<br>–throughput：最大消息吞吐限制<br>–producer-props：kafka集群参数<br>acks：1默认值副本收到数据得到确认后发送下一条数据，0可靠性最低无需确认副本是否收到数据，-1可靠性最高等待副本所有的follower都确认收到数据后再发送下一条数据<br>retries：2<br>linger.ms:基于时间的batching策略1<br>batch.size:基于大小的batching策略100000<br>compression.type:压缩类型,速度排序lz4 &#x3D; snappy &lt; gzip</p><p>以下条件之一达到了,认为一个batch是完毕的</p><p>1. batch.size达到<br>2. linger.ms达到<br>3. 同一个broker的其他batch已经完毕<br>4. flush()和close()被调用</p><p><strong>bin&#x2F;kafka-consumer-perf-test.sh</strong><br>–zookeeper：zookeeper连接信息<br>–broker-list：kafka连接信息<br>–topic：topic名称<br>–fetch-size：每次fetch的数据大小，1048576为1M<br>–messages：总共要消费的消息数</p><h4 id="3-3-1-2-测试命令"><a href="#3-3-1-2-测试命令" class="headerlink" title="3.3.1.2 测试命令"></a>3.3.1.2 <strong>测试命令</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic my-topic --num-records 100000000 --record-size 100 --throughput 5000000 --producer-props bootstrap.servers=my-cluster-kafka-bootstrap.myproject.svc:9092 retries=2 batch.size=100000</span><br><span class="line">bin/kafka-consumer-perf-test.sh --broker-list my-cluster-kafka-bootstrap.myproject.svc:9092 --topic my-topic --messages 100000000</span><br></pre></td></tr></table></figure><h3 id="3-3-2-Kafka生产消息压力测试-集群内部"><a href="#3-3-2-Kafka生产消息压力测试-集群内部" class="headerlink" title="3.3.2 Kafka生产消息压力测试[集群内部]"></a>3.3.2 <strong>Kafka<strong><strong>生产</strong></strong>消息压力测试[集群内部]</strong></h3><h4 id="3-3-2-1-测试方法和步骤"><a href="#3-3-2-1-测试方法和步骤" class="headerlink" title="3.3.2.1 测试方法和步骤"></a>3.3.2.1 <strong>测试方法和步骤</strong></h4><p>步骤一：创建4种类型Topic：1副本1分区、1副本3分区、3副本1分区、3副本3分区</p><p>步骤二：运行kafka写入压测命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic my-topic --num-records 10000000 --record-size 100 --throughput 5000000 --producer-props bootstrap.servers=my-cluster-kafka-bootstrap.myproject.svc:9092 linger.ms=1</span><br></pre></td></tr></table></figure><h4 id="3-3-2-2-测试结果"><a href="#3-3-2-2-测试结果" class="headerlink" title="3.3.2.2 测试结果"></a>3.3.2.2 <strong>测试结果</strong></h4><p>使用kafka-producer-perf-test.sh测试Kafka消息写入性能：</p><table><thead><tr><th>副本数</th><th>分区数</th><th>线程数</th><th>消息&#x2F;s</th><th>流量MB&#x2F;s</th><th>延时99th ms</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>1514692</td><td>144.45</td><td>2</td></tr><tr><td>1</td><td>3</td><td>1</td><td>1462009</td><td>139.43</td><td>7</td></tr><tr><td>3</td><td>1</td><td>1</td><td>987069</td><td>94.13</td><td>9</td></tr><tr><td>3</td><td>3</td><td>1</td><td>918020</td><td>87.55</td><td>23</td></tr></tbody></table><h3 id="3-3-3-Kafka-消费消息压力测试-集群内部"><a href="#3-3-3-Kafka-消费消息压力测试-集群内部" class="headerlink" title="3.3.3 Kafka 消费消息压力测试[集群内部]"></a>3.3.3 <strong>Kafka 消费消息压力测试[集群内部]</strong></h3><h4 id="3-3-3-1-测试方法和步骤"><a href="#3-3-3-1-测试方法和步骤" class="headerlink" title="3.3.3.1 测试方法和步骤"></a>3.3.3.1 <strong>测试方法和步骤</strong></h4><p>步骤一：使用3.3.2中创建的消息进行消费</p><p>步骤二：运行kafka消费压测命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list my-cluster-kafka-bootstrap.myproject.svc:9092 --topic my-topic --fetch-size 1048576 --messages 100000000 --threads 1</span><br></pre></td></tr></table></figure><h4 id="3-3-3-2-测试结果"><a href="#3-3-3-2-测试结果" class="headerlink" title="3.3.3.2 测试结果"></a>3.3.3.2 <strong>测试结果</strong></h4><p>使用kafka-consumer-perf-test.sh测试Kafka消息消费性能：</p><table><thead><tr><th>副本数</th><th>分区数</th><th>线程数</th><th>消息&#x2F;s</th><th>流量MB&#x2F;s</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>800262.4861</td><td>76.3190</td></tr><tr><td>1</td><td>3</td><td>1</td><td>1000100.0100</td><td>95.3770</td></tr><tr><td>3</td><td>1</td><td>1</td><td>3037667.0717</td><td>289.6945</td></tr><tr><td>3</td><td>3</td><td>1</td><td>796854.8513</td><td>75.9940</td></tr><tr><td>1</td><td>1</td><td>3</td><td>800409.8098</td><td>76.3330</td></tr><tr><td>1</td><td>3</td><td>3</td><td>974896.4173</td><td>92.9734</td></tr><tr><td>3</td><td>1</td><td>3</td><td>3033060.3579</td><td>289.2552</td></tr><tr><td>3</td><td>3</td><td>3</td><td>795820.1480</td><td>75.8953</td></tr></tbody></table><h3 id="3-3-4-Kafka生产消息压力测试-集群外部NodePort方案"><a href="#3-3-4-Kafka生产消息压力测试-集群外部NodePort方案" class="headerlink" title="3.3.4 Kafka生产消息压力测试[集群外部NodePort方案]"></a>3.3.4 <strong>Kafka<strong><strong>生产</strong></strong>消息压力测试[集群外部NodePort方案]</strong></h3><h4 id="3-3-4-1-测试方法和步骤"><a href="#3-3-4-1-测试方法和步骤" class="headerlink" title="3.3.4.1 测试方法和步骤"></a>3.3.4.1 <strong>测试方法和步骤</strong></h4><p>步骤一：创建4种类型Topic：1副本1分区、1副本3分区、3副本1分区、3副本3分区</p><p>步骤二：运行kafka写入压测命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh --topic my-topic --num-records 10000000 --record-size 100 --throughput 5000000 --producer-props bootstrap.servers=99.248.82.11:32678 linger.ms=1</span><br></pre></td></tr></table></figure><h4 id="3-3-4-2-测试结果"><a href="#3-3-4-2-测试结果" class="headerlink" title="3.3.4.2 测试结果"></a>3.3.4.2 <strong>测试结果</strong></h4><p>使用kafka-producer-perf-test.sh测试Kafka消息写入性能：</p><table><thead><tr><th>副本数</th><th>分区数</th><th>线程数</th><th>消息&#x2F;s</th><th>流量MB&#x2F;s</th><th>延时99th ms</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>884486</td><td>84.35</td><td>34</td></tr><tr><td>1</td><td>3</td><td>1</td><td>880669</td><td>83.99</td><td>73</td></tr><tr><td>3</td><td>1</td><td>1</td><td>822842</td><td>78.47</td><td>258</td></tr><tr><td>3</td><td>3</td><td>1</td><td>607053</td><td>57.89</td><td>193</td></tr></tbody></table><h3 id="3-3-5-Kafka-消费消息压力测试-集群外部NodePort方案"><a href="#3-3-5-Kafka-消费消息压力测试-集群外部NodePort方案" class="headerlink" title="3.3.5 Kafka 消费消息压力测试[集群外部NodePort方案]"></a>3.3.5 <strong>Kafka 消费消息压力测试[集群外部NodePort方案]</strong></h3><h4 id="3-3-5-1-测试方法和步骤"><a href="#3-3-5-1-测试方法和步骤" class="headerlink" title="3.3.5.1 测试方法和步骤"></a>3.3.5.1 <strong>测试方法和步骤</strong></h4><p>步骤一：使用3.3.2中创建的消息进行消费</p><p>步骤二：运行kafka消费压测命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --broker-list 99.248.82.11:32678 --topic my-topic --fetch-size 1048576 --messages 100000000 --threads 1</span><br></pre></td></tr></table></figure><h4 id="3-3-5-2-测试结果"><a href="#3-3-5-2-测试结果" class="headerlink" title="3.3.5.2 测试结果"></a>3.3.5.2 <strong>测试结果</strong></h4><table><thead><tr><th>副本数</th><th>分区数</th><th>线程数</th><th>消息&#x2F;s</th><th>流量MB&#x2F;s</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>387672.0295</td><td>36.9713</td></tr><tr><td>1</td><td>3</td><td>1</td><td>389226.2183</td><td>37.1195</td></tr><tr><td>3</td><td>1</td><td>1</td><td>564939.8339</td><td>53.8769</td></tr><tr><td>3</td><td>3</td><td>1</td><td>432991.3929</td><td>41.2932</td></tr><tr><td>1</td><td>1</td><td>3</td><td>386488.3667</td><td>36.8584</td></tr><tr><td>1</td><td>3</td><td>3</td><td>389468.7646</td><td>37.1426</td></tr><tr><td>3</td><td>1</td><td>3</td><td>563920.3744</td><td>53.7796</td></tr><tr><td>3</td><td>3</td><td>3</td><td>433067.1543</td><td>41.3004</td></tr></tbody></table><h2 id="3-4-附录"><a href="#3-4-附录" class="headerlink" title="3.4 附录"></a>3.4 附录</h2><h3 id="3-4-1-镜像列表"><a href="#3-4-1-镜像列表" class="headerlink" title="3.4.1 镜像列表"></a>3.4.1 镜像列表</h3><p>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-cluster-operator:1.1.0<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-zookeeper:1.1.0-kafka-2.1.1<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-kafka:1.1.0-kafka-2.1.1<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-kafka-connect:1.1.0-kafka-2.1.1<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-kafka-connect-s2i:1.1.0-kafka-2.1.1<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-kafka-mirror-maker:1.1.0-kafka-2.1.1<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-topic-operator:1.1.0<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-user-operator:1.1.0<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-kafka-init:1.1.0<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-zookeeper-stunnel:1.1.0<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-kafka-stunnel:1.1.0<br>harbor.apps.it.mbcloud.com&#x2F;amq7&#x2F;amq-streams-entity-operator-stunnel:1.1.0</p><h3 id="3-4-2-部署脚本"><a href="#3-4-2-部署脚本" class="headerlink" title="3.4.2 部署脚本"></a>3.4.2 部署脚本</h3><p><a href="https://github.com/strimzi/strimzi-kafka-operator/releases">strimzi-kafka-operator</a></p><p>百度云盘：&#x2F;招银云创&#x2F;openshift&#x2F;redhat-kafka&#x2F;</p><p>while true; do a&#x3D;$(date); echo $a; echo $a &gt; ~&#x2F;a.txt; .&#x2F;kafka-console-producer.sh –broker-list 99.248.82.11:31761,99.248.82.12:31304,99.248.82.21:31271 –topic my_topic &lt; ~&#x2F;a.txt; done</p><p>.&#x2F;kafka-console-consumer.sh –bootstrap-server 99.248.82.11:31761,99.248.82.12:31304,99.248.82.21:31271 –topic my_topic</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Kubernetes中易理解错误的问题汇总</title>
      <link href="/openshift/OpenShift-Kubernetes%E4%B8%AD%E6%98%93%E7%90%86%E8%A7%A3%E9%94%99%E8%AF%AF%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
      <url>/openshift/OpenShift-Kubernetes%E4%B8%AD%E6%98%93%E7%90%86%E8%A7%A3%E9%94%99%E8%AF%AF%E7%9A%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-5f7ab0c0543096c5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift/Kubernetes中易理解错误的问题汇总"></p><p>###1. readiness健康检查一直失败，Pod会不会重启？</p><p> 不会，一直处于Running状态，但Not Ready。</p><h3 id="2-Pod重启时，Pod的容器是重启，还是重新创建？"><a href="#2-Pod重启时，Pod的容器是重启，还是重新创建？" class="headerlink" title="2. Pod重启时，Pod的容器是重启，还是重新创建？"></a>2. Pod重启时，Pod的容器是重启，还是重新创建？</h3><p> POD容器不动，应用容器是重新创建。POD IP保持不变，但应用容器中的临时文件会丢失。</p><p>###3. 如果更改Deployment的配置后，马上将配置恢复回去，应用Pod是否会触发重新部署？<br>不会，恢复回去后不会创建新的RS。</p><h3 id="4-master-cluster-hostname与master-cluster-public-hostname的区别"><a href="#4-master-cluster-hostname与master-cluster-public-hostname的区别" class="headerlink" title="4. master_cluster_hostname与master_cluster_public_hostname的区别"></a>4. master_cluster_hostname与master_cluster_public_hostname的区别</h3><p>master_cluster_hostname是集群内部组件使用的域名<br>master_cluster_public_hostname是集群外部使用的域名<br>###5. 对于高可用集群中，3个master节点是完全相同的吗？<code>openshift</code></p><p>不是，虽然它们的运行态是完全一致的，但是在OpenShift的运维脚本中是有区分的，如集群扩容时。有一台是主master（inventory中的第一台），它会单独保存集群的证书及一些配置。</p><p>###6. 对于statefulset类型的工作负载，只能逐个启动吗？</p><p>并不是，statefulset类型的workload默认确实是逐个启动，但是可以通过更改它的启动策略来实现并行启动。<br>spec.podManagementPolicy值默认为OrderedReady，如果设置为Parallel，将会并行启动和删除Pod。</p><p>###7. statefulset类型的工作负载的多个副本，能共用一块共享存储吗？</p><p>当然可以，在statefulset的编排中不使用volumeTemplate，而是与deployment资源一样设置共享存储就可以了。</p><p>###8. 如果应用存活检查&#x2F;就绪检查未通过的情况下，是否能顺利地进行应用更新？</p><p>不一定，这个取决于应用的升级策略：滚动升级，maxSurge与maxUnavailable的配置。如果应用是一个副本，maxSurge与maxUnavailable的值为默认值25%，将无法关闭旧版本应用。</p><ul><li>maxSurge：升级过程中最多可以比原先设置多出的POD数量。可以是具体个数，也可以百分比（进一法取整）</li><li>maxUnavailable：升级过程中最多有多少个POD处于无法提供服务的状态。可以是具体个数，也可以百分比（去尾法取整）</li></ul><p>###9. 如果应用做了多副本，而且部署在不同的节点上，即使宿主机发生宕机，对业务也不会有影响，正确吗？</p><p>这个结论并不正确。因为作为内部负载均衡的Service并不能马上感知应用的问题，所以不会马上主动剔除故障应用，同时Service一般使用（ocp）iptables作为代理方式，它没有使用失败则使用别的节点的机制，所以在一段时间内请求会被发送到问题节点。</p><blockquote><p>默认情况如下：</p><ol><li>40s检测后，流量会从负载均衡中剔除。</li><li>5分钟之内完成重启，podname不变，pod的ip会更新。</li><li>如果5分钟后node节点仍然没有恢复，集群会将问题pod重新调度。</li></ol></blockquote><p>###10. NFS作为持久化卷挂载在应用中，如果NFS服务故障后恢复，容器是否会自动重新挂载存储服务？<br>是的。</p><h3 id="11-在Docker的服务器上，关闭-x2F-重启iptables，上面的容器网络依然正常吗？"><a href="#11-在Docker的服务器上，关闭-x2F-重启iptables，上面的容器网络依然正常吗？" class="headerlink" title="11. 在Docker的服务器上，关闭&#x2F;重启iptables，上面的容器网络依然正常吗？"></a>11. 在Docker的服务器上，关闭&#x2F;重启iptables，上面的容器网络依然正常吗？</h3><p>异常。docker安装完成后，会自动接管iptables或者firewalld，在docker run的时候，会自动往iptables里加入规则；所以当iptables重启后会丢失，只有再重启docker就好了的原因。<br>在使用Systemd 时， firewalld 会在 Docker 之前启动，但是如果你在 Docker 启动之后再启动或者重启 firewalld ，就需要重启 Docker 进程了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Kubernetes集群-Calico-BGP管理工具calicoctl配置</title>
      <link href="/openshift/OpenShift-Kubernetes%E9%9B%86%E7%BE%A4-Calico-BGP%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7calicoctl%E9%85%8D%E7%BD%AE/"/>
      <url>/openshift/OpenShift-Kubernetes%E9%9B%86%E7%BE%A4-Calico-BGP%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7calicoctl%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-bdb0917cbfac1caf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Calico OpenShift"></p><p>calico 是容器网络的一种解决方案，也是当前最流行的方案之一。它完全利用路由规则实现动态组网，通过BGP协议通告路由。Calico BGP没有像ovs那样需要封包解包，所以它的网络性能更好。<br>管理calico网络免不了使用calicoctl工具，本篇介绍如何在OpenShift&#x2F;Kubernetes环境下，配置calicoctl来管理集群网络。</p><p><code>calico元数据支持两种存储类：etcd与kubernetes</code></p><ol><li>安装calicoctl<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -O -L https://github.com/projectcalico/calicoctl/releases/download/v3.10.0/calicoctl</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> a+x calicoctl</span></span><br></pre></td></tr></table></figure></li><li>确认Calico部署时使用的元数据存储类型，查看calico-config<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc describe cm calico-config -n kube-system | grep datastore_type</span></span><br></pre></td></tr></table></figure>可以为<code>kubernetes</code>、<code>etcdv3</code>。默认为<code>etcdv3</code>。<br>设置为<code>kubernetes</code>时表示直接使用k8s api存取数据库服务；</li></ol><h3 id="使用kubernetes类型"><a href="#使用kubernetes类型" class="headerlink" title="使用kubernetes类型"></a>使用kubernetes类型</h3><p>创建calicoctl访问的配置文件calicoctl.conf</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /etc/calico</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt; /etc/calico/calicoctl.cfg</span></span></span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: CalicoAPIConfig</span><br><span class="line">metadata:</span><br><span class="line">spec:</span><br><span class="line">  datastoreType: &quot;kubernetes&quot;</span><br><span class="line">  kubeconfig: &quot;/root/.kube/config&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="使用etcdv3类型"><a href="#使用etcdv3类型" class="headerlink" title="使用etcdv3类型"></a>使用etcdv3类型</h3><ol start="2"><li>创建calicoctl访问的配置文件calicoctl.conf</li></ol><p><code>for openshift</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /etc/calico</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt; /etc/calico/calicoctl.cfg</span></span></span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: CalicoAPIConfig</span><br><span class="line">metadata:</span><br><span class="line">spec:</span><br><span class="line">  datastoreType: &quot;etcdv3&quot;</span><br><span class="line">  etcdEndpoints: https://master1.example.com:2379</span><br><span class="line">  etcdKeyFile: /etc/cni/net.d/calico-tls/etcd-key</span><br><span class="line">  etcdCertFile: /etc/cni/net.d/calico-tls/etcd-cert</span><br><span class="line">  etcdCACertFile: /etc/cni/net.d/calico-tls/etcd-ca</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p><code>for kubernetes</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /etc/calico</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt; /etc/calico/calicoctl.cfg</span></span></span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: CalicoAPIConfig</span><br><span class="line">metadata:</span><br><span class="line">spec:</span><br><span class="line">  datastoreType: &quot;etcdv3&quot;</span><br><span class="line">  etcdEndpoints: https://master1.example.com:2379</span><br><span class="line">  etcdKeyFile: /etc/kubernetes/pki/etcd/server.key</span><br><span class="line">  etcdCertFile: /etc/kubernetes/pki/etcd/server.crt</span><br><span class="line">  etcdCACertFile: /etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ol start="3"><li>执行calicoctl获取workloadendpoints<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./calicoctl get workloadendpoints</span></span><br><span class="line">WORKLOAD                   NODE                        NETWORKS           INTERFACE         </span><br><span class="line">docker-registry-3-fr8zn    infra1.example.com    10.129.200.29/32   cali046d7771a9f   </span><br><span class="line">registry-console-3-bxbck   master1.example.com   10.131.9.210/32    cali6d8bb449db0</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./calicoctl get workloadendpoints -a <span class="comment"># 查看所有namespace下的workloadendpoints</span></span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Master1彻底挂了，如何恢复？</title>
      <link href="/openshift/OpenShift-Master1%E5%BD%BB%E5%BA%95%E6%8C%82%E4%BA%86,%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/"/>
      <url>/openshift/OpenShift-Master1%E5%BD%BB%E5%BA%95%E6%8C%82%E4%BA%86,%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-ee817b383313a625.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="集群恢复"></p><p>小强维护着一套生成的OpenShift集群，突然有一天集群的master1节点出现异常，自动关机了。他尝试了多次，都无法开机，怎么办？<br>他需要赶快恢复master1节点，来满足集群的高可用性。</p><p>原来的masters在ansible&#x2F;hosts中的顺序如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[masters]</span><br><span class="line">master1  ## 重要主节点，安装完后单独保存/etc/etcd/ca中的证书</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master1</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line">master1</span><br><span class="line">master2</span><br><span class="line">master3</span><br></pre></td></tr></table></figure><p>恢复过程如下：</p><ol><li>新建一台 master1节点，hostname 与 IP 都和原 master1 节点一致</li><li>在master2上恢复master主节点的证书、ca.serial.txt及openshift软件。</li><li>通过新增 master 的方式将这个节点重新加回集群</li><li>通过新增 etcd 的方法，恢复了这台 master 节点 etcd 的状况</li></ol><p>以下是恢复的具体步骤。</p><h2 id="一、初始化Master节点"><a href="#一、初始化Master节点" class="headerlink" title="一、初始化Master节点"></a>一、初始化Master节点</h2><ul><li>与部署机互信</li><li>开启selinux</li><li>关闭firewalld</li><li>DNS配置或者&#x2F;etc&#x2F;hosts</li><li>HostName设置</li><li>NTP</li><li>ETCD盘与docker盘，如果需要提前准备的话</li><li>Yum源设置</li></ul><h2 id="二、删除问题Master节点"><a href="#二、删除问题Master节点" class="headerlink" title="二、删除问题Master节点"></a>二、删除问题Master节点</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc delete node master1</span><br></pre></td></tr></table></figure><h2 id="三、在master2节点上准备好相关证书及软件"><a href="#三、在master2节点上准备好相关证书及软件" class="headerlink" title="三、在master2节点上准备好相关证书及软件"></a>三、在master2节点上准备好相关证书及软件</h2><ol><li>恢复master主节点的证书<br>在&#x2F;etc&#x2F;ansible&#x2F;hosts的[masters]&#x2F;[etcd]&#x2F;[nodes]组中注释掉master1节点，后执行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible-playbook playbooks/openshift-etcd/redeploy-ca.yml</span><br></pre></td></tr></table></figure></li><li>恢复ca.serial.txt文件<br>在备份的配置中将ca.serial.txt文件拷贝到&#x2F;etc&#x2F;origin&#x2F;master&#x2F;ca.serial.txt<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scp ca.serial.txt master2:/etc/origin/master/ca.serial.txt</span><br></pre></td></tr></table></figure></li><li>安装openshift命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install openshift</span><br></pre></td></tr></table></figure>如果显示找不到该包，请查看&#x2F;etc&#x2F;yum.conf的配置，将openshift包从exclude中删除</li></ol><h2 id="四、恢复Master节点"><a href="#四、恢复Master节点" class="headerlink" title="四、恢复Master节点"></a>四、恢复Master节点</h2><ol><li>&#x2F;etc&#x2F;ansible&#x2F;hosts中将需要恢复的节点从[masters]&#x2F;[etcd]&#x2F;[nodes]组移到[new_masters]、[new_nodes]组，并将三个组添加到[OSEv3:children]<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">etcd</span><br><span class="line">nodes</span><br><span class="line">new_masters</span><br><span class="line">new_etcd</span><br><span class="line">new_nodes</span><br><span class="line"></span><br><span class="line">[masters]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[new_masters]</span><br><span class="line">master1</span><br><span class="line"></span><br><span class="line">[new_etcd]</span><br><span class="line">master1</span><br><span class="line"></span><br><span class="line">[new_nodes]</span><br><span class="line">master1</span><br></pre></td></tr></table></figure></li><li>执行master节点的scale_up.yaml<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-master/scaleup.yaml</span><br></pre></td></tr></table></figure></li><li>检查master1的恢复状态<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get node </span><br><span class="line">$ oc get pod -n kube-system</span><br></pre></td></tr></table></figure></li><li>将master1节点从[new_masters]&#x2F;[new_nodes]中移到[masters]&#x2F;[nodes]中，并将它放到各个组的最后面。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">etcd</span><br><span class="line">nodes</span><br><span class="line">new_etcd</span><br><span class="line"></span><br><span class="line">[masters]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line">master1</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line">master1</span><br><span class="line"></span><br><span class="line">[new_etcd]</span><br><span class="line">master1</span><br></pre></td></tr></table></figure></li></ol><h2 id="五、恢复ETCD服务"><a href="#五、恢复ETCD服务" class="headerlink" title="五、恢复ETCD服务"></a>五、恢复ETCD服务</h2><ol><li>在正常的master节点，如master2上移除有问题的etcd节点<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl2 member list</span><br><span class="line">23868989e8af989: name=master1 isLeader=false</span><br><span class="line">45f23429e8af943: name=master2 isLeader=false</span><br><span class="line">5323823fadaf989: name=master3 isLeader=true</span><br><span class="line">$ etcdctl2 member remove 23868989e8af989</span><br></pre></td></tr></table></figure></li><li>执行etcd的扩容操作etcd scaleup.yaml<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-etcd/scaleup.yaml</span><br></pre></td></tr></table></figure></li><li>待执行完成后，检查etcd pod状态<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get pod -n kube-system</span><br><span class="line">$ etcdctl2 cluster-health</span><br></pre></td></tr></table></figure></li><li>将master1节点从[new_etcd]组移到[etcd]组的最后面。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">etcd</span><br><span class="line">nodes</span><br><span class="line">[masters]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master2</span><br><span class="line">master3</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line">master2</span><br><span class="line">master3</span><br></pre></td></tr></table></figure></li><li>恢复master1节点的etcdctl命令<br>将&#x2F;etc&#x2F;profile.d&#x2F;etcdctl.sh文件拷贝到master1节点的&#x2F;etc&#x2F;profile.d&#x2F;etcdctl.sh，并执行source &#x2F;etc&#x2F;profile.d&#x2F;etcdctl.sh</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>多Master节点的集群具有高可用性，任一节点出现问题都不会影响到集群的服务，但是我们必须尽快恢复它，以免再出现一台主节点出现异常，这将会导致集群故障。</li><li>多台Master节点中，第一台Master节点是特殊的节点，有些证书、配置文件只放在这台节点上，但是扩容时会需要用到。（详情可看openshift-ansible中的代码，很多证书都是从openshift_ca_host主机复制，而openshift_ca_host&#x3D;&lt;!–swig￼13–&gt;）。</li><li>在完成恢复后，需要及时恢复ansible&#x2F;hosts中的内容，将恢复的节点加到对应组的后面，方便下次主机的扩容与维护。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.jianshu.com/p/887d480882a7">OpenShift集群故障恢复–只剩一个master节点可用，没有备份</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Prometheus使用集群外部Prometheus级联的方法实现多集群统一监控告警</title>
      <link href="/openshift/OpenShift-Prometheus%E4%BD%BF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%A4%96%E9%83%A8Prometheus%E7%BA%A7%E8%81%94%E7%9A%84%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%BB%9F%E4%B8%80%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/"/>
      <url>/openshift/OpenShift-Prometheus%E4%BD%BF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%A4%96%E9%83%A8Prometheus%E7%BA%A7%E8%81%94%E7%9A%84%E6%96%B9%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%BB%9F%E4%B8%80%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-189a78982012ffd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift 和 Prometheus"></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>大家知道OpenShfit官方通过Prometheus Operator可以快速构建高可用的监控告警平台，它不仅能够收集集群本身的监控指标，还可以通过ServiceMonitor扩展以监控应用自身的指标，实现单集群内部的统一监控。但是生产实践中，我们并不会只采用一个OpenShift部署应用，还会部署非容器应用，在非容器环境下也可能会部署Prometheus来监控相关服务（特别是现在Prometheus已经成为了监控的一个标配），甚至有可能会在不同的网络区部署多个集群，由于不同网络的隔离特性显然一组Prometheus是无法满足所有平台及应用的监控的。这就使得生产中会有很多套Prometheus集群需要管理与维护，查看监控指标也很分散，也就让我们想到必须采用一种办法能够将各处的指标统一收集，实现多集群多Prometheus服务的统一监控。<br>目前实现这种要求的方法主要有两个，一个是通过Prometheus联邦 Federate，另一个是通过Thanos。今天主要介绍集群外部如何使用Prometheus联邦机制收集OpenShift内部Prometheus服务的监控指标。</p><h1 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h1><p>实现其实很简单，主要就是配置外部Prometheus的prometheus.yml文件来实现Prometheus联邦。具体配置如下，后面有相关重要配置的详细说明</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  evaluation_interval: 15s</span><br><span class="line">  scrape_interval: 15s</span><br><span class="line">  scrape_timeout: 10s</span><br><span class="line"></span><br><span class="line">- job_name: prometheus_test</span><br><span class="line">  honor_labels: true</span><br><span class="line">  metrics_path: &#x27;/federate&#x27;</span><br><span class="line">  params:</span><br><span class="line">    &#x27;match[]&#x27;:</span><br><span class="line">      - &#x27;&#123;__name__=~&quot;.+&quot;&#125;&#x27;</span><br><span class="line">  scheme: https</span><br><span class="line">  tls_config:</span><br><span class="line">    insecure_skip_verify: true</span><br><span class="line">#basic_auth:</span><br><span class="line">#  username: &#x27;internal&#x27;</span><br><span class="line">#  password: &lt;PASSWORD&gt;</span><br><span class="line">  bearer_token: &lt;TOKEN&gt;</span><br><span class="line">  static_configs:</span><br><span class="line">  - targets: [&#x27;prometheus-k8s-openshift-monitoring.app.group.domain:443&#x27;]</span><br><span class="line">    labels:</span><br><span class="line">      env: test</span><br></pre></td></tr></table></figure><ul><li><code>&#39;match[]&#39;= &#39;&#123;__name__=~&quot;.+&quot;&#125;&#39;</code>表示所有的指标都收集，如果只需要收集部分的话，可以通过类似<code>- &#39;&#123;job=&quot;node-exporter&quot;&#125;&#39;</code>格式筛选<code>Label</code>指定。</li><li>除了使用bearer_token的方式认证，也可以使用basic_auth的方式认证，openshift默认安装的Prometheus支持这两种方式认证，basic_auth的用户名：<code>internal</code>与密码在secret grafana-datasources中，具体获取方式如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#用户名为 internal</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#获取密码脚本</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get secret grafana-datasources -o yaml -n openshift-monitoring | grep prometheus | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | <span class="built_in">base64</span> -d | grep basicAuthPassword | awk -F\&quot; <span class="string">&#x27;&#123;print $4&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure></li><li><TOKEN>通过创建一个serviceaccount来获取它的Token<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: prom-fed</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: prom-fed</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: prom-fed</span><br><span class="line">  namespace: kube-system</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep prom-fed | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>)</span></span><br></pre></td></tr></table></figure><img src="https://upload-images.jianshu.io/upload_images/5793257-fdeb9e488adf495f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="监控Targets"></li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-531331f15134b855.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="联邦Prometheus上展示监控指标"></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Prometheus添加Alert-Rules</title>
      <link href="/openshift/OpenShift-Prometheus%E6%B7%BB%E5%8A%A0Alert-Rules/"/>
      <url>/openshift/OpenShift-Prometheus%E6%B7%BB%E5%8A%A0Alert-Rules/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-31f5b940882dd3e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Prometheus和Openshift"></p><ol><li><p>prometheus.yml配置中绑定alertmanager服务</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - scheme: http</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      - &quot;localhost:9093&quot;</span><br></pre></td></tr></table></figure></li><li><p>prometheus.rules设置prometheus告警规则</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">rules:</span><br><span class="line">- alert: TooManyPods</span><br><span class="line">  expr: kuberlet_running_pod_count &gt; 10</span><br><span class="line">  for: 2m</span><br><span class="line">  labels:</span><br><span class="line">    team: node</span><br><span class="line">  annotations:</span><br><span class="line">    summary: &quot;&#123;&#123;$labels.instance&#125;&#125;: has &#123;&#123;$value&#125;&#125; pods&quot;</span><br><span class="line">    description: &quot;&#123;&#123;$labels.instance&#125;&#125; be cateful&quot;</span><br></pre></td></tr></table></figure><p>规则：<code>kuberlet_running_pod_count</code>指标持续2分钟超过10，则发出告警。</p></li><li><p>AlertManager中设置告警接收器alertmanager.yml</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  smtp_smarthost: &#x27;mail.xx.com:25&#x27;</span><br><span class="line">  smtp_from: &#x27;service@xx.com&#x27;</span><br><span class="line">  smtp_auth_username: &#x27;service@xx.com&#x27;</span><br><span class="line">  smtp_auth_password: &#x27;password&#x27;</span><br><span class="line">  smtp_require_tls: false</span><br><span class="line">route:</span><br><span class="line">  group_by: [&#x27;alertname&#x27;]</span><br><span class="line">  receiver: alert-email</span><br><span class="line">receivers:</span><br><span class="line">- name: alert-email</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;pan@xx.com&#x27;</span><br><span class="line">    send_resolved: true</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Router通过分片实现不同环境网络南北流量隔离</title>
      <link href="/openshift/OpenShift-Router%E9%80%9A%E8%BF%87%E5%88%86%E7%89%87%E5%AE%9E%E7%8E%B0%E4%B8%8D%E5%90%8C%E7%8E%AF%E5%A2%83%E7%BD%91%E7%BB%9C%E5%8D%97%E5%8C%97%E6%B5%81%E9%87%8F%E9%9A%94%E7%A6%BB/"/>
      <url>/openshift/OpenShift-Router%E9%80%9A%E8%BF%87%E5%88%86%E7%89%87%E5%AE%9E%E7%8E%B0%E4%B8%8D%E5%90%8C%E7%8E%AF%E5%A2%83%E7%BD%91%E7%BB%9C%E5%8D%97%E5%8C%97%E6%B5%81%E9%87%8F%E9%9A%94%E7%A6%BB/</url>
      
        <content type="html"><![CDATA[<p>在企业实践中，通常会部署多个OpenShift集群：开发测试、生产等。每个集群都是独立的，通过物理资源进行隔离。这种方式管理简单，易于理解，但是消耗的资源更多，每个集群都需要额外的控制节点及运维节点。有没有办法，使不同环境运行在同一个集群上，并且它们之间实现隔离呢？答案是可以的。<br>对于不同的环境，做好资源隔离，我们需要对计算资源——宿主机做好规划，同时还需要对网络做好规划。宿主机的隔离，可以通过给主机添加label的方法，规划pod的调度。本篇中，我们只针对网络Route部分做好开发测试环境与生产环境的隔离。</p><h1 id="OpenShift集群Route分片机制"><a href="#OpenShift集群Route分片机制" class="headerlink" title="OpenShift集群Route分片机制"></a>OpenShift集群Route分片机制</h1><p>大家都知道OpenShift管理南北流量是通过Route来实现的，所谓的Route本质就是一个Haproxy&#x2F;Nginx服务，与K8S中的Ingress类似。<br>默认情况下，OpenShift集群的Router是全局共用的，也就是说，在创建新的Route资源、Pod更新或者证书更新时，所有的OpenShift Router Pod都会更新Haproxy&#x2F;Nginx的配置，并重新加载。所有的Route后台应用可以通过任一Router服务访问。通过创建多个Router服务，并使用Route分片机制，将不同的应用配置到不同的Router上，实现应用Router服务的隔离。下图为多Router节点分片的架构图。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-858c1451e84aaed8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="多Router节点分片"></p><p>该架构图中，并没有考虑将节点隔离，只是通过适当的路由来做流量划分。</p><ol><li>流量入口为集群外部的负载均衡器。我们只考虑<code>*.apps-prod.example.com</code>与<code>*.apps-dev.example.com</code>域名访问情况。<br>*.apps-prod.example.com域名的后端服务为router-prod<br>*.apps-dev.example.com域名的后端服务为router-dev</li><li>每个router都强制设置Route的域名subdomain格式【可选】<br>router-prod路由设置的subdomain为：${name}-${namespace}.apps-prod.example.com<br>router-dev路由设置的subdomain为：${name}-${namespace}.apps-dev.example.com<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm router router-prod --replicas=2 --force-subdomain=&#x27;$&#123;name&#125;-$&#123;namespace&#125;.apps-prod.example.com&#x27;</span><br><span class="line">$ oc adm router router-dev --replicas=1 --force-subdomain=&#x27;$&#123;name&#125;-$&#123;namespace&#125;.apps-dev.example.com&#x27;</span><br></pre></td></tr></table></figure>对于已完成部署的Router服务可以使用如下命令设置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm router router-prod  --replicas=2 --force-subdomain=&#x27;$&#123;name&#125;-$&#123;namespace&#125;.apps-prod.example.com&#x27; --dry-run -o yaml | oc apply -f -</span><br></pre></td></tr></table></figure>此时新建的所有Route的host将无法自定义设置，而会被将被强制设置为两个，其格式为：<code>$&#123;name&#125;-$&#123;namespace&#125;.apps-prod.example.com</code> 与<code>$&#123;name&#125;-$&#123;namespace&#125;.apps-dev.example.com</code>。</li><li>接下来是最重要的一步，为每个Router应用设置Project过滤器，只有带有指定Label的Project下的Route资源才能在该Router下创建配置。<br>router-pod路由设置过滤器为：router&#x3D;prod<br>router-dev路由设置过滤器为：router&#x3D;dev<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env dc/router-prod NAMESPACE_LABELS=&quot;router=prod&quot;</span><br><span class="line">$ oc set env dc/router-dev NAMESPACE_LABELS=&quot;router=dev&quot;</span><br></pre></td></tr></table></figure></li><li>将对应的router服务与计算节点绑定<br>确保带有Label<code>router=prod</code>的Router应用部署在带有Label<code>router=prod</code>的Infra节点上，同样带有Label<code>router=dev</code>的Router应用部署在带有Label<code>router=dev</code>的Infra节点上。该创建步骤与<code>步骤3</code>合在一起的脚本如下，即在创建的时候指定Node，及环境变量<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ # prod router节点</span><br><span class="line">$ oc label node infra1 &quot;router=prod&quot;</span><br><span class="line">$ oc label node infra2 &quot;router=prod&quot;</span><br><span class="line">$ oc adm router router-prod --replicas=2 --force-subdomain=&#x27;$&#123;name&#125;-$&#123;namespace&#125;.apps-prod.example.com&#x27; --selector=router=prod</span><br><span class="line">$ oc set env dc/router-prod NAMESPACE_LABELS=&quot;router=prod&quot;</span><br><span class="line"></span><br><span class="line">$ # dev router节点</span><br><span class="line">$ oc label node infra3 &quot;router=dev&quot;</span><br><span class="line">$ oc adm router router-dev --replicas=1 --force-subdomain=&#x27;$&#123;name&#125;-$&#123;namespace&#125;.apps-dev.example.com&#x27; --selector=router=dev</span><br><span class="line">$ oc set env dc/router-dev NAMESPACE_LABELS=&quot;router=dev&quot;</span><br></pre></td></tr></table></figure></li><li>设置对应Label的Project，将会自动匹配该Project下的Route资源与Router服务<br>创建新的project，添加Label<code>router=prod</code>，将会把该Project下的Route资源配置在prod Router服务中，同理Label<code>router=dev</code>下的Route资源配置将会在dev Router服务中配置。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ # 创建project project-prod-1设置Label router=prod</span><br><span class="line">$ oc new-project project-prod-1</span><br><span class="line">$ oc label namespace project-prod-1 router=prod</span><br><span class="line"></span><br><span class="line">$ # 创建project project-dev-1设置Label router=dev</span><br><span class="line">$ oc new-project project-dev-1</span><br><span class="line">$ oc label namespace project-dev-1 router=dev</span><br></pre></td></tr></table></figure></li><li>此时创建的应用，将会自动进行Router选择配置。Project<code>router=prod</code>下创建的Route将会自动在Router<code>router=prod</code>下配置，同时它的域名格式为：<br><code>$&#123;name&#125;-$&#123;namespace&#125;.apps-prod.example.com</code>。<br>同样的Project<code>router=dev</code>下创建的Route将会自动在Router<code>router=dev</code>下配置，同时它的域名格式为：<br><code>$&#123;name&#125;-$&#123;namespace&#125;.apps-dev.example.com</code>。</li></ol><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>以上是通过Router启动添加NAMESPACE_LABEL来设置项目级别的分片，也可以通过为dc&#x2F;route中的ROUTE_LABEL环境变量来设置Route级别的分配。</p><ol><li>为dc&#x2F;route设置ROUTE_LABEL<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env dc/router-prod ROUTE_LABELS=&quot;router=prod&quot;</span><br></pre></td></tr></table></figure></li><li>为Route资源对象指定Label<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc label route &lt;route=name&gt; router=prod</span><br></pre></td></tr></table></figure>该route只会部署在设置有<code>router=prod</code>的路由节点上配置。</li><li>如果要在一台节点上部署多个Router实例来承载业务，需要注意其HTTP、HTTPS、STATS端口不能重复。该端口可以通过<code>ROUTER_SERVICE_HTTP_PORT</code>、<code>ROUTER_SERVICE_HTTPS_PORT</code>、<code>ROUTER_LISTEN_ADDR</code>环境变量进行设置。</li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul><li><a href="https://www.jianshu.com/p/e861325ccd92">企业级容器云平台建设之资源管理</a>一文中，总结了资源管理分为四部分：计算、网络、存储、镜像仓库。真正实现不同环境的隔离，这四个方面都需要考虑。本文的主要内容说明了网络部分南北流量的隔离。</li><li>通过Route流量分片机制，将不同环境下的应用部署在同一个OpenShift集群中，在满足网络南北流量隔离的情况下，减少了集群的数量，节约管理及硬件成本。</li><li>要实现集群网络中东西流量的隔离，可以在不同环境下的宿主机之间建立防火墙来实现，同时也可以使用OpenShift的<code>ovs-multitenant</code>或者<code>ovs-networkpolicy</code>网络策略来实现。可阅读之前写的文章：<a href="https://www.jianshu.com/p/ae705078fd27">Openshift的网络策略networkpolicy</a></li><li>计算隔离必须保证不同环境下的应用不会运行在同一台宿主机下，以避免它们之间相互影响，抢占资源。这就需要使用OpenShift的调度策略来实现。可阅读之前写的文章：<a href="https://www.jianshu.com/p/40050e2a05d4">玩转Openshift中Pod调度</a></li><li>存储隔离。可以通过创建不同的storageclass为不同的环境提供服务。</li><li>镜像仓库隔离。可以创建多个镜像仓库，同时也可以使用一套镜像仓库，而使用不同的project来作镜像间的逻辑隔离。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://blog.openshift.com/openshift-router-sharding-for-production-and-development-traffic/">OpenShift Router Sharding for Production and Development Traffic</a><br>OpenShift Route配置加载的机制可以参考文章：<a href="https://www.jianshu.com/p/5aeadf25dab8">OpenShift Router配置重新加载机制</a><br><a href="https://docs.openshift.com/container-platform/3.11/install_config/router/default_haproxy_router.html">官方文档：Using the Default HAProxy Router</a><br><a href="https://docs.openshift.com/container-platform/3.11/architecture/networking/routes.html#router-sharding">OpenShift Router Sharding</a><br><a href="https://docs.openshift.com/container-platform/3.11/install_config/router/default_haproxy_router.html#using-router-shards">OpenShift Using Router Shards</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Router配置重新加载机制</title>
      <link href="/openshift/OpenShift-Router%E9%85%8D%E7%BD%AE%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
      <url>/openshift/OpenShift-Router%E9%85%8D%E7%BD%AE%E9%87%8D%E6%96%B0%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-e6e9763b993e55f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Haproxy Router机制"></p><p>OpenShift的Router是几乎所有南北流量的入口，对它的运行机制的了解非常重要，尤其是Router的配置更新加载机制。在服务请求出现异常情况下，我们能够快速分析出问题的原因，及时修复，保证应用的连续性。本章主要介绍OpenShift Router的配置加载机制。</p><p>OpenShift路由默认是基于Haproxy实现的。当Pod有更新或者证书更新等情况时会重新加载Haproxy的配置，来保证集群的路由信息是最新的。重载配置是否会对当前在线业务产生影响，这是系统管理员担心的问题。</p><h2 id="一、-Haproxy配置重载的过程"><a href="#一、-Haproxy配置重载的过程" class="headerlink" title="一、 Haproxy配置重载的过程"></a>一、 Haproxy配置重载的过程</h2><p>Haproxy在重新加载配置过程分两步。</p><ol><li>生成最新的配置</li><li>重启Haproxy进程</li></ol><h3 id="Haproxy生成最新的配置"><a href="#Haproxy生成最新的配置" class="headerlink" title="Haproxy生成最新的配置"></a>Haproxy生成最新的配置</h3><p>OpenShift上以下三种资源的改变会触发Haproxy配置的更新</p><ol><li>Routes改变</li><li>Pod IP&#x2F;Endpoint 改变</li><li>证书改变</li></ol><p>OpenShift Route有一个配置模板文件，最终的配置会根据这个模板文件来创建。该模板文件，默认路径为<code>/var/lib/haproxy/conf/haproxy-config.template</code>，也可以通过环境变量TEMPLATE_FILE来指定。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">exec</span> router-3-r2scd <span class="built_in">cat</span> haproxy-config.template | <span class="built_in">head</span> -n5</span></span><br><span class="line">&#123;&#123;/*</span><br><span class="line">    haproxy-config.cfg: contains the main config with helper backends that are used to terminate</span><br><span class="line">                        encryption before finally sending to a host_be which is the backend that is the final</span><br><span class="line">                        backend for a route and contains all the endpoints for the service</span><br><span class="line">*/&#125;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="Haproxy配置的加载过程"><a href="#Haproxy配置的加载过程" class="headerlink" title="Haproxy配置的加载过程"></a>Haproxy配置的加载过程</h3><p>OpenShift Router Pod中运行着两个进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">exec</span> router-3-r2scd -n default -- ps -ef</span></span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">1000000+      1      0  0 Nov07 ?        00:00:08 /usr/bin/openshift-router</span><br><span class="line">1000000+     5076      1  0 Nov07 ?        00:00:02 /usr/sbin/haproxy -f /var/lib/haproxy/conf/haproxy.config -p /var/lib/haproxy/run/haproxy.pid -x /var/lib/haproxy/run/haproxy.sock -sf 5061</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>其中Haproxy进程的父进程是openshift-router，它管理着haproxy进程。openshift-router将通过Master API查询Route、EndPoint及证书的状态，生成最新的Haproxy配置，并执行重新加载操作。在每次重新加载后，haproxy 进程将会被终止并重新启动，haproxy的进程ID将会变化。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">exec</span> router-3-r2scd -n default -- ps -ef</span></span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">1000000+      1      0  0 Nov07 ?        00:00:08 /usr/bin/openshift-router</span><br><span class="line">1000000+     5208      1  0 Nov07 ?        00:00:02 /usr/sbin/haproxy -f /var/lib/haproxy/conf/haproxy.config -p /var/lib/haproxy/run/haproxy.pid -x /var/lib/haproxy/run/haproxy.sock -sf 5148 5193</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="二、-openshift-router环境变量"><a href="#二、-openshift-router环境变量" class="headerlink" title="二、 openshift-router环境变量"></a>二、 openshift-router环境变量</h2><p>openshift-router接受很多环境变量，来控制haproxy的配置，以及haproxy的重载过程。</p><h3 id="RELOAD-SCRIPT"><a href="#RELOAD-SCRIPT" class="headerlink" title="RELOAD_SCRIPT"></a>RELOAD_SCRIPT</h3><p>重载haproxy的脚本，默认地址为<code>/var/lib/haproxy/reload-haproxy</code>。一般不作更改。openshift-router进程将会隔一定的时间周期去运行该脚本，其中时间周期通过环境变量RELOAD_INTERVAL来设置，默认是5s。</p><h3 id="RELOAD-INTERVAL"><a href="#RELOAD-INTERVAL" class="headerlink" title="RELOAD_INTERVAL"></a>RELOAD_INTERVAL</h3><p>设置openshift-router进程执行RELOAD_SCRIPT的时间周期，默认为5s。将它调大可以减少openshift-router重载haproxy的次数。</p><p>##三、 加快Haproxy的重载速度<br>对Haproxy来说，快速完成配置的加载非常重要。这样客户端就不会达到其SYN重试限制，从而导致连接失败。</p><h3 id="OpenShift路由器优化方法"><a href="#OpenShift路由器优化方法" class="headerlink" title="OpenShift路由器优化方法"></a>OpenShift路由器优化方法</h3><ol><li>更新到3.9以上版本，支持无缝重载</li><li>使用<a href="https://docs.openshift.com/container-platform/3.11/install_config/router/default_haproxy_router.html?extIdCarryOver=true&sc_cid=701f2000001OH7JAAW#using-router-shards">路由分片</a>方式，减少每个路由的策略，从而达到加快加载的目的</li><li>增大环境变量<code>RELOAD_INTERVAL</code>值，减少周期性Reload调用</li></ol><h3 id="检查重载速度"><a href="#检查重载速度" class="headerlink" title="检查重载速度"></a>检查重载速度</h3><p>通过检查HAProxy的重载速度，可以帮助我们确认连接问题是否是由于重新加载引起的。prometheus中会保存haproxy的加载时间信息到监控项<code>template_router_reload_seconds</code>中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sh-4.2$ curl -s  http://admin:aAIKAyrX1s@localhost:1936/metrics | grep template_router_reload_seconds</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">HELP template_router_reload_seconds Measures the time spent reloading the router <span class="keyword">in</span> seconds.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TYPE template_router_reload_seconds summary</span></span><br><span class="line">template_router_reload_seconds&#123;quantile=&quot;0.5&quot;&#125; NaN</span><br><span class="line">template_router_reload_seconds&#123;quantile=&quot;0.9&quot;&#125; NaN</span><br><span class="line">template_router_reload_seconds&#123;quantile=&quot;0.99&quot;&#125; NaN</span><br><span class="line">template_router_reload_seconds_sum 7.299802469000001</span><br><span class="line">template_router_reload_seconds_count 140</span><br></pre></td></tr></table></figure><p>看到重新加载总数为140，重新加载总和约为7.3秒。平均装载时间为7.3 &#x2F; 140 &#x3D; 0.05秒，相当快！</p><h3 id="自动关闭Router重载后保留的旧Haproxy进程"><a href="#自动关闭Router重载后保留的旧Haproxy进程" class="headerlink" title="自动关闭Router重载后保留的旧Haproxy进程"></a>自动关闭Router重载后保留的旧Haproxy进程</h3><p>OpenShift 3.9以上版本的Router在重载Haproxy后，会保留旧的Haproxy进程一段时间。因为它要等待正在连接中的请求关闭，所以旧的进程将会挂起一段时间。这些请求只通过以下两种方式关闭：</p><ol><li>客户端关闭</li><li>连接超时</li></ol><p>OpenShift默认的连接超时时间为1h，可以通过降低环境变量ROUTER_DEFAULT_TUNNEL_TIMEOUT的值来减少Haproxy进程挂起时间，同时通过降低ROUTER_BACKEND_CHECK_INTERVAL环境变量，能够调整后序健康检查的时间。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://access.redhat.com/articles/3679861">OpenShift Router Reload Technical Overview</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Route会话保持与负载均衡策略</title>
      <link href="/openshift/OpenShift-Route%E4%BC%9A%E8%AF%9D%E4%BF%9D%E6%8C%81%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5/"/>
      <url>/openshift/OpenShift-Route%E4%BC%9A%E8%AF%9D%E4%BF%9D%E6%8C%81%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="Route会话保持"><a href="#Route会话保持" class="headerlink" title="Route会话保持"></a>Route会话保持</h2><p>OpenShift Router是基于Haproxy反向代理实现的，客户端请求与后端应用POD通过cookie来实现会话保持。</p><ol><li>默认是开启会话保持的，基于cookie的会话保持。</li><li>如果设置<code>haproxy.router.openshift.io/disable_cookies</code>为<code>True</code>，将会禁用基于cookie的会话保持，而使用balance的负载策略。</li></ol><p>此过程分为两个阶段：第一次请求阶段、再次发起请求阶段</p><h3 id="第一次请求阶段"><a href="#第一次请求阶段" class="headerlink" title="第一次请求阶段"></a>第一次请求阶段</h3><p>客户端发起第一次请求时，Router会给返回的数据中添加一条指定的cookie。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-db58257990a43b5d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="第一次请求阶段：获取特定的COOKIE"></p><ol><li>客户端请求到达Router节点。</li><li>Router节点通过默认的负载均衡策略选择后端应用POD。</li><li>后端应用POD返回数据到Router节点。</li><li>Router根据后端应用POD,给返回的数据包set-cookie: cookiename[HASH值]&#x3D;cookievalue(HASH值），有效期为SESSION(浏览器客户端关闭前有效)。</li></ol><h3 id="再次发起请求阶段"><a href="#再次发起请求阶段" class="headerlink" title="再次发起请求阶段"></a>再次发起请求阶段</h3><p>客户端再次发起请求时，会带上第一次Router设置的cookie,Router根据该cookie值选择对应的POD。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-4671504e7b87cd2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="再次发起请求阶段：根据COOKIE选择对应的POD"></p><ol><li>客户端再次请求，带上第一次请求获得的cookie(HASH值)，访问Router节点。</li><li>Router节点根据请求中带的cookie(HASH值），将请求负载到对应的应用POD上。</li><li>后端应用POD返回数据到Router，进而返回客户端。</li></ol><ul><li><p>Router会话保持可以保证浏览器不关闭的情况下，同一个客户端请求被负载到同一个POD。但是如果浏览器重启后，第一个请求会重新负载获取新的COOKIE，这时就不能保证请求到同一个POD了。</p></li><li><p>如果某些应用一定需要满足同一个客户端必须负载到同一个POD的话，可以设置Route的负载策略为source的方式来满足。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc annotate route &lt;route_name&gt; \</span><br><span class="line">    --overwrite haproxy.router.openshift.io/balance=source </span><br></pre></td></tr></table></figure></li></ul><h2 id="Route负载均衡策略"><a href="#Route负载均衡策略" class="headerlink" title="Route负载均衡策略"></a>Route负载均衡策略</h2><p>而<code>haproxy.router.openshift.io/balance</code>是设置的负载策略。这个值对于passthrough类型的Route默认使用的是基于源地址策略，而对于非passthrough类型的Route默认使用的是最小连接策略。</p><ul><li>全局默认值可以通过环境变量ROUTER_TCP_BALANCE_SCHEME与ROUTER_LOAD_BALANCE_ALGORITHM设置。</li><li>ROUTER_TCP_BALANCE_SCHEME：对于pass-through类型的Route的负载策略，默认为基于源地址。</li><li>ROUTER_LOAD_BALANCE_ALGORITHM：对于非pass-through类型的Route的负载策略，默认为最小连接。</li></ul><p>负载均衡类型有以下三种：</p><ul><li>roundrobin：轮询。根据其权重依次使用每个端点。 当服务器的处理时间保持均匀分布时，这是最流畅，最公平的算法。</li><li>leastconn：最小连接数。当多个端点具有相同的最低连接数时，执行循环。 当需要非常长的会话（例如LDAP，SQL，TSE或其他会话）时，请使用此算法。 不适用于通常使用短会话的协议，例如HTTP。</li><li>source：源地址。对源IP地址进行哈希处理，然后除以运行中服务器的总权重，以指定将接收请求的服务器。 这样可以确保相同的客户端IP地址始终会到达同一服务器，只要没有服务器出现故障即可。 如果哈希结果由于正在运行的服务器数量变化而变化，那么许多客户端将被定向到不同的服务器。 此算法通常与直通路由一起使用。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Route支持TCP负载均衡改造与使用</title>
      <link href="/openshift/OpenShift-Route%E6%94%AF%E6%8C%81TCP%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%94%B9%E9%80%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
      <url>/openshift/OpenShift-Route%E6%94%AF%E6%8C%81TCP%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%94%B9%E9%80%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-b28d299da38195fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860"></p><h2 id="Route作为TCP负载均衡器的部署"><a href="#Route作为TCP负载均衡器的部署" class="headerlink" title="Route作为TCP负载均衡器的部署"></a>Route作为TCP负载均衡器的部署</h2><ol><li>获取当前Route的haproxy-template配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc project default</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc get pod</span></span><br><span class="line">NAME              READY     STATUS    RESTARTS   AGE</span><br><span class="line">router-16-5rv4q    2/2         Running   2            18h</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc rsh router-16-5rv4q <span class="built_in">cat</span> haproxy-config.template &gt; haproxy-config.template</span></span><br></pre></td></tr></table></figure></li><li>编辑导出的haproxy-config.template文件<br>在内容<code>&#123;&#123;- end &#125;&#125;&#123;&#123;/*end tls==passthrough*/&#125;&#125;</code>下一行，添加以下内容：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;/*TCP support*/&#125;&#125;</span><br><span class="line">&#123;&#123;- if eq &quot;tcp&quot; (index $cfg.Annotations &quot;haproxy.router.openshift.io/proxy-type&quot;) &#125;&#125;</span><br><span class="line">  &#123;&#123;- if (isInteger (index $cfg.Annotations &quot;haproxy.router.openshift.io/external-tcp-port&quot;)) &#125;&#125; </span><br><span class="line">frontend tcp-&#123;&#123; (index $cfg.Annotations &quot;haproxy.router.openshift.io/external-tcp-port&quot;) &#125;&#125;</span><br><span class="line">  bind :&#123;&#123; (index $cfg.Annotations &quot;haproxy.router.openshift.io/external-tcp-port&quot;) &#125;&#125;</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  default_backend &#123;&#123;genBackendNamePrefix $cfg.TLSTermination&#125;&#125;:&#123;&#123;$cfgIdx&#125;&#125;</span><br><span class="line">  &#123;&#123;- end&#125;&#125;&#123;&#123;/* end haproxy.router.openshift.io */&#125;&#125;</span><br><span class="line">&#123;&#123;- end&#125;&#125;&#123;&#123;/* end */&#125;&#125;</span><br><span class="line">&#123;&#123;/*end TCP support*/&#125;&#125;</span><br></pre></td></tr></table></figure></li><li>创建configmap模板保存新的haproxy-template文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc project default</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc create configmap customrouter --from-file=haproxy-config.template</span></span><br></pre></td></tr></table></figure></li><li>部署新的专门为TCP负载服务的Router节点，将HTTP、HTTPS默认端口换成别的端口不要产生冲突。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc adm router router-tcp --replicas=0 --selector=router=<span class="literal">true</span> --image=registry.example.com/openshfit3/ose-haproxy-router:v3.11 --stats=port=1937 -o yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc <span class="built_in">set</span> <span class="built_in">env</span> dc/router-tcp ROUTER_LABELS=router=tcp ROUTER_SERVICE_HTTP_PORT=81 ROUTER_SERVICE_HTTPS_PORT=444</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc <span class="built_in">set</span> volume dc/router --add --overwrite --name=config-volume --mount-path=/var/lib/haproxy/conf/custom --<span class="built_in">source</span>=<span class="string">&#x27;&#123;&quot;configMap&quot;: &#123; &quot;name&quot;: &quot;customrouter&quot;&#125;&#125;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc <span class="built_in">set</span> <span class="built_in">env</span> dc/router-tcp TEMPLATE_FILE=/var/lib/haproxy/conf/custom/haproxy-config.template</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc scale dc/router-tcp --replicas=2</span></span><br></pre></td></tr></table></figure></li><li>为Route节点添加防火墙<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vi /etc/sysconfig/iptables</span></span><br><span class="line">-A OS_FIREWALL_ALLOW -p tcp -m state --state NEW -m tcp --dport 11000:29999 -j ACCEPT</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemctl restart iptables</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="使用Route作为TCP负载均衡器"><a href="#使用Route作为TCP负载均衡器" class="headerlink" title="使用Route作为TCP负载均衡器"></a>使用Route作为TCP负载均衡器</h2><p>创建Route资源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    haproxy.router.openshift.io/external-tcp-port: &#x27;16379&#x27;</span><br><span class="line">    haproxy.router.openshift.io/proxy-type: tcp</span><br><span class="line">  labels:</span><br><span class="line">    router: tcp</span><br><span class="line">  name: myredis</span><br><span class="line">spec:</span><br><span class="line">  port:</span><br><span class="line">    targetPort: redis</span><br><span class="line">  tls:</span><br><span class="line">    insecureEdgeTerminationPolicy: None</span><br><span class="line">    termination: passthrough</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: myredis</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://mp.weixin.qq.com/s/gBujb2Gk-z3XAHS99QdcVA">灵魂拷问x10：OpenShift 4层Ingress实现方式大全</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-Service的域名</title>
      <link href="/openshift/OpenShift-Service%E7%9A%84%E5%9F%9F%E5%90%8D/"/>
      <url>/openshift/OpenShift-Service%E7%9A%84%E5%9F%9F%E5%90%8D/</url>
      
        <content type="html"><![CDATA[<ol><li>正常情况下<br>Service的域名格式为：service-name.project-name.svc.cluster.local<br>对应的IP是Service Cluster IP</li><li>设置Service的clusterIP&#x3D;None<br>Service的域名格式为：service-name.project-name.svc.cluster.local<br>对应的IP是后台对应的Pod的容器的IP<br>同时后台对应的Pod都有DNS记录，格式为Pod-name.service-name.project-name.svc.cluster.local</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-云原生容器应用设计原则</title>
      <link href="/openshift/OpenShift-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"/>
      <url>/openshift/OpenShift-%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%B9%E5%99%A8%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-ff50eb6f9192a11c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="设计原则"></p><p>引自：<a href="https://zhuanlan.zhihu.com/p/35131464">容器化应用的设计原则</a><br>来源自<a href="https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper">RedHat云原生容器应用设计原则白皮书</a></p><p>本文来自于Red Hat咨询顾问Bilgin Ibryam所编写的一篇白皮书，名为《PRINCIPLES OF CONTAINER-BASED APPLICATION DESIGN》。这篇文章在作者的Blog上发表后，作者的twitter被Kubernetes官方twitter转发。白皮书在Red Hat官网的下载地址：<a href="https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper">https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper</a> 文本是对这篇文章的学习和整理。</p><ol><li>先回顾经典的软件设计原则：</li></ol><ul><li>保持简单，愚蠢（KISS）</li><li>不要重复自己（DRY）</li><li>你不会需要它 （YAGNI）</li><li>关注点分离（SoC）</li><li>Single responsibility, Open&#x2F;closed, Liskov substitution, Interface segregation, Dependency inversion （SOLID）</li></ul><ol start="2"><li>然后是Red Hat的云原生容器设计原则：</li></ol><ul><li>唯一关注性原则（SCP）</li><li>高度可观测性原则（HOP）</li><li>生命周期一致性原则（LCP）</li><li>镜像不可变性原则（IIP）</li><li>进程可处置性原则（PDP）</li><li>自包含性原则（S-CP）</li><li>运行时约束性原则（RCP）</li></ul><p>很多组织都理解云原生的重要性和必要性，但是并不知道从哪里开始。那么请确保：云原生平台和容器化应用能无缝的运行在一起，并且具备抵御故障的能力，甚至在底层的基础架构出现宕机的时候，也能通过过弹性扩展的方式表现出可靠性。本文描述了容器化应用时需要遵循的基本准则，实施这些原则有助于使之与云原生平台Kubernetes更加适配。</p><h2 id="唯一关注性原则-SINGLE-CONCERN-PRINCIPLE（SCP）"><a href="#唯一关注性原则-SINGLE-CONCERN-PRINCIPLE（SCP）" class="headerlink" title="唯一关注性原则 SINGLE CONCERN PRINCIPLE（SCP）"></a>唯一关注性原则 SINGLE CONCERN PRINCIPLE（SCP）</h2><p>在许多方面，唯一关注性原则与来自SOLID的SRP是类似的，它建议一个类应该只有一个责任。SRP背后的动机是每个责任是变更的一个轴心，一个类应该有，且也只有一个需要改变的理由。SCP原则中的“关注”一词强调关注是一种更高层次的抽象的责任，而且它更好地将范围描述为一个容器而不是一个类。虽然SRP的主要动机是变化原因的唯一性，而SCP的主要动机是容器镜像重用和可替换性。如果你创建一个解决单个问题的容器，并且以功能完整的方式来实现，不同应用程序中的容器镜像重用的可能性就会更高。</p><p>因此，SCP原则规定每个集容器都应该解决一个问题，并做得很好。 实现这一点，通常比在面向对象的世界中实现SRP更容易，容器通常管理的一个单一的进程，大多数情况下一个进程解决一个问题。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-2f49098815a15a25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="image.png"></p><p>如果你的容器化微服务需要解决多个问题，它可以使用这样的模式，将多个容器用sidecar和init-containers的模式合并成一个部署单元（pod），这样每个容器仍然是处理单个问题。同样，您可以替换处理同样问题的容器。 例如，将Web服务器容器或队列实现容器，更新为更具可扩展性的容器。</p><h2 id="高度可观测性原则-HIGH-OBSERVABILITY-PRINCIPLE（HOP）"><a href="#高度可观测性原则-HIGH-OBSERVABILITY-PRINCIPLE（HOP）" class="headerlink" title="高度可观测性原则 HIGH OBSERVABILITY PRINCIPLE（HOP）"></a>高度可观测性原则 HIGH OBSERVABILITY PRINCIPLE（HOP）</h2><p>容器提供了一种统一的方式来打包和运行应用程序，将它们视为一个黑盒子对象。 但任何旨在成为云原生公民的容器都必须提供API支持，要为运行时环境编写接口（API），以观察容器的健康状况和行为。 这是自动化容器更新和生命周期回收的基本先决条件和统一的方式，从而提高系统的弹性和用户体验。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-15c6782b9b825ece.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>实际上，您的容器化应用程序必须至少为其提供不同类型的健康检查的API–活动和就绪等状态。更好的应用程序的行为则必须提供其他手段来观察容器化应用程序的状态。应用程序应该将重要事件记录到标准错误（STDERR）和标准输出（STDOUT）中，从而通过统一的日志聚合工具（诸如Fluentd和Logstash之类的工具）进行分析，并与跟踪和指标收集库相结合，例如OpenTracing，Prometheus等。</p><p>将您的应用程序视为黑盒子，但实施所有必要的API以帮助平台对其进行观测，并以最佳方式管理您的应用程序。</p><h2 id="生命周期一致性原则-LIFE-CYCLE-CONFORMANCE-PRINCIPLE（LCP）"><a href="#生命周期一致性原则-LIFE-CYCLE-CONFORMANCE-PRINCIPLE（LCP）" class="headerlink" title="生命周期一致性原则 LIFE-CYCLE CONFORMANCE PRINCIPLE（LCP）"></a>生命周期一致性原则 LIFE-CYCLE CONFORMANCE PRINCIPLE（LCP）</h2><p>HOP规定了你的容器提供供平台观测的API。 LCP则规定：您的应用程序有办法读取来自平台的事件。 此外，除了获得事件以外，容器还应该对这些事件相应地作出反应。这就是此原则名字由来。这几乎就像在应用程序通过一个“写入API”与平台进行交互。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-48a0ca7b4069080e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>来自管理平台的各种事件都是为了帮助您管理您的容器的生命周期的。决定处理哪些事件取决于您的应用程序 以及是否对这些事件做出反应。</p><p>但有些事件比其他事件更重要。例如，任何需要一个干净的关闭进程，这就需要捕获信号：终止（SIGTERM）消息，并尽可能迅速关闭。 这是为了避免通过强制关闭信号：kill（SIGKILL），之后跟随一个SIGTERM。</p><p>还有其他事件，例如PostStart和PreStop，可能对您的应用程序生命周期管理也非常重要。 例如，某些应用程序需要在服务之前进行预热请求和一些需要在关闭干净之前释放资源。</p><h2 id="镜像不可变性原则-IMAGE-IMMUTABILITY-PRINCIPLE（IIP）"><a href="#镜像不可变性原则-IMAGE-IMMUTABILITY-PRINCIPLE（IIP）" class="headerlink" title="镜像不可变性原则 IMAGE IMMUTABILITY PRINCIPLE（IIP）"></a>镜像不可变性原则 IMAGE IMMUTABILITY PRINCIPLE（IIP）</h2><p>IMAGE IMMUTABILITY PRINCIPLE（IIP）容器化的应用程序是不可变更的，镜像一旦完成了构建，预计在不同的环境中运行都不会改变。这意味着在因外部环境的不同，在需要的时候需要使用外部手法处理所依赖的外部配置数据，而不是每个环境修改或者构建不同的容器。而容器应用程序中的任何变更，都应该因此触发构建新的容器映像，并在所有环境中重用它。相同于这个原理的，不可变服务器和不可变基础架构的概念也很受欢迎，并且对于服务器&#x2F;主机管理也是如此。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-a1cd6ab5f0b01dca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>在遵循IIP原则的情况下，应该防止为不同的环境创建相似的容器镜像，要始终坚持为所有环境只配置一个容器映像。 这个原则允许在应用程序更新期间，采用自动回滚和前滚等做法，这是云原生自动化的重要方面。</p><h2 id="进程可处置性原则-PROCESS-DISPOSABILITY-PRINCIPLE（PDP）"><a href="#进程可处置性原则-PROCESS-DISPOSABILITY-PRINCIPLE（PDP）" class="headerlink" title="进程可处置性原则 PROCESS DISPOSABILITY PRINCIPLE（PDP）"></a>进程可处置性原则 PROCESS DISPOSABILITY PRINCIPLE（PDP）</h2><p>迁移到容器应用程序的主要动机之一是：容器需要尽可能做到临时性，并做好在任何时候被另一个容器实例替换的准备。需要更换容器的原因有很多，比如：健康检查失败、缩容、应用程序将容器迁移到不同的主机，平台资源匮乏或其它的问题。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f1fc3cff843fe04f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>这意味着容器化的应用程序必须保持其状态为向外扩展的或分布式和冗余的。这也意味着应用程序应该快速启动和关闭，甚至为彻底的硬件故障做好准备。 实施这一原则的另一个有用的做法是创建小容器。 容器在云原生环境可以自动调度并在不同的主机上启动。较小的容器可以实现更快启动时间，因为在重新启动之前容器镜像需要被物理地复制到主机系统。</p><h2 id="自包含性原则-SELF-CONTAINMENT-PRINCIPLE（S-CP）"><a href="#自包含性原则-SELF-CONTAINMENT-PRINCIPLE（S-CP）" class="headerlink" title="自包含性原则 SELF-CONTAINMENT PRINCIPLE（S-CP）"></a>自包含性原则 SELF-CONTAINMENT PRINCIPLE（S-CP）</h2><p>这个原则规定一个容器应该在构建时包含所有需要的东西。容器的存在应该仅仅依赖于Linux®内核，在并添加相关额外的库，在容器构建时加入它们。除了库之外，它还应该包含语言运行时，应用程序平台（如果需要），以及运行所需的其他依赖关系，等运行容器化应用所需要的诸如此类的东西。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-880ca01107f44f9e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>唯一的例外是：由于不同环境之间差异，并且只能在运行时提供的配置; 例如，通过Kubernetes提供的ConfigMap。</p><p>某些应用程序由多个容器组件组成。 例如，容器化的Web应用程序也可能需要数据库容器。 根据这个原则，并不建议合并两个容器。相反，它建议的是数据库容器只包含运行数据库所需的所有内容，Web应用程序容器只包含运行Web应用程序所需的所有内容，如Web服务器。 在运行时，Web应用程序容器将根据需要依赖于并访问数据库容器。</p><h2 id="运行时约束性原则-RUNTIME-CONFINEMENT-PRINCIPLE（RCP）"><a href="#运行时约束性原则-RUNTIME-CONFINEMENT-PRINCIPLE（RCP）" class="headerlink" title="运行时约束性原则 RUNTIME CONFINEMENT PRINCIPLE（RCP）"></a>运行时约束性原则 RUNTIME CONFINEMENT PRINCIPLE（RCP）</h2><p>S-CP从构建时的角度查看容器，并关注于生成的二进制文件及其内容。但是容器不仅仅是磁盘上一个只有尺寸大小的单一维度的黑盒子。 容器运行时有多个维度，例如内存使用维度，CPU使用维度等资源消耗维度。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-2174cfbc8d165b83.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>这个RCP原则建议每个容器申报资源需求，并发送信息到平台。它应该分享容器的资源配置文件，从CPU，内存，网络，磁盘的角度声明。这影响到平台如何执行调度，自动扩展，容量 管理以及容器常规的服务级别协议（SLA）等。</p><p>除了向平台声明容器的资源需求之外，还有一点也很重要， 应用被约束在使用所声明的资源需求内。如果应用程序对资源的使用保持在约束的范围内，则当资源匮乏发生时，平台不太可能将其终止和迁移。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>云原生不仅仅是一种最终状态 - 它也是一种工作方式。 本份白皮书描述了一系列容器应用的基本原则，必须遵守才能成为优秀的云原生公民。</p><p>除了这些原则之外，创建良好的容器应用程序还需要熟悉其他容器相关的最佳实践和技术。 尽管上述原则非常根本，适用于大多数用例，下面列出的最佳实践在应用和不应用的时候，则需要判断力。以下是一些与容器相关的更常见的最佳实践：</p><ul><li>镜像要尽可能的小。 通过清理临时文件，并避免安装不必要的软件包来构建小尺寸镜像。 这减少了容器的尺寸，构建时间和复制容器镜像的网络传输时间。</li><li>支持任意用户ID。 避免使用sudo命令或要求特定用户名运行你的容器。</li><li>标记重要的端口。 虽然可以在运行时指定端口号，然而使用EXPOSE命令在运行的时候指定，则可以让镜像的使用者更轻松。</li><li>为持久数据使用卷。 在容器摧毁之后还需要保存的容器数据的，必须将数据写入一个数据卷。</li><li>设置镜像元数据。 以标签和注释形式存在的镜像元数据可以使您的容器镜像更加实用，从而为使用您的容器的开发人员提供了更好的体验。<br>使主机和镜像同步。 一些容器应用需要容器在某些属性（如时间和机器ID）上与主机同步。</li></ul><p>这里是指向各种模式和最佳实践的资源的链接，以帮助您能有效地实现上述目标：</p><p>• <a href="https://www.slideshare.net/luebken/container-patterns">https://www.slideshare.net/luebken/container-patterns</a><br>• <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices">https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices</a><br>• <a href="http://docs.projectatomic.io/container-best-practices">http://docs.projectatomic.io/container-best-practices</a><br>• <a href="https://docs.openshift.com/enterprise/3.0/creating_images/guidelines.html">https://docs.openshift.com/enterprise/3.0/creating_images/guidelines.html</a><br>• <a href="https://www.usenix.org/system/files/conference/hotcloud16/hotcloud16_burns.pdf">https://www.usenix.org/system/files/conference/hotcloud16/hotcloud16_burns.pdf</a><br>• <a href="https://leanpub.com/k8spatterns/">https://leanpub.com/k8spatterns/</a><br>• <a href="https://12factor.net/">https://12factor.net</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-如何设置使用Prometheus来监控Router</title>
      <link href="/openshift/OpenShift-%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E4%BD%BF%E7%94%A8Prometheus%E6%9D%A5%E7%9B%91%E6%8E%A7Router/"/>
      <url>/openshift/OpenShift-%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E4%BD%BF%E7%94%A8Prometheus%E6%9D%A5%E7%9B%91%E6%8E%A7Router/</url>
      
        <content type="html"><![CDATA[<p>OpenShift集群中的Router服务作为几乎所有南北流量的入口非常重要，对它的监控有很大的意义，既能够查看流量的变化，及时发现业务的变化，也可以发现异常请求及时发现问题。<br> 红帽对于Router服务其实已经开启了监控指标的服务，但是默认并没有与Prometheus服务对接，需要手动对接，具体对接的操作如下。</p><ol><li><p>获取Router应用的访问用户名与密码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env dc/router -n default --list  | grep STATS</span><br><span class="line">STATS_PASSWORD=Oby3Y2FXs5</span><br><span class="line">STATS_PORT=1936</span><br><span class="line">STATS_USERNAME=admin</span><br></pre></td></tr></table></figure></li><li><p>在prometheus项目下创建访问Router指标的密钥</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc create secret generic router-auth --from-literal=user=admin --from-literal=password=Oby3Y2FXs5 -n openshift-monitoring</span><br></pre></td></tr></table></figure></li><li><p>在openshift-monitoring项目下创建ServiceMonitor</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">$ cat &lt;&lt;EOF | oc create -f -</span><br><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  name: router-metrics</span><br><span class="line">  metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: haproxy-router</span><br><span class="line">  namespace: openshift-monitoring</span><br><span class="line">spec:</span><br><span class="line">  endpoints:</span><br><span class="line">  - basicAuth:</span><br><span class="line">      password:</span><br><span class="line">        name: router-auth</span><br><span class="line">        key: password</span><br><span class="line">      username:</span><br><span class="line">        name: router-auth</span><br><span class="line">        key: user</span><br><span class="line">    interval: 5s</span><br><span class="line">    path: /metrics</span><br><span class="line">    port: 1936-tcp</span><br><span class="line">    scheme: http</span><br><span class="line">  jobLabel: k8s-app</span><br><span class="line">  namespaceSelector:</span><br><span class="line">    matchNames:</span><br><span class="line">    - default</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      router: router</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>但是此时只是完成了Prometheus监控Router服务的指标，而没有通过Grafana查看。所以还需要单独部署Grafana</p></li><li><p>部署独立的Grafana</p></li><li><p>导入Haproxy的监控面板</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-通过Operator-SDK制作Operator</title>
      <link href="/openshift/OpenShift-%E9%80%9A%E8%BF%87Operator-SDK%E5%88%B6%E4%BD%9COperator/"/>
      <url>/openshift/OpenShift-%E9%80%9A%E8%BF%87Operator-SDK%E5%88%B6%E4%BD%9COperator/</url>
      
        <content type="html"><![CDATA[<h2 id="制作Operator过程"><a href="#制作Operator过程" class="headerlink" title="制作Operator过程"></a>制作Operator过程</h2><ol><li>下载安装operator-sdk</li><li>创建github仓库</li><li>operator-sdk创建应用<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">operator-sdk new memcached-go-operator --repo=github.com/example-inc/memcached-operator</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># or</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">operator-sdk new memcached-ansible-operator --api-version=fcloudy.com/v1alpha1 --kind=Memcached --<span class="built_in">type</span>=ansible</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># or</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">operator-sdk new memcached-helm-operator --api-version=fcloudy.com/v1alpha1 --kind=Memcached --<span class="built_in">type</span>=helm</span></span><br></pre></td></tr></table></figure>operator-sdk new默认使用的type为go，必须在$GOPATH目录下创建项目。type为go时项目的目录结构如下：<a href="https://github.com/operator-framework/operator-sdk/blob/master/doc/project_layout.md">项目的目录结构</a></li></ol><p>type的可选值还可以为：ansible与helm，如果是这两个，则还可以带参数–kind来定义CRD<br>示例：<br><a href="https://github.com/operator-framework/operator-sdk/blob/master/doc/user-guide.md">GO</a><br><a href="https://github.com/operator-framework/operator-sdk/blob/master/doc/ansible/user-guide.md">Ansible</a><br><a href="https://github.com/operator-framework/operator-sdk/blob/master/doc/helm/user-guide.md">Helm</a><br>更多实例：<a href="https://github.com/operator-framework/operator-sdk-samples">etcd,memcached,vault,bitcoin-sv</a><br>4. 创建ansible role</p><ul><li>创建应用时使用变量指的是CR中metadata的变量，而指的是CR中spec的变量。</li><li>如果只有一个role的话，在watches.yaml中指定role即可，例如<code>role: /opt/ansible/roles/memcached</code></li><li>如果有多个role的话，可以添加playbook.yaml，并指定它为启动脚本，例如<code>playbook: /opt/ansible/playbook.yaml</code></li></ul><ol start="5"><li>构建operator镜像<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">operator-sdk build docker.io/xhuaustc/memcached-operator:v0.0.1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker push docker.io/xhuaustc/memcached-operator:v0.0.1</span></span><br></pre></td></tr></table></figure></li><li>使用operator创建应用<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 1. 导入crd文件</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">create -f deploy/crds/cache_v1alpha1_memcached_crd.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 2. 替换deploy/operator.yaml文件中的变量REPLACE_IMAGE，pull_policy</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">&quot;&quot;</span> <span class="string">&#x27;s|&#123;&#123; REPLACE_IMAGE &#125;&#125;|docker.io/xhuaustc/memcached-operator:v0.0.1|g&#x27;</span> deploy/operator.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">&quot;&quot;</span> <span class="string">&#x27;s|&#123;&#123; pull_policy\|default(&#x27;</span>\<span class="string">&#x27;&#x27;</span>Always<span class="string">&#x27;\&#x27;</span><span class="string">&#x27;) &#125;&#125;|Always|g&#x27;</span> deploy/operator.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 3. 创建相关资源</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f deploy</span></span><br></pre></td></tr></table></figure></li><li>创建CR资源<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f deploy/crds/cache_v1alpha1_memcached_cr.yaml</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="监控全局Namespace"><a href="#监控全局Namespace" class="headerlink" title="监控全局Namespace"></a>监控全局Namespace</h2><p>默认情况下，Operator只能监听当前project下创建的应用。如果要监听所有的namespace,需将WATCH_NAMESPACE值设置为””，同时将role更换为clusterrole，rolebinding更新为clusterrolebinding。以下为具体实例。</p><ol><li>将deploy&#x2F;operator.yaml中的WATCH_NAMESPACE值设置为””<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="string">...</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">memcached-operator</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">memcached-operator</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">WATCH_NAMESPACE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure></li><li>将deploy&#x2F;role.yaml更改为ClusterRole<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">memcached-operator</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></li><li>将deploy&#x2F;role_binding.yaml更改为ClusterRoleBinding<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">memcached-operator</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">memcached-operator</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">&lt;operator-namespace&gt;</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">memcached-operator</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>operator会不断监听创建的CRD资源配置的变化，更新资源的状态，保证资源处于需要的状态下。<code>目前Operator只支持openshift 3.11及以上版本</code>。<br>通过使用operator-sdk可以非常方便地创建自己的operator。它不仅可以轻易将通用参数提取出来，同时支持编码的方式，让资源的定义更加灵活，而且可以通过operator的设置资源的调用顺序及依赖。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift-集群为项目提供专属节点</title>
      <link href="/openshift/OpenShift-%E9%9B%86%E7%BE%A4%E4%B8%BA%E9%A1%B9%E7%9B%AE%E6%8F%90%E4%BE%9B%E4%B8%93%E5%B1%9E%E8%8A%82%E7%82%B9/"/>
      <url>/openshift/OpenShift-%E9%9B%86%E7%BE%A4%E4%B8%BA%E9%A1%B9%E7%9B%AE%E6%8F%90%E4%BE%9B%E4%B8%93%E5%B1%9E%E8%8A%82%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>在生产实践中，某些系统因一些特殊的要求，需要独占节点，即专属节点：具有特殊要求的应用POD必须运行在这些专属节点上；同时这些节点不为其它应用服务。本文将提供一种具体的配置策略，以满足这种特殊的调度需求。<br>该策略主要使用到两种工具：</p><ol><li>节点标签实现应用与节点的绑定</li><li>污点配置实现其它应用不会被调度到该节点。</li></ol><h2 id="设置步骤"><a href="#设置步骤" class="headerlink" title="设置步骤"></a>设置步骤</h2><ol><li>为专属节点设置特定标签LABEL：dedicated&#x3D;sys0，及设置污点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc label node node-10 dedicated=sys0</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm taint nodes node-10 dedicated=sys0:NoSchedule</span></span><br></pre></td></tr></table></figure></li><li>在使用专属节点的应用编排中绑定的Node<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: nginx</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        dedicated: &quot;sys0&quot;</span><br><span class="line">      containers:</span><br><span class="line">...</span><br></pre></td></tr></table></figure>或<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    nodeAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        nodeSelectorTerms:</span><br><span class="line">          - matchExpressions:</span><br><span class="line">              - key: dedicated</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                  - sys0</span><br><span class="line">  containers:</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li>使用专属节点的应用编排中指定的标签及容忍污点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  tolerations:</span><br><span class="line">  - key: &quot;dedicated&quot;</span><br><span class="line">    operator: &quot;Equal&quot;</span><br><span class="line">    value: &quot;sys0&quot;</span><br><span class="line">    effect: &quot;NoExecute&quot;</span><br></pre></td></tr></table></figure>注意，本例中使用的operator是”Equal”，会比较污点的键与值。如果operator使用”Exists”，则应用可以容忍所有带有dedicated污点。</li></ol><h2 id="去除专属节点操作"><a href="#去除专属节点操作" class="headerlink" title="去除专属节点操作"></a>去除专属节点操作</h2><p>要是需要去除专属节点的限制，让它恢复成一个正常应用的节点。只需要将它的污点移除即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm taint nodes dedicated-</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift上使用NFS作为共享存储的线上问题</title>
      <link href="/openshift/OpenShift%E4%B8%8A%E4%BD%BF%E7%94%A8NFS%E4%BD%9C%E4%B8%BA%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E7%9A%84%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/"/>
      <url>/openshift/OpenShift%E4%B8%8A%E4%BD%BF%E7%94%A8NFS%E4%BD%9C%E4%B8%BA%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8%E7%9A%84%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-98d36f2791744a81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="NFS"></p><h2 id="NFS-exports文件配置格式"><a href="#NFS-exports文件配置格式" class="headerlink" title="NFS exports文件配置格式"></a>NFS exports文件配置格式</h2><p><code>&lt;输出目录&gt; [客户端1 选项（访问权限,用户映射,其他）] [客户端2 选项（访问权限,用户映射,其他）]</code></p><h3 id="a-输出目录："><a href="#a-输出目录：" class="headerlink" title="a. 输出目录："></a>a. 输出目录：</h3><p>输出目录是指NFS系统中需要共享给客户机使用的目录；</p><h3 id="b-客户端："><a href="#b-客户端：" class="headerlink" title="b. 客户端："></a>b. 客户端：</h3><p>客户端是指网络中可以访问这个NFS输出目录的计算机<br>客户端常用的指定方式</p><p>指定ip地址的主机：192.168.0.200<br>指定子网中的所有主机：192.168.0.0&#x2F;24 192.168.0.0&#x2F;255.255.255.0<br>指定域名的主机：david.bsmart.cn<br>指定域中的所有主机：*.bsmart.cn<br>所有主机：*</p><h3 id="c-选项："><a href="#c-选项：" class="headerlink" title="c. 选项："></a>c. 选项：</h3><p>选项用来设置输出目录的访问权限、用户映射等。</p><p>NFS主要有3类选项：</p><ul><li>访问权限选项</li></ul><p>设置输出目录只读：ro<br>设置输出目录读写：rw</p><ul><li>用户映射选项<br><strong>all_squash</strong>：将远程访问的所有普通用户及所属组都映射为匿名用户或用户组（nfsnobody）；<br><strong>no_all_squash</strong>：与all_squash取反（默认设置）；<br><strong>root_squash</strong>：将root用户及所属组都映射为匿名用户或用户组（默认设置）；<br><strong>no_root_squash</strong>：与rootsquash取反；<br><strong>anonuid&#x3D;xxx</strong>：将远程访问的所有用户都映射为匿名用户，并指定该用户为本地用户（UID&#x3D;xxx）；<br><strong>anongid&#x3D;xxx</strong>：将远程访问的所有用户组都映射为匿名用户组账户，并指定该匿名用户组账户为本地用户组账户（GID&#x3D;xxx）；</li></ul><p>其它选项<br><strong>secure</strong>：限制客户端只能从小于1024的tcp&#x2F;ip端口连接nfs服务器（默认设置）；<br><strong>insecure</strong>：允许客户端从大于1024的tcp&#x2F;ip端口连接服务器；<br><strong>sync</strong>：将数据同步写入内存缓冲区与磁盘中，效率低，但可以保证数据的一致性；<br><strong>async</strong>：将数据先保存在内存缓冲区中，必要时才写入磁盘；<br><strong>wdelay</strong>：检查是否有相关的写操作，如果有则将这些写操作一起执行，这样可以提高效率（默认设置）；<br>****no_wdelay：若有写操作则立即执行，应与sync配合使用；<br><strong>subtree</strong>：若输出目录是一个子目录，则nfs服务器将检查其父目录的权限(默认设置)；<br><strong>no_subtree</strong>：即使输出目录是一个子目录，nfs服务器也不检查其父目录的权限，这样可以提高效率；</p><p><em><strong>例如：&#x2F;data&#x2F;nfsTest&#x2F; 127.0.0.1(rw,sync,no_root_squash)</strong></em></p><h2 id="OpenShift相关的账号权限问题"><a href="#OpenShift相关的账号权限问题" class="headerlink" title="OpenShift相关的账号权限问题"></a>OpenShift相关的账号权限问题</h2><ol><li>SUPGROUP为容器运行的用户添加所属组，可动态添加<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">securityContext:</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    - 1001</span><br><span class="line">    - 1002</span><br></pre></td></tr></table></figure>如果NFS服务共享目录中设置了<code>anongid</code>，则可以通过设置supgroup来赋予容器用户对NFS目录的访问权限。</li><li>指定NFS请求版本<br>配置PV，强制使用NFSv3来访问后端NFS服务。<br>参考配置如下：spec.mountOptions<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0003</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  mountOptions:</span><br><span class="line">    - hard</span><br><span class="line">    - nfsvers=3</span><br><span class="line">  nfs:</span><br><span class="line">    path: /tmp</span><br><span class="line">    server: 172.17.0.2</span><br></pre></td></tr></table></figure>另外也可以通过添加annotations.volume.beta.kubernetes.io&#x2F;mount-options来设置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc patch pv pv0003 -p &#x27;&#123;&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&quot;volume.beta.kubernetes.io/mount-options&quot;:&quot;rw,nfsvers=3&quot;&#125;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift中etcd集群的某个etcd服务文件损坏，导致节点故障，恢复过程</title>
      <link href="/openshift/OpenShift%E4%B8%ADetcd%E9%9B%86%E7%BE%A4%E7%9A%84%E6%9F%90%E4%B8%AAetcd%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%EF%BC%8C%E5%AF%BC%E8%87%B4%E8%8A%82%E7%82%B9%E6%95%85%E9%9A%9C%EF%BC%8C%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B/"/>
      <url>/openshift/OpenShift%E4%B8%ADetcd%E9%9B%86%E7%BE%A4%E7%9A%84%E6%9F%90%E4%B8%AAetcd%E6%9C%8D%E5%8A%A1%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F%EF%BC%8C%E5%AF%BC%E8%87%B4%E8%8A%82%E7%82%B9%E6%95%85%E9%9A%9C%EF%BC%8C%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>etcd集群中某个etcd出现故障，使用<code>docker ps -a | grep etcd | grep -v POD</code>查看etcd节点，发现它异常退出。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs -f &lt;etcd-container-id&gt;</span><br><span class="line">....</span><br><span class="line">etcdserver : open wal error: wal: file not found </span><br></pre></td></tr></table></figure><h2 id="恢复步骤"><a href="#恢复步骤" class="headerlink" title="恢复步骤"></a>恢复步骤</h2><p>大方向步骤：<br><strong>一、将问题etcd节点从etcd集群剥离；</strong><br><strong>二、将恢复的新的etcd节点添加到etcd集群。</strong><br>具体步骤如下：</p><ol><li><p>查看etcd状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl2 cluster-health</span><br><span class="line">$ ## 获取问题节点的member ID</span><br><span class="line">$ etcdctl2 member remove  &lt;member ID&gt;</span><br><span class="line">$ ## 将问题etcd服务从etcd集群中删除</span><br></pre></td></tr></table></figure></li><li><p>停止问题节点上的etcd服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br></pre></td></tr></table></figure></li><li><p>删除问题节点上的etcd数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd/*</span></span><br></pre></td></tr></table></figure><p>4.更新ansible中的inventory hosts内容，设置new_etcd配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">etcd</span><br><span class="line">nodes</span><br><span class="line">new_etcd</span><br><span class="line"></span><br><span class="line">[OSEv3:vars]</span><br><span class="line">openshift_is_atomic=false</span><br><span class="line"></span><br><span class="line">[masters]</span><br><span class="line">master-1</span><br><span class="line">master-2</span><br><span class="line">master-3</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line">master-1</span><br><span class="line">master-2</span><br><span class="line">master-3</span><br><span class="line">...</span><br><span class="line">[etcd]</span><br><span class="line">master-1</span><br><span class="line">#master-2</span><br><span class="line">master-3</span><br><span class="line"></span><br><span class="line">[new_etcd]</span><br><span class="line">master-2</span><br></pre></td></tr></table></figure><p><code>需要注意：</code>将问题节点从masters&#x2F;nodes中注释掉，否则执行etcd扩容会报如下错误。<br><code>TASK [Run variable sanity checks] </code><br><code>fatal: [master-1]: FAILED! =&gt; &#123;&quot;msg&quot;: &quot;last_checked_host: master-2, last_checked_var: ansible_python;&#39;NoneType&#39; object has no attribute &#39;__getitem__&#39;&quot;&#125;</code></p></li><li><p>更新节点的node group配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-master/openshift_node_group.yml</span></span><br></pre></td></tr></table></figure></li><li><p>执行etcd扩容脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-etcd/scaleup.yml</span></span><br></pre></td></tr></table></figure></li><li><p>执行完成扩容后，进行验证。<br><code>注意</code>：如果在<code>hosts</code>中将masters对应的节点注释掉，在etcd安装时会使用本地服务的方式安装运行，这个适合独立的节点部署etcd。</p></li></ol><h2 id="etcd命令"><a href="#etcd命令" class="headerlink" title="etcd命令"></a>etcd命令</h2><p>etcd压测脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl --write-out=table check perf</span></span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openshift.com/container-platform/3.11/install_config/adding_hosts_to_existing_cluster.html#adding-etcd-hosts-to-existing-cluster">Adding etcd Hosts to existing cluster</a>&#96;</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift中如何将PV与PVC绑定</title>
      <link href="/openshift/OpenShift%E4%B8%AD%E5%A6%82%E4%BD%95%E5%B0%86PV%E4%B8%8EPVC%E7%BB%91%E5%AE%9A/"/>
      <url>/openshift/OpenShift%E4%B8%AD%E5%A6%82%E4%BD%95%E5%B0%86PV%E4%B8%8EPVC%E7%BB%91%E5%AE%9A/</url>
      
        <content type="html"><![CDATA[<h2 id="PV-x2F-PVC是什么？"><a href="#PV-x2F-PVC是什么？" class="headerlink" title="PV&#x2F;PVC是什么？"></a>PV&#x2F;PVC是什么？</h2><p>PV（Persistent Volume）：描述的是持久化的Volume实体概念，生命周期与Pod创建和销毁事件无关。要么运行事先准备好，要么通过动态创建。<br>PVC（PersistentVolumeClaim）：PVC是对PV的请求，申明Pod所希望使用的持久化存储的属性，例如容量，读写权限。</p><p>Kubernete Volumes能够帮忙应用持久化数据，PV&#x2F;PVC是Kubernetes Volumes存储类型的一种，其它类型还有：<br>本地存储：emptyDir &#x2F; hostPath<br>网络存储：<br>in-tree: aws ElasticBlockStore &#x2F; gcePersistentDisk &#x2F; nfs<br>out-of-tree：csi等网络存储插件<br>Project Volume：secret &#x2F; configmap &#x2F; downwardAPI &#x2F; serviceAccountToken</p><h2 id="PV-x2F-PVC的意义"><a href="#PV-x2F-PVC的意义" class="headerlink" title="PV&#x2F;PVC的意义"></a>PV&#x2F;PVC的意义</h2><ol><li>使用不同的控制器来管理计算与存储资源，解耦POD与Volume的生命周期，实现计算与存储分离。</li><li>PVC只需要关注应用需要知道的配置，如存储大小、访问模式，读写模式等，而不需要知道存储的细节，实现开发与运维职责分离。开发只需要提需求，知道自己需要的存储容量，模式就够了，他并不关心存储是由什么设备提供的，资源池的够不够，而运维人员则相反，他更关心的底层的存储状态。</li></ol><h2 id="PV创建的两种方式：静态与动态"><a href="#PV创建的两种方式：静态与动态" class="headerlink" title="PV创建的两种方式：静态与动态"></a>PV创建的两种方式：静态与动态</h2><p>静态创建方式，下图为静态创建的示意图。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-345f910e71ae509b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="静态创建方式"></p><ol><li>研发用户需要创建存储资源，于是创建了PVC（持久化存储卷请求），申明需要的存储资源大小以及访问模式</li><li>集群管理人员（运维人员）根据需求配置手动创建对应的PV（持久化存储卷）</li><li>OpenShift&#x2F;K8S会根据配置将PV&#x2F;PVC进行绑定，让PVC与真实的存储资源关联。</li></ol><p>这种方式有几个问题：</p><ol><li>需要手动创建PV，增加了运维管理的复杂度。</li><li>如果有大量配置一样的PVC需求时，PVC与设定的PV需要单独的设置进行绑定。</li></ol><p>动态创建方式，下图为动态创建的示意图。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-75d279449a004089.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="动态创建方式"><br>0. 集群管理人员（运维人员）提前部署好存储的provisioner，并创建好对应storageclass</p><ol><li>研发用户需要创建存储资源，于是创建了PVC（持久化存储卷请求），申明需要的存储的provisioner以及存储大小</li><li>provisioner监听到PVC资源的创建，自动创建PV，并与PVC进行绑定，让PVC与真实的存储资源关联。</li></ol><p>一旦准备好动态创建存储环境，存储资源便以服务的方式提供给研发人员，实现存储资源自服务。</p><h2 id="如何将PV与PVC绑定"><a href="#如何将PV与PVC绑定" class="headerlink" title="如何将PV与PVC绑定"></a>如何将PV与PVC绑定</h2><p>在上一部分介绍了静态创建存储资源与动态创建存储资源的过程与特点，很明显动态创建存储资源使用更方便，但是在生产中，受到环境的限制，静态创建存储资源的方式仍然很常见。这时，如何准确地绑定PVC与对应的PV就是需要注意的问题了。下面列出了解决这个问题的三种方法。</p><h3 id="第一种，在PV中添加label，在PVC中添加matchLabels进行关联"><a href="#第一种，在PV中添加label，在PVC中添加matchLabels进行关联" class="headerlink" title="第一种，在PV中添加label，在PVC中添加matchLabels进行关联"></a>第一种，在PV中添加label，在PVC中添加matchLabels进行关联</h3><p>创建PV</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-pv1</span><br><span class="line">  labels:</span><br><span class="line">    pv: nfs-pv1</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 1Gi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  nfs:</span><br><span class="line">    server: 10.2.1.2</span><br><span class="line">    path: &quot;/exports/pv1&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc1</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      pv: &quot;nfs-pv1&quot;</span><br><span class="line">    matchExpressions:</span><br><span class="line">      - &#123;key: environment, operator: In, values: [dev]&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 本地盘PV</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: test2-pv</span><br><span class="line">  namespace: kubeflow</span><br><span class="line">  labels:</span><br><span class="line">    pv: test2</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 100Mi</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  hostPath:</span><br><span class="line">    path: &quot;/data/test2&quot;</span><br></pre></td></tr></table></figure><h3 id="第二种，PV配置中指定关联的PVC"><a href="#第二种，PV配置中指定关联的PVC" class="headerlink" title="第二种，PV配置中指定关联的PVC"></a>第二种，PV配置中指定关联的PVC</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-pv1</span><br><span class="line">  labels:</span><br><span class="line">    pv: nfs-pv1</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 1Gi</span><br><span class="line">  claimRef:</span><br><span class="line">    apiVersion: v1</span><br><span class="line">    kind: PersistentVolumeClaim</span><br><span class="line">    name: openldap-volume-1</span><br><span class="line">    namespace: openldap</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  nfs:</span><br><span class="line">    server: 10.2.1.2</span><br><span class="line">    path: &quot;/exports/pv1&quot;</span><br></pre></td></tr></table></figure><h3 id="第三种，PVC中设置volumeName"><a href="#第三种，PVC中设置volumeName" class="headerlink" title="第三种，PVC中设置volumeName"></a>第三种，PVC中设置volumeName</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc1</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">  volumeName: nfs-pv1</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift中如何通过脚本获取Alertmanager的告警数据</title>
      <link href="/openshift/OpenShift%E4%B8%AD%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E8%84%9A%E6%9C%AC%E8%8E%B7%E5%8F%96Alertmanager%E7%9A%84%E5%91%8A%E8%AD%A6%E6%95%B0%E6%8D%AE/"/>
      <url>/openshift/OpenShift%E4%B8%AD%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E8%84%9A%E6%9C%AC%E8%8E%B7%E5%8F%96Alertmanager%E7%9A%84%E5%91%8A%E8%AD%A6%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<p>一、为什么需要通过脚本获取告警信息</p><p>二、Alertmanager的告警信息</p><p>三、amtool工具获取告警信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc <span class="built_in">exec</span> -it alertmanager-main-0 -c alertmanager -n openshift-monitoring -- amtool alert query <span class="string">&#x27;severity=critical&#x27;</span> --alertmanager.url http://localhost:9093</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc <span class="built_in">exec</span> -it alertmanager-main-0 -c alertmanager -n openshift-monitoring -- amtool alert query <span class="string">&#x27;severity=critical&#x27;</span> --alertmanager.url http://localhost:9093 -o extended</span></span><br></pre></td></tr></table></figure><p>-o：默认值为simple，输出格式，还可以是extended，json</p><p>四、amtool更多功能</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift中的Grafana监控界面无法完成登录</title>
      <link href="/openshift/OpenShift%E4%B8%AD%E7%9A%84Grafana%E7%9B%91%E6%8E%A7%E7%95%8C%E9%9D%A2%E6%97%A0%E6%B3%95%E5%AE%8C%E6%88%90%E7%99%BB%E5%BD%95/"/>
      <url>/openshift/OpenShift%E4%B8%AD%E7%9A%84Grafana%E7%9B%91%E6%8E%A7%E7%95%8C%E9%9D%A2%E6%97%A0%E6%B3%95%E5%AE%8C%E6%88%90%E7%99%BB%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-08f808d3c6961f56.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Grafana OpenShift"></p><p><strong>问题描述：</strong><br>访问OpenShift默认的grafana无法跳转到OpenShift console界面。报如下错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;error&quot;:&quot;invalid_request&quot;,&quot;error_description&quot;:&quot;The request is missing a required parameter,</span><br><span class="line"> includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed.&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>解决办法：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc patch sa grafana -p <span class="string">&#x27;&#123;&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&quot;serviceaccounts.openshift.io/oauth-redirecturi.first&quot;:&quot;https://grafana.apps.example.com:450&quot;&#125;&#125;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure><p><strong>解释说明：</strong><br>因为某些原因，外部负载均衡器并没有使用与Router对应的80&#x2F;443端口，而是使用了83&#x2F;450端口。<br>默认情况下OpenShift oauth-proxy登录验证会传入clientId为应用的serviceaccount，它会将跳转链接与serviceaccount中的redirecturi校验。如果匹配则允许跳转，否则会报参数不合法的错误。</p><p>grafana serviceaccount的默认跳转相关的配置如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get serviceaccount grafana -n openshift-monitoring -o yaml</span></span><br><span class="line">...</span><br><span class="line">  serviceaccounts.openshift.io/oauth-redirectreference.grafana: &#x27;&#123;&quot;kind&quot;:&quot;OAuthRedirectReference&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;reference&quot;:&#123;&quot;kind&quot;:&quot;Route&quot;,&quot;name&quot;:&quot;grafana&quot;&#125;&#125;&#x27;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>它会从grafana Route中获取跳转链接，它与真实的链接（83&#x2F;450）不匹配，所以会报出不合法的错误。<br>故而需要添加指定的认证链接<code>https://grafana.apps.example.com:450</code>。</p><p>除了grafana外，其它OpenShift默认的服务也会出类似的问题，也可以通过同样的方法解决。<br><strong>参考文档：</strong><br><a href="https://docs.openshift.com/container-platform/3.11/architecture/additional_concepts/authentication.html">https://docs.openshift.com/container-platform/3.11/architecture/additional_concepts/authentication.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift中节点的垃圾收集——容器与镜像</title>
      <link href="/openshift/OpenShift%E4%B8%AD%E8%8A%82%E7%82%B9%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E2%80%94%E2%80%94%E5%AE%B9%E5%99%A8%E4%B8%8E%E9%95%9C%E5%83%8F/"/>
      <url>/openshift/OpenShift%E4%B8%AD%E8%8A%82%E7%82%B9%E7%9A%84%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E2%80%94%E2%80%94%E5%AE%B9%E5%99%A8%E4%B8%8E%E9%95%9C%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/garbage_collection.html">https://docs.openshift.com/container-platform/3.11/admin_guide&#x2F;garbage_collection.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift之应用环境变量篇</title>
      <link href="/openshift/OpenShift%E4%B9%8B%E5%BA%94%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%AF%87/"/>
      <url>/openshift/OpenShift%E4%B9%8B%E5%BA%94%E7%94%A8%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%AF%87/</url>
      
        <content type="html"><![CDATA[<p><a href="https://k8smeetup.github.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/">通过环境变量向容器暴露 Pod 信息</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift企业版离线安装：下载RedHat-Repo源及镜像文件</title>
      <link href="/openshift/OpenShift%E4%BC%81%E4%B8%9A%E7%89%88%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%EF%BC%9A%E4%B8%8B%E8%BD%BDRedHat-Repo%E6%BA%90%E5%8F%8A%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6/"/>
      <url>/openshift/OpenShift%E4%BC%81%E4%B8%9A%E7%89%88%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%EF%BC%9A%E4%B8%8B%E8%BD%BDRedHat-Repo%E6%BA%90%E5%8F%8A%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-e89857f2e1f31f86.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="RedHat OpenShift"></p><p>为了安全起见，在很多企业，网络环境是不能连接外网的，而需要使用OpenShift的话，就需要离线部署。离线部署与在线部署最大区别，就是我们得自己准备介质源：YUM源与镜像仓库。只要你拥有红帽订阅，下载最新的介质，其实很简单。</p><h2 id="一、同步YUM源"><a href="#一、同步YUM源" class="headerlink" title="一、同步YUM源"></a>一、同步YUM源</h2><p>RHEL主机注册到红帽订阅，并关联到相应的YUM仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ subscription-manager register</span><br><span class="line">$ subscription-manager refresh</span><br><span class="line">$ subscription-manager list --available --matches &#x27;*OpenShift*&#x27;</span><br><span class="line">$ subscription-manager attach --pool=&lt;pool_id&gt;</span><br><span class="line">$ subscription-manager repos --disable=&quot;*&quot;</span><br><span class="line">$ subscription-manager repos \</span><br><span class="line">    --enable=&quot;rhel-7-server-rpms&quot; \</span><br><span class="line">    --enable=&quot;rhel-7-server-extras-rpms&quot; \</span><br><span class="line">    --enable=&quot;rhel-7-fast-datapath-rpms&quot; \</span><br><span class="line">    --enable=&quot;rhel-7-server-ose-3.7-rpms&quot;</span><br></pre></td></tr></table></figure><p>同步yum源，reposync命令添加-n标记，表示只下载最新的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ yum -y install yum-utils createrepo docker git</span><br><span class="line">$ mkdir -p /opt/repos/</span><br><span class="line">$ for repo in \</span><br><span class="line">rhel-7-server-rpms \</span><br><span class="line">rhel-7-server-extras-rpms \</span><br><span class="line">rhel-7-fast-datapath-rpms \</span><br><span class="line">rhel-7-server-ose-3.7-rpms</span><br><span class="line">do</span><br><span class="line">  reposync --gpgcheck -lm --repoid=$&#123;repo&#125; --download_path=/opt/repos/ -n</span><br><span class="line">  createrepo -v /opt/repos/$&#123;repo&#125; -o /opt/repos/$&#123;repo&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>将YUM源文件打包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/repos/</span><br><span class="line">$ tar zcvf rhel-7-server-rpms.tar.gz rhel-7-server-rpms </span><br><span class="line">$ tar zcvf rhel-7-server-extras-rpms.tar.gz rhel-7-server-extras-rpms</span><br><span class="line">$ tar zcvf rhel-7-fast-datapath-rpms.tar.gz rhel-7-fast-datapath-rpms</span><br><span class="line">$ tar zcvf rhel-7-server-ose-3.7-rpms.tar.gz rhel-7-server-ose-3.7-rpms</span><br></pre></td></tr></table></figure><h2 id="二、同步镜像"><a href="#二、同步镜像" class="headerlink" title="二、同步镜像"></a>二、同步镜像</h2><p>登录红帽镜像仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker login registry.redhat.io</span><br></pre></td></tr></table></figure><p>下载镜像，例如<tag>&#x3D;v3.11.219</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull registry.redhat.io/openshift3/apb-base:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/apb-tools:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/automation-broker-apb:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/csi-attacher:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/csi-driver-registrar:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/csi-livenessprobe:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/csi-provisioner:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/grafana:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/local-storage-provisioner:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/manila-provisioner:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/mariadb-apb:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/mediawiki:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/mediawiki-apb:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/mysql-apb:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-ansible-service-broker:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-cli:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-cluster-autoscaler:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-cluster-capacity:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-cluster-monitoring-operator:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-console:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-configmap-reloader:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-control-plane:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-deployer:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-descheduler:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-docker-builder:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-docker-registry:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-efs-provisioner:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-egress-dns-proxy:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-egress-http-proxy:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-egress-router:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-haproxy-router:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-hyperkube:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-hypershift:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-keepalived-ipfailover:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-kube-rbac-proxy:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-kube-state-metrics:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-metrics-server:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-node:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-node-problem-detector:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-operator-lifecycle-manager:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-ovn-kubernetes:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-pod:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-prometheus-config-reloader:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-prometheus-operator:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-recycler:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-service-catalog:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-template-service-broker:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-tests:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-web-console:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/postgresql-apb:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/registry-console:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/snapshot-controller:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/snapshot-provisioner:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/rhel7/etcd:3.2.26</span><br><span class="line">$ docker pull registry.redhat.io/rhel7/etcd:3.2.22</span><br><span class="line"></span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-efs-provisioner:&lt;tag&gt;</span><br><span class="line"></span><br><span class="line">$ docker pull registry.redhat.io/openshift3/metrics-cassandra:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/metrics-hawkular-metrics:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/metrics-hawkular-openshift-agent:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/metrics-heapster:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/metrics-schema-installer:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/oauth-proxy:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-logging-curator5:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-logging-elasticsearch5:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-logging-eventrouter:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-logging-fluentd:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/ose-logging-kibana5:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/prometheus:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/prometheus-alertmanager:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/openshift3/prometheus-node-exporter:&lt;tag&gt;</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-openshift-postgresql</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-openshift-memcached</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-openshift-app-ui</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-openshift-app</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-openshift-embedded-ansible</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-openshift-httpd</span><br><span class="line">$ docker pull registry.redhat.io/cloudforms46/cfme-httpd-configmap-generator</span><br><span class="line">$ docker pull registry.redhat.io/rhgs3/rhgs-server-rhel7</span><br><span class="line">$ docker pull registry.redhat.io/rhgs3/rhgs-volmanager-rhel7</span><br><span class="line">$ docker pull registry.redhat.io/rhgs3/rhgs-gluster-block-prov-rhel7</span><br><span class="line">$ docker pull registry.redhat.io/rhgs3/rhgs-s3-server-rhel7</span><br></pre></td></tr></table></figure><p>将镜像打包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">$ docker save -o ose3-images.tar \</span><br><span class="line">    registry.redhat.io/openshift3/apb-base \</span><br><span class="line">    registry.redhat.io/openshift3/apb-tools \</span><br><span class="line">    registry.redhat.io/openshift3/automation-broker-apb \</span><br><span class="line">    registry.redhat.io/openshift3/csi-attacher \</span><br><span class="line">    registry.redhat.io/openshift3/csi-driver-registrar \</span><br><span class="line">    registry.redhat.io/openshift3/csi-livenessprobe \</span><br><span class="line">    registry.redhat.io/openshift3/csi-provisioner \</span><br><span class="line">    registry.redhat.io/openshift3/grafana \</span><br><span class="line">    registry.redhat.io/openshift3/local-storage-provisioner \</span><br><span class="line">    registry.redhat.io/openshift3/manila-provisioner \</span><br><span class="line">    registry.redhat.io/openshift3/mariadb-apb \</span><br><span class="line">    registry.redhat.io/openshift3/mediawiki \</span><br><span class="line">    registry.redhat.io/openshift3/mediawiki-apb \</span><br><span class="line">    registry.redhat.io/openshift3/mysql-apb \</span><br><span class="line">    registry.redhat.io/openshift3/ose-ansible-service-broker \</span><br><span class="line">    registry.redhat.io/openshift3/ose-cli \</span><br><span class="line">    registry.redhat.io/openshift3/ose-cluster-autoscaler \</span><br><span class="line">    registry.redhat.io/openshift3/ose-cluster-capacity \</span><br><span class="line">    registry.redhat.io/openshift3/ose-cluster-monitoring-operator \</span><br><span class="line">    registry.redhat.io/openshift3/ose-console \</span><br><span class="line">    registry.redhat.io/openshift3/ose-configmap-reloader \</span><br><span class="line">    registry.redhat.io/openshift3/ose-control-plane \</span><br><span class="line">    registry.redhat.io/openshift3/ose-deployer \</span><br><span class="line">    registry.redhat.io/openshift3/ose-descheduler \</span><br><span class="line">    registry.redhat.io/openshift3/ose-docker-builder \</span><br><span class="line">    registry.redhat.io/openshift3/ose-docker-registry \</span><br><span class="line">    registry.redhat.io/openshift3/ose-efs-provisioner \</span><br><span class="line">    registry.redhat.io/openshift3/ose-egress-dns-proxy \</span><br><span class="line">    registry.redhat.io/openshift3/ose-egress-http-proxy \</span><br><span class="line">    registry.redhat.io/openshift3/ose-egress-router \</span><br><span class="line">    registry.redhat.io/openshift3/ose-haproxy-router \</span><br><span class="line">    registry.redhat.io/openshift3/ose-hyperkube \</span><br><span class="line">    registry.redhat.io/openshift3/ose-hypershift \</span><br><span class="line">    registry.redhat.io/openshift3/ose-keepalived-ipfailover \</span><br><span class="line">    registry.redhat.io/openshift3/ose-kube-rbac-proxy \</span><br><span class="line">    registry.redhat.io/openshift3/ose-kube-state-metrics \</span><br><span class="line">    registry.redhat.io/openshift3/ose-metrics-server \</span><br><span class="line">    registry.redhat.io/openshift3/ose-node \</span><br><span class="line">    registry.redhat.io/openshift3/ose-node-problem-detector \</span><br><span class="line">    registry.redhat.io/openshift3/ose-operator-lifecycle-manager \</span><br><span class="line">    registry.redhat.io/openshift3/ose-ovn-kubernetes \</span><br><span class="line">    registry.redhat.io/openshift3/ose-pod \</span><br><span class="line">    registry.redhat.io/openshift3/ose-prometheus-config-reloader \</span><br><span class="line">    registry.redhat.io/openshift3/ose-prometheus-operator \</span><br><span class="line">    registry.redhat.io/openshift3/ose-recycler \</span><br><span class="line">    registry.redhat.io/openshift3/ose-service-catalog \</span><br><span class="line">    registry.redhat.io/openshift3/ose-template-service-broker \</span><br><span class="line">    registry.redhat.io/openshift3/ose-tests \</span><br><span class="line">    registry.redhat.io/openshift3/ose-web-console \</span><br><span class="line">    registry.redhat.io/openshift3/postgresql-apb \</span><br><span class="line">    registry.redhat.io/openshift3/registry-console \</span><br><span class="line">    registry.redhat.io/openshift3/snapshot-controller \</span><br><span class="line">    registry.redhat.io/openshift3/snapshot-provisioner \</span><br><span class="line">    registry.redhat.io/rhel7/etcd:3.2.22 \</span><br><span class="line">    registry.redhat.io/rhel7/etcd:3.2.26</span><br><span class="line"></span><br><span class="line">$ docker save -o ose3-optional-imags.tar \</span><br><span class="line">    registry.redhat.io/openshift3/metrics-cassandra \</span><br><span class="line">    registry.redhat.io/openshift3/metrics-hawkular-metrics \</span><br><span class="line">    registry.redhat.io/openshift3/metrics-hawkular-openshift-agent \</span><br><span class="line">    registry.redhat.io/openshift3/metrics-heapster \</span><br><span class="line">    registry.redhat.io/openshift3/metrics-schema-installer \</span><br><span class="line">    registry.redhat.io/openshift3/oauth-proxy \</span><br><span class="line">    registry.redhat.io/openshift3/ose-logging-curator5 \</span><br><span class="line">    registry.redhat.io/openshift3/ose-logging-elasticsearch5 \</span><br><span class="line">    registry.redhat.io/openshift3/ose-logging-eventrouter \</span><br><span class="line">    registry.redhat.io/openshift3/ose-logging-fluentd \</span><br><span class="line">    registry.redhat.io/openshift3/ose-logging-kibana5 \</span><br><span class="line">    registry.redhat.io/openshift3/prometheus \</span><br><span class="line">    registry.redhat.io/openshift3/prometheus-alertmanager \</span><br><span class="line">    registry.redhat.io/openshift3/prometheus-node-exporter \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-openshift-postgresql \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-openshift-memcached \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-openshift-app-ui \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-openshift-app \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-openshift-embedded-ansible \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-openshift-httpd \</span><br><span class="line">    registry.redhat.io/cloudforms46/cfme-httpd-configmap-generator \</span><br><span class="line">    registry.redhat.io/rhgs3/rhgs-server-rhel7 \</span><br><span class="line">    registry.redhat.io/rhgs3/rhgs-volmanager-rhel7 \</span><br><span class="line">    registry.redhat.io/rhgs3/rhgs-gluster-block-prov-rhel7 \</span><br><span class="line">    registry.redhat.io/rhgs3/rhgs-s3-server-rhel7 </span><br></pre></td></tr></table></figure><h2 id="小坑留意"><a href="#小坑留意" class="headerlink" title="小坑留意"></a>小坑留意</h2><ul><li>OpenShift官方文档中在同步YUM源时采用全量同步，这会导致光<code>rhel-7-server-rpms</code>这个源下载文件就有40G，下载时间长。其实只需要在同步YUM源时添加参数<code>-n</code>，只会下载最新的包，同样是<code>rhel-7-server-rpms</code>源，文件总共 是5G左右。</li><li>大家都知道的原因，国内网络下载很慢，所以可以购买一台（香港&#x2F;日本）云主机进行下载，再把介质压缩后，拷贝到本地。所有介绍压缩后，大概为11G。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openshift.com/container-platform/3.11/install/disconnected_install.html">OpenShift官方文档：Disconnected installation</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift使用HostPath挂载本地目录无权限</title>
      <link href="/openshift/OpenShift%E4%BD%BF%E7%94%A8HostPath%E6%8C%82%E8%BD%BD%E6%9C%AC%E5%9C%B0%E7%9B%AE%E5%BD%95%E6%97%A0%E6%9D%83%E9%99%90/"/>
      <url>/openshift/OpenShift%E4%BD%BF%E7%94%A8HostPath%E6%8C%82%E8%BD%BD%E6%9C%AC%E5%9C%B0%E7%9B%AE%E5%BD%95%E6%97%A0%E6%9D%83%E9%99%90/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: centos</span><br><span class="line">  namespace: monitor</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        busybox: &#x27;true&#x27;</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - args:</span><br><span class="line">          image: &#x27;centos:v2&#x27;</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: busybox</span><br><span class="line">          securityContext:</span><br><span class="line">            runAsUser: 1000</span><br><span class="line">            runAsGroup: 2000  #该特性在k8s 1.10之后才支持，本环境未支持，参见Support for RunAsGroup as a pod security context</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /centos</span><br><span class="line">              name: centos-volume</span><br><span class="line">      securityContext: &#123;&#125;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/hostname: test</span><br><span class="line">      volumes:</span><br><span class="line">        - hostPath:</span><br><span class="line">            path: /home/testHostPath</span><br><span class="line">          name: centos-volume</span><br><span class="line">      serviceAccountName: new-sa</span><br><span class="line">  triggers:</span><br><span class="line">    - type: ConfigChange</span><br></pre></td></tr></table></figure><p>host上&#x2F;home&#x2F;testHostPath的权限如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># ls -Z</span><br><span class="line">drwxr-xr-x. root root unconfined_u:object_r:home_root_t:s0 testHostPath</span><br></pre></td></tr></table></figure><p>进入容器,可以看到该文件夹已经挂载进去,但没有任何操作该文件夹的权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh-4.2$ cd /centos                                                                                                                                                                                                                 </span><br><span class="line">sh-4.2$ ls                                                                                                                                                                                                                         </span><br><span class="line">ls: cannot open directory .: Permission denied</span><br></pre></td></tr></table></figure><p>登陆该容器所在node节点，查看该容器的SELinux设置如下，显然创建的文件夹的SELinux与容器不匹配，将host上文件夹的SELinux设置为与容器相匹配。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect c21736278d1a|grep &quot;MountLabel&quot;</span><br><span class="line">        &quot;MountLabel&quot;: &quot;system_u:object_r:svirt_sandbox_file_t:s0:c15,c10&quot;,</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ chcon -Rt svirt_sandbox_file_t /testHostPath</span><br><span class="line">or </span><br><span class="line">$ chcon -R unconfined_u:object_r:svirt_sandbox_file_t:s0 /testHostPath</span><br><span class="line">or </span><br><span class="line">$ semanage fcontext -a -t svirt_sandbox_file_t &#x27;/testHostPath(/.*)?&#x27;</span><br><span class="line">$ restorecon -Rv /testHostPath</span><br><span class="line"># 确认设置 semanage fcontext -l | grep testHostPath</span><br><span class="line"># 确认文件生效 ls -Z /testHostPath</span><br></pre></td></tr></table></figure><p>解决完SELinux之后，查看该容器对应进程(docker inspect $CONTAINERID |grep Pid)的信息&#x2F;proc&#x2F;$PID&#x2F;status(具体含义参见<a href="http://man7.org/linux/man-pages/man5/proc.5.html">&#x2F;proc&#x2F;[pid]&#x2F;status</a>)。可以看到该容器使用的user id为1000，group id为0，supplemental groups为100023000。user id和supplemental groups(Groups)使用了所在project的默认值，group id(含fsgroup)则使用了0。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># cat /proc/23032/status</span><br><span class="line">......</span><br><span class="line">Uid:    1000    1000    1000    1000</span><br><span class="line">Gid:    0       0       0       0</span><br><span class="line">FDSize: 2048</span><br><span class="line">Groups: 1000230000</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.cnblogs.com/charlieroro/p/10830721.html">openshift scc解析</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift使用KeepAlived+LVS实现外部负载均衡器</title>
      <link href="/openshift/OpenShift%E4%BD%BF%E7%94%A8KeepAlived+LVS%E5%AE%9E%E7%8E%B0%E5%A4%96%E9%83%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"/>
      <url>/openshift/OpenShift%E4%BD%BF%E7%94%A8KeepAlived+LVS%E5%AE%9E%E7%8E%B0%E5%A4%96%E9%83%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>OpenShift集群资源列表</p><table><thead><tr><th>主机名</th><th>类型</th><th>IP</th></tr></thead><tbody><tr><td><strong>相关节点IP</strong></td><td></td><td></td></tr><tr><td>master0</td><td>master</td><td>192.168.0.2</td></tr><tr><td>master1</td><td>master</td><td>192.168.0.3</td></tr><tr><td>master2</td><td>master</td><td>192.168.0.4</td></tr><tr><td>infra0</td><td>infra</td><td>192.168.0.5</td></tr><tr><td>infra1</td><td>infra</td><td>192.168.0.6</td></tr><tr><td><strong>vip地址分配</strong></td><td></td><td></td></tr><tr><td>master-vip</td><td>vip</td><td>192.168.0.250</td></tr><tr><td>infra-vip</td><td>vip</td><td>192.168.0.251</td></tr></tbody></table><h2 id="部署Master-API负载均衡器作为集群内外访问的入口"><a href="#部署Master-API负载均衡器作为集群内外访问的入口" class="headerlink" title="部署Master API负载均衡器作为集群内外访问的入口"></a>部署Master API负载均衡器作为集群内外访问的入口</h2><ol><li>在三个Master节点安装KeepAlived与LVS<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible masters -m package -a <span class="string">&#x27;name=keepalived state=present&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible masters -m package -a <span class="string">&#x27;name=ipvsadm state=present&#x27;</span></span></span><br></pre></td></tr></table></figure></li><li>选择master0作为VIP的Master节点<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/keepalived/keepalived.conf</span><br><span class="line">global_defs &#123;</span><br><span class="line">   #指定keepalived在发生切换时需要发送email到的对象</span><br><span class="line">   notification_email &#123; </span><br><span class="line">      receiver@example.com    #邮件接收者</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from sender@example.com  #邮件发送者</span><br><span class="line">   smtp_server 127.0.0.1     #邮件服务器地址，如未安装，使用本地</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#IP漂移协议</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER   #指定A节点为主节点 备分机上设置为BACKUP即可</span><br><span class="line">    interface eth0  #绑定IP漂移的网络接口，在该接口上绑定VIP</span><br><span class="line">    virtual_router_id 51   #VRRP组名，三个节点的设置必须一样</span><br><span class="line">    priority 100   #优先级，同一个 vrrp_instance 的 MASTER 优先级必须比 BACKUP 高</span><br><span class="line">    advert_int 1   #MASTER 与 BACKUP 负载均衡器之间同步检查的时间间隔，单位为秒</span><br><span class="line">    authentication &#123;    # 设置认证</span><br><span class="line">        auth_type PASS    #认证方式，支持 PASS 和 HA</span><br><span class="line">        auth_pass 1111    #证密码为明文，同一 vrrp 实例 MASTER 与 BACKUP 使用相同的密码才能正常通信</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;    #虚拟IP地址(VIP)，可以有多个地址，每个地址占一行</span><br><span class="line">        192.168.0.250  #绑定VIP</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#只接收8443端口过来的请求</span><br><span class="line">virtual_server 192.168.232.206 8443 &#123;</span><br><span class="line">    delay_loop 6  # 服务健康检查周期，6秒</span><br><span class="line">    lb_algo wlc   # 负载均衡调度算法，一般用wrr、rr、wlc</span><br><span class="line">    lb_kind DR   # 负载均衡转发规则。一般包括DR,NAT,TUN 3种</span><br><span class="line">    nat_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 50   #会话保持时间。把用户请求请求间隔在未超过保持时间时，一直分发到某个服务节点</span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    #RS服务器1</span><br><span class="line">    real_server 192.168.0.2 8443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        #健康检查</span><br><span class="line">        TCP_CHECK &#123;     # 通过TcpCheck判断RealServer的健康状态</span><br><span class="line">            connect_timeout 10    # 连接超时时间</span><br><span class="line">            nb_get_retry 3            # 重连次数</span><br><span class="line">            delay_before_retry 3  # 重连时间间隔</span><br><span class="line">            connect_port 8443     # 检测端口</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    #RS服务器2</span><br><span class="line">    real_server 192.168.0.3 8443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        #健康检查</span><br><span class="line">        TCP_CHECK &#123;     # 通过TcpCheck判断RealServer的健康状态</span><br><span class="line">            connect_timeout 10    # 连接超时时间</span><br><span class="line">            nb_get_retry 3            # 重连次数</span><br><span class="line">            delay_before_retry 3  # 重连时间间隔</span><br><span class="line">            connect_port 8443     # 检测端口</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    #RS服务器2</span><br><span class="line">    real_server 192.168.0.4 8443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        #健康检查</span><br><span class="line">        TCP_CHECK &#123;     # 通过TcpCheck判断RealServer的健康状态</span><br><span class="line">            connect_timeout 10    # 连接超时时间</span><br><span class="line">            nb_get_retry 3            # 重连次数</span><br><span class="line">            delay_before_retry 3  # 重连时间间隔</span><br><span class="line">            connect_port 8443     # 检测端口</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>KeepAlive健康检查类型有五种：TCP_CHECK&#x2F;HTTP_GET&#x2F;SSL_GET&#x2F;MISC_CHECK&#x2F;SMTP_CHECK</li><li>TCP_CHECK：TCP端口是否能通<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TCP_CHECK &#123;     # 通过TcpCheck判断RealServer的健康状态</span><br><span class="line">    connect_timeout 10    # 连接超时时间</span><br><span class="line">    nb_get_retry 3        # 重连次数</span><br><span class="line">    delay_before_retry 3  # 重连时间间隔</span><br><span class="line">    connect_port 6500     # 检测端口</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>HTTP_GET：请求HTTP URL的Code是否为200<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">HTTP_GET &#123;</span><br><span class="line">    url &#123;</span><br><span class="line">      path /</span><br><span class="line">      status_code 200</span><br><span class="line">    &#125;</span><br><span class="line">    connect_timeout 3</span><br><span class="line">    nb_get_retry 3</span><br><span class="line">    delay_before_retry 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>SSL_GET：请求HTTPS URL的Code是否为200<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SSL_GET &#123;</span><br><span class="line">    url &#123;</span><br><span class="line">      path /</span><br><span class="line">      status_code 200</span><br><span class="line">    &#125;</span><br><span class="line">    connect_timeout 3</span><br><span class="line">    nb_get_retry 3</span><br><span class="line">    delay_before_retry 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>MISC_CHECK：脚本运行的返回码是否为0<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MISC_CHECK &#123;</span><br><span class="line">    misc_path &quot;/etc/keepalived/misc_check.sh https://192.168.0.2:6500/check_status&quot;    # 外部程序或者脚本的路径和参数</span><br><span class="line">    misc_timeout 10   # 脚本执行的超时时间</span><br><span class="line">    misc_dynamic    #动态权重标志。脚本返回0则检测成功权重不变，返回1表示失败权重设置为0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>SMTP_CHECK：SMTP健康检查器<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">SMTP_CHECK</span><br><span class="line">      &#123;</span><br><span class="line"># 用于smtp HELO请求的可选字符串</span><br><span class="line">helo_name hello</span><br><span class="line">host &#123;</span><br><span class="line"># 默认值为真实服务器的IP</span><br><span class="line">connect_ip 192.168.0.3</span><br><span class="line"># 默认值为25</span><br><span class="line">connect_port 25</span><br><span class="line">&#125;</span><br><span class="line"># 连接超时时间</span><br><span class="line">connect_timeout 5</span><br><span class="line"># 重试失败检查的次数</span><br><span class="line">retry 3</span><br><span class="line"># 重试前延迟秒</span><br><span class="line">delay_before_retry &lt;INTEGER&gt;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift使用MetalLB，打开了Service通向外界的大门</title>
      <link href="/openshift/OpenShift%E4%BD%BF%E7%94%A8MetalLB%EF%BC%8C%E6%89%93%E5%BC%80%E4%BA%86Service%E9%80%9A%E5%90%91%E5%A4%96%E7%95%8C%E7%9A%84%E5%A4%A7%E9%97%A8/"/>
      <url>/openshift/OpenShift%E4%BD%BF%E7%94%A8MetalLB%EF%BC%8C%E6%89%93%E5%BC%80%E4%BA%86Service%E9%80%9A%E5%90%91%E5%A4%96%E7%95%8C%E7%9A%84%E5%A4%A7%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-a8753cd21ceaccfd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1024" alt="MetalLB + OpenShift"></p><p>#背景<br>在K8S&#x2F;OpenShift中，如果要向集群外部暴露应用的服务，目前使用的方法有：NodePort、HostPort、Route、LoadBalancer、HostNetwork。</p><ul><li>Route：为最常用的方法，但是一般只支持7层负载（默认），使用一个外部LB来负载多个Route实例，对外的访问的IP为该LB的IP。</li><li>NodePort：在私有集群中也常用来暴露服务，但是它必须使用30000以上的端口，数量有限，不便于管理，而且对于一些特殊的服务，如DNS，必须使用小端口号，那么使用NodePort则无法满足。</li><li>HostNetwork：对于集群中的一些特殊服务使用该方式，它将容器与宿主机的网络绑定，如OpenShift中的Router服务就是使用HostNetwork与Router节点绑定。它的缺点是pod必须与主机绑定，同时每个Node上只能运行一个Pod实例，因为端口无法被复用。</li><li>HostPort：与HostNetwork类似，将Pod指定的端口与Node对应的端口绑定。</li><li>LoadBalancer：一般只在公有云平台使用，可以使Service获得与主机同一平面的IP，方便对服务进行控制与对外输出。缺点是依赖于公有云平台。</li></ul><p>从上可看出对于HTTP服务使用Route可以很方便地对外提供服务，而对于TCP&#x2F;UDP服务比较好的方式是使用LoadBalancer（当然HTTP服务也方便使用该方式），但是它依赖于云平台，有没有一种方式能够帮助集群在非IaaS平台上使用LoadBalancer方式呢？答案是有的，那就是Google的项目MetalLB。</p><h1 id="什么是MetalLB"><a href="#什么是MetalLB" class="headerlink" title="什么是MetalLB"></a>什么是MetalLB</h1><p>MetalLB的官方地址：<a href="https://metallb.universe.tf/">https://metallb.universe.tf/</a><br>MetalLB是使用标准路由协议的裸机Kubernetes&#x2F;OpenShift集群的软负载均衡器，可以在物理机环境下实现对Service服务分配IP。</p><h3 id="MetalLB支持两种申明模式："><a href="#MetalLB支持两种申明模式：" class="headerlink" title="MetalLB支持两种申明模式："></a>MetalLB支持两种申明模式：</h3><blockquote><ol><li>Layer 2模式：ARP&#x2F;NDP</li></ol></blockquote><p>Layer 2模式下，每个service会有集群中的一个node来负责。当服务客户端发起ARP解析的时候，对应的node会响应该ARP请求，之后，该service的流量都会指向该node（看上去该node上有多个地址）。</p><p>Layer 2模式并不是真正的负载均衡，因为流量都会先经过1个node后，再通过kube-proxy转给多个end points。如果该node故障，MetalLB会迁移 IP到另一个node，并重新发送免费ARP告知客户端迁移。现代操作系统基本都能正确处理免费ARP，因此failover不会产生太大问题。</p><p>Layer 2模式更为通用，不需要用户有额外的设备；但由于Layer 2模式使用ARP&#x2F;ND，地址池分配需要跟客户端在同一子网，地址分配略为繁琐。同时Layer 2模式所有流量会进入到一个Node，该Node的带宽可能会成为一个网络瓶颈。</p><blockquote><ol start="2"><li>BGP模式。</li></ol></blockquote><p>BGP模式下，集群中所有node都会跟上联路由器建立BGP连接，并且会告知路由器应该如何转发service的流量。</p><p>BGP模式是真正的LoadBalancer。</p><h3 id="MetalLB由两个组件组成："><a href="#MetalLB由两个组件组成：" class="headerlink" title="MetalLB由两个组件组成："></a>MetalLB由两个组件组成：</h3><ol><li>controller，负责IP地址的分配，以及service和endpoint的监听。</li><li>speaker，负责保证service地址可达，例如Layer 2模式下，speaker会负责ARP请求应答。</li></ol><h1 id="部署MetalLB"><a href="#部署MetalLB" class="headerlink" title="部署MetalLB"></a>部署MetalLB</h1><h2 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h2><ol><li>安装metalLB相关的应用<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.8.1/manifests/metallb.yaml</span><br></pre></td></tr></table></figure></li><li>创建configmap配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># cat &lt;&lt; EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  namespace: metallb-system</span><br><span class="line">  name: config</span><br><span class="line">data:</span><br><span class="line">  config: |</span><br><span class="line">    address-pools:</span><br><span class="line">    - name: default</span><br><span class="line">      protocol: layer2</span><br><span class="line">      addresses:</span><br><span class="line">      - 192.168.1.240-192.168.1.250</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ol><h2 id="OpenShift"><a href="#OpenShift" class="headerlink" title="OpenShift"></a>OpenShift</h2><ol><li>关闭OpenShift自带的LoadBalancer功能，这一步很重要，否则会跟<br><strong><code>删除</code></strong>&#x2F;etc&#x2F;origin&#x2F;master&#x2F;master-config.yaml中的<code>externalIPNetworkCIDRs</code>设置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">networkConfig:</span><br><span class="line">  externalIPNetworkCIDRs:</span><br><span class="line">  - 0.0.0.0/0</span><br></pre></td></tr></table></figure></li><li>下载MetalLB安装文件<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># wget https://raw.githubusercontent.com/google/metallb/v0.8.1/manifests/metallb.yaml</span><br></pre></td></tr></table></figure></li><li>删除将文件中DaemonSet资源中的配置<code>spec.template.spec.securityContext.runAsUser</code></li><li>添加权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc adm policy add-scc-to-user privileged -n metallb-system -z speaker</span></span><br></pre></td></tr></table></figure></li><li>运行安装<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc apply -f metallb.yaml</span></span><br></pre></td></tr></table></figure></li><li>创建configmap配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># cat &lt;&lt; EOF | kubectl apply -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  namespace: metallb-system</span><br><span class="line">  name: config</span><br><span class="line">data:</span><br><span class="line">  config: |</span><br><span class="line">    address-pools:</span><br><span class="line">    - name: default</span><br><span class="line">      protocol: layer2</span><br><span class="line">      addresses:</span><br><span class="line">      - 192.168.1.240-192.168.1.250</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ol><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><ol><li>对已有的一个应用创建新LoadBalancer类型的svc<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# oc expose dc/flask-app --name=metallb-app --type=LoadBalancer --port=5000</span><br></pre></td></tr></table></figure></li><li>查看当前svc的状态<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# oc get svc</span><br><span class="line">NAME        TYPE           CLUSTER-IP      EXTERNAL-IP                         PORT(S)          AGE</span><br><span class="line">flask-app   ClusterIP      172.30.193.89   &lt;none&gt;                              5000/TCP         35d</span><br><span class="line">metallb-app    LoadBalancer   172.30.7.121    192.168.1.240,172.29.114.1          5000:32276/TCP   6m</span><br></pre></td></tr></table></figure>其中service flask-app为之前创建的ClusterIP类型；service metallb-app为新建的LoadBalancer类型的服务，它带有一个由MetalLB控制器分配的一个IP <code>192.168.1.240</code>（另外还有一个OpenShift分配的一个额外IP 172.29.114.1，该IP可忽略）。</li><li>使用openshift集群外部的机器访问该应用<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@i-avler8qs ~]# curl http://192.168.1.240:5000</span><br><span class="line">Hello world v2</span><br></pre></td></tr></table></figure></li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在没有使用了LoadBalancer（如MetalLB）前，OpenShift上的Service像是待在这里的宠物，外部访问它非常受限；使用了LoadBalancer后，Service主动向外面世界敞开了怀抱，每个Service都绑定有一个独立的IP，方便外部应用访问，同时也方便使用传统的防火墙方式进行控制访问。<br>LoadBalancer扩大了对OpenShift&#x2F;Kubernetes集群使用的想象空间，而MetalLB无疑是性价比最高的方式。<br>#参考文章<br><a href="https://blog.fleeto.us/post/intro-metallb/">MetalLB - 贫苦 K8S 用户的负载均衡支持</a><br><a href="https://blog.gmem.cc/external-lb-for-on-premise-k8s-cluster">为裸金属K8S集群提供外部负载均衡器</a><br><a href="https://metallb.universe.tf/installation/clouds/#metallb-on-openshift-ocp">OpenShift上安装MetalLB</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift容器中读取Project信息</title>
      <link href="/openshift/OpenShift%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%AF%BB%E5%8F%96Project%E4%BF%A1%E6%81%AF/"/>
      <url>/openshift/OpenShift%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%AF%BB%E5%8F%96Project%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-b7bba590df40caf7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift容器中读取Project信息"></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在日常运维管理中，经常需要获取OpenShift集群资源的信息，甚至创建、编辑或删除资源。我们都很清楚，使用oc命令就能够非常方便地完成这些操作。但是有时，我们希望通过调用接口来实现，以便于与其它组件或者应用进行集成。那么我们该如何做呢？本篇就以读取Project信息为例，展示如何通过HTTP请求操作OpenShift的资源。</p><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><ol><li>首先需要创建具有读取Project信息权限的clusterrole project_view<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: authorization.openshift.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: project_view</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - project.openshift.io</span><br><span class="line">  resources:</span><br><span class="line">  - projects</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>为需要调用的应用POD添加获取Project信息的权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm policy add-cluster-role-to-user project_view -z default</span></span><br></pre></td></tr></table></figure>为所有应用授予获取Project信息的权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm policy add-cluster-role-to-group project_view system:serviceaccounts</span></span><br></pre></td></tr></table></figure></li><li>通过发送serviceaccount认证信息，应用Pod实例中便可通过HTTP请求获取Project信息<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ TOKEN=$(cat /run/secrets/kubernetes.io/serviceaccount/token)</span><br><span class="line">$ CACERT=/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">$ PROJECT_OBJ=$(curl -s -H &quot;Authorization: bearer $TOKEN&quot;) --caert $CACERT https://openshift.default.svc/api/project.openshift.io/v1/projects/$NAMESPACE)</span><br><span class="line">$ PROJEXT_UUID=$(echo $PROJECT_OJB | jq --raw-output .metadata.uid)</span><br></pre></td></tr></table></figure></li><li>完成</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift存储管理方案——Rook</title>
      <link href="/openshift/OpenShift%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E6%96%B9%E6%A1%88%E2%80%94%E2%80%94Rook/"/>
      <url>/openshift/OpenShift%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E6%96%B9%E6%A1%88%E2%80%94%E2%80%94Rook/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-8ce18f984167b389.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift Rook"></p><h2 id="存储的重要意义"><a href="#存储的重要意义" class="headerlink" title="存储的重要意义"></a>存储的重要意义</h2><p>存储资源是容器云平台中的一个核心基础设施，为不同的应用服务提供可靠的持久化服务。<br>大家都知道，容器运行过程中产生的数据是临时数据，并不可靠，一旦容器挂了，这些数据都会丢失。所以对数据可靠性有要求的应用就必须使用存储资源。<br>存储的方案有很多种，常用的有本地盘存储、NFS、Ceph、Gluster FS等等。其中Ceph是一个开源的分布式文件系统，同时支持对象存储、块存储、文件存储,为云计算平台提供了最全面的存储方案。它以可靠、高性能等特性得到了很多企业的认可，并使用它来作为生产环境的存储。<br>但是运维Ceph存储集群是一件较复杂工作，通过Rook项目，我们可以非常方便简单地实施Ceph存储方案，并且已有企业使用Rook来运维生产级别的存储方案。</p><h2 id="Rook：CNCF云原生存储项目"><a href="#Rook：CNCF云原生存储项目" class="headerlink" title="Rook：CNCF云原生存储项目"></a>Rook：CNCF云原生存储项目</h2><p>Rook于2018年1月加入了CNCF，成为了CNCF第15个项目，同时它也是CNCF首个云原生存储项目。Rook并不是自己开发一套存储方案，而是将现有的分布式存储系统云原生化，让它们能够实现自我管理，自我扩展，自我修复。 它使存储管理员的任务自动化：部署，引导，配置，配置，扩展，升级，迁移，灾难恢复，监视和资源管理。大大降低了存储系统的运维门槛，大大减少了维护成本。</p><p>Rook支持多种存储系统服务</p><ul><li>Ceph（v1）</li><li>EdgeFS（v1）</li><li>Minio（Alpha）</li><li>CockroachDB（Alpha）</li><li>Cassandra（Alpha）</li><li>NFS（Alpha）</li><li>Yugabyte DB（Alpha）</li></ul><p>Rook的特性</p><ul><li>简单可靠的自动化资源管理</li><li>超大规模或超融合存储集群</li><li>高效地分发和复制数据以最大程度地减少损失</li><li>通过多个存储提供程序配置，文件，阻止和对象</li><li>管理开源存储技术</li><li>轻松地在数据中心中启用弹性存储</li><li>根据Apache 2.0许可发布的开源软件</li><li>优化商品硬件上的工作负载</li></ul><p>以下是Rook在Kubernetes上部署的架构<br><img src="https://upload-images.jianshu.io/upload_images/5793257-dd152f18f3d207cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Rook与K8S"></p><h2 id="OpenShift-容器平台部署Rook"><a href="#OpenShift-容器平台部署Rook" class="headerlink" title="OpenShift 容器平台部署Rook"></a>OpenShift 容器平台部署Rook</h2><p>OpenShift是红帽开发的K8S的企业级方案，它为原生K8S增加了许多安全及其他特性，特别是约束了运行中的Pod的权限。在部署与使用Rook时，需要允许应用拥有这些权限。</p><blockquote><ol><li>下载部署需要的代码</li></ol></blockquote><p>代码所在地址：<a href="https://github.com/rook/rook/blob/release-1.1/cluster/examples/kubernetes/ceph">https://github.com/rook/rook/blob/release-1.1/cluster/examples/kubernetes/ceph</a></p><ul><li>common.yaml：创建Namespace、CRD、Role、RoleBinding、ClusterRole、ClusterRoleBinding、PodSecurityPolicy、ServiceAccount</li><li>operator-openshift.yaml: 创建SCC以及完成Rook Operator部署</li><li>cluster.yaml：创建CephCluster</li><li>object-openshift.yaml: 使用rgw创建对象存储，并设置对象存储服务对外的端口</li></ul><blockquote><ol start="2"><li>修改operator-openshift.yaml文件</li></ol></blockquote><ul><li>将ROOK_ENABLE_FLEX_DRIVER设置为true</li><li>将FLEXVOLUME_DIR_PATH值设置为&#x2F;usr&#x2F;libexec&#x2F;kubernetes&#x2F;kubelet-plugins&#x2F;volume&#x2F;exec</li></ul><blockquote><ol start="3"><li>修改cluster.yaml指定OSD主机及目录&#x2F;盘符，以下列出了三种配置方式，可任意搭配。</li></ol></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">storage: </span><br><span class="line">    useAllNodes: false</span><br><span class="line">    useAllDevices: false</span><br><span class="line">    topologyAware: true</span><br><span class="line">    deviceFilter:</span><br><span class="line">    location:</span><br><span class="line">    config:</span><br><span class="line">      nodes:</span><br><span class="line">      - name: &quot;172.17.4.101&quot;</span><br><span class="line">        directories: </span><br><span class="line">        - path: &quot;/rook/storage-dir&quot;</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">            memory: &quot;1024Mi&quot;</span><br><span class="line">          requests:</span><br><span class="line">            cpu: &quot;500m&quot;</span><br><span class="line">            memory: &quot;1024Mi&quot;</span><br><span class="line">      - name: &quot;172.17.4.201&quot;</span><br><span class="line">        devices: </span><br><span class="line">        - name: &quot;sdb&quot;</span><br><span class="line">        - name: &quot;nvme01&quot; </span><br><span class="line">          config:</span><br><span class="line">            osdsPerDevice: &quot;5&quot;</span><br><span class="line">        config: </span><br><span class="line">          storeType: filestore</span><br><span class="line">      - name: &quot;172.17.4.301&quot;</span><br><span class="line">        deviceFilter: &quot;^sd.&quot;</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>部署安装rook</li></ol></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f common.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f operator-openshift.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f cluster.yaml</span></span><br></pre></td></tr></table></figure><p>完成部署好后，在rook-ceph Project下将会创建对应的资源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get  all -n rook-ceph</span></span><br><span class="line">NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">service/rook-ceph-mgr             ClusterIP   172.30.21.61     &lt;none&gt;        9283/TCP            17h</span><br><span class="line">service/rook-ceph-mgr-dashboard   ClusterIP   172.30.243.194   &lt;none&gt;        8443/TCP            17h</span><br><span class="line">service/rook-ceph-mon-a           ClusterIP   172.30.61.7      &lt;none&gt;        6789/TCP,3300/TCP   17h</span><br><span class="line">service/rook-ceph-mon-b           ClusterIP   172.30.22.104    &lt;none&gt;        6789/TCP,3300/TCP   17h</span><br><span class="line">service/rook-ceph-mon-c           ClusterIP   172.30.29.27     &lt;none&gt;        6789/TCP,3300/TCP   17h</span><br><span class="line"></span><br><span class="line">NAME                             DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/rook-ceph-agent   9         6         6         6            6           &lt;none&gt;          14h</span><br><span class="line">daemonset.apps/rook-discover     9         6         6         6            6           &lt;none&gt;          14h</span><br><span class="line"></span><br><span class="line">NAME                                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/rook-ceph-mgr-a      1         1         1            1           17h</span><br><span class="line">deployment.apps/rook-ceph-mon-a      1         1         1            1           17h</span><br><span class="line">deployment.apps/rook-ceph-mon-b      1         1         1            1           17h</span><br><span class="line">deployment.apps/rook-ceph-mon-c      1         1         1            1           17h</span><br><span class="line">deployment.apps/rook-ceph-operator   1         1         1            1           1d</span><br><span class="line">deployment.apps/rook-ceph-osd-0      1         1         1            1           17h</span><br><span class="line">deployment.apps/rook-ceph-osd-1      1         1         1            1           15h</span><br></pre></td></tr></table></figure><blockquote><ol start="4"><li>为Ceph Dashboard创建Route</li></ol></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: rook-ceph-mgr</span><br><span class="line">    rook_cluster: rook-ceph</span><br><span class="line">  name: rook-ceph-mgr-dashboard</span><br><span class="line">  namespace: rook-ceph</span><br><span class="line">spec:</span><br><span class="line">  host: dashboard-rook.apps.example.com</span><br><span class="line">  port:</span><br><span class="line">    targetPort: https-dashboard</span><br><span class="line">  tls:</span><br><span class="line">    termination: passthrough</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: rook-ceph-mgr-dashboard</span><br><span class="line">    weight: 100</span><br><span class="line">  wildcardPolicy: None</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">oc get route</span></span></span><br><span class="line">NAME                      HOST/PORT                               SERVICES                  PORT              TERMINATION </span><br><span class="line">rook-ceph-mgr-dashboard   dashboard-rook.apps.ceshi.fenhang.com   rook-ceph-mgr-dashboard   https-dashboard   passthrough</span><br></pre></td></tr></table></figure><p>此时便可通过浏览器访问Ceph Dashboard页面，查看Ceph集群状态</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-ef112feb7537765d.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="ceph-dashboard"></p><blockquote><ol start="5"><li>创建Ceph Block Pool及storageclass</li></ol></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: ceph.rook.io/v1</span><br><span class="line">kind: CephBlockPool</span><br><span class="line">metadata:</span><br><span class="line">  name: replicapool</span><br><span class="line">  namespace: rook-ceph</span><br><span class="line">spec:</span><br><span class="line">  failureDomain: host</span><br><span class="line">  replicated:</span><br><span class="line">    size: 3</span><br><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">   name: rook-ceph-block</span><br><span class="line">provisioner: ceph.rook.io/block</span><br><span class="line">parameters:</span><br><span class="line">  blockPool: replicapool</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="string">设置为rook cluster operator所在的namespace</span></span></span><br><span class="line">  clusterNamespace: rook-ceph</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="string">文件系统，默认是ext4</span></span></span><br><span class="line">  fstype: xfs</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">reclaimPolicy，默认是&quot;Delete&quot;，可以设置为&quot;Retain&quot;,&quot;Recycle&quot;</span></span> </span><br><span class="line">reclaimPolicy: Retain</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string"> Kubernetes 1.14+支持Resize功能，只支持ext3, ext4, xfs类型</span></span></span><br><span class="line">allowVolumeExpansion: true</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>至此完成了通过Rook部署Ceph集群，并创建了相应的StorageClass，该StorageClass便可以为应用提供使用。<br>如果需要对Ceph集群扩容，只需要更新CephCluster的配置，在<code>storage</code>项中添加新加入的目录或磁盘（生产上建议不要使用目录），Rook Operator将会自动将它加入到集群，实现集群的扩容。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f1fd1ec3baead320.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Rook架构"></p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://rook.io/">Rook官网</a><br><a href="https://rook.io/docs/rook/v1.1/openshift.html">Rook 文档OpenShift</a><br><a href="https://rook.io/docs/rook/v1.1/ceph-storage.html">Rook文档——Ceph存储</a><br><a href="https://rook.io/docs/rook/v1.1/ceph-block.html#flex-driver">Rook文档-Ceph Block</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift应用补丁检查与升级</title>
      <link href="/openshift/OpenShift%E5%BA%94%E7%94%A8%E8%A1%A5%E4%B8%81%E6%A3%80%E6%9F%A5%E4%B8%8E%E5%8D%87%E7%BA%A7/"/>
      <url>/openshift/OpenShift%E5%BA%94%E7%94%A8%E8%A1%A5%E4%B8%81%E6%A3%80%E6%9F%A5%E4%B8%8E%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<p>OpenShift版本补丁查看：<a href="https://docs.openshift.com/container-platform/3.11/release_notes/ocp_3_11_release_notes.html">https://docs.openshift.com/container-platform/3.11/release_notes/ocp_3_11_release_notes.html</a></p><h2 id="自动查看新增的补丁版本脚本-96-96-96-coding-utf-8-“””"><a href="#自动查看新增的补丁版本脚本-96-96-96-coding-utf-8-“””" class="headerlink" title="自动查看新增的补丁版本脚本&#96;&#96;&#96;# -- coding: utf-8 --“””"></a>自动查看新增的补丁版本脚本<br>&#96;&#96;&#96;<br># -<em>- coding: utf-8 -</em>-<br>“””</h2><h2 id="File-Name：-get-update-v3-11"><a href="#File-Name：-get-update-v3-11" class="headerlink" title="   File Name：     get_update_v3.11"></a>   File Name：     get_update_v3.11</h2><p>“””</p><p>last_index&#x3D;”RHSA-2020:2992”</p><p>last_flag &#x3D; False</p><p>import requests<br>from pyquery import PyQuery</p><p>url&#x3D;”<a href="https://docs.openshift.com/container-platform/3.11/release_notes/ocp_3_11_release_notes.html">https://docs.openshift.com/container-platform/3.11/release_notes/ocp_3_11_release_notes.html</a>“</p><p>content&#x3D;requests.get(url)<br>query_doc &#x3D; PyQuery(content.content)(“.sectlevel2:eq(2) li”).items()</p><p>for update_item in query_doc:<br>    if not last_flag:<br>        item_text &#x3D; update_item.text()<br>        if item_text.find(last_index) &gt; -1:<br>            last_flag &#x3D; True<br>        continue</p><pre><code>print(update_item.text())</code></pre><hr><p>RHBA-2020:3245 - OpenShift Container Platform 3.11.272 bug fix update<br>RHSA-2020:3541 - Important: OpenShift Container Platform security update<br>RHBA-2020:3695 - OpenShift Container Platform 3.11.286 bug fix update<br>RHSA-2020:3727 - Moderate: OpenShift Container Platform security update<br>RHBA-2020:4170 - OpenShift Container Platform 3.11.306 bug fix update<br>RHSA-2020:4223 - Important: OpenShift Container Platform security update<br>RHBA-2020:4430 - OpenShift Container Platform 3.11.317 bug fix update<br>RHBA-2020:5107 - OpenShift Container Platform 3.11.318 bug fix update<br>RHSA-2020:5102 - Moderate: OpenShift Container Platform security update<br>RHSA-2020:5363 - OpenShift Container Platform 3.11.346 security and bug fix update</p><pre><code>软件包：https://access.redhat.com/downloads/content/package-browser</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift容器云平台建设之部署前准备</title>
      <link href="/openshift/OpenShift%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E4%B9%8B%E9%83%A8%E7%BD%B2%E5%89%8D%E5%87%86%E5%A4%87/"/>
      <url>/openshift/OpenShift%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E4%B9%8B%E9%83%A8%E7%BD%B2%E5%89%8D%E5%87%86%E5%A4%87/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-c40c813c3fff22d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift"></p><p>在企业级部署OpenShift前，需要先考虑以下几个问题：</p><ol><li>使用的主机架构是什么?IBM Power还是x86。</li><li>集群多大的容量，运行多少个Pod?</li></ol><table><thead><tr><th>Limit Type</th><th>3.7 Limit</th><th>3.9 Limit</th><th>3.10 Limit</th><th>3.11 Limit</th></tr></thead><tbody><tr><td>节点数 <sup>[<a href="https://docs.openshift.com/container-platform/3.11/scaling_performance/cluster_limits.html#_footnotedef_1" title="View footnote.">1</a>]</sup></td><td>2,000</td><td>2,000</td><td>2,000</td><td>2,000</td></tr><tr><td>pod数 <sup>[<a href="https://docs.openshift.com/container-platform/3.11/scaling_performance/cluster_limits.html#_footnotedef_2" title="View footnote.">2</a>]</sup></td><td>120,000</td><td>120,000</td><td>150,000</td><td>150,000</td></tr><tr><td><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/manage_nodes.html#admin-guide-max-pods-per-node">每台节点支持的pod数</a></td><td>250</td><td>250</td><td>250</td><td>250</td></tr><tr><td><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/manage_nodes.html#admin-guide-max-pods-per-node">每核支持的pod数</a></td><td>默认为10. 最大值为主机支持的pod数</td><td>默认为10. 最大值为主机支持的pod数</td><td>无默认值. 最大值为主机支持的pod数</td><td>无默认值. 最大值为主机支持的pod数</td></tr><tr><td>namespaces数量</td><td>10,000</td><td>10,000</td><td>10,000</td><td>10,000</td></tr><tr><td>Pipeline构建策略数量</td><td>N&#x2F;A</td><td>10,000 (默认pod内存为512Mi)</td><td>10,000 (默认pod内存为512Mi)</td><td>10,000 (默认pod内存为512Mi)</td></tr><tr><td>每个namespace下创建的pod数 <sup>[<a href="https://docs.openshift.com/container-platform/3.11/scaling_performance/cluster_limits.html#_footnotedef_3" title="View footnote.">3</a>]</sup></td><td>3,000</td><td>3,000</td><td>3,000</td><td>25,000</td></tr><tr><td>services数 <sup>[<a href="https://docs.openshift.com/container-platform/3.11/scaling_performance/cluster_limits.html#_footnotedef_4" title="View footnote.">4</a>]</sup></td><td>10,000</td><td>10,000</td><td>10,000</td><td>10,000</td></tr><tr><td>每个namespace下创建的services数</td><td>N&#x2F;A</td><td>N&#x2F;A</td><td>5,000</td><td>5,000</td></tr><tr><td>每个service的back-ends数</td><td>5,000</td><td>5,000</td><td>5,000</td><td>5,000</td></tr><tr><td>每个namespace下创建的deployments数<sup>[<a href="https://docs.openshift.com/container-platform/3.11/scaling_performance/cluster_limits.html#_footnotedef_3" title="View footnote.">3</a>]</sup></td><td>2,000</td><td>2,000</td><td>2,000</td><td>2,000</td></tr><tr><td>另外根据部署的目标确定集群的节点数与节点配置。</td><td></td><td></td><td></td><td></td></tr><tr><td>3. 集群部署多少台主机，使用什么架构部署？多Master多Node，还是一个Master多Node，或者All in One?</td><td></td><td></td><td></td><td></td></tr><tr><td>4. 是否需要高可用集群？</td><td></td><td></td><td></td><td></td></tr><tr><td>5. 是否安装集群监控？这会消耗系统资源，默认是安装的。</td><td></td><td></td><td></td><td></td></tr><tr><td>6. 使用哪种账号认证体系？htpasswd，openldap，openid等。</td><td></td><td></td><td></td><td></td></tr><tr><td>7. 与其它应用集成时，<a href="https://access.redhat.com/articles/2176281">兼容性查看地址</a></td><td></td><td></td><td></td><td></td></tr><tr><td>8. service常用的有两种技术：iptables与ipvs。如果集群中serive总数量为1000以下，endpoints为20000以下，则推荐使用iptables，否则推荐使用ipvs。</td><td></td><td></td><td></td><td></td></tr></tbody></table><p>来自以下文章：<br><a href="https://docs.openshift.com/container-platform/3.11/install/index.html">OpenShift官方文档——准备安装</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift强大的oc-set命令详解</title>
      <link href="/openshift/OpenShift%E5%BC%BA%E5%A4%A7%E7%9A%84oc-set%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
      <url>/openshift/OpenShift%E5%BC%BA%E5%A4%A7%E7%9A%84oc-set%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-c40c813c3fff22d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/960/format/webp" alt="OpenShift"></p><p>OpenShift的client工具oc功能非常强大，几乎能实现所有的操作，它的每一个子命令都能实现非常多的功能。其中有个容易被忽视却很强大的子命令oc set可以实现对资源很多额外的配置，包括有环境变量、资源限制、持久化卷挂载、健康检查等等。<br>下面是oc set的帮助详情。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc set</span><br><span class="line">Configure application resources</span><br><span class="line">Usage:</span><br><span class="line">  oc set COMMAND [flags]</span><br><span class="line"></span><br><span class="line">Replication controllers, deployments, and daemon sets:</span><br><span class="line">  env             Update environment variables on a pod template</span><br><span class="line">  resources       Update resource requests/limits on objects with pod templates</span><br><span class="line">  volumes         Update volumes on a pod template</span><br><span class="line">  probe           Update a probe on a pod template</span><br><span class="line">  deployment-hook Update a deployment hook on a deployment config</span><br><span class="line">  image           Update image of a pod template</span><br><span class="line"></span><br><span class="line">Manage secrets:</span><br><span class="line">  build-secret    Update a build secret on a build config</span><br><span class="line"></span><br><span class="line">Manage application flows:</span><br><span class="line">  image-lookup    Change how images are resolved when deploying applications</span><br><span class="line">  triggers        Update the triggers on one or more objects</span><br><span class="line">  build-hook      Update a build hook on a build config</span><br><span class="line"></span><br><span class="line">Control load balancing:</span><br><span class="line">  route-backends  Update the backends for a route</span><br><span class="line"></span><br><span class="line">Use &quot;oc set &lt;command&gt; --help&quot; for more information about a given command.</span><br><span class="line">Use &quot;oc options&quot; for a list of global command-line options (applies to all commands).</span><br></pre></td></tr></table></figure><h2 id="环境变量-oc-set-env"><a href="#环境变量-oc-set-env" class="headerlink" title="环境变量 oc set env"></a>环境变量 <code>oc set env</code></h2><ol><li>列出sample dc设置的环境变量<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env dc/sample --list  # 列出sample dc设置的环境变量</span><br></pre></td></tr></table></figure></li><li>为sample dc设置环境变量NAME&#x3D;value<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env dc/sample NAME=value # 为sample dc设置环境变量NAME=value</span><br></pre></td></tr></table></figure></li><li>从secret mysecret中向sample dc导入环境变量<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env --from=secret/mysecret dc/sample #从secret mysecret中向sample dc导入环境变量</span><br></pre></td></tr></table></figure></li><li>从configmap myconfigmap中筛选出前缀为MYSQL_的变量向sample dc中导入为环境变量<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env --from=configmap/myconfigmap --prefix=MYSQL_ dc/sample #从configmap myconfigmap中筛选出前缀为MYSQL_的变量向sample dc中导入为环境变量</span><br></pre></td></tr></table></figure></li><li>删除sample dc中的名为NAME的环境变量<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set env dc/sample NAME- #删除sample dc中的名为NAME的环境变量</span><br></pre></td></tr></table></figure></li></ol><h2 id="资源限制-oc-set-resources"><a href="#资源限制-oc-set-resources" class="headerlink" title="资源限制 oc set resources"></a>资源限制 <code>oc set resources</code></h2><ol><li>为dc&#x2F;sample中的容器设置内存限制<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set resources dc/sample --limits=memory=2Gi --requests=memory=1Gi</span><br></pre></td></tr></table></figure></li><li>给sample dc中的所有容器设置资源cpu和memory限制<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set resources dc/sample --limits=cpu=200m,memory=2Gi --requests=cpu=100m,memory=1Gi #给sample dc中的所有容器设置资源cpu和memory限制</span><br></pre></td></tr></table></figure></li><li>给sample dc中的nginx容器设置资源cpu和memory限制<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set resources dc/sample -c=nginx --limits=cpu=200m,memory=2Gi --requests=cpu=100m,memory=1Gi #给sample dc中的nginx容器设置资源cpu和memory限制</span><br></pre></td></tr></table></figure></li><li>删除sample dc资源限制配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set resources dc/sample --limits=cpu=0,memory=0 --requests=cpu=0,memory=0 #删除资源限制配置</span><br></pre></td></tr></table></figure></li><li>不执行更新，只显示修改的配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set resources dc/sample --limits=cpu=200m,memory=512Mi -o yaml #不执行更新，只显示修改的配置</span><br></pre></td></tr></table></figure></li></ol><h2 id="挂载点-oc-set-volumes"><a href="#挂载点-oc-set-volumes" class="headerlink" title="挂载点 oc set volumes"></a>挂载点 <code>oc set volumes</code></h2><ol><li>查看sample dc的挂载点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample</span></span><br></pre></td></tr></table></figure></li><li>查看当前项目下的所有dc的挂载点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc --all</span></span><br></pre></td></tr></table></figure></li><li>给sample dc创建一个挂载点&#x2F;data，挂载emptyDir<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --add --mount-path=/data</span></span><br></pre></td></tr></table></figure></li><li>使用一个现有的名为pvc1的pvc挂载到名为v1的挂载点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --add --name=v1 -t pvc --claim-name=pvc1 --overwrite</span></span><br></pre></td></tr></table></figure></li><li>删除sample dc中名为v1的挂载点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --remove --name=v1</span></span><br></pre></td></tr></table></figure></li><li>新建一个pvc挂载到sample dc中名为v1的挂载点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --add --name=v1 -t pvc --claim-size=1G --overwrite</span></span><br></pre></td></tr></table></figure></li><li>更改名为v1的挂载点对应在sample dc中的目录为&#x2F;data2<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --add --name=v1 -m /data2 --overwrite</span></span><br></pre></td></tr></table></figure></li><li>删除sample dc中的nginx容器中名为v1的挂载点<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --remove --name=v1 --containers=nginx</span></span><br></pre></td></tr></table></figure></li><li>将configmap中的nginx.conf配置挂载到&#x2F;data&#x2F;nginx.config文件中<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volumes dc/sample --add --name=v1 --mount-path=/data/nginx.conf --<span class="built_in">type</span>=configmap --configmap-name=nginx --sub-path=nginx.conf</span></span><br></pre></td></tr></table></figure>另外还有一些常用的参数<br>–claim-name：指定pvc的名字<br>–claim-class：指定pvc使用的StorageClass名<br>–claim-mode：指定pvc访问类型，默认为ReadWriteOnce(rwo)，另外还有ReadWriteMany(rwm)和ReadOnlyMany(rom)<br>–default-mode：挂载目录的权限，默认为0644，必须在0000和0777之间取值<br>–configmap-name：挂载到挂载点的configmap名，必须设置挂载类型为configmap<br>–secret-name：挂载到挂载点的secret名，必须设置挂载类型为secret<br>–sub-path：只挂载指定的子目录<br>–path：本地主机路径，必须设置挂载类型为hostPath<br>–type：挂载类型，emptyDir，hostPath，secret，configmap</li></ol><h2 id="健康检查-oc-set-probe"><a href="#健康检查-oc-set-probe" class="headerlink" title="健康检查 oc set probe"></a>健康检查 <code>oc set probe</code></h2><ol><li>给sample dc添加liveness检查<code>shell</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> probe dc/sample --liveness --failure-threshold 3 --initial-delay-seconds 40 -- <span class="built_in">echo</span> ok</span></span><br></pre></td></tr></table></figure></li><li>给sample dc添加readiness检查<code>HTTP</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc set probe dc/sample --readiness --failure-threshold 3 --initial-delay-seconds 20 --get-url=http://:9000/about</span><br></pre></td></tr></table></figure></li><li>给sample dc添加readiness检查<code>TCP</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> probe dc/sample --readiness --open-tcp=3306</span></span><br></pre></td></tr></table></figure></li><li>设置readiness的初始检查延时时间30s，超时时间为3s<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> probe dc/sample --readiness --initial-delay-seconds=30 --<span class="built_in">timeout</span>=3</span></span><br></pre></td></tr></table></figure></li><li>删除rediness和liveness检查<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> probe dc/sample --remove --readiness --liveness</span></span><br></pre></td></tr></table></figure>另外还有一些常用的参数<br>–period-seconds：默认为10，两次检查间隔时长，单位为s<br>–success-threshold：默认为1，检查成功次数达到1次，才会触发成功处理操作<br>–failure-threshold：默认为3，检查失败次数达到3次，才会触发失败处理操作</li></ol><h2 id="设置Deploymentconfig钩子-oc-set-deployment-hook"><a href="#设置Deploymentconfig钩子-oc-set-deployment-hook" class="headerlink" title="设置Deploymentconfig钩子 oc set deployment-hook"></a>设置Deploymentconfig钩子 <code>oc set deployment-hook</code></h2><ol><li>为sample dc中的strategy设置pre钩子<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> deployment-hook dc/sample --container=sample --pre -v data -- /var/lib/migrate-db.sh</span></span><br></pre></td></tr></table></figure></li><li>为sample dc中的strategy设置mid钩子<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> deployment-hook dc/sample --mid -v data -e VAR1=value1 -e VAR2=value2 -- /var/lib/prepare-deploy.sh</span></span><br></pre></td></tr></table></figure></li><li>删除sample dc的pre、mid及post的钩子<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> deployment-hook dc/sample --remove --pre --mid --post</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="更新镜像-oc-set-image"><a href="#更新镜像-oc-set-image" class="headerlink" title="更新镜像 oc set image"></a>更新镜像 <code>oc set image</code></h2><ol><li>为sample dc中的容器sample1设置镜像sample1:v2，为容器sampel2设置镜像sample2:v2<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  oc <span class="built_in">set</span> image dc/sample sample1=sample1:v2 sample2=sample2:v2</span></span><br></pre></td></tr></table></figure></li><li>为sample dc中的容器app设置镜像为imagestream tag sample&#x2F;ruby:2.3<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  oc <span class="built_in">set</span> image dc/sample app=sample/ruby:2.3 --<span class="built_in">source</span>=imagestreamtag</span></span><br></pre></td></tr></table></figure></li><li>为所有dc中的容器sample设置镜像为sample:v2<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  oc <span class="built_in">set</span> image dc sample=sample:v2 --all</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="设置BuildConfig的拉取-x2F-推送镜像、拉取代码的密钥-oc-set-build-secret"><a href="#设置BuildConfig的拉取-x2F-推送镜像、拉取代码的密钥-oc-set-build-secret" class="headerlink" title="设置BuildConfig的拉取&#x2F;推送镜像、拉取代码的密钥 oc set build-secret"></a>设置BuildConfig的拉取&#x2F;推送镜像、拉取代码的密钥 <code>oc set build-secret</code></h2><ol><li>设置samplebuild bc的拉取镜像的密钥dockerhubsecret<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> build-secret --pull bc/samplebuild dockerhubsecret</span></span><br></pre></td></tr></table></figure></li><li>设置samplebuild bc的推送镜像的密钥dockerhubsecret<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> build-secret --push --pull bc/samplebuild dockerhubsecret</span></span><br></pre></td></tr></table></figure></li><li>设置samplebuild bc的拉取代码的密钥githubsecret<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> build-secret --<span class="built_in">source</span>  bc/samplebuild  githubsecret</span></span><br></pre></td></tr></table></figure></li><li>删除sample bc设置的推送镜像密钥<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  oc <span class="built_in">set</span> build-secret --push --remove bc/sample</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="设置触发器-oc-set-triggers"><a href="#设置触发器-oc-set-triggers" class="headerlink" title="设置触发器 oc set triggers"></a>设置触发器 <code>oc set triggers</code></h2><ol><li>列出sample dc当前的触发器<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> triggers dc/sample</span></span><br></pre></td></tr></table></figure></li><li>关闭sample dc所有的自动触发器<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> triggers dc/sample --manual</span></span><br></pre></td></tr></table></figure></li><li>开启sample dc所有的自动触发器<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> triggers dc/sample --auto</span></span><br></pre></td></tr></table></figure></li><li>更新sample bc的github触发器的密钥值<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> triggers bc/sample --from-github</span></span><br></pre></td></tr></table></figure></li><li>删除sample bc的所有触发器<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  oc <span class="built_in">set</span> triggers bc/sample --remove-all</span></span><br></pre></td></tr></table></figure></li><li>删除sample dc的ConfigChange触发器<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> triggers dc/sample --from-config --remove</span></span><br></pre></td></tr></table></figure></li><li>更新sample bc的ImageStreamTag触发器的镜像Tag为test&#x2F;sample:latest<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> triggers bc/sample --from-image=<span class="built_in">test</span>/sample:latest</span></span><br></pre></td></tr></table></figure></li><li>更新sample dc容器sample的ImageStreamTag触发器的镜像Tag为test&#x2F;sample:latest<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> triggers dc/sample --from-image=<span class="built_in">test</span>/sample:latest -c sample</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="设置BuildConfig的postcommit钩子-oc-set-build-hook"><a href="#设置BuildConfig的postcommit钩子-oc-set-build-hook" class="headerlink" title="设置BuildConfig的postcommit钩子 oc set build-hook"></a>设置BuildConfig的postcommit钩子 <code>oc set build-hook</code></h2><ol><li>设置samplebuild bc的command类型的post-commit<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> build-hook bc/samplebuild --post-commit --<span class="built_in">command</span> -- /bin/bash -c /var/lib/test-image.sh</span></span><br></pre></td></tr></table></figure></li><li>设置samplebuild bc的script类型的post-commit<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> build-hook bc/samplebuild --post-commit --script=<span class="string">&quot;/var/lib/test-image.sh param1 param2 &amp;&amp; /var/lib/done.sh&quot;</span></span></span><br></pre></td></tr></table></figure></li><li>设置samplebuild bc的args类型的post-commit<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc <span class="built_in">set</span> build-hook bc/samplebuild --post-commit  -- arg1 arg2</span></span><br></pre></td></tr></table></figure>command类型、script类型与args类型的区别：</li></ol><ul><li>script：执行时使用&#x2F;bin&#x2F;sh -ic替换掉默认的entrypoint来执行代码</li><li>command：不指定解析器，也不使用entrypoint，而是直接执行代码</li><li>args：使用默认的entrypoint执行代码</li></ul><ol start="4"><li>删除samplebuild bc的post-commit<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">  oc <span class="built_in">set</span> build-hook bc/samplebuild --post-commit --remove</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="设置Route的后端服务oc-set-route-backends"><a href="#设置Route的后端服务oc-set-route-backends" class="headerlink" title="设置Route的后端服务oc set route-backends"></a>设置Route的后端服务<code>oc set route-backends</code></h2><ol><li>列出sample route的后端服务<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> route-backends sample</span></span><br></pre></td></tr></table></figure></li><li>设置sample route的后端服务为两个并且流量比为1：9，samplev1（10%），samplev2（90%）<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> route-backends sample samplev1=1 samplev2=9</span></span><br></pre></td></tr></table></figure></li><li>为sample route后端服务samplev1添加10%的流量<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> route-backends sample --adjust samplev1=+10%</span></span><br></pre></td></tr></table></figure></li><li>将sample route所有后端服务流量设为0，该route将无法对外提供服务<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> route-backends sample --zero</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift数据库挂了问题解决</title>
      <link href="/openshift/OpenShift%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8C%82%E4%BA%86%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
      <url>/openshift/OpenShift%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8C%82%E4%BA%86%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
      
        <content type="html"><![CDATA[<p>每个计算节点都无法启动，报错信息为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.895622    4307 feature_gate.go:226] feature gates: &amp;&#123;&#123;&#125; map[RotateKubeletServerCertificate:true RotateKubeletClientCertificate:true]&#125;</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.902964    4307 mount_linux.go:211] Detected OS with systemd</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.908967    4307 server.go:383] Version: v1.10.0+b81c8f8</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.909036    4307 feature_gate.go:226] feature gates: &amp;&#123;&#123;&#125; map[RotateKubeletClientCertificate:true RotateKubeletServerCertificate:true]&#125;</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.909150    4307 plugins.go:89] No cloud provider specified.</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.909162    4307 server.go:499] No cloud provider specified: &quot;&quot; from the config file: &quot;&quot;</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: E0105 00:05:10.931121    4307 bootstrap.go:198] Part of the existing bootstrap client certificate is expired: 2020-01-04 07:20:00 +0000 UTC</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.931145    4307 bootstrap.go:56] Using bootstrap kubeconfig to generate TLS client cert, key and kubeconfig file</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.932606    4307 certificate_store.go:131] Loading cert/key pair from &quot;/etc/origin/node/certificates/kubelet-client-current.pem&quot;.</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.959131    4307 csr.go:105] csr for this node already exists, reusing</span><br><span class="line">Jan 05 00:05:10 node1.example.com origin-node[4307]: I0105 00:05:10.967338    4307 csr.go:113] csr for this node is still valid</span><br></pre></td></tr></table></figure><p>一、更新证书后，&#x2F;etc&#x2F;origin&#x2F;node&#x2F;cerxx**&#x2F;client-current.(server).</p><p>如果有csr的话，就需要将csr（CertificateSigningRequest）批准通过</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc get csr -o name | xargs oc adm certificate approve</span><br></pre></td></tr></table></figure><p>需要去查的是：</p><ol><li>为什么1月4日会自动去更新kubelet证书<br>因为生产上kubelet证书的默认有效期为1年，到期会自动更新证书。计算节点上相关的配置项为<code>kubeletArguments.rotate-certificates: [&#39;true&#39;]</code></li><li>为什么csr为Pending，而没有被批准<br>这是openshift 3.11的Master节点恰好刚过期，但是此时的bootstrap的token没有过期，Node节点会向Master申请证书csr。而在OpenShift中csr的审批需要手动通过。所以这块需要做好监控与告警，确保生产上的证书不要过期。</li></ol><p>相关文章：<br><a href="https://access.redhat.com/solutions/3716861">https://access.redhat.com/solutions/3716861</a><br><a href="https://access.redhat.com/solutions/4565991">https://access.redhat.com/solutions/4565991</a></p><p>二、数据库问题<br>数据库使用的镜像是：<code>centos/mysql-57-centos7</code><br>由于是操作数据库mysql改变root的密码，而common.sh中会校验数据库的状态，但是该镜像中的common.sh默认root密码是空的，需要更改该脚本的代码，(添加ROOT密码)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 第54行</span><br><span class="line">mysql_flags=&quot;-u root -p$MYSQL_ROOT_PASSWORD --socket=/tmp/mysql.sock</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift日志审计功能与策略配置</title>
      <link href="/openshift/OpenShift%E6%97%A5%E5%BF%97%E5%AE%A1%E8%AE%A1%E5%8A%9F%E8%83%BD%E4%B8%8E%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"/>
      <url>/openshift/OpenShift%E6%97%A5%E5%BF%97%E5%AE%A1%E8%AE%A1%E5%8A%9F%E8%83%BD%E4%B8%8E%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-166882050de6fa03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="审计"></p><p>OpenShift支持审计功能，它可以记录下所有API服务的请求。如果将所有请求记录下来，它的量非常庞大，同时也是没有太大意义的。所以OpenShift审计记录当然出会支持请求的过滤，通过方便地策略配置，可以有选择地记录下请求的内容。通常我们会记录对集群资源作更改的请求。</p><h2 id="打开审计功能"><a href="#打开审计功能" class="headerlink" title="打开审计功能"></a>打开审计功能</h2><p>在部署OpenShift时可以打开审计功能</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openshift_master_audit_config=&#123;&quot;enabled&quot;: true, &quot;auditFilePath&quot;: &quot;/var/lib/origin/audit-ocp.log&quot;, &quot;maximumFileRetentionDays&quot;: 14, &quot;maximumFileSizeMegabytes&quot;: 500, &quot;maximumRetainedFiles&quot;: 5, &quot;policyFile&quot;: &quot;/etc/origin/master/adv-audit.yaml&quot;, &quot;logFormat&quot;:&quot;json&quot;&#125;</span><br><span class="line">openshift_master_audit_policyfile=&quot;/&lt;path&gt;/adv-audit.yaml&quot;</span><br></pre></td></tr></table></figure><p>在<code>/etc/origin/master/master-config.yaml</code>中的配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">auditConfig:</span><br><span class="line">  auditFilePath: &quot;/var/lib/origin/audit-ocp.log&quot;</span><br><span class="line">  enabled: true</span><br><span class="line">  maximumFileRetentionDays: 10</span><br><span class="line">  maximumFileSizeMegabytes: 10</span><br><span class="line">  maximumRetainedFiles: 5</span><br><span class="line">  policyFile: &quot;/etc/origin/master/adv-audit.yaml&quot;</span><br><span class="line">  logFormat: json</span><br></pre></td></tr></table></figure><p>其中：<br><code>auditFilePath</code>：审计日志保存地址<br><code>maximumFileRetentionDays</code>：最长保留时间<br><code>maximumFileSizeMegabytes</code>：每个文件最大大小<br><code>maximumRetainedFiles</code>：保留最大文件数<br><code>policyFile</code>：审计规则配置路径<br><code>openshift_master_audit_policyfile</code>：安装时指定部署机上的审计规则配置文件路径<br><code>logFormat</code>：日志格式</p><h2 id="审计规则设置"><a href="#审计规则设置" class="headerlink" title="审计规则设置"></a>审计规则设置</h2><p>审计规则策略实例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: audit.k8s.io/v1beta1</span><br><span class="line">kind: Policy</span><br><span class="line">rules:</span><br><span class="line"></span><br><span class="line">  # Do not log watch requests by the &quot;system:kube-proxy&quot; on endpoints or services</span><br><span class="line">  - level: None </span><br><span class="line">    users: [&quot;system:kube-proxy&quot;] </span><br><span class="line">    verbs: [&quot;watch&quot;] </span><br><span class="line">    resources: </span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      resources: [&quot;endpoints&quot;, &quot;services&quot;]</span><br><span class="line"></span><br><span class="line">  # Do not log authenticated requests to certain non-resource URL paths.</span><br><span class="line">  - level: None</span><br><span class="line">    userGroups: [&quot;system:authenticated&quot;] </span><br><span class="line">    nonResourceURLs: </span><br><span class="line">    - &quot;/api*&quot; # Wildcard matching.</span><br><span class="line">    - &quot;/version&quot;</span><br><span class="line"></span><br><span class="line">  # Log the request body of configmap changes in kube-system.</span><br><span class="line">  - level: Request</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;configmaps&quot;]</span><br><span class="line">    # This rule only applies to resources in the &quot;kube-system&quot; namespace.</span><br><span class="line">    # The empty string &quot;&quot; can be used to select non-namespaced resources.</span><br><span class="line">    namespaces: [&quot;kube-system&quot;] </span><br><span class="line"></span><br><span class="line">  # Log configmap and secret changes in all other namespaces at the metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;secrets&quot;, &quot;configmaps&quot;]</span><br><span class="line"></span><br><span class="line">  # Log all other resources in core and extensions at the request level.</span><br><span class="line">  - level: Request</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">    - group: &quot;extensions&quot; # Version of group should NOT be included.</span><br><span class="line"></span><br><span class="line">  # A catch-all rule to log all other requests at the Metadata level.</span><br><span class="line">  - level: Metadata </span><br><span class="line"></span><br><span class="line">  # Log login failures from the web console or CLI. Review the logs and refine your policies.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    nonResourceURLs:</span><br><span class="line">    - /login* </span><br><span class="line">    - /oauth* </span><br></pre></td></tr></table></figure><p>每个事件可记录的有四个级别<code>level</code>：</p><ul><li><code>None</code>：不记录与此规则匹配的事件</li><li><code>Metadata</code>：记录请求元数据（请求用户，时间戳，资源，动词等），但不记录请求或响应正文。 此级别与基本审核中使用的级别相同。</li><li><code>Request</code>：记录事件元数据和请求正文，但不记录响应正文。</li><li><code>RequestResponse</code>：记录事件元数据，请求和响应主体。</li></ul><p>用户<code>users</code>：规则适用的用户列表。 空列表表示每个用户<br>请求类型<code>verbs</code>：调用 API的请求类型，(get, list, watch, create, update, patch, delete, deletecollection以及 proxy)。空列表表示每个动词。<br>资源类型<code>resources</code>：规则适用的资源列表。 空列表表示所有资源。<br>组列表<code>userGroups</code>：规则适用的组列表。 空列表表示每个组。<br><code>nonResourceURLs </code>：规则适用的非资源URL列表。<br><code>namespaces</code>：规则适用的名称空间列表。 空列表表示每个名称空间。</p><p><a href="https://translate.google.cn/translate_tts?ie=UTF-8&total=1&idx=0&client=t&q=A%20list%20of%20namespaces%20the%20rule%20applies%20to.%20An%20empty%20list%20implies%20every%20namespace.&tl=en&tk=863236.760770"></a></p><h2 id="一个实用的例子"><a href="#一个实用的例子" class="headerlink" title="一个实用的例子"></a>一个实用的例子</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: audit.k8s.io/v1beta1</span><br><span class="line">kind: Policy</span><br><span class="line">rules:</span><br><span class="line"></span><br><span class="line">  - level: None</span><br><span class="line">    userGroups: [&quot;system:masters&quot;, &quot;system:nodes&quot;, &quot;system:serviceaccounts:kube-system&quot;]</span><br><span class="line">  - level: None</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - level: Metadata</span><br></pre></td></tr></table></figure><p>该配置将会过滤掉大部分组件之间交互的请求，同时也会过滤掉一些查询请求的审计。</p><h2 id="参考文章："><a href="#参考文章：" class="headerlink" title="参考文章："></a>参考文章：</h2><p><a href="https://docs.openshift.com/container-platform/3.11/install_config/master_node_configuration.html#master-node-config-advanced-audit">OpenShift官方文档：master-node-config-advanced-audit</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift日志级别相关</title>
      <link href="/openshift/OpenShift%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB%E7%9B%B8%E5%85%B3/"/>
      <url>/openshift/OpenShift%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB%E7%9B%B8%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<p>总共需要考虑的服务日志有</p><ul><li>OpenShift 服务日志</li><li>Docker 守护进程日志</li><li>Etcd 日志</li><li>命令行日志</li><li>Pod&#x2F;容器日志</li><li>OpenShift Builder 日志</li><li>OpenShift 路由器日志</li></ul><h2 id="OpenShift服务日志"><a href="#OpenShift服务日志" class="headerlink" title="OpenShift服务日志"></a>OpenShift服务日志</h2><ol><li>docker的日志级别<br>docker日志级别总共有以下：”debug”, “info”, “warn”, “error”, “fatal”五个。<br>docker –log-level默认为info</li></ol><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://access.redhat.com/zh_CN/solutions/3345021">https://access.redhat.com/zh_CN&#x2F;solutions&#x2F;3345021</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift本地镜像仓库打不开</title>
      <link href="/openshift/OpenShift%E6%9C%AC%E5%9C%B0%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E6%89%93%E4%B8%8D%E5%BC%80/"/>
      <url>/openshift/OpenShift%E6%9C%AC%E5%9C%B0%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E6%89%93%E4%B8%8D%E5%BC%80/</url>
      
        <content type="html"><![CDATA[<p>访问OpenShift本地镜像仓库<code>https://registry.paas.net</code>，报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;error&quot;: &quot;invalid_request&quot;,</span><br><span class="line">&quot;error_description&quot;: &quot;The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed.&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般情况下，访问镜像仓库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ oc get oauthclient</span><br><span class="line"></span><br><span class="line">NAME                           SECRET                                                                 WWW-CHALLENGE   TOKEN-MAX-AGE   REDIRECT URIS</span><br><span class="line">cockpit-oauth-client           userqUADAdq1SKikUFwSSBwnq5fqgRjomXivWGbuoJV04mNPSYiOlaL1BSLBFLjjh4Ao   FALSE           default         https://registry-console-default.paas.net,https://registry.paas.net</span><br><span class="line">openshift-browser-client       imwY5ps0HftJH0VZ_V25i4S4a0E75iTtUKjNOuW9_5Q                            FALSE           default         https://paas.net:8443/oauth/token/display</span><br><span class="line">openshift-challenging-client                                                                          TRUE            default         https://paas.baison.net:8443/oauth/token/implicit</span><br><span class="line">openshift-console              c6vG5H3raNYBGqndetmn6BYaFAG6onUF                                       FALSE           default         https://console.paas.net/</span><br><span class="line">openshift-web-console                                                                                 FALSE           default         https://paas.net:8443/console/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift支持Calico-BGP-路由反射（RR）模式</title>
      <link href="/openshift/OpenShift%E6%94%AF%E6%8C%81Calico-BGP-%E8%B7%AF%E7%94%B1%E5%8F%8D%E5%B0%84%EF%BC%88RR%EF%BC%89%E6%A8%A1%E5%BC%8F/"/>
      <url>/openshift/OpenShift%E6%94%AF%E6%8C%81Calico-BGP-%E8%B7%AF%E7%94%B1%E5%8F%8D%E5%B0%84%EF%BC%88RR%EF%BC%89%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-bdb0917cbfac1caf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Calico OpenShift"></p><h2 id="一、Calico-是什么"><a href="#一、Calico-是什么" class="headerlink" title="一、Calico 是什么"></a>一、Calico 是什么</h2><p>calico 是容器网络的一种解决方案，也是当前最流行的方案之一。和其他虚拟网络最大的不同是，它没有采用 overlay 网络做报文的转发，提供了纯 3 层的网络模型。三层通信模型表示每个容器都通过 IP 直接通信，中间通过路由转发找到对方。在这个过程中，容器所在的节点类似于传统的路由器，提供了路由查找的功能。</p><p>要想路由工作能够正常，每个虚拟路由器（容器所在的主机节点）必须有某种方法知道整个集群的路由信息，calico 采用的是<a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP 路由协议</a>，全称是 Border Gateway Protocol。</p><p>除了能用于 docker 这样的容器外，它还能集成到容器集群平台 OpenShift&#x2F;kubernetes、公有云平台 AWS、GCE 等， 而且也能很容易地集成到 openstack 等 Iaas 平台。</p><h2 id="二、Calico网络方式"><a href="#二、Calico网络方式" class="headerlink" title="二、Calico网络方式"></a>二、Calico网络方式</h2><h3 id="2-1-IPIP模式"><a href="#2-1-IPIP模式" class="headerlink" title="2.1 IPIP模式"></a>2.1 IPIP模式</h3><p>从字面来理解，就是把一个IP数据包又套在一个IP包里，即把 IP 层封装到 IP 层的一个 tunnel，看起来似乎是浪费，实则不然。它的作用其实基本上就相当于一个基于IP层的网桥！一般来说，普通的网桥是基于mac层的，根本不需 IP，而这个 ipip 则是通过两端的路由做一个 tunnel，把两个本来不通的网络通过点对点连接起来。ipip 的源代码在内核 net&#x2F;ipv4&#x2F;ipip.c 中可以找到。</p><h3 id="2-2-BGP模式"><a href="#2-2-BGP模式" class="headerlink" title="2.2 BGP模式"></a>2.2 BGP模式</h3><p>边界网关协议（Border Gateway Protocol, BGP）是互联网上一个核心的去中心化自治路由协议。它通过维护IP路由表或‘前缀’表来实现自治系统（AS）之间的可达性，属于矢量路由协议。BGP不使用传统的内部网关协议（IGP）的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。BGP，通俗的讲就是讲接入到机房的多条线路（如电信、联通、移动等）融合为一体，实现多线单IP，BGP 机房的优点：服务器只需要设置一个IP地址，最佳访问路由是由网络上的骨干路由器根据路由跳数与其它技术指标来确定的，不会占用服务器的任何系统。</p><p>根据路由规则的同步方式，BGP模式也有两种方式，mesh模式与RR模式。</p><h4 id="2-2-1-mesh-模式"><a href="#2-2-1-mesh-模式" class="headerlink" title="2.2.1 mesh 模式"></a>2.2.1 mesh 模式</h4><p>mesh 模式又称为全互联模式，就是一个 BGP Speaker 需要与其它所有的 BGP Speaker 建立 bgp 连接（形成一个bgp mesh）。BGP Speaker越多，将会消耗越多的连接。所以它只能支持小规模集群，一般50-100为上限。</p><h4 id="2-2-2-RR模式"><a href="#2-2-2-RR模式" class="headerlink" title="2.2.2 RR模式"></a>2.2.2 RR模式</h4><p>RR模式，就是在网络中指定一个或多个 BGP Speaker 作为反射路由（Router Reflector），RR与所有的 BGP Speaker 建立 bgp 连接。每个BGP Speaker只与RR建立连接，交换路由信息就能获得全网的路由信息。Calico 中通过Global Peer来实现RR模式。</p><p>默认情况下，每个 calico 节点会和集群中其他所有节点建立 BGP peer 连接，也就是说这是一个 O(n^2) 的增长趋势。在集群规模比较小的情况下，这种模式是可以接受的，但是当集群规模扩展到百个节点、甚至更多的时候，这样的连接数无疑会带来很大的负担。为了解决集群规模较大情况下 BGP client 连接数膨胀的问题，calico 引入了 RR（Router Reflector） 的功能。</p><p>RR 的基本思想是选择一部分节点（一个或者多个）作为 Global BGP Peer，它们和所有的其他节点互联来交换路由信息，其他的节点只需要和 Global BGP Peer 相连就行，不需要之间再两两连接。更多的组网模式也是支持的，不管怎么组网，最核心的思想就是所有的节点能获取到整个集群的路由信息。</p><h2 id="三、Calico组件和架构"><a href="#三、Calico组件和架构" class="headerlink" title="三、Calico组件和架构"></a>三、Calico组件和架构</h2><p>calico 的工作有：</p><ul><li>分配和管理 IP</li><li>配置上容器的 veth pair 和容器内默认路由</li><li>根据集群网络情况实时更新节点上路由表</li></ul><p>完成以上所有的功能，除了 etcd 保存了数据外，还在每个节点运行 了calico-node 容器。calico&#x2F;node 这个容器运行了多个组件：</p><ul><li>libnetwork plugin</li><li>BIRD</li><li>confd</li><li>felix</li></ul><p>下图为Calico各组件之间的相互关系图。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-5c89d188cf2a921e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Calico BGP"></p><h3 id="3-1-libnetwork-plugin"><a href="#3-1-libnetwork-plugin" class="headerlink" title="3.1 libnetwork plugin"></a>3.1 libnetwork plugin</h3><p>libnetwork-plugin 是 calico 提供的 docker 网络插件，主要提供的是 IP 管理和网络管理的功能。</p><p>默认情况下，当网络中出现第一个容器时，calico 会为容器所在的节点分配一段子网（子网掩码为 &#x2F;26，比如192.168.196.128&#x2F;26），后续出现在该节点上的容器都从这个子网中分配 IP 地址。这样做的好处是能够缩减节点上的路由表的规模，按照这种方式节点上 2^6 &#x3D; 64 个 IP 地址只需要一个路由表项就行，而不是为每个 IP 单独创建一个路由表项。节点上创建的子网段可以在etcd 中 &#x2F;calico&#x2F;ipam&#x2F;v2&#x2F;host&#x2F;<node_name>&#x2F;ipv4&#x2F;block&#x2F; 看到。</p><p>calico 还允许创建容器的时候指定 IP 地址，如果用户指定的 IP 地址不在节点分配的子网段中，calico 会专门为该地址添加一个 &#x2F;32 的网段。</p><h3 id="3-2-BIRD"><a href="#3-2-BIRD" class="headerlink" title="3.2 BIRD"></a>3.2 BIRD</h3><p><a href="http://bird.network.cz/">BIRD</a>（BIRD Internet Routing Daemon） 是一个常用的网络路由软件，支持很多路由协议（BGP、RIP、OSPF等）。它会在每台宿主机上运行，calico 用它在实现主机间传播路由信息。</p><p>BIRD 对应的配置文件在 &#x2F;etc&#x2F;calico&#x2F;confd&#x2F;config&#x2F; 目录。</p><h3 id="3-3-confd"><a href="#3-3-confd" class="headerlink" title="3.3 confd"></a>3.3 confd</h3><p>confd是一个简单的配置管理工具。bird 的配置文件会根据用户设置的变化而变化，因此需要一种动态的机制来实时维护配置文件并通知 bird 使用最新的配置，这就是 confd 的工作。它会监听 etcd 的数据，用来更新 bird 的配置文件，并重新启动 bird 进程让它加载最新的配置文件。confd 的工作目录是 &#x2F;etc&#x2F;calico&#x2F;confd，里面有三个目录：</p><ul><li>conf.d：confd 需要读取的配置文件，每个配置文件告诉 confd 模板文件在什么，最终生成的文件应该放在什么地方，更新时要执行哪些操作等</li><li>config：生成的配置文件最终放的目录</li><li>templates：模板文件，里面包括了很多变量占位符，最终会替换成 etcd 中具体的数据<br>具体的配置文件很多，以下是一个例子：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/ # cat /etc/calico/confd/conf.d/bird.toml</span><br><span class="line">[template]</span><br><span class="line">src = &quot;bird.cfg.mesh.template&quot;</span><br><span class="line">dest = &quot;/etc/calico/confd/config/bird.cfg&quot;</span><br><span class="line">prefix = &quot;/calico/bgp/v1&quot;</span><br><span class="line">keys = [&quot;/host&quot;,&quot;/global&quot;]</span><br><span class="line">check_cmd = &quot;bird -p -c &#123;&#123;.src&#125;&#125;&quot;</span><br><span class="line">reload_cmd = &quot;pkill -HUP bird || true&quot;</span><br></pre></td></tr></table></figure>它会监听 etcd 的 &#x2F;calico&#x2F;bgp&#x2F;v1 路径，一旦发现更新，就用其中的内容更新模板文件 bird.cfg.mesh.template，把新生成的文件放在 &#x2F;etc&#x2F;calico&#x2F;confd&#x2F;config&#x2F;bird.cfg，文件改变之后还会运行 reload_cmd 指定的命令重启 bird 程序。</li></ul><h3 id="3-4-felix"><a href="#3-4-felix" class="headerlink" title="3.4 felix"></a>3.4 felix</h3><p>felix 负责最终网络相关的配置，也就是容器网络在 linux 上的配置工作，比如：</p><ul><li>更新节点上的路由表项</li><li>更新节点上的 iptables 表项</li></ul><p>它的主要工作是从 etcd 中读取网络的配置，然后根据配置更新节点的路由和 iptables，felix 的代码在 http:&#x2F;&#x2F;<a href="https://github.com/projectcalico/felix">github.com&#x2F;calico&#x2F;felix</a>。</p><h2 id="四、部署Calico-BGP-RR模式"><a href="#四、部署Calico-BGP-RR模式" class="headerlink" title="四、部署Calico BGP RR模式"></a>四、部署Calico BGP RR模式</h2><h3 id="4-1-安装Calico-BGP网络插件"><a href="#4-1-安装Calico-BGP网络插件" class="headerlink" title="4.1 安装Calico BGP网络插件"></a>4.1 安装Calico BGP网络插件</h3><p>在之前的文章中已经分享过Calico BGP网络插件的部署过程。<a href="https://www.jianshu.com/p/c2df0830fd92">Openshift开启Calico BGP 与 OVS性能PK</a><br>安装完成后，Calico BGP默认使用的是Mesh模式。</p><h2 id="4-2-开启RR模式"><a href="#4-2-开启RR模式" class="headerlink" title="4.2 开启RR模式"></a>4.2 开启RR模式</h2><h3 id="4-2-1-开启单RR部署（单个主机节点作为RR）"><a href="#4-2-1-开启单RR部署（单个主机节点作为RR）" class="headerlink" title="4.2.1 开启单RR部署（单个主机节点作为RR）"></a>4.2.1 开启单RR部署（单个主机节点作为RR）</h3><ol><li>关闭当前Calico Mesh模式 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@master calico]# cat &lt;&lt; EOF | calicoctl create -f -</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: BGPConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  name: default</span><br><span class="line">spec:</span><br><span class="line">  logSeverityScreen: Info</span><br><span class="line">  nodeToNodeMeshEnabled: false</span><br><span class="line">  asNumber: 63400</span><br></pre></td></tr></table></figure></li><li>设置指定Node为RR，比如选择infra01_node为RR，“添加router-reflector标签，设置routeReflectorClusterID”。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@master calico]# calicoctl get node infra01_node  --export -o yaml  &gt; infra01_node.yaml</span><br><span class="line">[root@master calico]# cat infra01_node.yaml</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: Node</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    i-am-a-route-reflector: &quot;true&quot;</span><br><span class="line">  name: infra01_node</span><br><span class="line">spec:</span><br><span class="line">  bgp:</span><br><span class="line">    ipv4Address: 192.168.0.3/16</span><br><span class="line">    routeReflectorClusterID: 224.0.0.1</span><br><span class="line">[root@master calico]# calico apply -f infra01_node.yaml</span><br></pre></td></tr></table></figure></li><li>配置BGPPeer资源，告诉Node节点路由反射器。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master calico]# cat &lt;&lt; EOF | calicoctl create -f -</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: BGPPeer</span><br><span class="line">metadata:</span><br><span class="line">  name: peer-to-rrs</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector: !has(i-am-a-route-reflector)</span><br><span class="line">  peerSelector: has(i-am-a-route-reflector)</span><br></pre></td></tr></table></figure></li><li>查看bgppeer<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 calico]# calicoctl get bgppeers</span><br><span class="line"> NAME          PEERIP   NODE                          ASN   </span><br><span class="line"> peer-to-rrs            (global)                      0   </span><br></pre></td></tr></table></figure></li><li>通过netstat命令查看节点间calico-node的连接<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 calico]# netstat -natp | grep bird</span><br></pre></td></tr></table></figure>可以看到非RR节点只与RR节点建立连接，而RR节点与所有节点建立连接。</li></ol><h3 id="4-2-2-多RR节点部署（多个主机节点作为RR）"><a href="#4-2-2-多RR节点部署（多个主机节点作为RR）" class="headerlink" title="4.2.2 多RR节点部署（多个主机节点作为RR）"></a>4.2.2 多RR节点部署（多个主机节点作为RR）</h3><p>当只有一个RR节点时，会有一定的风险。当该节点出现异常时，所有节点将无法获取路由，这将会影响到整个OpenShift集群的网络。所以需要考虑RR节点的高可用，一种最简单的方式就是设置多个RR节点。下面演示如何添加一个新RR节点。</p><ol><li>参考4.2.1，选择infra02_node作为新的RR节点。与infra01_node设置同样的routeReflectorClusterID值。</li><li>额外添加一条新的BGPPeer资源<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master calico]# cat &lt;&lt; EOF | calicoctl create -f -</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: BGPPeer</span><br><span class="line">metadata:</span><br><span class="line">  name: rr-mesh</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector: has(i-am-a-route-reflector)</span><br><span class="line">  peerSelector: has(i-am-a-route-reflector)</span><br></pre></td></tr></table></figure></li><li>查看bgppeer<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 calico]# calicoctl get bgppeers</span><br><span class="line"> NAME          PEERIP   NODE                          ASN   </span><br><span class="line"> peer-to-rrs            (global)                      0   </span><br><span class="line"> rr-mesh                has(i-am-a-route-reflector)   0 </span><br></pre></td></tr></table></figure>以上配置后，每个非RR节点会与所有RR节点建立连接，同时RR节点之间建立连接，RR节点间是一个双活的配置。</li></ol><h3 id="4-2-3-硬件设备RR节点部署（硬件交换机作为RR节点）"><a href="#4-2-3-硬件设备RR节点部署（硬件交换机作为RR节点）" class="headerlink" title="4.2.3 硬件设备RR节点部署（硬件交换机作为RR节点）"></a>4.2.3 硬件设备RR节点部署（硬件交换机作为RR节点）</h3><p>前提：硬件交换机支持BGP协议。</p><ol><li>查看硬件交换机对应vlan IP。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/ Display current-configuration interface vlan 16</span><br><span class="line">interface Vlanif16</span><br><span class="line"> ip address 192.168.16.251 255.255.255.0</span><br><span class="line"> vrrp vrid 84 virtual-ip 192.168.16.253</span><br><span class="line"> vrrp vrid 84 priority 150</span><br><span class="line"> vrrp vrid 84 preempt-mode timer delay 20</span><br><span class="line"> vrrp vrid 84 track interface XGigabitEthernet0/0/1 reduced 30</span><br><span class="line"> vrrp vrid 84 track interface XGigabitEthernet0/0/2 reduced 30</span><br></pre></td></tr></table></figure></li><li>在OpenShift集群关闭Calico mesh模式，并设置ASNumber。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@master calico]# cat &lt;&lt; EOF | calicoctl create -f -</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: BGPConfiguration</span><br><span class="line">metadata:</span><br><span class="line">  name: default</span><br><span class="line">spec:</span><br><span class="line">  logSeverityScreen: Info</span><br><span class="line">  nodeToNodeMeshEnabled: false</span><br><span class="line">  asNumber: 63400</span><br></pre></td></tr></table></figure></li><li>在OpenShift集群创建与硬件交换机的BGPPeer配置。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@master calico]# cat &lt;&lt; EOF | calicoctl create -f -</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: BGPPeer</span><br><span class="line">metadata:</span><br><span class="line">  name: bgppeer-global</span><br><span class="line">spec:</span><br><span class="line">  peerIP: 192.168.16.251</span><br><span class="line">  asNumber: 63400</span><br></pre></td></tr></table></figure></li><li>硬件交换机和NODE 在AS号63400 中,通过IBGP建立了对等体<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ bgp 63400</span><br><span class="line"> router-id 192.168.16.11</span><br><span class="line"> peer 192.168.16.1 as-number 63400</span><br><span class="line"> peer 192.168.16.2 as-number 63400</span><br><span class="line"> peer 192.168.16.3 as-number 63400</span><br></pre></td></tr></table></figure></li><li>硬件交换机的192.168.16.251 作为RR和NODE建立了BGP<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/  ipv4-family unicast</span><br><span class="line">  undo synchronization</span><br><span class="line">  peer 192.168.16.1 enable</span><br><span class="line">  peer 192.168.16.1 reflect-client</span><br><span class="line">  peer 192.168.16.2 enable</span><br><span class="line">  peer 192.168.16.2 reflect-client</span><br><span class="line">  peer 192.168.16.3 enable                 </span><br><span class="line">  peer 192.168.16.3 reflect-client</span><br></pre></td></tr></table></figure></li><li>在硬件交换机上查看bgp peer信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/  display  bgp peer </span><br><span class="line">BGP local router ID : 192.168.16.11</span><br><span class="line"> Local AS number : 63400</span><br><span class="line"> Total number of peers : 3                Peers in established state : 3</span><br><span class="line">  Peer           V     AS  MsgRcvd  MsgSent  OutQ  Up/Down   State PrefRcv</span><br><span class="line">  192.168.16.1   4    63400   26       29   0 00:19:34     Established    1</span><br><span class="line">  192.168.16.2   4    63400   26       29     0 00:19:34   Established    1</span><br><span class="line">  192.168.16.3   4    63400   22       22     0 00:16:27   Established    1</span><br></pre></td></tr></table></figure>BGP状态为established 表示已建立状态。</li><li>在硬件交换机上查看路由信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/  display  bgp routing-table </span><br><span class="line"> BGP Local router ID is 192.168.16.11 </span><br><span class="line"> Total Number of Routes: 3</span><br><span class="line">      Network            NextHop        MED        LocPrf    PrefVal Path/Ogn</span><br><span class="line"> *&gt;i  10.200.0.0/24      192.168.16.3                100        0      i</span><br><span class="line"> *&gt;i  10.200.1.0/24      192.168.16.2                100        0      i</span><br><span class="line"> *&gt;i  10.200.2.0/24      192.168.16.1                100        0      i</span><br></pre></td></tr></table></figure>并能通过NODE学到POD的地址段,从192.168.16.1学到10.200.2.0&#x2F;24的路由,192.168.16.2学到10.200.1.0&#x2F;24的路由,192.168.16.3学到10.200.0.0&#x2F;24的路由。</li></ol><h2 id="五、Calico-BGP管理工具calicoctl"><a href="#五、Calico-BGP管理工具calicoctl" class="headerlink" title="五、Calico BGP管理工具calicoctl"></a>五、Calico BGP管理工具calicoctl</h2><p>管理calico网络需要使用calicoctl工具，该工具的配置可参考<a href="https://www.jianshu.com/p/d935f41a5ca0">OpenShift&#x2F;Kubernetes集群 Calico BGP管理工具calicoctl配置</a></p><ol><li>查看calico节点状态<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">calicoctl node status</span></span><br></pre></td></tr></table></figure></li><li>查看ip池<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">calicoctl get ipPool</span></span><br></pre></td></tr></table></figure></li><li>查看node信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">calicoctl get node -o wide</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">calicoctl get node infra01_node -o yaml</span></span><br></pre></td></tr></table></figure></li><li>创建新的资源<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">calicoctl create -f resource.yaml</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>OpenShift Calico BGP网络模式下默认使用的是etcd存储，同时访问etcd的证书保存secret calico-etcd-secrets中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get secret | grep calico-etcd-secrets</span><br><span class="line">calico-etcd-secrets   Opaque    3     205d</span><br></pre></td></tr></table></figure><p>如果calico的存储etcd使用的正是OpenShift集群的etcd集群，那么当etcd的证书有更新时，请务必更新calico证书的内容，也就是更新该secret的内容，否则集群网络将无法为新的POD分配网络。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ oc project kube-system</span><br><span class="line">$ oc create secret generic calico-etcd-secrets \</span><br><span class="line"> --from-file=etcd-ca=/etc/etcd/ca.crt \</span><br><span class="line">--from-file=etcd-cert=/etc/etcd/server.crt \</span><br><span class="line">--from-file=etcd-key=/etc/etcd/server.key -o yaml \</span><br><span class="line"> --dry-run | oc apply -f -</span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.projectcalico.org/v3.2/getting-started/kubernetes/installation/calico">calico官方部署文档</a><br><a href="https://docs.projectcalico.org/v3.10/networking/bgp#example">calico官方配置案例</a><br><a href="https://docs.projectcalico.org/v2.1/reference/architecture/">Calico官方架构文档</a><br><a href="https://cizixs.com/2017/10/19/docker-calico-network/">docker 容器网络方案：calico 网络模型</a><br><a href="https://www.sdnlab.com/community/article/else/1052">在私有云上运行Calico：IP互连网络结构</a><br><a href="https://www.kubernetes.org.cn/3443.html">k8s使用calico网络</a><br><a href="https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/04/11/calico-usage.html">calico网络原理、组网方式和使用</a><br><a href="https://www.cnblogs.com/delacroix429/p/11718491.html">Calico配置双RR架构</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift灾备的方案及步骤</title>
      <link href="/openshift/OpenShift%E7%81%BE%E5%A4%87%E7%9A%84%E6%96%B9%E6%A1%88%E5%8F%8A%E6%AD%A5%E9%AA%A4/"/>
      <url>/openshift/OpenShift%E7%81%BE%E5%A4%87%E7%9A%84%E6%96%B9%E6%A1%88%E5%8F%8A%E6%AD%A5%E9%AA%A4/</url>
      
        <content type="html"><![CDATA[<p><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/assembly_restoring-cluster.html"><u>https://docs.openshift.com/container-platform/3.11/admin_guide&#x2F;assembly_restoring-cluster.html</u></a><br><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/assembly_replace-master-host.html"><u>https://docs.openshift.com/container-platform/3.11/admin_guide&#x2F;assembly_replace-master-host.html</u></a><br><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/assembly_restore-etcd-quorum.html"><u>https://docs.openshift.com/container-platform/3.11/admin_guide&#x2F;assembly_restore-etcd-quorum.html</u></a><br><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/assembly_replace-etcd-member.html"><u>https://docs.openshift.com/container-platform/3.11/admin_guide&#x2F;assembly_replace-etcd-member.html</u></a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift根据etcd备份数据恢复etcd集群</title>
      <link href="/openshift/OpenShift%E6%A0%B9%E6%8D%AEetcd%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8Detcd%E9%9B%86%E7%BE%A4/"/>
      <url>/openshift/OpenShift%E6%A0%B9%E6%8D%AEetcd%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8Detcd%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master1.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ETCD_ALL_ENDPOINTS=` etcdctl3 --write-out=fields   member list | awk <span class="string">&#x27;/ClientURL/&#123;printf &quot;%s%s&quot;,sep,$3; sep=&quot;,&quot;&#125;&#x27;</span>`</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl3 --endpoints=<span class="variable">$ETCD_ALL_ENDPOINTS</span>  endpoint status  --write-out=table</span> </span><br><span class="line">+-----------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">|           ENDPOINT                |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</span><br><span class="line">+-----------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">|     https://master1.etcd.com:2379 | d91b1c20df818655 |  3.2.22 |   17 MB |      true |         6 |       42   |</span><br><span class="line">|           https://10.0.88.33:2379 |  d35cfd2fedc078f |  3.2.22 |   17 MB |     false |         6 |       42   |</span><br><span class="line">|           https://10.0.88.22:2379 | c9624828ed10ae36 |  3.2.22 |   17 MB |     false |         6 |       42   |</span><br><span class="line">|           https://10.0.88.11:2379 | d91b1c20df818655 |  3.2.22 |   17 MB |      true |         6 |       42   |</span><br><span class="line">+-----------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl3 snapshot save /var/lib/etcd/snapshot.db</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /var/lib/etcd/snapshot.db /tmp/snapshot.db</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /var/lib/etcd/member/snap/db /tmp/db</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">scp /tmp/snapshot.db master2.etcd.com:/tmp/snapshot.db</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">scp /tmp/snapshot.db master3.etcd.com:/tmp/snapshot.db</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="built_in">mv</span> /var/lib/etcd/member /tmp/etcd-backup-$(<span class="built_in">date</span> +%d-%m-%y)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master2.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="built_in">mv</span> /var/lib/etcd/member /tmp/etcd-backup-$(<span class="built_in">date</span> +%d-%m-%y)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master3.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> <span class="built_in">mv</span> /var/lib/etcd/member /tmp/etcd-backup-$(<span class="built_in">date</span> +%d-%m-%y)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master1.etcd.com</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">source</span> /etc/etcd/etcd.conf</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> ETCDCTL_API=3</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">echo</span> -e  <span class="string">&quot;<span class="variable">$ETCD_INITIAL_CLUSTER</span> \n<span class="variable">$ETCD_INITIAL_CLUSTER_TOKEN</span>&quot;</span></span></span><br><span class="line">  master1.etcd.com=https://10.0.88.11:2380,master2.etcd.com=https://10.0.88.22:2380,master3.etcd.com=https://10.0.88.33:2380  </span><br><span class="line">  etcd-cluster-1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ETCDCTL_API=3 etcdctl snapshot restore /tmp/snapshot.db \</span></span><br><span class="line"><span class="language-bash">  --name master1.etcd.com \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster master1.etcd.com=https://10.0.88.11:2380,master2.etcd.com=https://10.0.88.22:2380,master3.etcd.com=https://10.0.88.33:2380 \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster-token etcd-cluster-1 \</span></span><br><span class="line"><span class="language-bash">  --initial-advertise-peer-urls https://10.0.88.11:2380 \</span></span><br><span class="line"><span class="language-bash">  --data-dir /var/lib/etcd</span> </span><br><span class="line">2019-02-05 12:49:04.103233 I | mvcc: restore compact to 2361744</span><br><span class="line">2019-02-05 12:49:04.135995 I | etcdserver/membership: added member d35cfd2fedc078f [https://10.0.88.33:2380] to cluster 1a196dd3442fbe59</span><br><span class="line">2019-02-05 12:49:04.136161 I | etcdserver/membership: added member c9624828ed10ae36 [https://10.0.88.22:2380] to cluster 1a196dd3442fbe59</span><br><span class="line">2019-02-05 12:49:04.136267 I | etcdserver/membership: added member d91b1c20df818655 [https://10.0.88.11:2380] to cluster 1a196dd3442fbe59</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">restorecon -Rv /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master2.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \</span></span><br><span class="line"><span class="language-bash">  --name master2.etcd.com \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster master1.etcd.com=https://10.0.88.11:2380,master2.etcd.com=https://10.0.88.22:2380,master3.etcd.com=https://10.0.88.33:2380 \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster-token etcd-cluster-1 \</span></span><br><span class="line"><span class="language-bash">  --initial-advertise-peer-urls https://10.0.88.22:2380 \</span></span><br><span class="line"><span class="language-bash">  --data-dir /var/lib/etcd</span> </span><br><span class="line">2019-02-05 12:51:25.179801 I | mvcc: restore compact to 2356950</span><br><span class="line">2019-02-05 12:51:25.193709 I | etcdserver/membership: added member d35cfd2fedc078f [https://10.0.88.33:2380] to cluster 1a196dd3442fbe59</span><br><span class="line">2019-02-05 12:51:25.193745 I | etcdserver/membership: added member c9624828ed10ae36 [https://10.0.88.22:2380] to cluster 1a196dd3442fbe59</span><br><span class="line">2019-02-05 12:51:25.193759 I | etcdserver/membership: added member d91b1c20df818655 [https://10.0.88.11:2380] to cluster 1a196dd3442fbe59</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">restorecon -Rv /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master3.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \</span></span><br><span class="line"><span class="language-bash">  --name master3.etcd.com \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster master1.etcd.com=https://10.0.88.11:2380,master2.etcd.com=https://10.0.88.22:2380,master3.etcd.com=https://10.0.88.33:2380 \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster-token etcd-cluster-1 \</span></span><br><span class="line"><span class="language-bash">  --initial-advertise-peer-urls https://10.0.88.33:2380 \</span></span><br><span class="line"><span class="language-bash">  --data-dir /var/lib/etcd</span> </span><br><span class="line">2019-02-05 12:53:06.612149 I | mvcc: restore compact to 2356950</span><br><span class="line">2019-02-05 12:53:06.634761 I | etcdserver/membership: added member d35cfd2fedc078f [https://10.0.88.33:2380] to cluster 1a196dd3442fbe59</span><br><span class="line">2019-02-05 12:53:06.634905 I | etcdserver/membership: added member c9624828ed10ae36 [https://10.0.88.22:2380] to cluster 1a196dd3442fbe59</span><br><span class="line">2019-02-05 12:53:06.635001 I | etcdserver/membership: added member d91b1c20df818655 [https://10.0.88.11:2380] to cluster 1a196dd3442fbe59</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">restorecon -Rv /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master1.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods-stopped/etcd.yaml /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master2.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods-stopped/etcd.yaml /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master3.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods-stopped/etcd.yaml /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master1.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ETCD_ALL_ENDPOINTS=` etcdctl3 --write-out=fields   member list | awk <span class="string">&#x27;/ClientURL/&#123;printf &quot;%s%s&quot;,sep,$3; sep=&quot;,&quot;&#125;&#x27;</span>`</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl3 --endpoints=<span class="variable">$ETCD_ALL_ENDPOINTS</span>  endpoint status  --write-out=table</span> </span><br><span class="line">+-----------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">|           ENDPOINT                |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</span><br><span class="line">+-----------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line">|     https://master1.etcd.com:2379 | d91b1c20df818655 |  3.2.22 |   17 MB |      true |         6 |       42   |</span><br><span class="line">|           https://10.0.88.33:2379 |  d35cfd2fedc078f |  3.2.22 |   17 MB |     false |         6 |       42   |</span><br><span class="line">|           https://10.0.88.22:2379 | c9624828ed10ae36 |  3.2.22 |   17 MB |     false |         6 |       42   |</span><br><span class="line">|           https://10.0.88.11:2379 | d91b1c20df818655 |  3.2.22 |   17 MB |      true |         6 |       42   |</span><br><span class="line">+-----------------------------------+------------------+---------+---------+-----------+-----------+------------+</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master1.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods-stopped/* /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master2.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods-stopped/* /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh master3.etcd.com</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods-stopped/* /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc get nodes,pods -n  kube-system</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift生产集群物理机部署与虚拟机部署各自优缺点</title>
      <link href="/openshift/OpenShift%E7%94%9F%E4%BA%A7%E9%9B%86%E7%BE%A4%E7%89%A9%E7%90%86%E6%9C%BA%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%83%A8%E7%BD%B2%E5%90%84%E8%87%AA%E4%BC%98%E7%BC%BA%E7%82%B9/"/>
      <url>/openshift/OpenShift%E7%94%9F%E4%BA%A7%E9%9B%86%E7%BE%A4%E7%89%A9%E7%90%86%E6%9C%BA%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%83%A8%E7%BD%B2%E5%90%84%E8%87%AA%E4%BC%98%E7%BC%BA%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-9bd640d3a5daaea8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift架构"></p><p>OpenShift是物理机部署，还是虚拟机部署？这是企业在做容器平台架构选型时必须考虑的问题。尤其是大企业，有机器，有业务。今天我们就来列一列物理机与虚拟机部署各自的优缺点。</p><h2 id="物理机部署"><a href="#物理机部署" class="headerlink" title="物理机部署"></a>物理机部署</h2><blockquote><p>优点</p></blockquote><ol><li>性能好，无虚拟化层性能开销</li><li>小业务集群，节点少</li><li>配置高能够支持更大规模的容器数量</li><li>License成本更低</li><li>架构复杂度低（PaaS）</li><li>需要额外准备LB与存储<blockquote><p>缺点</p></blockquote></li><li>运维复杂度高</li><li>集群扩容周期长</li><li>如果出现故障，恢复周期长，需要及时去机房诊断修复</li><li>一台主机出现故障，影响业务范围更广</li><li>合规限制，需要更高要求的安全与隐私控制</li></ol><h2 id="虚拟机部署"><a href="#虚拟机部署" class="headerlink" title="虚拟机部署"></a>虚拟机部署</h2><blockquote><p>优点</p></blockquote><ol><li>灵活部署、配置、维护简单</li><li>快速扩容</li><li>能与IaaS资源混合使用（LB、存储等）</li><li>一台虚拟机出现故障，影响业务范围小</li><li>虚拟机技术成熟，有热迁移技术，恢复快</li><li>IaaS高可用+PaaS高可用，两层保障</li><li>虚拟机支持虚拟快照，方便做主机回滚，集群可靠怀提升</li><li>IaaS目前已经有成熟的合规方案，在其上构建PaaS可以更方便地满足合规要求<blockquote><p>缺点</p></blockquote></li><li>性能较差（网络、计算等）</li><li>架构复杂度提升（IaaS + Paas）</li><li>配置较低，承载的容器容量更小（节点更多）</li><li>需要更多License成本</li></ol><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>关于License问题，从红帽官方得到的收费规则如下：<br>OpenShift订阅按照主机CPU核数来收费，如果虚拟机的话，2vcpu按一个核来收费。</p><p>所以建议OpenShift on IaaS方案，要把超分调小，这样可以在保证算力的情况下，节约License成本。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift管理节点Master与计算节点Node的配置说明</title>
      <link href="/openshift/OpenShift%E7%AE%A1%E7%90%86%E8%8A%82%E7%82%B9Master%E4%B8%8E%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9Node%E7%9A%84%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/"/>
      <url>/openshift/OpenShift%E7%AE%A1%E7%90%86%E8%8A%82%E7%82%B9Master%E4%B8%8E%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9Node%E7%9A%84%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>Master节点的配置文件地址：&#x2F;etc&#x2F;origin&#x2F;master&#x2F;master-config.yaml<br>Node节点的配置文件在：openshift-node项目下的configmap中。<br>OpenShift集群的配置信息都在这两个文件中，包括有覆盖默认插件，连接到etcd，自动创建服务帐户，构建映像名称，自定义项目请求，配置卷插件等等。</p><h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://docs.openshift.com/container-platform/3.11/install_config/master_node_configuration.html">Master and Node Configuration</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift自带的日志搜索引擎ES服务的扩容</title>
      <link href="/openshift/OpenShift%E8%87%AA%E5%B8%A6%E7%9A%84%E6%97%A5%E5%BF%97%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8EES%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%89%A9%E5%AE%B9/"/>
      <url>/openshift/OpenShift%E8%87%AA%E5%B8%A6%E7%9A%84%E6%97%A5%E5%BF%97%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8EES%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%89%A9%E5%AE%B9/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-eec881d70164150c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift自带的日志搜索引擎ES的扩容"></p><p>有以下两种扩容方式：</p><ol><li>存储扩容</li><li>节点扩容</li></ol><h2 id="存储扩容"><a href="#存储扩容" class="headerlink" title="存储扩容"></a>存储扩容</h2><ol><li>查看集群的状态<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- health</span><br></pre></td></tr></table></figure></li><li>停止ES节点分片平衡<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- curl --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XPUT https://localhost:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot;: &#123;&quot;cluster.routing.allocation.enable&quot;:&quot;none&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure></li><li>为每个ES节点的DC执行以下操作<br>3.1 获取需要暂停的ES pod所在的Node节点<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get pods -o wide </span><br></pre></td></tr></table></figure>3.2 暂停第一个ES pod<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc scale dc &lt;es-dc-01&gt; --replicas=0</span><br></pre></td></tr></table></figure>3.3 将节点的数据复制到更大的存储盘目录中<br>3.4 更新该ES节点的DC配置，将数据盘挂载到新的目录<br>3.5 恢复ES节点<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc scale dc &lt;es-dc-01&gt; --replicas=1</span><br></pre></td></tr></table></figure></li><li>按照3的步骤为剩下的ES节点进行扩容</li><li>恢复ES节点分片平衡<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- curl --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XPUT https://localhost:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot;: &#123;&quot;cluster.routing.allocation.enable&quot;:&quot;all&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure></li></ol><h2 id="节点扩容"><a href="#节点扩容" class="headerlink" title="节点扩容"></a>节点扩容</h2><ol><li>添加infra-logging节点，配置保持与之前的logging节点一致，并准备好数据盘目录</li><li>停止ES节点分片平衡<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- curl --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XPUT https://localhost:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot;: &#123;&quot;cluster.routing.allocation.enable&quot;:&quot;none&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure></li><li>修改部署配置文件ansible hosts文件，增大ES节点大小<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">openshift_logging_es_cluster_size=5</span><br><span class="line">openshift_logging_es_number_of_shards=3</span><br><span class="line">openshift_logging_es_number_of_replicas=1</span><br><span class="line">openshift_logging_elasticsearch_storage_type=hostmount</span><br><span class="line">openshift_logging_elasticsearch_hostmount_path=/es-data</span><br></pre></td></tr></table></figure></li><li>运行logging的部署安装playbook<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible-playbook openshift-ansible/playbooks/openshift-logging/config.yml</span><br></pre></td></tr></table></figure>5.恢复ES节点分片平衡<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- curl --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XPUT https://localhost:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot;: &#123;&quot;cluster.routing.allocation.enable&quot;:&quot;all&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift用户与组的管理功能如何在Kubernetes上实现</title>
      <link href="/openshift/OpenShift%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%9A%84%E7%AE%A1%E7%90%86%E5%8A%9F%E8%83%BD%E5%A6%82%E4%BD%95%E5%9C%A8Kubernetes%E4%B8%8A%E5%AE%9E%E7%8E%B0/"/>
      <url>/openshift/OpenShift%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%9A%84%E7%AE%A1%E7%90%86%E5%8A%9F%E8%83%BD%E5%A6%82%E4%BD%95%E5%9C%A8Kubernetes%E4%B8%8A%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-788241b7eca16665.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift用户管理图"></p><p>OpenShift中有用户及组的概念，并且提供了User与Group资源类型，可以非常方便地为OpenShift集群创建用户，创建组，以组给用户进行组管理，并授权。这也大大方便了集群账号的管理与权限的控制。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[openshift@master01 ~] oc create user dev-user # 创建用户dev-user</span><br><span class="line">[openshift@master01 ~] oc adm groups new my-group # 创建组my-group</span><br><span class="line">[openshift@master01 ~] oc adm groups new my-group dev-user # 创建组my-group，并添加dev-user到该组</span><br><span class="line">[openshift@master01 ~] oc adm groups add-users my-group dev-user # 为组my-group添加用户dev-user</span><br><span class="line">[openshift@master01 ~] oc adm groups remove-users my-group dev-user # 将用户dev-user从my-group组中移除</span><br></pre></td></tr></table></figure><p>与OpenShift一样，K8S也是通过RBAC实现权限控制。RBAC(Role-Based Access Control)即为基于角色的访问控制。K8S中与RBAC相关的资源类型有：Role、ClusterRole、RoleBinding、ClusterRoleBinding。那么针对K8S集群，有没有办法实现类似于OpenShift的用户、组的管理呢？答案是肯定的，但是需要执行一系列的脚本操作。</p><p>本篇将介绍如何通过命令为Kubernetes创建用户及用户组，并对用户进行授权。同时设计了一个脚本工具来模拟实现类似OpenShift用户与组的功能。</p><h2 id="K8S获取用户信息及对用户（组）授权"><a href="#K8S获取用户信息及对用户（组）授权" class="headerlink" title="K8S获取用户信息及对用户（组）授权"></a>K8S获取用户信息及对用户（组）授权</h2><p>获取当前用户名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[k8s@master01 ~] kubectl config view -o=jsonpath=&quot;&#123;.contexts[0].context.user&#125;&quot;</span><br><span class="line">dev-user</span><br></pre></td></tr></table></figure><p>为用户赋予namespace的管理员权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[k8s@master01 ~] kubectl create rolebinding dev-user-admin-binding --clusterrole=admin --user=dev-user --namespace=dev</span><br><span class="line">[k8s@master01 ~] kubectl create rolebinding dev-user-admin-binding --clusterrole=admin --user=dev-user -n sit</span><br></pre></td></tr></table></figure><p>为组授权，赋予namespace管理员权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[k8s@master01 ~] kubectl create rolebinding dev-group-admin-binding --clusterrole=admin --group=dev-group --namespace=dev</span><br><span class="line">[k8s@master01 ~] kubectl create rolebinding dev-group-admin-binding --clusterrole=admin --group=dev-user -n sit</span><br></pre></td></tr></table></figure><h2 id="生成用户及组证书"><a href="#生成用户及组证书" class="headerlink" title="生成用户及组证书"></a>生成用户及组证书</h2><ol><li>配置信息脚本 <code>config.sh</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">USERNAME=username  #用户名</span><br><span class="line">GROUP=/O=group          #用户所属组，多个组可以使用/O=group1/O=group2</span><br><span class="line">DEFAULT_NS=kube-system   # 默认ns</span><br><span class="line">API_SERVER=https://master.k8s.com:6443  #K8S API Server地址</span><br><span class="line">K8S_PKI_PATH=/etc/kubernetes/pki/    # K8S证书存放目录</span><br></pre></td></tr></table></figure></li><li>为新用户创建证书脚本 <code>add_user.sh</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">source config.sh   # 导入配置信息</span><br><span class="line">K8S_PKI_PATH=$&#123;K8S_PKI_PATH%/&#125;</span><br><span class="line">mkdir -p .tmp</span><br><span class="line">openssl genrsa -out .tmp/$USERNAME.key 2048 # 生成密钥</span><br><span class="line">openssl req -new -key .tmp/$USERNAME.key -out .tmp/$USERNAME.csr -subj &quot;/CN=$&#123;USERNAME&#125;$&#123;GROUP&#125;&quot; #生成csr证书，包含用户名及组信息</span><br><span class="line">openssl x509 -req -in .tmp/$USERNAME.csr -CA $&#123;K8S_PKI_PATH&#125;/ca.crt -CAkey $&#123;K8S_PKI_PATH&#125;/ca.key -CAcreateserial -out .tmp/$USERNAME.crt -days 3650 #生成crt证书</span><br><span class="line"></span><br><span class="line"># 使用k8s证书与生成的用户证书生成访问配置文件$USERNAME.conf</span><br><span class="line">kubectl config --kubeconfig=$USERNAME.conf set-cluster kubernetes --server=$API_SERVER --certificate-authority=$&#123;K8S_PKI_PATH&#125;/ca.crt --embed-certs</span><br><span class="line">kubectl config --kubeconfig=$USERNAME.conf set-credentials $USERNAME --client-certificate=.tmp/$USERNAME.crt --client-key=.tmp/$USERNAME.key --embed-certs=true</span><br><span class="line">kubectl config --kubeconfig=$USERNAME.conf set-context $USERNAME@kubernetes --cluster=kubernetes --user=$USERNAME --namespace=$DEFAULT_NS</span><br><span class="line">kubectl config --kubeconfig=$USERNAME.conf use-context $USERNAME@kubernetes</span><br><span class="line"></span><br><span class="line">echo -e &quot;请将下面的文件内容复制到需要的用户目录.kube/config文件中\n\n&quot;</span><br><span class="line">cat $USERNAME.conf</span><br><span class="line">echo -e &quot;\n\n&quot;</span><br></pre></td></tr></table></figure></li><li>在k8s的主节点运行add_user.sh，即可完成用户证书的生成。</li></ol><h2 id="用户、组权限与访问控制工具k8sum（K8S-User-Manager-设计"><a href="#用户、组权限与访问控制工具k8sum（K8S-User-Manager-设计" class="headerlink" title="用户、组权限与访问控制工具k8sum（K8S User Manager)设计"></a>用户、组权限与访问控制工具k8sum（K8S User Manager)设计</h2><p>该工具包含以下功能<br>0. 功能说明</p><ol><li>创建用户</li><li>为用户分配组信息</li><li>为用户或者组绑定role，设置权限</li><li>为用户或者组绑定clusterrole，设置权限</li></ol><p>工具使用手册说明<br>0. 功能说明</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum [-h/--help]</span></span><br><span class="line">k8sum是一个Kubernetes用户权限管理工具，它能够实现用户创建、分组、权限分配等功能。</span><br><span class="line">格式：</span><br><span class="line">k8sum [command] [--args]</span><br><span class="line">command:</span><br><span class="line">  create 创建访问配置文件</span><br><span class="line">  bind 为用户/组绑定权限</span><br></pre></td></tr></table></figure><ol><li>创建用户<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum create --user=user-dev</span></span><br></pre></td></tr></table></figure></li><li>为用户分配组信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum create --user=user-dev --group=group1,goup2</span></span><br></pre></td></tr></table></figure></li><li>为用户或者组绑定role<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum <span class="built_in">bind</span> --user=user-dev --role=role1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum <span class="built_in">bind</span> --group=group1 --role=role1</span></span><br></pre></td></tr></table></figure></li><li>为用户或者组绑定clusterrole<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum <span class="built_in">bind</span> --user=user-dev --clusterrole=clusterrole1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">k8sum <span class="built_in">bind</span> --group=group1 --clusterrole=clusterrole1</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>RBAC设计来源于OpenShift，最后融入到了K8S。虽然都是基于RBAC，但是OpenShift在对用户权限的管理这一块考虑得更加全面，也更为实用。K8S真正要做好权限管理这块，还需要做更多的集成或二次开发的工作。</p><p><code>补充说明</code>：OpenShift也好，Kubernetes也好，都可以对接第三方认证，如Keystone，LDAP，OpenID Connect等。<br>OpenShift与OpenLDAP结接，可参考之前分享的文章：<a href="https://www.jianshu.com/p/8701b6ce715d">Openshift上部署OpenLDAP实战：为账号一统</a></p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://zhuanlan.zhihu.com/p/43237959">为Kubernetes集群添加用户</a><br><a href="https://jimmysong.io/kubernetes-handbook/guide/rbac.html">RBAC——基于角色的访问控制</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift节点kubelet证书过期异常的解决步骤</title>
      <link href="/openshift/OpenShift%E8%8A%82%E7%82%B9kubelet%E8%AF%81%E4%B9%A6%E8%BF%87%E6%9C%9F%E5%BC%82%E5%B8%B8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%AD%A5%E9%AA%A4/"/>
      <url>/openshift/OpenShift%E8%8A%82%E7%82%B9kubelet%E8%AF%81%E4%B9%A6%E8%BF%87%E6%9C%9F%E5%BC%82%E5%B8%B8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%AD%A5%E9%AA%A4/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-dde4d8e7c1980f41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="证书过期"></p><p>环境：OpenShift 3.10 or 3.11<br>问题:</p><ul><li>重新部署了新的CA，节点不再处于就绪状态。</li><li>如何手动强制创建新证书。</li><li>节点无法更新其证书，并出现以下错误：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">atomic-openshift-node[3715]: I0313 11:40:48.864375    3715 bootstrap.go:56] Using bootstrap kubeconfig to generate TLS client cert, key and kubeconfig file</span><br><span class="line">atomic-openshift-node[3715]: I0313 11:40:48.865525    3715 bootstrap.go:86] No valid private key and/or certificate found, reusing existing private key or creating a new one</span><br><span class="line">atomic-openshift-node[3715]: F0313 11:40:48.893737    3715 server.go:262] failed to run Kubelet: cannot create certificate signing request: Unauthorized</span><br></pre></td></tr></table></figure>步骤：</li></ul><ol><li>为节点创建一个新的bootstrap.kubeconfig（主节点仅需要复制admin.kubeconfig）。 从任何Master节点运行：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc serviceaccounts create-kubeconfig node-bootstrapper -n openshift-infra --config /etc/origin/master/admin.kubeconfig &gt; ~/bootstrap.kubeconfig</span></span><br></pre></td></tr></table></figure></li><li>在Master节点上将admin.kubeconfig文件复制到&#x2F;etc&#x2F;origin&#x2F;node&#x2F;bootstrap.kubeconfig。 在每个Master上运行：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> /etc/origin/master/admin.kubeconfig /etc/origin/node/bootstrap.kubeconfig</span></span><br></pre></td></tr></table></figure></li><li>将第1步中的〜&#x2F; bootstrap.kubeconfig分发给计算节点(worker,infra)，替换计算节点的&#x2F;etc&#x2F;origin&#x2F;node&#x2F;bootstrap.kubeconfig文件。 还要将其分发到所有主节点（master）上的&#x2F;etc&#x2F;origin&#x2F;master&#x2F;bootstrap.kubeconfig中（注意，它是master文件夹，而不是node文件夹）。</li><li>在所有节点上移动node.kubeconfig 和 client-ca.crt文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/client-ca.crt&#123;,.old&#125;</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/node.kubeconfig&#123;,.old&#125;</span></span><br></pre></td></tr></table></figure></li><li>删除每个节点的&#x2F;etc&#x2F;origin&#x2F;node&#x2F;certificates&#x2F;目录（包括master，worker, infra）<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">rm</span> -rf  /etc/origin/node/certificates</span></span><br></pre></td></tr></table></figure></li><li>重启node服务<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemctl restart atomic-openshift-node.service</span> </span><br></pre></td></tr></table></figure></li><li>批准CSR，每个节点（master，worker, infra）应批准2个：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc get csr -o name | xargs oc adm certificate approve</span></span><br></pre></td></tr></table></figure>或者<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> $(oc get csr | grep -i Pending | awk <span class="string">&#x27;&#123; print $1 &#125;&#x27;</span>); <span class="keyword">do</span> oc adm certificate approve <span class="variable">$i</span> ; <span class="keyword">done</span></span></span><br></pre></td></tr></table></figure></li><li>检查Node状态<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">oc get node</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">for</span> i <span class="keyword">in</span> `oc get nodes -o jsonpath=$<span class="string">&#x27;&#123;range .items[*]&#125;&#123;.metadata.name&#125;\n&#123;end&#125;&#x27;</span>`; <span class="keyword">do</span> oc get --raw /api/v1/nodes/<span class="variable">$i</span>/proxy/healthz; <span class="built_in">echo</span> -e <span class="string">&quot;\t<span class="variable">$i</span>&quot;</span>; <span class="keyword">done</span></span></span><br></pre></td></tr></table></figure></li></ol><p><a href="https://access.redhat.com/solutions/3782361">Manually recreate OpenShift Node TLS bootstrapped certificates and kubeconfig files.</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift解决Route-Https--Http无法跳转的问题</title>
      <link href="/openshift/OpenShift%E8%A7%A3%E5%86%B3Route-Https--Http%E6%97%A0%E6%B3%95%E8%B7%B3%E8%BD%AC%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/openshift/OpenShift%E8%A7%A3%E5%86%B3Route-Https--Http%E6%97%A0%E6%B3%95%E8%B7%B3%E8%BD%AC%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-bc6dba53ff669ebf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift Haproxy"></p><h2 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h2><p>通过Route创建的edge类型的HTTPS，后端应用使用的是HTTP服务。但在某些情况下，后端应用使用Location时，Location地址为HTTP地址。这时浏览器将因为无法访问HTTP服务而无法实现跳转。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>Haproxy在返回客户端时，检查返回Head，将Location地址中的HTTP替换为HTTPS，从而让浏览器获取正确的跳转链接。</p><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>更新haproxy-config.template，为edge请求的应用添加标注判断<code>haproxy.router.openshift.io/location-scheme</code>，如果它为https，则将Location请求中的http替换为https。<br>具体配置如下：搜索 <code>ssl_fc_alpn -i h2</code>在其后添加如下配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;- if eq &quot;https&quot; (index $cfg.Annotaions &quot;haproxy.router.openshift.io/location-scheme&quot;)&#125;&#125;</span><br><span class="line">  acl check_location res.hdr(Location) -m found</span><br><span class="line">  rspirep ^Location:\ http://(.*) Location:\ https://\1 if check_location</span><br><span class="line">&#123;&#123;- end&#125;&#125;</span><br></pre></td></tr></table></figure><p>示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    haproxy.router.openshift.io/location-scheme: &#x27;https&#x27;</span><br><span class="line">  labels:</span><br><span class="line">    router: web-app</span><br><span class="line">  name: web-app</span><br><span class="line">spec:</span><br><span class="line">  host: test.com</span><br><span class="line">  port:</span><br><span class="line">    targetPort: http</span><br><span class="line">  tls:</span><br><span class="line">    termination: edge</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: web-app</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>对于已经创建的Route可通过命令设置annotations</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc annotate route web-app haproxy.router.openshift.io/location-scheme=<span class="string">&quot;https&quot;</span></span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift访问外部需要认证的镜像仓库</title>
      <link href="/openshift/OpenShift%E8%AE%BF%E9%97%AE%E5%A4%96%E9%83%A8%E9%9C%80%E8%A6%81%E8%AE%A4%E8%AF%81%E7%9A%84%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/"/>
      <url>/openshift/OpenShift%E8%AE%BF%E9%97%AE%E5%A4%96%E9%83%A8%E9%9C%80%E8%A6%81%E8%AE%A4%E8%AF%81%E7%9A%84%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>docker login登录成功后，会在~&#x2F;.docker&#x2F;中创建config.json文件，内容格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">          &quot;auths&quot;: &#123;</span><br><span class="line">                  &quot;https://registry.example.com&quot;: &#123;</span><br><span class="line">                          &quot;auth&quot;: &quot;c2xmams6c2RmbGtq&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">&#125;      </span><br></pre></td></tr></table></figure><p>两种方式：</p><ol><li>认证信息必须存放在OpenShift的NameSpace中的Secret下。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc -n &lt;test-namespace&gt; create secret docker-registry &lt;pull-secret&gt; --docker-server=registry.example.com --docker-username=&lt;username&gt; --docker-email=test@example.com --docker-password=&lt;password&gt;</span><br><span class="line">oc -n &lt;test-namespace&gt; secrets link &lt;serviceaccount&gt; &lt;pull-secret&gt; --for=pull</span><br></pre></td></tr></table></figure></li><li>在Master节点与Node节点的 <code>/var/lib/origin/.docker/config.json</code>文件中添加认证TOKEN<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp ~/.docker/config.json /var/lib/origin/.docker/config.json; systemctl restart atomic-openshift-node</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift运维点汇总</title>
      <link href="/openshift/OpenShift%E8%BF%90%E7%BB%B4%E7%82%B9%E6%B1%87%E6%80%BB/"/>
      <url>/openshift/OpenShift%E8%BF%90%E7%BB%B4%E7%82%B9%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><ol><li><p>部署</p><blockquote><p>镜像同步（UAT-&gt;PRO）<br> 应用部署配置</p><blockquote><p> New Project&#x2F;New App<br>环境变量<br>cpu与内存资源限制<br>健康检查<br>复本数量<br>创建router<br>特殊Node节点绑定<br>pod的亲和与互斥<br>pod网速限速（特别是对外提供服务的pod）</p></blockquote><p>应用配置中心(gitlab) </p></blockquote></li><li><p>更新</p><blockquote><p>镜像同步<br>应用新版本部署 </p></blockquote></li><li><p>监控</p><blockquote><p>Pod EFK<br>Registry与Router等重要服务的监控</p></blockquote></li></ol><h3 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h3><ol><li><p>创建资源</p><blockquote><p>负载均衡器<br>NAS存储<br>应用私有网络</p></blockquote></li><li><p>监控</p><blockquote><p>vpc<br>负载均衡器<br>主机状态监控（CPU与内存）</p></blockquote></li></ol><h3 id="集群层"><a href="#集群层" class="headerlink" title="集群层"></a>集群层</h3><ol><li><p>备份</p><blockquote><p>etcd全量备份<br>应用配置备份(Ark)<br>应用备份（oc export)</p></blockquote></li><li><p>集群版本管理</p><blockquote><p>集群升级（每个大版本升级）</p></blockquote></li><li><p>日志归档与清理</p><blockquote><p>EFK日志清理<br>hawkular-cassandra日志清理<br>journal日志归档<br> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">journalctl --vacuum-time=3days或者journalctl --vacuum-size=200M或者在/etc/systemd/journald.conf中设置日志大小</span><br></pre></td></tr></table></figure><br> message日志归档</p></blockquote></li><li><p>Node节点管理</p><blockquote><p>ansible脚本扩容<br>Node的隔离与恢复（关闭调度维护）</p></blockquote></li><li><p>资源管理</p><blockquote><p>资源配置范围管理（LimitRange）<br>资源的配额管理<br>PV（Persistent Volumes）的创建<br>项目间的网络隔离</p></blockquote></li><li><p>监控告警</p><blockquote><p>Heapster + Influxdb + Grafana 集群监控<br>统一的日志监控 EFK<br>Pod监控Restart数<br>Node节点资源使用情况（Limit + Request + Real）</p></blockquote></li><li><p>权限控制</p><blockquote><p>管理员账号<br>运维人员账号</p></blockquote></li><li><p>Harbor私有镜像仓库的运维</p><blockquote><p>镜像备份<br>高可用<br>可用性监控与告警</p></blockquote></li></ol><h3 id="网络区域划分"><a href="#网络区域划分" class="headerlink" title="网络区域划分"></a>网络区域划分</h3><blockquote><p>核心区<br>DMZ区<br>互联网区</p></blockquote><h3 id="中间件层"><a href="#中间件层" class="headerlink" title="中间件层"></a>中间件层</h3><ol><li>Redis</li><li>RDB</li><li>Rabbitmq</li><li>FastDFS</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift通过EgressIP为Project设置对外的出口IP</title>
      <link href="/openshift/OpenShift%E9%80%9A%E8%BF%87EgressIP%E4%B8%BAProject%E8%AE%BE%E7%BD%AE%E5%AF%B9%E5%A4%96%E7%9A%84%E5%87%BA%E5%8F%A3IP/"/>
      <url>/openshift/OpenShift%E9%80%9A%E8%BF%87EgressIP%E4%B8%BAProject%E8%AE%BE%E7%BD%AE%E5%AF%B9%E5%A4%96%E7%9A%84%E5%87%BA%E5%8F%A3IP/</url>
      
        <content type="html"><![CDATA[<p>集群管理员可以为项目分配特定的静态IP，方便外部系统能够识别项目下的应用的出口流量。</p><ol><li>将出口IP分配到指定的Node</li></ol><p>支持指定特定的IP</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc patch hostsubnet &lt;node-name&gt; -p &#x27;&#123;&quot;egressIPs&quot;: [&quot;192.168.1.2&quot;, &quot;192.168.1.3&quot;]&#125;&#x27;</span><br></pre></td></tr></table></figure><p>支持指定特定的IP段</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc patch hostsubnet &lt;node-name&gt; -p &#x27;&#123;&quot;egressCIDRs&quot;: [&quot;192.168.1.0/24&quot;]&#125;&#x27;</span><br></pre></td></tr></table></figure><ol start="2"><li>为项目指定静态出口IP<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc patch netnamespace &lt;project-name&gt; -p &#x27;&#123;&quot;egressIPs&quot;: [&quot;192.168.1.100&quot;]&#125;&#x27;</span><br></pre></td></tr></table></figure></li><li>OpenShift容器平台会自动以平衡的方式将特定的出口IP地址分配给可用节点。 在这种情况下，它将出口IP地址192.168.1.100分配给<node-name>。</li></ol><p>一个Project只能指定一个EgressIP</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift部署时如何延长组件证书的有效期</title>
      <link href="/openshift/OpenShift%E9%83%A8%E7%BD%B2%E6%97%B6%E5%A6%82%E4%BD%95%E5%BB%B6%E9%95%BF%E7%BB%84%E4%BB%B6%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F/"/>
      <url>/openshift/OpenShift%E9%83%A8%E7%BD%B2%E6%97%B6%E5%A6%82%E4%BD%95%E5%BB%B6%E9%95%BF%E7%BB%84%E4%BB%B6%E8%AF%81%E4%B9%A6%E7%9A%84%E6%9C%89%E6%95%88%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-5ebac14ac271bdfe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift证书时长"></p><h2 id="延长集群核心证书的有效期"><a href="#延长集群核心证书的有效期" class="headerlink" title="延长集群核心证书的有效期"></a>延长集群核心证书的有效期</h2><p>OpenShift集群正常运行中涉及到非常多的证书，有各节点通信的证书，有数据库的证书，有私有镜像仓库的证书，还有各种组件的证书（EFK、ClusterMonitor、Metrics等）。对于集群的相关证书可以通过在inventory文件中添加如下配置就可以非常方便地更改相关证书的默认有效期。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">openshift_hosted_registry_cert_expire_days=3650</span><br><span class="line">openshift_ca_cert_expire_days=3650</span><br><span class="line">openshift_master_cert_expire_days=3650</span><br><span class="line">etcd_ca_default_days=3650</span><br></pre></td></tr></table></figure><p>但是以上的几个配置对于一些组件并不起作用，如EFK等。</p><h2 id="延长一些特殊组件证书的有效期"><a href="#延长一些特殊组件证书的有效期" class="headerlink" title="延长一些特殊组件证书的有效期"></a>延长一些特殊组件证书的有效期</h2><p>openshift自签应用证书的有效期为2 or 5年。其中crt证书默认为两年，ca证书为5年。例如es中的证书中，admin-ca有效期为5年，admin-crt有效期为2年。</p><p>也就是说按照当前OpenShift安装的默认步骤安装的EFK组件，证书最短有效期为两年，两年后需要执行证书更新操作。而ES证书更新时，需要对ES应用进行重启，这将会影响到ES的可用性。那么如果我们希望在在安装部署EFK组件的时候，将证书设置为更长的时间的话，就不需要进行证书的更新，也就不会影响到ES的服务了。那么怎样做到这一点呢？</p><p>带着这个问题，仔细研究了OpenShift部署的脚本，发现要实现这点并不困难，只需要将生成证书的地方添加过期时间就ok了。</p><p>与相关证书有效期有关的地方有如下五类：</p><h3 id="1-使用create-signer-cert命令创建的证书"><a href="#1-使用create-signer-cert命令创建的证书" class="headerlink" title="1. 使用create-signer-cert命令创建的证书"></a>1. 使用create-signer-cert命令创建的证书</h3><p>以ES服务为例，admin-ca证书的有效期时间默认为5年，将<code>roles/openshift_logging/tasks/generate_certs.yaml</code>中的oc adm ca create-signer-cert命令添加过期时间<code>--expire-days=36500</code>，例如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123; openshift_client_binary &#125;&#125; adm --config=&#123;&#123; mktemp.stdout &#125;&#125;/admin.kubeconfig ca create-signer-cert</span><br><span class="line">    --key=&#123;&#123;generated_certs_dir&#125;&#125;/ca.key --cert=&#123;&#123;generated_certs_dir&#125;&#125;/ca.crt</span><br><span class="line">    --serial=&#123;&#123;generated_certs_dir&#125;&#125;/ca.serial.txt --name=logging-signer-test --expire-days=36500</span><br></pre></td></tr></table></figure><h3 id="2-使用keytool创建的证书"><a href="#2-使用keytool创建的证书" class="headerlink" title="2. 使用keytool创建的证书"></a>2. 使用keytool创建的证书</h3><p>以ES服务为例，admin-crt有效期时间默认为2年。将<code>roles/openshift_logging/files/generate-jks.sh</code>脚本中的默认过期时间设置-validity设置为36500（一百年）即可，例如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">keytool -genkey \</span><br><span class="line">        -alias     $NODE_NAME \</span><br><span class="line">        -keystore  $dir/$NODE_NAME.jks \</span><br><span class="line">        -keyalg    RSA \</span><br><span class="line">        -keysize   2048 \</span><br><span class="line">        -validity  36500\</span><br><span class="line">        -startdate &quot;$startdate&quot; \</span><br><span class="line">        -keypass $ks_pass \</span><br><span class="line">        -storepass $ks_pass \</span><br><span class="line">        -dname &quot;CN=$NODE_NAME, OU=OpenShift, O=Logging&quot;</span><br></pre></td></tr></table></figure><h3 id="3-使用create-server-cert命令创建的证书"><a href="#3-使用create-server-cert命令创建的证书" class="headerlink" title="3. 使用create-server-cert命令创建的证书"></a>3. 使用create-server-cert命令创建的证书</h3><p>oc adm ca create-server-cert命令创建的证书的过期时间为2年，所以对于这些命令生成的证书脚本也需要设置过期时间<code>--expire-days=36500</code>,例如<code>metrics_server/tasks/generate_certs_and_apiservice.yaml</code>文件中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">- name: generate new serving cert secrets if needed</span><br><span class="line">  when: existing_metrics_server_secret.rc != 0</span><br><span class="line">  block:</span><br><span class="line">  - name: generate ca certificate chain</span><br><span class="line">    command: &gt;</span><br><span class="line">      &#123;&#123; openshift_client_binary &#125;&#125; adm ca create-signer-cert</span><br><span class="line">      --config=&#123;&#123; mktemp.stdout &#125;&#125;/admin.kubeconfig</span><br><span class="line">      --key=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/ca.key&#x27;</span><br><span class="line">      --cert=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/ca.crt&#x27;</span><br><span class="line">      --serial=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/ca.serial.txt&#x27;</span><br><span class="line">      --name=&quot;metrics-signer@&#123;&#123;lookup(&#x27;pipe&#x27;,&#x27;date +%s&#x27;)&#125;&#125;&quot;</span><br><span class="line">      --expire-days=36500</span><br><span class="line"></span><br><span class="line">  - name: generate metrics-server keys</span><br><span class="line">    command: &gt;</span><br><span class="line">      &#123;&#123; openshift_client_binary &#125;&#125; adm ca create-server-cert</span><br><span class="line">      --config=&#123;&#123; mktemp.stdout &#125;&#125;/admin.kubeconfig</span><br><span class="line">      --key=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/metrics-server.key&#x27;</span><br><span class="line">      --cert=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/metrics-server.crt&#x27;</span><br><span class="line">      --hostnames=&#x27;metrics-server,metrics-server.&#123;&#123; openshift_metrics_server_project &#125;&#125;.svc,metrics-server.&#123;&#123; openshift_metrics_server_project &#125;&#125;.svc.cluster.local&#x27;</span><br><span class="line">      --signer-cert=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/ca.crt&#x27;</span><br><span class="line">      --signer-key=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/ca.key&#x27;</span><br><span class="line">      --signer-serial=&#x27;&#123;&#123; mktemp.stdout &#125;&#125;/ca.serial.txt&#x27;</span><br><span class="line">      --expire-days=36500</span><br></pre></td></tr></table></figure><h3 id="4-使用oc-adm-ca-create-master-certs创建的证书"><a href="#4-使用oc-adm-ca-create-master-certs创建的证书" class="headerlink" title="4. 使用oc adm ca create-master-certs创建的证书"></a>4. 使用oc adm ca create-master-certs创建的证书</h3><p>oc adm ca证书创建相关的命令还有create-master-certs，通过它能够创建master的证书，OpenShift已经提供了相关的配置ansible&#x2F;hosts中添加变量：<code>openshift_master_cert_expire_days</code>与<code>openshift_ca_cert_expire_days</code>来设置证书的过期时间，不需要更改playbook脚本与shell脚本。</p><h3 id="5-使用openssl创建的证书"><a href="#5-使用openssl创建的证书" class="headerlink" title="5. 使用openssl创建的证书"></a>5. 使用openssl创建的证书</h3><p>openssl req -out xx.csr -days 712这是脚本中创建证书默认指定为2年。可将-days 712改为新的有效期时间。例如<code>roles/openshift_logging/tasks/generate_pems.yaml</code>。<br>另外<code>openssl ca -in ...</code>也需要添加<code>-days 36500</code>，也在该文件下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openssl ca -in &#123;&#123;generated_certs_dir&#125;&#125;/&#123;&#123;component&#125;&#125;.csr -notext -out &#123;&#123;generated_certs_dir&#125;&#125;/&#123;&#123;component&#125;&#125;.crt</span><br><span class="line">    -config &#123;&#123;generated_certs_dir&#125;&#125;/signing.conf -extensions v3_req -batch -extensions server_ext -days 36500</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift集群健康检查</title>
      <link href="/openshift/OpenShift%E9%9B%86%E7%BE%A4%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5/"/>
      <url>/openshift/OpenShift%E9%9B%86%E7%BE%A4%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5/</url>
      
        <content type="html"><![CDATA[<p>参考文章<br><a href="https://docs.openshift.com/container-platform/3.11/day_two_guide/environment_health_checks.html#day-two-guide-router-and-registry-health">https://docs.openshift.com/container-platform/3.11/day_two_guide&#x2F;environment_health_checks.html#day-two-guide-router-and-registry-health</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshfit-4-1部署手册</title>
      <link href="/openshift/Openshfit-4-1%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/"/>
      <url>/openshift/Openshfit-4-1%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<h2 id="设备与网络准备"><a href="#设备与网络准备" class="headerlink" title="设备与网络准备"></a>设备与网络准备</h2><ol><li>网络要求<ul><li>能够访问<a href="https://cloud.redhat.com/openshift/install">OpenShift Infrastructure Providers</a>以下载安装程序</li><li>能访问quay.io以获取安装群集所需的软件包</li><li>能访问<a href="http://cloud.redhat.com/">Red Hat’s software as a service page</a>以获取相关订阅</li></ul></li><li>准备节点<br>  1 bootstrap节点 RHCOS，引导计算机部署集群，在完成部署后该机器可被删除<br>  3 master节点 RHCOS<br>  2 compte节点 RHCOS or RHEL 7.6</li></ol><h2 id="部署前准备"><a href="#部署前准备" class="headerlink" title="部署前准备"></a>部署前准备</h2><ul><li>外部负载均衡器</li><li>配置主机端口</li><li>配置DNS</li><li>确保网络连接</li></ul><ol><li>以下端口必须能被集群中的所有机器访问</li></ol><table><thead><tr><th>端口</th><th>说明</th></tr></thead><tbody><tr><td>2379-2380</td><td>etcd server, peer, and metrics ports</td></tr><tr><td>6443</td><td>Kubernetes API</td></tr><tr><td>9000-9999</td><td>Host level services, including the node exporter on ports 9100-9101 and the Cluster Version Operator on port 9099.</td></tr><tr><td>10249-10259</td><td>The default ports that Kubernetes reserves</td></tr><tr><td>10256</td><td>openshift-sdn</td></tr><tr><td>30000-32767</td><td>Kubernetes NodePort</td></tr></tbody></table><ol start="2"><li>提供四层负载均衡器</li></ol><table><thead><tr><th>Port</th><th>Machines</th><th>Internal</th><th>External</th><th>Description</th></tr></thead><tbody><tr><td>6443</td><td>Bootstrap and control plane. You remove the bootstrap machine from the load balancer after the bootstrap machine initializes the cluster control plane.</td><td>x</td><td>x</td><td>Kubernetes API server</td></tr><tr><td>22623</td><td>Bootstrap and control plane. You remove the bootstrap machine from the load balancer after the bootstrap machine initializes the cluster control plane.</td><td>x</td><td>Machine Config server</td><td></td></tr><tr><td>443</td><td>The machines that run the Ingress router pods, compute, or worker, by default.</td><td>x</td><td>x</td><td>HTTPS traffic</td></tr><tr><td>80</td><td>The machines that run the Ingress router pods, compute, or worker by default.</td><td>x</td><td>x</td><td>HTTP traffic</td></tr><tr><td>3. DNS必须满足以下条件</td><td></td><td></td><td></td><td></td></tr></tbody></table><table><thead><tr><th>Component</th><th>Record</th><th>Description</th></tr></thead><tbody><tr><td>Kubernetes API</td><td>api.<cluster_name>.<base_domain></td><td>This DNS record must point to the load balancer for the control plane machines. This record must be resolvable by both clients external to the cluster and from all the nodes within the cluster.</td></tr><tr><td>Kubernetes API</td><td>api-int.<cluster_name>.<base_domain></td><td>This DNS record must point to the load balancer for the control plane machines. This record must be resolvable from all the nodes within the cluster.<br>The API server must be able to resolve the worker nodes by the host names that are recorded in Kubernetes. If it cannot resolve the node names, proxied API calls can fail, and you cannot retrieve logs from Pods.</td></tr><tr><td>Routes</td><td>*.apps.<cluster_name>.<base_domain></td><td>A wildcard DNS record that points to the load balancer that targets the machines that run the Ingress router pods, which are the worker nodes by default. This record must be resolvable by both clients external to the cluster and from all the nodes within the cluster.</td></tr><tr><td>etcd</td><td>etcd-<index>.<cluster_name>.<base_domain></td><td>OpenShift Container Platform requires DNS records for each etcd instance to point to the control plane machines that host the instances. The etcd instances are differentiated by <index> values, which start with 0 and end with n-1, where n is the number of control plane machines in the cluster. The DNS record must resolve to an unicast IPV4 address for the control plane machine, and the records must be resolvable from all the nodes in the cluster.</td></tr><tr><td>etcd</td><td>_etcd-server-ssl._tcp.<cluster_name>.<base_domain></td><td>For each control plane machine, OpenShift Container Platform also requires a SRV DNS record for etcd server on that machine with priority 0, weight 10 and port 2380. A cluster that uses three control plane machines requires the following records:</td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># _service._proto.name.                            TTL    class SRV priority weight port target.</span><br><span class="line">_etcd-server-ssl._tcp.&lt;cluster_name&gt;.&lt;base_domain&gt;  86400 IN    SRV 0        10     2380 etcd-0.&lt;cluster_name&gt;.&lt;base_domain&gt;.</span><br><span class="line">_etcd-server-ssl._tcp.&lt;cluster_name&gt;.&lt;base_domain&gt;  86400 IN    SRV 0        10     2380 etcd-1.&lt;cluster_name&gt;.&lt;base_domain&gt;.</span><br><span class="line">_etcd-server-ssl._tcp.&lt;cluster_name&gt;.&lt;base_domain&gt;  86400 IN    SRV 0        10     2380 etcd-2.&lt;cluster_name&gt;.&lt;base_domain&gt;.</span><br></pre></td></tr></table></figure><ol start="4"><li>生成SSH私钥，并启动ssh-agent<ol><li>生成SSH私钥 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -b 4096 -N &#x27;&#x27; \</span><br><span class="line">-f &lt;path&gt;/&lt;file_name&gt; </span><br></pre></td></tr></table></figure></li><li>后台运行ssh-agent <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ eval &quot;$(ssh-agent -s)&quot;</span><br><span class="line"></span><br><span class="line"> Agent pid 31874</span><br></pre></td></tr></table></figure></li><li>将SSH私钥添加到ssh-agent <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-add &lt;path&gt;/&lt;file_name&gt; </span><br><span class="line"></span><br><span class="line">Identity added: /home/&lt;you&gt;/&lt;path&gt;/&lt;file_name&gt; (&lt;computer_name&gt;)</span><br></pre></td></tr></table></figure></li></ol></li><li>下载安装程序<ol><li>访问<a href="https://cloud.redhat.com/openshift/install">OpenShift Infrastructure Providers</a>网页</li><li>下载对应操作系统的安装包</li><li>将安装包解压 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar xvf &lt;installation_program&gt;.tar.gz  </span><br></pre></td></tr></table></figure></li><li>在<a href="https://cloud.redhat.com/openshift/install">OpenShift Infrastructure Providers</a>网页下载镜像的拉取密钥</li></ol></li><li>安装Openshfit 客户端工具</li><li>手动创建安装配置文件</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift+Jenkins+zalenium+HtmlReporter实现自动化测试</title>
      <link href="/openshift/Openshift+Jenkins+zalenium+HtmlReporter%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"/>
      <url>/openshift/Openshift+Jenkins+zalenium+HtmlReporter%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p>上篇介绍了如果<a href="https://www.jianshu.com/p/c38abbcff5cc">在openshift上部署zalenium及python对应用功能进行测试的方法</a>。<br>该篇介绍<strong>如何通过Jenkins的Slave容器配合上篇中的zalenium实现自动化功能测试，并生成测试报告</strong>。虽然只是一个小例子，但是麻雀虽小，五脏俱全。同时所有的操作及工具都建立在Openshift上。<br>下图为各工具之间的关系：<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/1f0a705ac716e3f8c042d52afd7aed8cf552827d5db096524a2f14d672bed6fd.png" alt="jenkins+zalenium+HtmlReporter">  </p><p>###具体操作：</p><ul><li><ol><li>启动Jenkins需要添加环境变量<br><code>JENKINS_JAVA_OVERRIDES</code> &#x3D;&gt; <code>-Dhudson.model.DirectoryBrowserSupport.CSP=</code><br>该环境变量使得HtmlReporter页面展示正常</li></ol></li><li><ol start="2"><li>Jenkins系统管理-&gt;系统设置中创建新的Kubernetes Pod Template<br>基础镜像<code>jenkins-slave-python-centos7:3.10</code>，Dockerfile安装需要的python依赖包</li></ol> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">FROM informaticsmatters/jenkins-slave-python-centos7</span><br><span class="line">RUN pip install selenium -i https://pypi.douban.com/simple/</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/02bb5e58cd845a59a119505e37e8a78b1ca6c17fcc04f8cf991bc6b46f6080b2.png" alt="添加Jenkins Slave模板.PNG">  </p><ul><li><ol start="3"><li>代码中添加自动化测试脚本 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import unittest</span><br><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.remote.remote_connection import RemoteConnection</span><br><span class="line">from HTMLTestRunner import HTMLTestRunner</span><br><span class="line"></span><br><span class="line">class SeleniumTestCase(unittest.TestCase):</span><br><span class="line">    def setUp(self):</span><br><span class="line">        remoteconnection = RemoteConnection(&#x27;http://zalenium.example.com/wd/hub&#x27;,</span><br><span class="line">                                            keep_alive=False,</span><br><span class="line">                                            resolve_ip=False)</span><br><span class="line"></span><br><span class="line">        self.driver = webdriver.Remote(command_executor=remoteconnection,</span><br><span class="line">                                       desired_capabilities=&#123;</span><br><span class="line">                                           &#x27;browserName&#x27;: &quot;chrome&quot;,</span><br><span class="line">                                           &#x27;video&#x27;: &#x27;True&#x27;,</span><br><span class="line">                                           &#x27;platform&#x27;: &#x27;LINUX&#x27;,</span><br><span class="line">                                           &#x27;platformName&#x27;: &#x27;LINUX&#x27;</span><br><span class="line">                                       &#125;)</span><br><span class="line">        self.driver.implicitly_wait(30)</span><br><span class="line">        self.driver.maximize_window()</span><br><span class="line"></span><br><span class="line">    def test_login_test_case(self):</span><br><span class="line">        self.driver.get(&quot;https://devpf.example.com&quot;)</span><br><span class="line">        username_input = self.driver.find_element_by_id(&#x27;username&#x27;)</span><br><span class="line">        password_input = self.driver.find_element_by_id(&#x27;password&#x27;)</span><br><span class="line">        login_button = self.driver.find_element_by_id(&#x27;login_btn&#x27;)</span><br><span class="line">        username_input.clear()</span><br><span class="line">        username_input.send_keys(&#x27;panxiaohua&#x27;)</span><br><span class="line">        password_input.clear()</span><br><span class="line">        password_input.send_keys(&#x27;12345678&#x27;)</span><br><span class="line">        login_button.click()</span><br><span class="line"></span><br><span class="line">        assert not None is self.driver.find_element_by_id(&#x27;content&#x27;), &#x27;Error Happends&#x27;</span><br><span class="line"></span><br><span class="line">    def tearDown(self):</span><br><span class="line">        self.driver.quit()</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    suite = unittest.TestSuite()</span><br><span class="line">    suite.addTest(unittest.TestLoader().loadTestsFromTestCase(SeleniumTestCase))</span><br><span class="line">    with open(&#x27;report.html&#x27;, &#x27;w&#x27;) as f:</span><br><span class="line">        runner = HTMLTestRunner(stream=f, title=&#x27;Test Report&#x27;, verbosity=2)</span><br><span class="line">        runner.run(suite)</span><br></pre></td></tr></table></figure></li></ol></li><li><ol start="4"><li>Jenkins Job中完成部署后，执行测试脚本<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd tests</span><br><span class="line">python test_urls.py</span><br></pre></td></tr></table></figure><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/a11aca0485914de1ebedac5959779f320c50afafb9377e580e76c7c152536d46.png" alt="测试执行操作.PNG"></li></ol></li><li><ol start="5"><li>导出自动测试报表</li></ol></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ba8900ff40faed422da37060f650629a9d4e301784151b2da8f3566ba92c5a73.png" alt="构建后操作.PNG">  </p><ul><li><ol start="6"><li>最后结果展示</li></ol></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/dccf4ae9e0efb1f7ce4baff44b06f90469f2a97c58b7cc1ffe1c3770c4af8bf6.png" alt="Reporter报告展示.PNG">  </p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshfit上用ConfigMap来自定义Nginx配置</title>
      <link href="/openshift/Openshfit%E4%B8%8A%E7%94%A8ConfigMap%E6%9D%A5%E8%87%AA%E5%AE%9A%E4%B9%89Nginx%E9%85%8D%E7%BD%AE/"/>
      <url>/openshift/Openshfit%E4%B8%8A%E7%94%A8ConfigMap%E6%9D%A5%E8%87%AA%E5%AE%9A%E4%B9%89Nginx%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>Nginx是最常用的代理软件，也是最常用的WebServer，怎样很方便地在openshift上部署呢？同时又能很方便地对它自定义进行配置？<br>直接使用docker的nginx会有以下问题：</p><blockquote><ol><li>启动时权限问题。默认openshift的应用会使用类似10000100的user_id启用docker，但是官方nginx镜像会使用root启用；还有nginx默认会启用80端口这个也是需要root权限的。</li><li>无法动态更新nginx配置。nginx配置在镜像中设置，如果需要更新配置的话，需要重新编译镜像。</li><li>应用代码更新。如果用户的代码，如静态代码，版本更新，是否可以不更新镜像，而完成版本的升级？</li></ol></blockquote><p>在Openshift上部署一个nginx应用如何解决以上3个问题。</p><blockquote><ol><li>权限问题</li></ol></blockquote><p> <code>解决办法: 制作专用nginx镜像，1. 更改特殊文件夹的权限为777；2.将默认端口设置为8080</code><br>default.conf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">    listen  8080;</span><br><span class="line">    server_name _;</span><br><span class="line">    location /&#123;</span><br><span class="line">      root  /usr/share/nginx/html;</span><br><span class="line">      index index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">    error_page 500 502 503 504 /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">      root  /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Dockerfile文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#Dockerfile</span><br><span class="line">FROM docker.io/nginx:1.14</span><br><span class="line">LABEL io.openshift.expose-services=&quot;8080:http&quot;</span><br><span class="line">COPY default.conf /etc/nginx/conf.d/default.conf</span><br><span class="line">RUN chmod -R 777 /var/log/nginx /var/cache/nginx /var/run \</span><br><span class="line">    &amp;&amp; chgrp -R 0 /etc/nginx \</span><br><span class="line">    &amp;&amp; chmod -R g=u /etc/nginx</span><br><span class="line">EXPOSE 8080</span><br></pre></td></tr></table></figure><p>制作镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t harbor.apps.example.com/public/nginx:1.14 .</span><br><span class="line">docker push harbor.apps.example.com/public/nginx:1.14</span><br></pre></td></tr></table></figure><p>使用新的镜像部署应用(在nginx-project中创建DeploymentConfig nginx-demo)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc new-app harbor.apps.example.com/public/nginx:1.14 --allow-missing-images --name=nginx-demo -n nginx-project</span><br></pre></td></tr></table></figure><p>创建Service对应pod的8080端口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc expose dc nginx-demo --port=8080</span><br></pre></td></tr></table></figure><p>创建Route对应Service，使得服务能够对外提供服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc expose svc nginx-demo --hostname=www.web.example.com</span><br></pre></td></tr></table></figure><p>本地绑定hostname<code>www.web.example.com</code>与Openshift集群的Router所在主机的ip，即可通过浏览器访问到服务。</p><blockquote><p>2.自定义nginx配置</p></blockquote><p><code>解决办法：使用ConfigMap创建nginx的配置，并挂载到/etc/nginx/conf.d目录</code></p><p>ConfigMap文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-config</span><br><span class="line">  namespace: nginx-project</span><br><span class="line">data:</span><br><span class="line">  demo.conf: &quot;proxy_set_header Host $host;\r\nproxy_set_header X-Real-IP $remote_addr;\r\nproxy_set_header     X-Forwarded-Server $host;\r\nserver &#123;\r\n        listen       8080;\r\n        server_name  _;\r\n    \tlocation / &#123;\r\n        \tproxy_pass http://test.back.svc:28080/; \r\n    \t&#125;error_page   500 502 503 504  /50x.html;\r\n        location = /50x.html &#123;\r\n            root   html;\r\n        &#125;\r\n    &#125;&quot;</span><br></pre></td></tr></table></figure><p>ConfigMap的内容即为nginx的conf.d目录下的所有conf配置文件。将它们挂载到&#x2F;etc&#x2F;nginx&#x2F;conf.d目录下。<br><code>通过openshift的web console可以非常方便地操作</code>如下图<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/1c23f77ba850e335023b0376dbe145169dbed6e65fdcf0e86137c23ed962fa3d.png" alt="将ConfigMap挂载到DeployConfig应用/etc/nginx/conf.d目录">  </p><p><code>当然我们也可以更改DeployConfig的配置来实现同样的效果</code><br>在nginx-demo的DeployConfig中添加挂载点及ConfigMap挂载<br>我们可以把所有配置一次性挂载到目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">      containers:</span><br><span class="line">        - image: &#x27;harbor.apps.example.com/public/nginx:1.14&#x27;</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: nginx-demo</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/nginx/conf.d</span><br><span class="line">              name: nginx-config-hgj4i</span><br><span class="line">              readOnly: true</span><br><span class="line">      volumes:</span><br><span class="line">        - configMap:</span><br><span class="line">            defaultMode: 420</span><br><span class="line">            name: nginx-config</span><br><span class="line">          name: nginx-config-hgj4i</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>同时我们也可以只挂载指定的文件，同时不覆盖同目录下的其他文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">      containers:</span><br><span class="line">        - image: &#x27;harbor.apps.example.com/public/nginx:1.14&#x27;</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: nginx-demo</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/nginx/conf.d/test.conf</span><br><span class="line">              name: nginx-config-hgj4i</span><br><span class="line">              subPath: test.conf</span><br><span class="line">              readOnly: true</span><br><span class="line">      volumes:</span><br><span class="line">        - configMap:</span><br><span class="line">            defaultMode: 420</span><br><span class="line">            name: nginx-config</span><br><span class="line">            items:</span><br><span class="line">              - key: default.conf</span><br><span class="line">                path: test.conf</span><br><span class="line">          name: nginx-config-hgj4i</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>对于不同的应用，我们需要不同的nginx配置时，只需要挂载不同的configmap即可。常见的应用场景为：将nginx作为代理服务器来使用的情况。</p><blockquote><p>3.应用代码更新</p></blockquote><p><code>解决办法：持久化存储</code><br>Openshift是建立在Kubernetes的基础上的，而K8S支持十多种存储方式，如：NFS，GlusterFS，CephFS，RBD，HostPath等。<br>这里使用NFS作为持久化存储方案。CentOS系统自带NFS服务。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nfs #启动nfs，如果已启动，则不用操作</span><br><span class="line">mkdir -p /nfsdata/nginx_app</span><br><span class="line">chown nfsnobody:nfsnobody /nfsdata/nginx_app</span><br><span class="line">chmod 700 /nfsdata/nginx_app</span><br><span class="line"></span><br><span class="line">#开放nfs访问的端口</span><br><span class="line">iptables -A INPUT -p tcp --dport 111 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p udp --dport 111 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p tcp --dport 2049 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p udp --dport 2049 -j ACCEPT</span><br><span class="line"></span><br><span class="line"># 配置NFS</span><br><span class="line">echo &quot;/nfsdata/nginx_app *(rw,async,no_root_squash)&quot; &gt;&gt; /etc/exports</span><br><span class="line">exportfs -a #加载共享目录配置</span><br><span class="line">showmount -e #查看当前可用的共享目录</span><br></pre></td></tr></table></figure><p>创建PV持久化存储</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># nginx-pv.yml</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pv</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: &quot;5Gi&quot;</span><br><span class="line">  accessModes:</span><br><span class="line">    - &quot;ReadWriteMany&quot;</span><br><span class="line">  nfs:</span><br><span class="line">    path: &quot;/nfsdata/nginx_app&quot;</span><br><span class="line">    server: &quot;192.168.0.4&quot;</span><br></pre></td></tr></table></figure><p>创建PV</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f nginx-pv.yml</span><br></pre></td></tr></table></figure><p>创建PVC</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-app-pvc</span><br><span class="line">  namespace: nginx-project</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: &quot;5Gi&quot;</span><br></pre></td></tr></table></figure><p>将创建的PVC挂载到DeploymentConfig中需要放的应用的目录下，同时注意该目录也应该是与ConfigMap中的server的root目录一致。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - image: &#x27;harbor.apps.example.com/public/nginx:1.14&#x27;</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      name: nginx-demo</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - mountPath: /etc/nginx/conf.d</span><br><span class="line">          name: nginx-config-hgj4i</span><br><span class="line">          readOnly: true</span><br><span class="line">        - mountPath: /appdata</span><br><span class="line">          name: appdata-pvc</span><br><span class="line">  volumes:</span><br><span class="line">    - name: nginx-config-hgj4i</span><br><span class="line">      configMap:</span><br><span class="line">        defaultMode: 420</span><br><span class="line">        name: nginx-config</span><br><span class="line">      </span><br><span class="line">    - name: appdata-pvc</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: nginx-app-pvc</span><br></pre></td></tr></table></figure><p>将对应的NFS挂载到开发或者部署的服务器上，同时将代码拷入共享存储，此时代码自动同步到的应用中。实现了代码同步。</p><p>综上，我们实现了使用同一个Nginx镜像，实现了在Openshift上自定义nginx配置及应用代码的部署。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-3scale简单介绍</title>
      <link href="/openshift/Openshift-3scale%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/"/>
      <url>/openshift/Openshift-3scale%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h3 id="API经济"><a href="#API经济" class="headerlink" title="API经济"></a>API经济</h3><h3 id="3scale做了什么？"><a href="#3scale做了什么？" class="headerlink" title="3scale做了什么？"></a>3scale做了什么？</h3><h3 id="关注指标"><a href="#关注指标" class="headerlink" title="关注指标"></a>关注指标</h3><ul><li>支持应用数据</li><li>完整用例的数量</li><li>用户数量</li><li>资金价值</li><li>开发速度</li><li>部署速度</li><li>迁移工作量</li><li>已有问题</li></ul><h3 id="完整的API管理不仅仅只是创建与发布，还需要配套全方位的运维"><a href="#完整的API管理不仅仅只是创建与发布，还需要配套全方位的运维" class="headerlink" title="完整的API管理不仅仅只是创建与发布，还需要配套全方位的运维"></a>完整的API管理不仅仅只是创建与发布，还需要配套全方位的运维</h3><ul><li>创建与发布API</li><li>度量和计费</li><li>安全 &amp; 认证</li><li>API文档Portal</li><li>扩展性 &amp; 集中策略</li><li>API监控</li><li>版本控制</li><li>生命周期</li><li>配置 &amp; 告警</li><li>API测试</li></ul><h3 id="3scale架构（可容器化部署）"><a href="#3scale架构（可容器化部署）" class="headerlink" title="3scale架构（可容器化部署）"></a>3scale架构（可容器化部署）</h3><p><img src="https://upload-images.jianshu.io/upload_images/5793257-952926923b9cdfb0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="3scale架构.png"></p><p>实验内容<br>github.com&#x2F;hgueere</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-All-In-One一键部署工具上线</title>
      <link href="/openshift/Openshift-All-In-One%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7%E4%B8%8A%E7%BA%BF/"/>
      <url>/openshift/Openshift-All-In-One%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7%E4%B8%8A%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<h3 id="Openshift-All-In-One工具制作的初衷："><a href="#Openshift-All-In-One工具制作的初衷：" class="headerlink" title="Openshift All In One工具制作的初衷："></a>Openshift All In One工具制作的初衷：</h3><ul><li>工作中为了测试各种情况，比如备份恢复等，经常需要部署一套全新的Openshift环境，虽然镜像与安装包都是现成，但是部署过程中还是很容易出错，毕竟还是有些复杂的。竟然部署过程是一致的，那就干脆用脚本化，一键到位得了。</li><li><a href="https://www.jianshu.com/p/3e8db6a34af5">Openshift3.9部署手册</a>，这是我之前整理的一篇单机部署Openshift 3.9的手册，有一些朋友看了后，按照上面的操作还是会遇到一些问题，毕竟步骤有那么多，差了一步，就很容易就会失败。有了这个脚本工具后，想要部署测试Openshift的朋友就很容易去部署测试了，而不是在部署这一步就放弃了。</li><li>有些厂商提供了Openshift的解决方案，但是做支持的厂商朋友并不太熟悉容器平台环境，也想在自己的环境下部署一套Openshift来测试，最后往往困难重重，从展望到放弃。</li></ul><p><strong>做个自动化工具，让所有关心Openshift&#x2F;K8s的朋友就可以跳过部署的步骤，快速进入到Paas这个神奇的世界，去了解到自己真正关心的内容。</strong></p><h3 id="进入正题"><a href="#进入正题" class="headerlink" title="进入正题"></a>进入正题</h3><ul><li><p>什么是正题？直接上工具git地址<br>OpenshiftOneClick：<a href="https://gitee.com/xhua/OpenshiftOneClick">https://gitee.com/xhua/OpenshiftOneClick</a></p></li><li><p>开发工具： Ansible + Shell</p></li></ul><h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><ol><li><p>准备一台主机&#x2F;虚拟机(CentOS 7.4以上, CPU &gt; 2core, Memory &gt; 4G)</p></li><li><p>将一键部署脚本拷贝到主机上</p></li><li><p>cd到openshift-oneclick-allinone目录</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd openshift-oneclick-allinone</span><br></pre></td></tr></table></figure></li><li><p>运行部署(必须切到root账号)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line">/bin/bash deploy_openshift.sh</span><br></pre></td></tr></table></figure></li><li><p>本地绑定hosts</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># HOSTNAME 默认为os39.test.it.example.com</span><br><span class="line">&lt;ip&gt; os39.test.it.example.com</span><br></pre></td></tr></table></figure></li><li><p>浏览器访问</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># HOSTNAME 默认为os39.test.it.example.com</span><br><span class="line">https://os39.test.it.example.com:8443</span><br></pre></td></tr></table></figure><p>默认账号：<strong>admin</strong><br>默认密码：<strong>admin</strong></p><h3 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h3><ul><li>用本地的Vagrant创建的Centos 7.4的虚拟机（VirtualBox）</li><li>配置2核4G</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-aba0f980b502b61d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="一键部署的Openshift3.9"></p><h3 id="工具说明"><a href="#工具说明" class="headerlink" title="工具说明"></a>工具说明</h3><blockquote><p>该工具具有一定的可配置性</p></blockquote><p>查看config.yml文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CHANGEREPO: true</span><br><span class="line">HOSTNAME: os39.test.it.example.com</span><br><span class="line"></span><br><span class="line">Change_Base_Registry: false</span><br><span class="line">Harbor_Url: harbor.apps.it.example.com</span><br><span class="line"></span><br><span class="line">FULL_INSTALL: false</span><br></pre></td></tr></table></figure><p>   说明:</p><ul><li><strong>CHANGEREPO</strong>: 是否使用files&#x2F;all.repo替换系统默认repo源</li><li><strong>HOSTNAME</strong>：安装Openshift的主机的hostname，也是集群的访问域名</li><li><strong>Change_Base_Registry</strong>：是否使用私有镜像仓库</li><li><strong>Harbor_Url</strong>：私有镜像仓库地址，Change_Base_Registry为True时有效</li><li><strong>FULL_INSTALL</strong>：是否全量安装（包括日志，监控等）<br>如果选择全量安装(FULL_INSTALL&#x3D;true)，请保证主机内存有<strong>16G</strong>.</li></ul><blockquote><p>如果执行过程中出现异常，不用怕。工具是基于ansible的，幂等性。</p></blockquote><p>重新运行deploy_openshift.sh就OK了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line">/bin/bash deploy_openshift.sh</span><br></pre></td></tr></table></figure><blockquote><p>有什么疑问和改进的想法，欢迎留言。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 报错 ERROR! | failed expects hostvars is a dict</span><br><span class="line">In /etc/ansible/playbooks/openshift-ansible/roles/openshift_master_certificates/tasks/main.yml around line 63 I simply changed the with_items clause from</span><br><span class="line">- &quot;&#123;&#123; hostvars[inventory_hostname] | certificates_to_synchronize &#125;&#125;&quot;</span><br><span class="line">to</span><br><span class="line">- &quot;&#123;&#123; hostvars[inventory_hostname][&#x27;ansible_facts&#x27;] | certificates_to_synchronize &#125;&#125;&quot;</span><br><span class="line">and everything progressed.</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-F5集成（南北流量走F5）</title>
      <link href="/openshift/Openshift-F5%E9%9B%86%E6%88%90%EF%BC%88%E5%8D%97%E5%8C%97%E6%B5%81%E9%87%8F%E8%B5%B0F5%EF%BC%89/"/>
      <url>/openshift/Openshift-F5%E9%9B%86%E6%88%90%EF%BC%88%E5%8D%97%E5%8C%97%E6%B5%81%E9%87%8F%E8%B5%B0F5%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="使用F5与Openshift集成目的"><a href="#使用F5与Openshift集成目的" class="headerlink" title="使用F5与Openshift集成目的"></a>使用F5与Openshift集成目的</h3><p>外部流量访问应用时，通过F5 BIG-IP硬件设备直接代理到集群中的Pod。<br>这样做的好处，很明显。</p><ul><li>使用硬件负载均衡器替换掉软件负载均衡器，提高性能。</li><li>F5有更灵活的配置，可以实现更复杂的流量控制</li></ul><h3 id="Openshift操作"><a href="#Openshift操作" class="headerlink" title="Openshift操作"></a>Openshift操作</h3><p>Openshift通过BIG-IP Controller来控制BIG-IP设备。由于Openshift是基于Kubernetes的，所以它们使用同一个Controller（k8s-bigip-ctlr）。BIG-IP Controller为集群中的应用配置BIG-IP对象，提供南北流量的服务。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-1660de5ba556891f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="F5集成Openshift原理图"><br>BIG-IP Controller有两种方式来使用F5 BIG-IP设备</p><ul><li>为Openshift中的Service提供代理流量</li><li>为Openshift中的Route提供代理流量</li></ul><h4 id="为Openshift中的Service提供代理流量-不介绍具体部署操作"><a href="#为Openshift中的Service提供代理流量-不介绍具体部署操作" class="headerlink" title="为Openshift中的Service提供代理流量_(不介绍具体部署操作)_"></a>为Openshift中的Service提供代理流量_(不介绍具体部署操作)_</h4><p>这种方式，我们测试下来发现，需要为对外提供服务的Service绑定到F5的不同端口，同时外部访问应用时需要指定端口号。如：<br><code>app1.openshift.example.com:8000</code>, <code>app2.openshift.example.com:8001</code>，<code>app3.openshift.example.com:8002</code>，其中端口号不能重复。</p><ul><li><em><strong>这种方式在真正使用时不能满足业务需求，除非在F5的前面再加一层代理，这又增加了架构的复杂性。</strong></em></li><li><em><strong>理想的状态是，所以的App应用的HTTP请求都访问F5的80端口，而HTTPS的请求访问F5的443端口，根据请求的域名路由到对应的Pool中（每个Pool是一个Service下的所有Pod的列表）。</strong></em></li><li><em><strong>很高兴告诉大家，第二种方式能够满足上面的需求</strong></em></li></ul><h4 id="为Openshift中的Route提供代理流量"><a href="#为Openshift中的Route提供代理流量" class="headerlink" title="为Openshift中的Route提供代理流量"></a>为Openshift中的Route提供代理流量</h4><p>使用BIG-IP作为Openshift的Router，能实现以下功能：</p><ul><li>为Services创建BIG-IP本地流量规则</li><li>提供HTTP&#x2F;HTTPS路由</li><li>为Route资源添加BIG-IP健康检查</li></ul><p><strong>本文只介绍，如何使用F5提供HTTP&#x2F;HTTPS路由。这也是最核心的部分。</strong></p><blockquote><p>部署环境版本：<br>  <strong>2台F5：v13</strong>  192.168.200.82 192.168.200.83<br>  <strong>Openshift集群： v3.9.1</strong></p></blockquote><blockquote><p>创建新的HostSub <code>Openshift</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># hostsubnet.yml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: HostSubnet</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-node01</span><br><span class="line">  annotations:</span><br><span class="line">    pod.network.openshift.io/fixed-vnid-host: &quot;0&quot;</span><br><span class="line">    pod.network.openshift.io/assign-subnet: &quot;true&quot;</span><br><span class="line"># provide a name for the node that will serve as BIG-IP&#x27;s entry into the cluster</span><br><span class="line">host: f5-bigip-node01</span><br><span class="line"># The hostIP address will be the BIG-IP interface address routable to the</span><br><span class="line"># OpenShift Origin nodes.</span><br><span class="line"># This address is the BIG-IP VTEP in the SDN&#x27;s VXLAN.</span><br><span class="line">hostIP: 192.168.200.82</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: HostSubnet</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-node02</span><br><span class="line">  annotations:</span><br><span class="line">    pod.network.openshift.io/fixed-vnid-host: &quot;0&quot;</span><br><span class="line">    pod.network.openshift.io/assign-subnet: &quot;true&quot;</span><br><span class="line"># provide a name for the node that will serve as BIG-IP&#x27;s entry into the cluster</span><br><span class="line">host: f5-bigip-node02</span><br><span class="line"># The hostIP address will be the BIG-IP interface address routable to the</span><br><span class="line"># OpenShift Origin nodes.</span><br><span class="line"># This address is the BIG-IP VTEP in the SDN&#x27;s VXLAN.</span><br><span class="line">hostIP: 192.168.200.83</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: HostSubnet</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-float</span><br><span class="line">  annotations:</span><br><span class="line">    pod.network.openshift.io/fixed-vnid-host: &quot;0&quot;</span><br><span class="line">    pod.network.openshift.io/assign-subnet: &quot;true&quot;</span><br><span class="line"># provide a name for the node that will serve as BIG-IP&#x27;s entry into the cluster</span><br><span class="line">host: f5-bigip-float</span><br><span class="line"># The hostIP address will be the BIG-IP interface address routable to the</span><br><span class="line"># OpenShift Origin nodes.</span><br><span class="line"># This address is the BIG-IP VTEP in the SDN&#x27;s VXLAN.</span><br><span class="line">hostIP: 192.168.200.84</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f hostsubnet.yml</span><br></pre></td></tr></table></figure><p>查看执行结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# oc get hostsubnet </span><br><span class="line">NAME                                 HOST                                 HOST IP         SUBNET          EGRESS IPS</span><br><span class="line">f5-bigip-float                       f5-bigip-float                       192.168.200.84   10.128.6.0/23   []</span><br><span class="line">f5-bigip-node01                      f5-bigip-node01                      192.168.200.82   10.129.6.0/23   []</span><br><span class="line">f5-bigip-node02                      f5-bigip-node02                      192.168.200.83   10.130.4.0/23   []</span><br><span class="line">master01.example.com   master01.example.com   192.168.200.1     10.130.0.0/23   []</span><br><span class="line">master02.example.com   master02.example.com   192.168.200.2     10.128.0.0/23   []</span><br><span class="line">master03.example.com   master03.example.com   192.168.200.3     10.128.2.0/23   []</span><br><span class="line">node01.example.com     node01.example.com     192.168.200.21    10.129.0.0/23   []</span><br><span class="line">node02.example.com     node02.example.com     192.168.200.22    10.131.0.0/23   []</span><br><span class="line">router01.example.com   router01.example.com   192.168.200.11    10.129.2.0/23   []</span><br><span class="line">router02.example.com   router02.example.com   192.168.200.12    10.130.2.0/23   []</span><br></pre></td></tr></table></figure><blockquote><p>创建一个VXLAN profile <code>F5</code></p></blockquote><p>在F5的TMOS终端，创建一个多点模式的vxlan</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /net tunnels vxlan openshift_vxlan flooding-type multipoint</span><br></pre></td></tr></table></figure><blockquote><p>创建一个VXLAN Tunnel <code>F5</code></p></blockquote><p>Local Address使用vip： 192.168.200.84<br>Secondary Address使用F5的设备IP：node1 192.168.200.82， node2 192.168.200.83<br>在F5 Node1上的TMOS创建Tunnel</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /net tunnels tunnel &lt;float_tun_name&gt; key 0 profile openshift_vxlan local-address 192.168.200.84 secondary-address 192.168.200.82 traffic-group traffic-group-1</span><br></pre></td></tr></table></figure><p>在F5 Node2上的TMOS创建Tunnel</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /net tunnels tunnel &lt;float_tun_name&gt; key 0 profile openshift_vxlan local-address 192.168.200.84 secondary-address 192.168.200.83 traffic-group traffic-group-1</span><br></pre></td></tr></table></figure><blockquote><p>在每个F5设备VXLAN中创建Self IP <code>F5</code></p></blockquote><p>IP为设备对应在Openshift的HostSubnet下的一个IP（只要在对应的HostSubnet下就OK）<br>在F5 Node1中创建Self IP</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /net self 10.129.6.82/14 allow-service none vlan openshift_vxlan</span><br></pre></td></tr></table></figure><p>在F5 Node2中创建Self IP</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /net self 10.130.4.83/14 allow-service none vlan openshift_vxlan</span><br></pre></td></tr></table></figure><blockquote><p>在当前主F5设备的VXLAN下创建Floating IP <code>F5</code></p></blockquote><p>如：当前主F5设备为node1，那Floating IP为主设备所在的HostSubnet下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /net self 10.128.6.84/14 allow-service none traffic-group traffic-group-1 vlan openshift_vxlan</span><br></pre></td></tr></table></figure><blockquote><p>创建一个新的Partition <code>F5</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create auth partition OpenShift</span><br></pre></td></tr></table></figure><blockquote><p>创建访问F5 BIG-IP的私钥 <code>Openshift</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create secret generic bigip-login --from-literal=username=admin --from-literal=password=admin -n kube-system</span><br></pre></td></tr></table></figure><blockquote><p>创建RBAC认证 <code>Openshift</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># cluster-role.yml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: bigip-ctlr</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># For use in OpenShift clusters</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    authorization.openshift.io/system-only: &quot;true&quot;</span><br><span class="line">  name: system:bigip-ctlr</span><br><span class="line">  namespace: kube-system</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;]</span><br><span class="line">  resources: [&quot;nodes&quot;, &quot;services&quot;, &quot;endpoints&quot;, &quot;namespaces&quot;, &quot;ingresses&quot;, &quot;routes&quot; ]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;]</span><br><span class="line">  resources: [&quot;configmaps&quot;, &quot;events&quot;, &quot;ingresses/status&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;, &quot;create&quot;, &quot;patch&quot; ]</span><br><span class="line">- apiGroups: [&quot;&quot;, &quot;extensions&quot;]</span><br><span class="line">  resources: [&quot;secrets&quot;]</span><br><span class="line">  resourceNames: [&quot;bigip-login&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: bigip-ctlr-role</span><br><span class="line">  namespace: kube-system</span><br><span class="line">userNames:</span><br><span class="line">- system:serviceaccount:kube-system:bigip-ctlr</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: bigip-ctlr</span><br><span class="line">roleRef:</span><br><span class="line">  name: system:bigip-ctlr</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f cluster-role.yml</span><br></pre></td></tr></table></figure><blockquote><p>部署BIG-IP Controller <code>Openshift</code></p></blockquote><ul><li>对应每台F5设备创建一个Deployment</li><li>Deployment中的 –bigip-url 为设备的IP</li><li>Deployment中的 –bigip-partition为之前F5下创建的Partition,Openshift</li><li>Deployment中的 –route-vserver-addr 为F5对外提供服务的IP<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">#deployment.yml</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-ctlr-01</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: k8s-bigip-ctlr</span><br><span class="line">      labels:</span><br><span class="line">        app: k8s-bigip-ctlr</span><br><span class="line">    spec:</span><br><span class="line">      # Name of the Service Account bound to a Cluster Role with the required</span><br><span class="line">      # permissions</span><br><span class="line">      serviceAccountName: bigip-ctlr</span><br><span class="line">      containers:</span><br><span class="line">        - name: k8s-bigip-ctlr</span><br><span class="line">          # replace the version as needed</span><br><span class="line">          image: &quot;f5networks/k8s-bigip-ctlr:1.5.1&quot;</span><br><span class="line">          env:</span><br><span class="line">            - name: BIGIP_USERNAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: username</span><br><span class="line">            - name: BIGIP_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: password</span><br><span class="line">          command: [&quot;/app/bin/k8s-bigip-ctlr&quot;]</span><br><span class="line">          args: [</span><br><span class="line">            # See the k8s-bigip-ctlr documentation for information about</span><br><span class="line">            # all config options</span><br><span class="line">            # http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest</span><br><span class="line">            &quot;--bigip-username=$(BIGIP_USERNAME)&quot;,</span><br><span class="line">            &quot;--bigip-password=$(BIGIP_PASSWORD)&quot;,</span><br><span class="line">            &quot;--bigip-url=192.168.200.82&quot;,</span><br><span class="line">            &quot;--bigip-partition=OpenShift&quot;,</span><br><span class="line">            &quot;--pool-member-type=cluster&quot;,</span><br><span class="line">            &quot;--openshift-sdn-name=/Common/openshift_vxlan&quot;,</span><br><span class="line">            &#x27;--manage-routes=true&#x27;,</span><br><span class="line">            &#x27;--route-vserver-addr=192.168.200.80&#x27;</span><br><span class="line">            ]</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        # Secret containing the BIG-IP system login credentials</span><br><span class="line">        - name: bigip-login</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-ctlr-02</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: k8s-bigip-ctlr</span><br><span class="line">      labels:</span><br><span class="line">        app: k8s-bigip-ctlr</span><br><span class="line">    spec:</span><br><span class="line">      # Name of the Service Account bound to a Cluster Role with the required</span><br><span class="line">      # permissions</span><br><span class="line">      serviceAccountName: bigip-ctlr</span><br><span class="line">      containers:</span><br><span class="line">        - name: k8s-bigip-ctlr</span><br><span class="line">          # replace the version as needed</span><br><span class="line">          image: &quot;f5networks/k8s-bigip-ctlr:1.5.1&quot;</span><br><span class="line">          env:</span><br><span class="line">            - name: BIGIP_USERNAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: username</span><br><span class="line">            - name: BIGIP_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: password</span><br><span class="line">          command: [&quot;/app/bin/k8s-bigip-ctlr&quot;]</span><br><span class="line">          args: [</span><br><span class="line">            # See the k8s-bigip-ctlr documentation for information about</span><br><span class="line">            # all config options</span><br><span class="line">            # http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest</span><br><span class="line">            &quot;--bigip-username=$(BIGIP_USERNAME)&quot;,</span><br><span class="line">            &quot;--bigip-password=$(BIGIP_PASSWORD)&quot;,</span><br><span class="line">            &quot;--bigip-url=192.168.200.83&quot;,</span><br><span class="line">            &quot;--bigip-partition=OpenShift&quot;,</span><br><span class="line">            &quot;--pool-member-type=cluster&quot;,</span><br><span class="line">            &quot;--openshift-sdn-name=/Common/openshift_vxlan&quot;,</span><br><span class="line">            &#x27;--manage-routes=true&#x27;,</span><br><span class="line">            &#x27;--route-vserver-addr=192.168.200.80&#x27;</span><br><span class="line">            ]</span><br><span class="line">      imagePullSecrets:</span><br><span class="line">        - name: bigip-login</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f deployment.yml</span><br></pre></td></tr></table></figure>查看BIG-IP Controller的部署进度<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# oc get pod</span><br><span class="line">NAME                                READY     STATUS    RESTARTS   AGE</span><br><span class="line">f5-bigip-ctlr-01-7f44695b97-lmwdh   1/1       Running   0          17h</span><br><span class="line">f5-bigip-ctlr-02-54df674f58-j2x26   1/1       Running   0          17h</span><br></pre></td></tr></table></figure>当BIG-IP Controller POD启动后，在F5上会自动创建两个virtual servers</li><li>“ose-vserver” 为HTTP请求</li><li>“https-ose-vserver” 为HTTPS请求<br>这两个virtual servers是Openshift下所有的Route共用的。</li></ul><blockquote><p>创建新的应用F5-Test，并创建HTTP Route <code>Openshift</code></p></blockquote><ul><li>使用自己镜像仓库中的镜像：harbor.example.com&#x2F;public&#x2F;nginx:1.14</li><li>该镜像的制作方法及说明参考：<a href="https://www.jianshu.com/p/d500debde045">Openshfit上用ConfigMap来自定义Nginx配置</a><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc new-project f5-test</span><br><span class="line">oc new-app harbor.example.com/public/nginx:1.14 --name=f5-test --allow-missing-images</span><br><span class="line">oc expose dc/f5-test --port=8080</span><br></pre></td></tr></table></figure>创建Route<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    name: f5-test</span><br><span class="line">  name: f5-test</span><br><span class="line">  annotations:</span><br><span class="line">    virtual-server.f5.com/balance: least-connections-node</span><br><span class="line">spec:</span><br><span class="line">  host: f5-test.example.com</span><br><span class="line">  port:</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: f5-test</span><br></pre></td></tr></table></figure>本地绑定hosts<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.200.80 f5-test.example.com</span><br></pre></td></tr></table></figure>浏览器访问<code>http://f5-test.example.com</code>，即能看到应用页面。<blockquote><p>创建HTTPS Route（仍然使用上面的应用） <code>Openshift</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    virtual-server.f5.com/balance: least-connections-node</span><br><span class="line">  labels:</span><br><span class="line">    app: f5-test</span><br><span class="line">  name: f5-test-2</span><br><span class="line">spec:</span><br><span class="line">  host: f5-tes-2t.example.com</span><br><span class="line">  tls:</span><br><span class="line">    insecureEdgeTerminationPolicy: Allow</span><br><span class="line">    termination: edge</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: f5-test</span><br></pre></td></tr></table></figure>本地绑定hosts<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.200.80 f5-test-2.example.com</span><br></pre></td></tr></table></figure>浏览器访问<code>https://f5-test.example.com</code>，即能看到应用页面。<blockquote><p>说明</p></blockquote></li><li>Openshit上创建Service后，F5会自动创建新的Pool，Pool里的资源即为Service下的Pod</li><li>请求到达F5后，F5根据请求的域名，找到对应的Pool，请求直接到达Pod。不会请求集群里的Route。</li></ul><blockquote><p>参考资料</p></blockquote><ul><li><a href="http://clouddocs.f5.com/containers/v2/openshift/kctlr-openshift-routes.html">F5与Openshift中的Route集成</a></li><li><a href="http://clouddocs.f5.com/containers/v2/kubernetes/kctlr-create-service-vs.html">F5与Openshift中的Service集成</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-F5集成（总结）——与Router方案对比</title>
      <link href="/openshift/Openshift-F5%E9%9B%86%E6%88%90%EF%BC%88%E6%80%BB%E7%BB%93%EF%BC%89%E2%80%94%E2%80%94%E4%B8%8ERouter%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/"/>
      <url>/openshift/Openshift-F5%E9%9B%86%E6%88%90%EF%BC%88%E6%80%BB%E7%BB%93%EF%BC%89%E2%80%94%E2%80%94%E4%B8%8ERouter%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/</url>
      
        <content type="html"><![CDATA[<p>这篇文章来自9月份自己在F5年度会议上分享的PPT，感谢过程中帮忙一起联调的小伙伴。<br>PPT也分享出来，地址如下：<a href="https://pan.baidu.com/s/1VkXjbhwIYlCPuATSrhI07w">openshift与F5的联合解决方案</a><br><a href="https://www.jianshu.com/p/c2c8df42ee5b">Openshift-F5集成（南北流量走F5）</a><br><a href="https://www.jianshu.com/p/83678b5610da">Openshift-F5集成（续）——实现灰度发布</a></p><h2 id="Openshift的基础概念"><a href="#Openshift的基础概念" class="headerlink" title="Openshift的基础概念"></a>Openshift的基础概念</h2><h3 id="Openshift简介"><a href="#Openshift简介" class="headerlink" title="Openshift简介"></a>Openshift简介</h3><p>红帽® OpenShift 是一款性能强大的开源企业级PaaS产品。不仅是企业级的Kubernetes，可以构建、部署与管理容器应用，还提供从开发到投入生产的整个应用生命周期内使用的完整解决方案，帮助客户享受快速创新带来的收益，同时保持企业级平台的稳定性、可靠性和安全性。<br>Openshift支持多种环境下部署，无论是在企业内部，公共云，或是托管环境中。</p><h3 id="Openshift-Pod"><a href="#Openshift-Pod" class="headerlink" title="Openshift Pod"></a>Openshift Pod</h3><ul><li>Pod是Openshift调度的最小单元</li><li>一个Pod包含一个或多个容器</li><li>Pod内的容器共享网络，IP不固定<br><img src="https://upload-images.jianshu.io/upload_images/5793257-fe290e25d8152021.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Pod"></li></ul><p>实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: MyApp     </span><br><span class="line">  labels:</span><br><span class="line">    app: MyApp    </span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp</span><br><span class="line">    image: app/myapp:latest</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 9376</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Openshift-Service"><a href="#Openshift-Service" class="headerlink" title="Openshift Service"></a>Openshift Service</h3><ul><li>Service是一个内部负均衡器，能将流量代理转发到一组pod中</li><li>Service能提供一个稳定可靠的内部IP</li><li>Service标识的一组pod可以任意伸缩，而不影响业务<br><img src="https://upload-images.jianshu.io/upload_images/5793257-009eb49c85639c4f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Service"></li></ul><p>实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: MyAppService     </span><br><span class="line">spec:</span><br><span class="line">  selector:                  </span><br><span class="line">    app: MyApp</span><br><span class="line">  clusterIP: 172.30.136.123   </span><br><span class="line">  ports:</span><br><span class="line">  - port: 9376               </span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9376</span><br></pre></td></tr></table></figure><h3 id="Openshift-Router与Route"><a href="#Openshift-Router与Route" class="headerlink" title="Openshift Router与Route"></a>Openshift Router与Route</h3><p>Router组件是解决外部访问Openshift集群中应用的一种解决方案</p><ul><li>Router节点上运行一个特殊定制的Haproxy </li><li>Route为Openshift中的资源对象，配置对应的Service及域名</li><li>Service更新会自动更新Haproxy的配置</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-7a50fd86aa5415eb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Route.png"></p><h3 id="Openshift-Router的不足"><a href="#Openshift-Router的不足" class="headerlink" title="Openshift Router的不足"></a>Openshift Router的不足</h3><ul><li>Router无法支持灰度发布 (可以引入<a href="https://www.jianshu.com/p/3679db38f34f">Nginx&#x2F;Haproxy实现灰度发布</a>)</li><li>对外所有南北流量都走Router，随着流量增加，Router的压力也不断增加</li><li>生产环境中，面对突发流量，Router的可靠性与稳定性是一个挑战</li><li>全站SSL的性能压力如何解决</li></ul><h2 id="F5与Openshift集成架构与实践"><a href="#F5与Openshift集成架构与实践" class="headerlink" title="F5与Openshift集成架构与实践"></a>F5与Openshift集成架构与实践</h2><h3 id="F5与Openshift集成架构"><a href="#F5与Openshift集成架构" class="headerlink" title="F5与Openshift集成架构"></a>F5与Openshift集成架构</h3><p><img src="https://upload-images.jianshu.io/upload_images/5793257-891519de7361d7c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="F5与Openshift集成架构"></p><h3 id="F5与Openshift中的Service集成"><a href="#F5与Openshift中的Service集成" class="headerlink" title="F5与Openshift中的Service集成"></a>F5与Openshift中的Service集成</h3><ul><li>通过对应的应用配置ConfigMap（Openshift的配置资源）为每个ConfigMap自动创建对应的Virtual Server并与Pool映射</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-66251ec6cd384882.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="F5与Service"></p><p>实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: myApp.vs</span><br><span class="line">  labels:</span><br><span class="line">    f5type: virtual-server</span><br><span class="line">data:</span><br><span class="line">  schema: &quot;f5schemadb://bigip-virtual-server_v0.1.7.json&quot;</span><br><span class="line">  data: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;virtualServer&quot;: &#123;</span><br><span class="line">        &quot;backend&quot;: &#123;</span><br><span class="line">          &quot;servicePort&quot;: 9376,</span><br><span class="line">          &quot;serviceName&quot;: &quot;myAppService&quot;</span><br><span class="line">          &#125;]</span><br><span class="line">        &#125;,</span><br><span class="line">       &quot;frontend&quot;: &#123;</span><br><span class="line">          &quot;virtualAddress&quot;: &#123;</span><br><span class="line">            &quot;port&quot;: 8080,</span><br><span class="line">            &quot;bindAddr&quot;: &quot;99.248.82.220&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;partition&quot;: &quot;openshift&quot;,</span><br><span class="line">          &quot;balance&quot;: &quot;round-robin&quot;,</span><br><span class="line">          &quot;mode&quot;: &quot;http&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><h3 id="F5与Openshift中的Route集成"><a href="#F5与Openshift中的Route集成" class="headerlink" title="F5与Openshift中的Route集成"></a>F5与Openshift中的Route集成</h3><ul><li>F5代替了Openshift中的Router组件的功能</li><li>Bigip-ctl启动配置中添加参数:<br>  –manage-routes&#x3D;true,<br>  –route-vserver-addr&#x3D;99.248.82.220</li><li>Bigip-ctl一启动就会在F5上创建好Virtual Server:80与Virtual Server:443</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-5b3ebcabf7f6a2b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Route"></p><p>实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: route.openshift.io/v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    name: f5-test</span><br><span class="line">  name: f5-test</span><br><span class="line">  annotations:</span><br><span class="line">    virtual-server.f5.com/balance: least-connections-node</span><br><span class="line">spec:</span><br><span class="line">  host: f5-test.example.com</span><br><span class="line">  port:</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: f5-test</span><br></pre></td></tr></table></figure><h3 id="F5与Openshift实现灰度发布"><a href="#F5与Openshift实现灰度发布" class="headerlink" title="F5与Openshift实现灰度发布"></a>F5与Openshift实现灰度发布</h3><ul><li>手动创建Virtual Server 80(testroute)与443(testroute_https)</li><li>Bigip-ctl启动配置中添加参数:<br>  –manage-routes&#x3D;true,<br> –route-http-vserver&#x3D;testroute,<br> –route-https-vserver&#x3D;testroute_https,<br> –route-vserver-addr&#x3D;99.248.82.220</li><li>手动创建iRule规则应用到Virtual Server<br><img src="https://upload-images.jianshu.io/upload_images/5793257-57ab821564269fd2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="灰度"><br>实例：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">when HTTP_REQUEST &#123;</span><br><span class="line"> if &#123; [HTTP::host] equals &quot;test1.apps.openshift.com&quot; &#125;&#123;</span><br><span class="line">   if &#123;[IP::addr [IP::client_addr] equals 192.168.100.23/32 ]&#125; &#123;</span><br><span class="line">  pool /f5-openShift/openshift_testapp_myapp-v2</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">   pool /f5-openShift/openshift_testapp_myapp-v1</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用F5实现灰度发布的不足"><a href="#使用F5实现灰度发布的不足" class="headerlink" title="使用F5实现灰度发布的不足"></a>使用F5实现灰度发布的不足</h3><ul><li>自定义iRule无法通过控制器自动下发，所以需要在F5端手动创建VServer及添加iRule来实现灰度发布</li></ul><h3 id="F5与Openshift的集成与Openshift的Router可以并存"><a href="#F5与Openshift的集成与Openshift的Router可以并存" class="headerlink" title="F5与Openshift的集成与Openshift的Router可以并存"></a>F5与Openshift的集成与Openshift的Router可以并存</h3><p>F5与Router节点是可以并存，同时为应用提供对外服务，并不会产生冲突。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f8d09126c6f0e3dc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="F5与Router并存"></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-F5集成（续）——实现灰度发布</title>
      <link href="/openshift/Openshift-F5%E9%9B%86%E6%88%90%EF%BC%88%E7%BB%AD%EF%BC%89%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/"/>
      <url>/openshift/Openshift-F5%E9%9B%86%E6%88%90%EF%BC%88%E7%BB%AD%EF%BC%89%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/</url>
      
        <content type="html"><![CDATA[<p>上篇：<a href="https://www.jianshu.com/p/c2c8df42ee5b">Openshift-F5集成（南北流量走F5）</a>中介绍了如何实现使用F5替换掉Openshift中的Route，但是它的可控性是弱的。本篇则通过手动创建VS及iRule来实现更强的流量控制，实现识别客户端IP来访问相应的服务。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-160812007efc3abe.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="灰度发布"></p><h2 id="为什么要使用灰度发布"><a href="#为什么要使用灰度发布" class="headerlink" title="为什么要使用灰度发布"></a>为什么要使用灰度发布</h2><ul><li>什么是灰度发布<br>灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。ABtest就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 </li><li>灰度发布的价值<br>使用灰度发布可以在产品正式上线前针对特定一些目标用户进行开放，获得这些目标用户的反馈，及早发现问题，修复问题，完善产品的不足。如果发现新的版本价值不大，能够及早更换思路，避免产品直接上线后产生不好的影响。</li></ul><h2 id="Openshift-Route自带的灰度发布功能"><a href="#Openshift-Route自带的灰度发布功能" class="headerlink" title="Openshift Route自带的灰度发布功能"></a>Openshift Route自带的灰度发布功能</h2><ul><li>Openshift Route自带的灰度发布，是通过Route下“挂载”两个或两个以上Service，并调整各个Service的权值进行控制流量的分布。</li><li>例如应用有两个服务，分别为service-v1和service-v2，其中service-v2为新版本。通过不断放大service-v2的权值，观察用户的反馈，及时发现service-v2中的问题，并完善修复，最终service-v2承载所有service-v1的流量，实现服务的升级。通过这种方式，可以大大地降低service-v2中的问题对客户产生的影响。</li><li>Openshift Route对Service分流使用非常方便，一些普通的业务完全可以使用这个特性达到测试的目的。但是它的简单也带来了一些不足，就是它只能对请求进行概率地划分流量，并不能定向到用户。</li><li>例如，以下需求Openshift Route目前还无法实现。产品新版本正式发布前，我们希望对产品进行一些测试，只允许指定的一批用户或者一些网段的ip下的用户才能访问新版本。</li></ul><h2 id="F5与Openshift集成实现灰度发布"><a href="#F5与Openshift集成实现灰度发布" class="headerlink" title="F5与Openshift集成实现灰度发布"></a>F5与Openshift集成实现灰度发布</h2><ul><li>流量到达F5时，F5会优先对请求进行iRule下的匹配检查，定向到对应的Pool</li><li>如果iRule下未匹配，则会控制vs下绑定的Polices规则进行匹配</li><li>在<a href="https://www.jianshu.com/p/c2c8df42ee5b">上篇</a>中，我们知道Openshift上的F5控制器会自动在F5上生成Polices规则，来满足Openshift Route的功能。那么只需要将它与自定义的iRule结合就能够实现既满足服务的分流，又能控制用户对服务的定向访问。</li></ul><h2 id="F5与Openshift集成配置与部署（实现灰度发布）"><a href="#F5与Openshift集成配置与部署（实现灰度发布）" class="headerlink" title="F5与Openshift集成配置与部署（实现灰度发布）"></a>F5与Openshift集成配置与部署（实现灰度发布）</h2><blockquote><p>准备工作（详细见<a href="https://www.jianshu.com/p/c2c8df42ee5b">上篇：Openshift-F5集成（南北流量走F5）</a>）</p></blockquote><ul><li>创建新的HostSub <code>Openshift</code></li><li>创建一个VXLAN profile <code>F5</code></li><li>创建一个VXLAN Tunnel <code>F5</code></li><li>在每个F5设备VXLAN中创建Self IP <code>F5</code></li><li>在当前主F5设备的VXLAN下创建Floating IP <code>F5</code></li><li>创建一个新的Partition <code>F5</code></li><li>创建访问F5 BIG-IP的私钥 <code>Openshift</code></li><li>创建RBAC认证 <code>Openshift</code></li></ul><p><code>说明:以上操作具体步骤参考</code><a href="https://www.jianshu.com/p/c2c8df42ee5b">上篇</a></p><blockquote><p>手动创建VS（HTTP、HTTPS） <code>F5</code></p></blockquote><ul><li><code>Local Traffic -&gt; Virtual Servers</code> 选中指定的<code>Partition</code>，新建VS</li><li>HTTP<ul><li><code>Name</code>：VS名字</li><li><code>Destination Address/Mask</code>：VS的IP地址</li><li><code>Service Port</code>：HTTP</li><li><code>HTTP Profile</code>：http</li><li><code>Source Address Translation</code>：Auto Map</li></ul></li><li>HTTPS<ul><li><code>Name</code>：VS名字</li><li><code>Destination Address/Mask</code>：VS的IP地址</li><li><code>Service Port</code>：HTTPS</li><li><code>HTTP Profile</code>：http</li><li><code>SSL Profile (Client)</code>：&#x2F;Common&#x2F;clientssl</li><li><code>Source Address Translation</code>：Auto Map<blockquote><p>设置VS中的cccl-whitelist为1 <code>F5</code></p></blockquote></li></ul></li></ul><p>目的：修改cccl-whitelist的值为1，是为了防止当openshift创建控制器时，route模式下将VS原本的配置覆盖掉</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tmsh</span><br><span class="line">cd /f5-openShift  (openshift所在的partition)</span><br><span class="line">modify ltm virtual testroute metadata add &#123; cccl-whitelist &#123; value 1 &#125; &#125;</span><br><span class="line">modify ltm virtual testroute_https metadata add &#123; cccl-whitelist &#123; value 1 &#125; &#125;</span><br></pre></td></tr></table></figure><blockquote><p>创建F5控制器 <code>Openshift</code></p></blockquote><ul><li><p>对应每台F5设备创建一个Deployment</p></li><li><p>Deployment中的 –bigip-url 为设备的IP</p></li><li><p>Deployment中的 –bigip-partition为之前F5下创建的Partition,Openshift</p></li><li><p>Deployment中的–route-http-vserver为手动创建的HTTP VS</p></li><li><p>Deployment中的–route-https-vserver为手动创建的HTTPS VS</p></li><li><p>Deployment中的–route-label为给Controller打的标签（对于一组F5不需要配置，多组F5通过它打Label，并在Route中设置label f5type:label来指定使用的F5）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-ctlr-01</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: k8s-bigip-ctlr</span><br><span class="line">      labels:</span><br><span class="line">        app: k8s-bigip-ctlr</span><br><span class="line">    spec:</span><br><span class="line">      # Name of the Service Account bound to a Cluster Role with the required</span><br><span class="line">      # permissions</span><br><span class="line">      serviceAccountName: bigip-ctlr</span><br><span class="line">      containers:</span><br><span class="line">        - name: k8s-bigip-ctlr</span><br><span class="line">          # replace the version as needed</span><br><span class="line">          image: &quot;f5networks/k8s-bigip-ctlr:1.5.1&quot;</span><br><span class="line">          env:</span><br><span class="line">            - name: BIGIP_USERNAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: username</span><br><span class="line">            - name: BIGIP_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: password</span><br><span class="line">          command: [&quot;/app/bin/k8s-bigip-ctlr&quot;]</span><br><span class="line">          args: [</span><br><span class="line">            # See the k8s-bigip-ctlr documentation for information about</span><br><span class="line">            # all config options</span><br><span class="line">            # http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest</span><br><span class="line">            &quot;--bigip-username=$(BIGIP_USERNAME)&quot;,</span><br><span class="line">            &quot;--bigip-password=$(BIGIP_PASSWORD)&quot;,</span><br><span class="line">            &quot;--bigip-url=192.168.200.82&quot;,</span><br><span class="line">            &quot;--bigip-partition=OpenShift&quot;,</span><br><span class="line">            &quot;--pool-member-type=cluster&quot;,</span><br><span class="line">            &quot;--openshift-sdn-name=/Common/openshift_vxlan&quot;,</span><br><span class="line">            &#x27;--manage-routes=true&#x27;</span><br><span class="line">            &#x27;--route-http-vserver=testroute&#x27;</span><br><span class="line">            &#x27;--route-https-vserver=testroute_https&#x27;</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: f5-bigip-ctlr-02</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: k8s-bigip-ctlr</span><br><span class="line">      labels:</span><br><span class="line">        app: k8s-bigip-ctlr</span><br><span class="line">    spec:</span><br><span class="line">      # Name of the Service Account bound to a Cluster Role with the required</span><br><span class="line">      # permissions</span><br><span class="line">      serviceAccountName: bigip-ctlr</span><br><span class="line">      containers:</span><br><span class="line">        - name: k8s-bigip-ctlr</span><br><span class="line">          # replace the version as needed</span><br><span class="line">          image: &quot;f5networks/k8s-bigip-ctlr:1.5.1&quot;</span><br><span class="line">          env:</span><br><span class="line">            - name: BIGIP_USERNAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: username</span><br><span class="line">            - name: BIGIP_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  # Replace with the name of the Secret containing your login</span><br><span class="line">                  # credentials</span><br><span class="line">                  name: bigip-login</span><br><span class="line">                  key: password</span><br><span class="line">          command: [&quot;/app/bin/k8s-bigip-ctlr&quot;]</span><br><span class="line">          args: [</span><br><span class="line">            # See the k8s-bigip-ctlr documentation for information about</span><br><span class="line">            # all config options</span><br><span class="line">            # http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest</span><br><span class="line">            &quot;--bigip-username=$(BIGIP_USERNAME)&quot;,</span><br><span class="line">            &quot;--bigip-password=$(BIGIP_PASSWORD)&quot;,</span><br><span class="line">            &quot;--bigip-url=192.168.200.83&quot;,</span><br><span class="line">            &quot;--bigip-partition=OpenShift&quot;,</span><br><span class="line">            &quot;--pool-member-type=cluster&quot;,</span><br><span class="line">            &quot;--openshift-sdn-name=/Common/openshift_vxlan&quot;,</span><br><span class="line">            &#x27;--manage-routes=true&#x27;</span><br><span class="line">            &#x27;--route-http-vserver=testroute&#x27;</span><br><span class="line">            &#x27;--route-https-vserver=testroute_https&#x27;</span><br><span class="line">            ]</span><br></pre></td></tr></table></figure><blockquote><p>给vs手动绑定Policies <code>F5</code></p></blockquote></li><li><p>Openshift F5控制器创建好后，在F5上会自动创建两条Policies, 分别为：openshift_insecure_routes、openshift_secure_routes。</p></li><li><p>openshift_insecure_routes为HTTP应用服务</p></li><li><p>openshift_secure_routes为HTTPS应用服务。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-5a5f253409e29cb1.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="绑定Policies与iRule"></p></li></ul><blockquote><p>创建应用（Project名为testapp，Service名为f5-nginx-v1与f5-nginx-v2）</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">oc new-project testapp</span><br><span class="line">oc new-app harbor.example.com/public/nginx:1.14 --name=f5-nginx-v1 --allow-missing-images</span><br><span class="line">oc expose dc/f5-test-v1 --port=8080</span><br><span class="line">oc expose svc/f5-test-v1 test1.apps.openshift.com</span><br><span class="line"></span><br><span class="line">oc new-app harbor.example.com/public/nginx:1.14 --name=f5-nginx-v2 --allow-missing-images</span><br><span class="line">oc expose dc/f5-test-v2 --port=8080</span><br></pre></td></tr></table></figure><blockquote><p>创建iRule,并绑定到VS <code>F5</code></p></blockquote><p>说明：请求域名<code>test1.apps.openshift.com</code>时，如果客户端IP为192.168.100.23，则访问testapp项目下的f5-nginx-v2服务，否则访问testapp项目下的f5-nginx-v1服务<br>注意：iRule规则需要在Common的Partition下创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">when HTTP_REQUEST &#123;</span><br><span class="line"> if &#123; [HTTP::host] equals &quot;test1.apps.openshift.com&quot; &#125;&#123;</span><br><span class="line">  log local0.info [HTTP::host]</span><br><span class="line">   if &#123;[IP::addr [IP::client_addr] equals 192.168.100.23/32 ]&#125; &#123;</span><br><span class="line">  log local0.info &quot;enter 2 pool before&quot;</span><br><span class="line">  log local0.info [HTTP::host]</span><br><span class="line">  pool /f5-openShift/openshift_testapp_f5-nginx-v2</span><br><span class="line">  log local0.info &quot;enter 2 pool later&quot;</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">  log local0.info &quot;enter 3&quot;</span><br><span class="line">   pool /f5-openShift/openshift_testapp_f5-nginx-v1</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>测试访问服务</p></blockquote><p>本地(192.168.100.23)与另一台非192.168.100.23的机器上绑定hosts</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VS的IP地址 test1.apps.openshift.com</span><br></pre></td></tr></table></figure><p>再访问test1.apps.openshift.com，查看页面显示，访问不同的Service。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Build构建详解</title>
      <link href="/openshift/Openshift-Build%E6%9E%84%E5%BB%BA%E8%AF%A6%E8%A7%A3/"/>
      <url>/openshift/Openshift-Build%E6%9E%84%E5%BB%BA%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="Build是什么"><a href="#Build是什么" class="headerlink" title="Build是什么"></a>Build是什么</h2><p>Build是Openshift容器平台上将输入转化为输出的过程，通常情况下是将代码转化为镜像的过程。</p><p>Build的配置叫BuildConfig，它将定义构建策略及构建参数。设置的构建策略和参数确定了Build的构建过程。</p><p>Openshift构建有四种主要策略</p><ul><li>Docker 构建</li><li>源代码构建（S2i)</li><li>自定义构建</li><li>Pipeline构建可以实现复杂的工作流</li></ul><p>Docker构建、S2i构建、Pipeline构建是默认支持的。</p><p>不同的构建有六种源</p><ul><li>Git</li><li>Dockerfile</li><li>Binary</li><li>Image</li><li>Input secrets</li><li>External artifacts</li></ul><p>其中Binary和Git不能同时使用。 Dockerfile和Image可以单独使用，也可以与Git或Binary一起使用。 如果使用Binary作为BuildConfig.spec.source.type，只能通过命令行工具<code>oc start-build</code>来构建。</p><p>BuildConfig实例</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;ruby-sample-build&quot; </span><br><span class="line">spec:</span><br><span class="line">  runPolicy: &quot;Serial&quot; </span><br><span class="line">  triggers: </span><br><span class="line">    -</span><br><span class="line">      type: &quot;GitHub&quot;</span><br><span class="line">      github:</span><br><span class="line">        secret: &quot;secret101&quot;</span><br><span class="line">    - type: &quot;Generic&quot;</span><br><span class="line">      generic:</span><br><span class="line">        secret: &quot;secret101&quot;</span><br><span class="line">    -</span><br><span class="line">      type: &quot;ImageChange&quot;</span><br><span class="line">  source: </span><br><span class="line">    git:</span><br><span class="line">      uri: &quot;https://github.com/openshift/ruby-hello-world&quot;</span><br><span class="line">  strategy: </span><br><span class="line">    sourceStrategy:</span><br><span class="line">      from:</span><br><span class="line">        kind: &quot;ImageStreamTag&quot;</span><br><span class="line">        name: &quot;ruby-20-centos7:latest&quot;</span><br><span class="line">  output: </span><br><span class="line">    to:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;origin-ruby-sample:latest&quot;</span><br><span class="line">  postCommit: </span><br><span class="line">      script: &quot;bundle exec rake test&quot;</span><br></pre></td></tr></table></figure><table><thead><tr><th>属性</th><th>说明</th></tr></thead><tbody><tr><td>metadata.name</td><td>BuildConfig名</td></tr><tr><td>spec.runPolicy</td><td>运行策略，默认是顺序运行</td></tr><tr><td>spec.triggers</td><td>触发器，这个可以触发新的构建</td></tr><tr><td>spec.source</td><td>定义了构建的源。 源类型确定输入的主要来源，可以是Git，指向代码存储库位置，Dockerfile，从内联Dockerfile构建，或Binary，以接受二进制有效负载。 可以同时拥有多个源，有关详细信息，请参阅每种源类型的文档。</td></tr><tr><td>spec.strategy</td><td>策略部分描述了用于执行构建的构建策略。 您可以在此处指定Source，Docker或Custom策略。</td></tr><tr><td>spec.output</td><td>成功构建容器映像后，它将被推送到输出部分中描述的存储库中。</td></tr><tr><td>spec.postCommit</td><td>postCommit部分定义了一个可选的构建钩子。</td></tr></tbody></table><p>postCommit支持多种不同方式的配置</p><p>script: 默认会使用&#x2F;bin&#x2F;sh -ic来运行内容</p><p>command: 如果镜像没有&#x2F;bin&#x2F;sh，则使用command</p><p>args: 给Entrypoint传递参数，镜像必须支持传入参数</p><p>例子：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">postCommit:</span><br><span class="line">  script: &quot;bundle exec rake test --verbose&quot;</span><br><span class="line">  </span><br><span class="line">postCommit:</span><br><span class="line">  command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;bundle exec rake test --verbose&quot;]</span><br><span class="line">  </span><br><span class="line">postCommit:</span><br><span class="line">  args: [&quot;bundle&quot;, &quot;exec&quot;, &quot;rake&quot;, &quot;test&quot;, &quot;--verbose&quot;]</span><br><span class="line"></span><br><span class="line">postCommit:</span><br><span class="line">  script: &quot;bundle exec rake test $1&quot;</span><br><span class="line">  args: [&quot;--verbose&quot;]</span><br><span class="line">  </span><br><span class="line">postCommit:</span><br><span class="line">  command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;rake&quot;, &quot;test&quot;]</span><br><span class="line">  args: [&quot;--verbose&quot;]</span><br></pre></td></tr></table></figure><p>通过命令行设置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ oc set build-hook bc/mybc \</span><br><span class="line">    --post-commit \</span><br><span class="line">    --command \</span><br><span class="line">    -- bundle exec rake test --verbose</span><br><span class="line">$ oc set build-hook bc/mybc --post-commit --script=&quot;bundle exec rake test --verbose&quot;</span><br></pre></td></tr></table></figure><h2 id="基础的构建操作"><a href="#基础的构建操作" class="headerlink" title="基础的构建操作"></a>基础的构建操作</h2><p>启动一个Build</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc start-build &lt;buildconfig_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#使用--from-build启动</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc start-build --from-build=&lt;build_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#添加--follow参数，在终端输出日志</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc start-build &lt;buildconfig_name&gt; --follow</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#给构建传入环境变量</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc start-build &lt;buildconfig_name&gt; --<span class="built_in">env</span>=&lt;key&gt;=&lt;value&gt;</span></span><br></pre></td></tr></table></figure><p>您可以通过直接推送源代码来启动构建，而不是依赖于Git源代码拉取或Dockerfile构建构建，这可能是Git或SVN工作目录的内容，也就是您想要的一组预构建二进制工件。 部署或单个文件。 这可以通过为start-build命令指定以下选项之一来完成：</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>–from-dir&#x3D;<directory></td><td>指定将归档并用作构建的二进制输入的目录。</td></tr><tr><td>–from-file&#x3D;<file></td><td>指定将成为构建源中唯一文件的单个文件。 该文件放在空目录的根目录中，其文件名与提供的原始文件相同。</td></tr><tr><td>–from-repo&#x3D;<local_source_repo></td><td>指定本地存储库的路径，以用作构建的二进制输入。 添加–commit选项以控制用于构建的分支，标记或提交。</td></tr></tbody></table><p> 将任何这些选项直接传递给构建时，内容将流式传输到构建并覆盖当前构建源设置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 将本地Git仓库的v2分支/tag的内容作为存档并启动构建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc start-build hello-world --from-repo=../hello-world --commit=v2</span></span><br></pre></td></tr></table></figure><p>取消一个构建</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc cancel-build &lt;build_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#取消多个构建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc cancel-build &lt;build1_name&gt; &lt;build2_name&gt; &lt;build3_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#取消通过buildconfig构建的所有构建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc cancel-build bc/&lt;buildconfig_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#取消指定状态的构建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc cancel-build bc/&lt;buildconfig_name&gt;  --state=&lt;state&gt;</span></span><br></pre></td></tr></table></figure><p>删除构建</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#删除BuildConfig，同时删除之前的Build</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc delete bc &lt;BuildConfigName&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#删除BuildConfig，但保留之前的Build</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc delete --cascade=<span class="literal">false</span> bc &lt;BuildConfigName&gt;</span></span><br></pre></td></tr></table></figure><p>查看Build的详情</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc describe build &lt;build_name&gt;</span></span><br></pre></td></tr></table></figure><p>查看Build的日志</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc logs -f build/&lt;build_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#查看最新的一个Build的日志</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc logs -f bc/&lt;buildconfig_name&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#查看指定版本的Build日志</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc logs --version=&lt;number&gt; bc/&lt;buildconfig_name&gt;</span></span><br></pre></td></tr></table></figure><p>设置Build的日志级别</p><p>要启用更详细的输出，请在BuildConfig中将BUILD_LOGLEVEL环境变量作为sourceStrategy或dockerStrategy的一部分传递：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sourceStrategy:</span><br><span class="line">...</span><br><span class="line">  env:</span><br><span class="line">    - name: &quot;BUILD<span class="built_in">_</span>LOGLEVEL&quot;</span><br><span class="line">      value: &quot;2&quot; </span><br></pre></td></tr></table></figure><h2 id="Build的输入"><a href="#Build的输入" class="headerlink" title="Build的输入"></a>Build的输入</h2><p>构建输入需要提供输入源</p><ol><li>内联Dockerfile定义</li><li>从现有图像中提取的内容</li><li>Git仓库</li><li>本地输入</li><li>输入Secret和ConfigMaps</li><li>额外的文件</li></ol><p>不同的输入可以组合成一个构建。 由于内联Dockerfile优先，它可以覆盖另一个输入提供的名为Dockerfile的任何其他文件。 二进制（本地）输入和Git仓库是不能同时使用。</p><p>当您不希望构建期间使用的某些资源或凭据在构建生成的最终应用程序映像中可用时，或者想要使用在Secret资源中定义的值时，输入机密很有用。 外部工件可用于提取其他文件，这些文件不可用作其他构建输入类型之一。</p><ol><li><p>构造工作目录，并将所有输入内容放在工作目录中。 例如，输入Git存储库被克隆到工作目录中，并且使用目标路径将从输入镜像指定的文件复制到工作目录中。</p></li><li><p>构建过程将目录更改为contextDir（如果已定义）。</p></li><li><p>内联Dockerfile（如果有）将写入当前目录。</p></li><li><p>来自当前目录的内容将提供给构建过程，以供Dockerfile。 这意味着构建将忽略驻留在contextDir之外的任何输入内容。</p></li></ol><p>以下例子中设置了多个输入源</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  git:</span><br><span class="line">    uri: https://github.com/openshift/ruby-hello-world.git </span><br><span class="line">  images:</span><br><span class="line">  - from:</span><br><span class="line">      kind: ImageStreamTag</span><br><span class="line">      name: myinputimage:latest</span><br><span class="line">      namespace: mynamespace</span><br><span class="line">    paths:</span><br><span class="line">    - destinationDir: app/dir/injected/dir </span><br><span class="line">      sourcePath: /usr/lib/somefile.jar</span><br><span class="line">  contextDir: &quot;app/dir&quot; </span><br><span class="line">  dockerfile: &quot;FROM centos:7<span class="keyword">\nRUN</span> yum install -y httpd&quot; </span><br></pre></td></tr></table></figure><ol><li>git仓库将会被clone到构建的工作目录中。</li><li>myinputimage:latest镜像中的&#x2F;usr&#x2F;lib&#x2F;somefile.jar文件，将会被拷贝到工作目录中的app&#x2F;dir&#x2F;injected&#x2F;dir文件夹下</li><li>构建的工作目录将变为原工作目录下的&#x2F;app&#x2F;dir</li><li>具有此内容的Dockerfile将在<original_workingdir> &#x2F; app &#x2F; dir中创建，覆盖具有该名称的任何现有文件。</li></ol><h3 id="Dockerfile源"><a href="#Dockerfile源" class="headerlink" title="Dockerfile源"></a>Dockerfile源</h3><p>当提供dockerfile值时，该字段的内容将作为名为Dockerfile的文件写入磁盘。 这是在处理完其他输入源之后完成的，因此如果输入源存储库在根目录中包含Dockerfile，则它将被此内容覆盖。</p><p>该字段的典型用途是为Docker策略提供Dockerfile</p><p>该字段是定义在BuildConfig中的spec下</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  dockerfile: &quot;FROM centos:7<span class="keyword">\nRUN</span> yum install -y httpd&quot; </span><br></pre></td></tr></table></figure><h3 id="镜像源"><a href="#镜像源" class="headerlink" title="镜像源"></a>镜像源</h3><p>可以通过图像向构建过程提供其他文件。 输入图像的引用方式与定义From和To图像目标的方式相同。 这意味着可以引用容器图像和图像流标记。 与映像一起使用时，必须提供一个或多个路径对，以指示要复制映像的文件或目录的路径以及将它们放置在构建上下文中的目标。</p><p>源路径可以是指定图像中的任何绝对路径。 目标必须是相对目录路径。 在构建时，将加载映像，并将指示的文件和目录复制到构建过程的上下文目录中。 这是克隆源存储库内容（如果有）的目录。 如果源路径以&#x2F;结尾。 然后将复制目录的内容，但不会在目标上创建目录本身。</p><p>该字段是定义在BuildConfig中的spec下</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  git:</span><br><span class="line">    uri: https://github.com/openshift/ruby-hello-world.git</span><br><span class="line">  images: </span><br><span class="line">  - from: </span><br><span class="line">      kind: ImageStreamTag</span><br><span class="line">      name: myinputimage:latest</span><br><span class="line">      namespace: mynamespace</span><br><span class="line">    paths: </span><br><span class="line">    - destinationDir: injected/dir </span><br><span class="line">      sourcePath: /usr/lib/somefile.jar </span><br><span class="line">  - from:</span><br><span class="line">      kind: ImageStreamTag</span><br><span class="line">      name: myotherinputimage:latest</span><br><span class="line">      namespace: myothernamespace</span><br><span class="line">    pullSecret: mysecret </span><br><span class="line">    paths:</span><br><span class="line">    - destinationDir: injected/dir</span><br><span class="line">      sourcePath: /usr/lib/somefile.jar</span><br></pre></td></tr></table></figure><h3 id="Git源"><a href="#Git源" class="headerlink" title="Git源"></a>Git源</h3><p>设置了Git源后，将从指定的Git源clone下代码</p><p>如果设置了dockerfile源，那么它将会覆盖掉代码中目录下的Dockerfile文件</p><p>git源字段也是BuildConfig中的spec下</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  git: </span><br><span class="line">    uri: &quot;https://github.com/openshift/ruby-hello-world&quot;</span><br><span class="line">    ref: &quot;master&quot;</span><br><span class="line">  contextDir: &quot;app/dir&quot; </span><br><span class="line">  dockerfile: &quot;FROM openshift/ruby-22-centos7<span class="keyword">\nUSER</span> example&quot; </span><br></pre></td></tr></table></figure><p>Git源设置中还可以指定代码</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  git:</span><br><span class="line">    uri: &quot;https://github.com/openshift/ruby-hello-world&quot;</span><br><span class="line">    httpProxy: http://proxy.example.com</span><br><span class="line">    httpsProxy: https://proxy.example.com</span><br><span class="line">    noProxy: somedomain.com, otherdomain.com</span><br></pre></td></tr></table></figure><p>Git源设置下载的用户及密码</p><p>Builder pods需要访问定义为构建源的任何Git存储库。 源克隆密钥用于为构建器窗格提供通常无法访问的访问权限，例如具有自签名或不可信SSL证书的私有存储库或存储库。</p><ol><li>.gitconfig配置文件</li><li>Basic Authentication</li><li>SSH Key Authentication</li><li>Trusted Certificate Authorities</li></ol><p>使用builder服务帐户运行构建，该帐户必须能够访问所使用的任何源克隆密钥。 使用以下命令授予访问权限：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc secrets <span class="built_in">link</span> builder mysecret</span></span><br></pre></td></tr></table></figure><p>说明：默认情况下是不需要主动绑定builder与secret的，除非在masterconfig中的serviceAccountConfig.limitSecretReferences设置为true。</p><p>自动将源克隆密码添加到构建配置中</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;sample-build&quot;</span><br><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;sample-image:latest&quot;</span><br><span class="line">  source:</span><br><span class="line">    git:</span><br><span class="line">      uri: &quot;https://github.com/user/app.git&quot;</span><br><span class="line">    sourceSecret:</span><br><span class="line">      name: &quot;basicsecret&quot;</span><br><span class="line">  strategy:</span><br><span class="line">    sourceStrategy:</span><br><span class="line">      from:</span><br><span class="line">        kind: &quot;ImageStreamTag&quot;</span><br><span class="line">        name: &quot;python-33-centos7:latest&quot;</span><br></pre></td></tr></table></figure><p>secret构建</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create secret generic &lt;secret_name&gt; \</span></span><br><span class="line"><span class="language-bash">    --from-literal=username=&lt;user_name&gt; \</span></span><br><span class="line"><span class="language-bash">    --from-literal=password=&lt;password&gt; \</span></span><br><span class="line"><span class="language-bash">    --<span class="built_in">type</span>=kubernetes.io/basic-auth</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create secret generic &lt;secret_name&gt; \</span></span><br><span class="line"><span class="language-bash">    --from-literal=password=&lt;token&gt; \</span></span><br><span class="line"><span class="language-bash">    --<span class="built_in">type</span>=kubernetes.io/basic-auth</span></span><br><span class="line">    </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create secret generic &lt;secret_name&gt; \</span></span><br><span class="line"><span class="language-bash">    --from-file=ssh-privatekey=&lt;path/to/ssh/private/key&gt; \</span></span><br><span class="line"><span class="language-bash">    --<span class="built_in">type</span>=kubernetes.io/ssh-auth</span></span><br></pre></td></tr></table></figure><h3 id="本地源"><a href="#本地源" class="headerlink" title="本地源"></a>本地源</h3><p>从本地文件系统到构建器的流内容称为二进制类型构建。 对于此类构建，BuildConfig.spec.source.type的对应值为Binary。</p><p>此源类型的独特之处在于它仅基于您对oc start-build的使用而被利用。</p><p>在star-build构建时需要指定以下参数之一</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>–from-dir&#x3D;<directory></td><td>指定将归档并用作构建的二进制输入的目录。</td></tr><tr><td>–from-file&#x3D;<file></td><td>指定将成为构建源中唯一文件的单个文件。 该文件放在空目录的根目录中，其文件名与提供的原始文件相同。</td></tr><tr><td>–from-repo&#x3D;<local_source_repo></td><td>指定本地存储库的路径，以用作构建的二进制输入。 添加–commit选项以控制用于构建的分支，标记或提交。</td></tr><tr><td>–from-archive</td><td>指定的压缩包文件将发送到构建器，在构建器上下文目录中将其解压缩。 此选项与–from-dir的行为相同; 只要这些选项的参数是目录，就会首先在主机上创建压缩文件。</td></tr></tbody></table><ul><li><p>如果您的BuildConfig已经定义为binary类型，那它将会被客户端发送的内容给替代。</p></li><li><p>如果您的BuildConfig定义了Git源类型，则会动态禁用Git源类型，因为Binary和Git是互斥的，并且提供给构建器的二进制流中的数据优先。</p></li></ul><p>您可以将带有HTTP或HTTPS架构的URL传递给–from-file和–from-archive，而不是文件名。 将-from-file与URL一起使用时，构建器映像中文件的名称由Web服务器发送的Content-Disposition标头确定，如果标头不存在，则由URL路径的最后一个组件确定。 不支持任何形式的身份验证，也无法使用自定义TLS证书或禁用证书验证。</p><p>使用<code>oc new-build --binary = true</code>时，该命令可确保强制执行与二进制构建关联的限制。 生成的BuildConfig将具有Binary的源类型，这意味着为此BuildConfig运行构建的唯一有效方法是使用oc start-build和其中一个–from选项来提供必需的二进制数据。</p><p>dockerfile和contextDir源选项对二进制构建具有特殊含义。</p><p>dockerfile可以与任何二进制构建源一起使用。 如果使用dockerfile且二进制流是存档，则其内容将作为存档中任何Dockerfile的替换Dockerfile。 如果dockerfile与–from-file参数一起使用，并且file参数名为dockerfile，则dockerfile中的值将替换二进制流中的值。</p><p> 在二进制流封装提取的存档内容的情况下，contextDir字段的值被解释为存档中的子目录，并且如果有效，则构建器在执行构建之前更改为该子目录。</p><p>本地源构建的一个实例：</p><ol><li><p>创建本地文件夹，存放代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> myapp</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> myapp</span></span><br></pre></td></tr></table></figure></li><li><p>在目录下创建一个Dockerfile文件</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:centos7</span><br><span class="line"></span><br><span class="line">EXPOSE 8080</span><br><span class="line"></span><br><span class="line">COPY index.html /var/run/web/index.html</span><br><span class="line"></span><br><span class="line">CMD cd /var/run/web <span class="built_in">&amp;</span><span class="built_in">&amp;</span> python -m SimpleHTTPServer 8080</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>在目录下添加一个index.html文件</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">  &lt;head&gt;</span><br><span class="line">    &lt;title&gt;My local app&lt;/title&gt;</span><br><span class="line">  &lt;/head&gt;</span><br><span class="line">  &lt;body&gt;</span><br><span class="line">    &lt;h1&gt;Hello World&lt;/h1&gt;</span><br><span class="line">    &lt;p&gt;This is my local application&lt;/p&gt;</span><br><span class="line">  &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>创建一个buildConfig</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-build --strategy docker --binary --docker-image centos:centos7 --name myapp</span></span><br></pre></td></tr></table></figure></li><li><p>开始一个构建，使用当前文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc start-build myapp --from-dir . --follow</span></span><br></pre></td></tr></table></figure></li><li><p>根据生成的镜像部署应用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-app myapp</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc expose svc/myapp</span></span><br></pre></td></tr></table></figure></li><li><p>查看当前应用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get route myapp</span></span><br></pre></td></tr></table></figure></li></ol><p><a href="https://docs.openshift.com/dedicated/dev_guide/dev_tutorials/binary_builds.html#binary-builds-local-code-changes">https://docs.openshift.com/dedicated/dev_guide/dev_tutorials/binary_builds.html#binary-builds-local-code-changes</a></p><h3 id="导入Secret与ConfigMap"><a href="#导入Secret与ConfigMap" class="headerlink" title="导入Secret与ConfigMap"></a>导入Secret与ConfigMap</h3><p> 在某些情况下，构建操作需要凭据或其他配置数据来访问相关资源，但不希望将该信息放置在源代码管理中。 您可以为此目的定义输入密钥并输入ConfigMaps。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#创建configmap</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create configmap settings-mvn --from-file=settings.xml=&lt;path/to/settings.xml&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 创建Secret</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create secret generic secret-mvn --from-file=id_rsa=&lt;path/to/.ssh/id_rsa&gt;</span></span><br></pre></td></tr></table></figure><p>将ConfigMap与Secret加入到构建目录</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  git:</span><br><span class="line">    uri: https://github.com/wildfly/quickstart.git</span><br><span class="line">  contextDir: helloworld</span><br><span class="line">  configMaps:</span><br><span class="line">    - configMap:</span><br><span class="line">        name: settings-mvn</span><br><span class="line">  secrets:</span><br><span class="line">    - secret:</span><br><span class="line">        name: secret-mvn</span><br></pre></td></tr></table></figure><p>要在新的构建中添加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-build \</span></span><br><span class="line"><span class="language-bash">    openshift/wildfly-101-centos7~https://github.com/wildfly/quickstart.git \</span></span><br><span class="line"><span class="language-bash">    --context-dir helloworld --build-secret “secret-mvn” \</span></span><br><span class="line"><span class="language-bash">    --build-config-map <span class="string">&quot;settings-mvn&quot;</span></span></span><br></pre></td></tr></table></figure><p>指定文件保存的工作目录下的子目录</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">source:</span><br><span class="line">  git:</span><br><span class="line">    uri: https://github.com/wildfly/quickstart.git</span><br><span class="line">  contextDir: helloworld</span><br><span class="line">  configMaps:</span><br><span class="line">    - configMap:</span><br><span class="line">        name: settings-mvn</span><br><span class="line">      destinationDir: &quot;.m2&quot;</span><br><span class="line">  secrets:</span><br><span class="line">    - secret:</span><br><span class="line">        name: secret-mvn</span><br><span class="line">      destinationDir: &quot;.ssh&quot;</span><br></pre></td></tr></table></figure><p>在新建构建时指定</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-build \</span></span><br><span class="line"><span class="language-bash">    openshift/wildfly-101-centos7~https://github.com/wildfly/quickstart.git \</span></span><br><span class="line"><span class="language-bash">    --context-dir helloworld --build-secret “secret-mvn:.ssh” \</span></span><br><span class="line"><span class="language-bash">    --build-config-map <span class="string">&quot;settings-mvn:.m2&quot;</span></span></span><br></pre></td></tr></table></figure><p>setting.xml将会被放在.&#x2F;.m2目录下</p><p>id_rsa文件将会放在.&#x2F;.ssh目录下</p><h2 id="Build输出"><a href="#Build输出" class="headerlink" title="Build输出"></a>Build输出</h2><p>Build构建好的镜像输出可以是ImageStreamTag，也可以是外部的镜像仓库</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;sample-image:latest&quot;</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: &quot;DockerImage&quot;</span><br><span class="line">      name: &quot;my-registry.mycompany.com:5000/myimages/myimage:tag&quot;</span><br></pre></td></tr></table></figure><p>Docker和Source策略，在构建好的镜像中会写入以下环境变量</p><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>OPENSHIFT_BUILD_NAME</td><td>构建名</td></tr><tr><td>OPENSHIFT_BUILD_NAMESPACE</td><td>构建的namespace</td></tr><tr><td>OPENSHIFT_BUILD_SOURCE</td><td>构建的代码地址</td></tr><tr><td>OPENSHIFT_BUILD_REFERENCE</td><td>构建的代码所在的分支</td></tr><tr><td>OPENSHIFT_BUILD_COMMIT</td><td>构建的代码的Commit</td></tr></tbody></table><p>输出的镜像ImageStreamTag有以下label</p><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>io.openshift.build.commit.author</td><td>代码提交的作者</td></tr><tr><td>io.openshift.build.commit.date</td><td>代码提交的时间</td></tr><tr><td>io.openshift.build.commit.id</td><td>代码提交的Commit ID</td></tr><tr><td>io.openshift.build.commit.message</td><td>代码提交的Message</td></tr><tr><td>io.openshift.build.commit.ref</td><td>代码构建所在的分支</td></tr><tr><td>io.openshift.build.source-location</td><td>构建的地址</td></tr></tbody></table><p>也可以通过设置<strong>imageLabels</strong>给镜像添加新的lable</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;my-image:latest&quot;</span><br><span class="line">    imageLabels:</span><br><span class="line">    - name: &quot;vendor&quot;</span><br><span class="line">      value: &quot;MyCompany&quot;</span><br><span class="line">    - name: &quot;authoritative-source-url&quot;</span><br><span class="line">      value: &quot;registry.mycompany.com&quot;</span><br></pre></td></tr></table></figure><p>镜像输出到外部的镜像仓库，需要添加外部镜像仓库的权限</p><p>您可以使用.docker &#x2F; config.json文件为私有容器注册表提供有效凭据。 这允许您将输出图像推送到私有容器映像注册表，或从需要身份验证的私有容器映像注册表中提取构建器映像。</p><p>默认情况下，.docker&#x2F;config.json文件位于主目录中，格式如下：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">auths:</span><br><span class="line">  https://index.docker.io/v1/: </span><br><span class="line">    auth: &quot;YWRfbGzhcGU6R2labnRib21ifTE=&quot; </span><br><span class="line">    email: &quot;user@example.com&quot; </span><br></pre></td></tr></table></figure><p>在Openshift平台上，可以将它保存在Secret中，供build时调用</p><ol><li><p>根据本地的.docker&#x2F;config.json文件创建Secret</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create secret generic dockerhub \</span></span><br><span class="line"><span class="language-bash">    --from-file=.dockerconfigjson=&lt;path/to/.docker/config.json&gt; \</span></span><br><span class="line"><span class="language-bash">    --<span class="built_in">type</span>=kubernetes.io/dockerconfigjson</span></span><br></pre></td></tr></table></figure></li><li><p>将该secret授权给builder，一般这一步不需要，默认是已经授过权的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc secrets <span class="built_in">link</span> builder dockerhub</span></span><br></pre></td></tr></table></figure></li><li><p>将pushSecret字段添加到BuildConfig的输出部分，并将其设置为您创建的秘密的名称，在上面的示例中为dockerhub：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: &quot;DockerImage&quot;</span><br><span class="line">      name: &quot;private.registry.com/org/private-image:latest&quot;</span><br><span class="line">    pushSecret:</span><br><span class="line">      name: &quot;dockerhub&quot;</span><br></pre></td></tr></table></figure><p>或者使用oc命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> build-secret --push bc/sample-build dockerhub</span></span><br></pre></td></tr></table></figure></li><li><p>通过指定pullSecret字段从私有容器映像注册表中提取构建器容器映像，该字段是构建策略定义的一部分：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  sourceStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;DockerImage&quot;</span><br><span class="line">      name: &quot;docker.io/user/private<span class="built_in">_</span>repository&quot;</span><br><span class="line">    pullSecret:</span><br><span class="line">      name: &quot;dockerhub&quot;</span><br></pre></td></tr></table></figure><p>或者使用oc命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> build-secret --pull bc/sample-build dockerhub</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="Build策略"><a href="#Build策略" class="headerlink" title="Build策略"></a>Build策略</h2><h3 id="s2i策略"><a href="#s2i策略" class="headerlink" title="s2i策略"></a>s2i策略</h3><p>强制更新镜像</p><p>默认情况下，通过ImageStreamTag构建时，如果构建容器所在的主机上已存在镜像，就会直接使用该镜像，除非添加<code>forcePull:true</code>属性</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  sourceStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;builder-image:latest&quot; </span><br><span class="line">    forcePull: true </span><br></pre></td></tr></table></figure><p>增量构建</p><p>S2I可以执行增量构建，这意味着它可以重用先前构建的图像中的工件。 要创建增量构建，请创建一个BuildConfig，并对策略定义进行以下修改</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  sourceStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;incremental-image:latest&quot; </span><br><span class="line">    incremental: true </span><br></pre></td></tr></table></figure><p>替换默认的构建脚本</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  sourceStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;builder-image:latest&quot;</span><br><span class="line">    scripts: &quot;http://somehost.com/scripts<span class="built_in">_</span>directory&quot; </span><br></pre></td></tr></table></figure><h3 id="Docker策略"><a href="#Docker策略" class="headerlink" title="Docker策略"></a>Docker策略</h3><p> Dockerfile的FROM指令将替换为BuildConfig的from：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  dockerStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;debian:latest&quot;</span><br></pre></td></tr></table></figure><p>默认情况下，Docker构建使用位于BuildConfig.spec.source.contextDir字段中指定的上下文根的Dockerfile（名为Dockerfile）。</p><p>dockerfilePath字段允许构建使用不同的路径来定位Dockerfile，相对于BuildConfig.spec.source.contextDir字段。 它可以是除默认Dockerfile之外的其他文件名（例如，MyDockerfile），或者是子目录中Dockerfile的路径（例如，dockerfiles &#x2F; app1 &#x2F; Dockerfile）</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  dockerStrategy:</span><br><span class="line">    dockerfilePath: dockerfiles/app1/Dockerfile</span><br></pre></td></tr></table></figure><p>Docker构建通常重用在执行构建的主机上找到的缓存层。 将noCache选项设置为true会强制构建忽略缓存层并重新运行Dockerfile的所有步骤：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  dockerStrategy:</span><br><span class="line">    noCache: true</span><br></pre></td></tr></table></figure><p>默认情况下，通过ImageStreamTag构建时，如果构建容器所在的主机上已存在镜像，就会直接使用该镜像，除非添加<code>forcePull:true</code>属性</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  dockerStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;ImageStreamTag&quot;</span><br><span class="line">      name: &quot;debian:latest&quot; </span><br><span class="line">    forcePull: true </span><br></pre></td></tr></table></figure><p>构建添加环境变量</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dockerStrategy:</span><br><span class="line">...</span><br><span class="line">  env:</span><br><span class="line">    - name: &quot;HTTP<span class="built_in">_</span>PROXY&quot;</span><br><span class="line">      value: &quot;http://myproxy.net:5187/&quot;</span><br></pre></td></tr></table></figure><p>构建参数</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dockerStrategy:</span><br><span class="line">...</span><br><span class="line">  buildArgs:</span><br><span class="line">    - name: &quot;foo&quot;</span><br><span class="line">      value: &quot;bar&quot;</span><br></pre></td></tr></table></figure><h3 id="自定义策略"><a href="#自定义策略" class="headerlink" title="自定义策略"></a>自定义策略</h3><p>根据镜像构建</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  customStrategy:</span><br><span class="line">    from:</span><br><span class="line">      kind: &quot;DockerImage&quot;</span><br><span class="line">      name: &quot;openshift/sti-image-builder&quot;</span><br></pre></td></tr></table></figure><p>为了允许从容器内部运行Docker命令和构建容器映像，必须将构建容器绑定到可访问的套接字。 为此，请将exposeDockerSocket选项设置为true：</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  customStrategy:</span><br><span class="line">    exposeDockerSocket: true</span><br></pre></td></tr></table></figure><p>强制更新镜像</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">strategy:</span><br><span class="line">  customStrategy:</span><br><span class="line">    forcePull: true </span><br></pre></td></tr></table></figure><p>构建添加环境变量</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">customStrategy:</span><br><span class="line">...</span><br><span class="line">  env:</span><br><span class="line">    - name: &quot;HTTP<span class="built_in">_</span>PROXY&quot;</span><br><span class="line">      value: &quot;http://myproxy.net:5187/&quot;</span><br></pre></td></tr></table></figure><h3 id="Pipeline流水线策略"><a href="#Pipeline流水线策略" class="headerlink" title="Pipeline流水线策略"></a>Pipeline流水线策略</h3><p>通过两种方式提供jenkinsfile文件</p><ol><li><p>在BuildConfig配置文件中写</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;sample-pipeline&quot;</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    jenkinsPipelineStrategy:</span><br><span class="line">      jenkinsfile: |-</span><br><span class="line">        node(&#x27;agent&#x27;) &#123;</span><br><span class="line">          stage &#x27;build&#x27;</span><br><span class="line">          openshiftBuild(buildConfig: &#x27;ruby-sample-build&#x27;, showBuildLogs: &#x27;true&#x27;)</span><br><span class="line">          stage &#x27;deploy&#x27;</span><br><span class="line">          openshiftDeploy(deploymentConfig: &#x27;frontend&#x27;)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></li><li><p>在git代码文件中添加jenkinsfile文件</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;sample-pipeline&quot;</span><br><span class="line">spec:</span><br><span class="line">  source:</span><br><span class="line">    git:</span><br><span class="line">      uri: &quot;https://github.com/openshift/ruby-hello-world&quot;</span><br><span class="line">  strategy:</span><br><span class="line">    jenkinsPipelineStrategy:</span><br><span class="line">      jenkinsfilePath: some/repo/dir/filename </span><br></pre></td></tr></table></figure><p>可选的jenkinsfilePath字段指定要使用的文件的名称，相对于源contextDir。 如果省略了contextDir，则默认为存储库的根。 如果省略jenkinsfilePath，则默认为Jenkinsfile。</p></li></ol><p>环境变量</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jenkinsPipelineStrategy:</span><br><span class="line">...</span><br><span class="line">  env:</span><br><span class="line">    - name: &quot;FOO&quot;</span><br><span class="line">      value: &quot;BAR&quot;</span><br></pre></td></tr></table></figure><h2 id="Build构建的高级用法"><a href="#Build构建的高级用法" class="headerlink" title="Build构建的高级用法"></a>Build构建的高级用法</h2><h3 id="设置构建时对资源进行限制-cpu-x2F-memory"><a href="#设置构建时对资源进行限制-cpu-x2F-memory" class="headerlink" title="设置构建时对资源进行限制(cpu&#x2F;memory)"></a>设置构建时对资源进行限制(cpu&#x2F;memory)</h3><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;sample-build&quot;</span><br><span class="line">spec:</span><br><span class="line">  resources:</span><br><span class="line">    limits:</span><br><span class="line">      cpu: &quot;100m&quot; </span><br><span class="line">      memory: &quot;256Mi&quot; </span><br></pre></td></tr></table></figure><h3 id="设置构建的超时时间"><a href="#设置构建的超时时间" class="headerlink" title="设置构建的超时时间"></a>设置构建的超时时间</h3><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  completionDeadlineSeconds: 1800</span><br></pre></td></tr></table></figure><h3 id="构建pod与Node绑定，只在指定的Node上执行构建"><a href="#构建pod与Node绑定，只在指定的Node上执行构建" class="headerlink" title="构建pod与Node绑定，只在指定的Node上执行构建"></a>构建pod与Node绑定，只在指定的Node上执行构建</h3><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;sample-build&quot;</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector:</span><br><span class="line">    key1: value1</span><br><span class="line">    key2: value2</span><br></pre></td></tr></table></figure><h3 id="Build链"><a href="#Build链" class="headerlink" title="Build链"></a>Build链</h3><p>有一些构建，比如说Java应用，在构建的过程中会产生大量的中间文件与缓存，及一些构建的工具包，这些资源在运行时是不需要的，但它们会导致最终的镜像包很大。所以运行时的镜像中只需要存在构建的结果，而不需要构建过程中的文件与工作包。这就需要将构建拆分成两部分，第一部分执行构建，生成最终的制品文件，第二部分将制品文件放在可运行环境中进行运行。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f9e0b0dbf046ccd6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Build构建链.png"></p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: BuildConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: artifact-build</span><br><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: ImageStreamTag</span><br><span class="line">      name: artifact-image:latest</span><br><span class="line">  source:</span><br><span class="line">    git:</span><br><span class="line">      uri: https://github.com/openshift/openshift-jee-sample.git</span><br><span class="line">    type: Git</span><br><span class="line">  strategy:</span><br><span class="line">    sourceStrategy:</span><br><span class="line">      from:</span><br><span class="line">        kind: ImageStreamTag</span><br><span class="line">        name: wildfly:10.1</span><br><span class="line">        namespace: openshift</span><br><span class="line">    type: Source</span><br></pre></td></tr></table></figure><p>将上一个构建的输出，作为新的构建的输入</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: BuildConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: image-build</span><br><span class="line">spec:</span><br><span class="line">  output:</span><br><span class="line">    to:</span><br><span class="line">      kind: ImageStreamTag</span><br><span class="line">      name: image-build:latest</span><br><span class="line">  source:</span><br><span class="line">    type: Dockerfile</span><br><span class="line">    dockerfile: |-</span><br><span class="line">      FROM jee-runtime:latest</span><br><span class="line">      COPY ROOT.war /deployments/ROOT.war</span><br><span class="line">    images:</span><br><span class="line">    - from: </span><br><span class="line">        kind: ImageStreamTag</span><br><span class="line">        name: artifact-image:latest</span><br><span class="line">      paths: </span><br><span class="line">      - sourcePath: /wildfly/standalone/deployments/ROOT.war</span><br><span class="line">        destinationDir: &quot;.&quot;</span><br><span class="line">  strategy:</span><br><span class="line">    dockerStrategy:</span><br><span class="line">      from: </span><br><span class="line">        kind: ImageStreamTag</span><br><span class="line">        name: jee-runtime:latest</span><br><span class="line">    type: Docker</span><br><span class="line">  triggers:</span><br><span class="line">  - imageChange: &#123;&#125;</span><br><span class="line">    type: ImageChange</span><br></pre></td></tr></table></figure><h3 id="Build清理"><a href="#Build清理" class="headerlink" title="Build清理"></a>Build清理</h3><p>只保留构建成功的2个历史构建，和2个失败的历史构建</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: &quot;v1&quot;</span><br><span class="line">kind: &quot;BuildConfig&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;sample-build&quot;</span><br><span class="line">spec:</span><br><span class="line">  successfulBuildsHistoryLimit: 2 </span><br><span class="line">  failedBuildsHistoryLimit: 2 </span><br></pre></td></tr></table></figure><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p><a href="https://docs.openshift.com/container-platform/3.11/dev_guide/dev_tutorials/binary_builds.html">二进制文件构建</a><br><a href="https://docs.openshift.com/container-platform/3.11/dev_guide/dev_tutorials/openshift_pipeline.html">Pipeline流水线构建</a><br><a href="https://docs.openshift.com/container-platform/3.11/dev_guide/builds/index.html">BuildConfig</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-GitLab安装及使用Nodeport支持ssh访问</title>
      <link href="/openshift/Openshift-GitLab%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8Nodeport%E6%94%AF%E6%8C%81ssh%E8%AE%BF%E9%97%AE/"/>
      <url>/openshift/Openshift-GitLab%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8Nodeport%E6%94%AF%E6%8C%81ssh%E8%AE%BF%E9%97%AE/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-b80bcebfa75a24ff.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="openshift-gitlab"></p><h2 id="部署Gitlab"><a href="#部署Gitlab" class="headerlink" title="部署Gitlab"></a>部署Gitlab</h2><ol><li>创建gitlab项目<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc new-project gitlab</span><br></pre></td></tr></table></figure></li><li>创建cicd serviceaccount<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc create serviceaccount cicd -n gitlab</span><br></pre></td></tr></table></figure></li><li>导入Gitlab模板<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://gitee.com/xhua/OpenshiftOneClick/raw/3.11/openshift-templates/gitlab-template.yaml</span><br><span class="line">oc create -f openshift-template.json -n openshift</span><br></pre></td></tr></table></figure></li><li>创建持久化存储（如果没有pv的情况下）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">$ cat gitlab-pv.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">items:</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolume</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: gitlabdata-volume</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">    capacity:</span><br><span class="line">      storage: 50Gi</span><br><span class="line">    claimRef:</span><br><span class="line">      apiVersion: v1</span><br><span class="line">      kind: PersistentVolumeClaim</span><br><span class="line">      name: gitlab-data</span><br><span class="line">      namespace: gitlab</span><br><span class="line">    nfs:</span><br><span class="line">      path: /mnt/gitlabdata</span><br><span class="line">      server: 192.168.0.13</span><br><span class="line">    persistentVolumeReclaimPolicy: Retain</span><br><span class="line">  status: &#123;&#125;</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolume</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: gitlabpostgresql-volume</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">    capacity:</span><br><span class="line">      storage: 10Gi</span><br><span class="line">    claimRef:</span><br><span class="line">      apiVersion: v1</span><br><span class="line">      kind: PersistentVolumeClaim</span><br><span class="line">      name: gitlab-postgresql</span><br><span class="line">      namespace: gitlab</span><br><span class="line">    nfs:</span><br><span class="line">      path: /mnt/gitlabpostgresql</span><br><span class="line">      server: 192.168.0.13</span><br><span class="line">    persistentVolumeReclaimPolicy: Retain</span><br><span class="line">  status: &#123;&#125;</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolume</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: gitlabredisdata-volume</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">    capacity:</span><br><span class="line">      storage: 50Gi</span><br><span class="line">    claimRef:</span><br><span class="line">      apiVersion: v1</span><br><span class="line">      kind: PersistentVolumeClaim</span><br><span class="line">      name: gitlab-redis-data</span><br><span class="line">      namespace: gitlab</span><br><span class="line">    nfs:</span><br><span class="line">      path: /mnt/gitlabredisdata</span><br><span class="line">      server: 192.168.0.13</span><br><span class="line">    persistentVolumeReclaimPolicy: Retain</span><br><span class="line">  status: &#123;&#125;</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: PersistentVolume</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: gitlabetc-volume</span><br><span class="line">  spec:</span><br><span class="line">    accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">    capacity:</span><br><span class="line">      storage: 50Gi</span><br><span class="line">    claimRef:</span><br><span class="line">      apiVersion: v1</span><br><span class="line">      kind: PersistentVolumeClaim</span><br><span class="line">      name: gitlab-etc</span><br><span class="line">      namespace: gitlab</span><br><span class="line">    nfs:</span><br><span class="line">      path: /mnt/gitlabetc</span><br><span class="line">      server: 192.168.0.13</span><br><span class="line">    persistentVolumeReclaimPolicy: Retain</span><br><span class="line">  status: &#123;&#125;</span><br><span class="line">$ oc create gitlab-pv.yaml</span><br></pre></td></tr></table></figure></li><li>给gitlab 容器使用root用户的权限<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  oc adm  policy add-scc-to-user anyuid -z cicd -n gitlab</span><br></pre></td></tr></table></figure></li><li>在Openshift上创建gitlab应用</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-d38d6877161cac3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="部署应用"></p><p>设置gitlab安装配置（自定义）</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-3a90dfb18f8670fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="自定义配置1"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-4b47f7977f1ee296.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="自定义配置2"></p><ol start="7"><li>通过访问Route访问gitlab<br>在访问的机器上hosts文件中配置Router Host与Ip的对应<br>用户名（root） 密码（根据自定义配置中设定）</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-4abbf414fadcb3d7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="GitLab访问"></p><h2 id="使用Nodeport让gitlab服务支持ssh访问"><a href="#使用Nodeport让gitlab服务支持ssh访问" class="headerlink" title="使用Nodeport让gitlab服务支持ssh访问"></a>使用Nodeport让gitlab服务支持ssh访问</h2><ul><li>Openshift上的服务最常使用的是Route来对外提供服务。但是Route只支持Http协议，而对于Gitlab通过ssh访问的方式，得通过TCP协议。所以可以使用NodePort向外提供服务。</li></ul><ol><li>创建NodePort <strong>(30022-&gt;gitlab 22)</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ cat gitlab-nodeport.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: gitlab-nodeport</span><br><span class="line">  namespace: gitlab</span><br><span class="line">  labels:</span><br><span class="line">    name: gitlab-nodeport</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 22</span><br><span class="line">      nodePort: 30022</span><br><span class="line">      name: ssh</span><br><span class="line">  selector:</span><br><span class="line">    app: gitlab-ce</span><br><span class="line">    deploymentconfig: gitlab-ce</span><br><span class="line">$ oc create -f gitlab-nodeport.yaml</span><br></pre></td></tr></table></figure></li><li>将本机的公钥拷贝到gitlab网站的ssh key管理</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-8a969b13a6937193.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="导入客户端的公钥"></p><p>3.客户端clone代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone ssh://git@gitlab.apps.it.example.com:30022/root/test.git</span><br><span class="line"># 或者</span><br><span class="line">git clone ssh://git@192.168.1.x:30022/root/test.git ##192.168.1.x为集群中任意Node的ip</span><br></pre></td></tr></table></figure><p><code>注意：</code>因为Nodeport使用的不是ssh默认的22端口，在clone时必须在前缀使用<code>ssh://</code>，同时在git服务后添加<code>:NodePort端口号</code><br>4. 结果展示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@gitlab ~]# git clone ssh://git@gitlab.apps.it.example.com:30022/root/test.git</span><br><span class="line">Cloning into &#x27;test&#x27;...</span><br><span class="line">Warning: Permanently added &#x27;[gitlab.apps.it.example.com]:30022,[192.168.1.3]:30022&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">remote: Counting objects: 12, done.</span><br><span class="line">remote: Compressing objects: 100% (4/4), done.</span><br><span class="line">remote: Total 12 (delta 0), reused 0 (delta 0)</span><br><span class="line">Receiving objects: 100% (12/12), done.</span><br></pre></td></tr></table></figure><h2 id="参考资源"><a href="#参考资源" class="headerlink" title="参考资源"></a>参考资源</h2><p><a href="https://docs.gitlab.com/ee/install/openshift_and_gitlab/index.html">https://docs.gitlab.com/ee/install/openshift_and_gitlab&#x2F;index.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Jenkins共享并支持pipeline</title>
      <link href="/openshift/Openshift-Jenkins%E5%85%B1%E4%BA%AB%E5%B9%B6%E6%94%AF%E6%8C%81pipeline/"/>
      <url>/openshift/Openshift-Jenkins%E5%85%B1%E4%BA%AB%E5%B9%B6%E6%94%AF%E6%8C%81pipeline/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-4b6198576554fbbe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Openshift Jenkins"></p><h2 id="诉求"><a href="#诉求" class="headerlink" title="诉求"></a>诉求</h2><ol><li>使用Openshift的pipeline构建流水线，在Openshift上统一管理</li><li>使用一个公共的Jenkins，而不需要每个Project下都创建一个新的jenkins。以节约资源</li><li>在创建新的项目时，尽量少地改动完成以上的需求</li></ol><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>openshift默认的BuildConfig如果设置为jenkinsPipelineStrategy策略，将会在当前project下查找jenkins服务，如果没有的话，将会使用master-config中设置的默认jenkins模板所在位置在当前project下创建一个新的jenkins应用，便使用该应用执行相关的pipeline。<br>每个项目都会创建一个新的jenkins。</p><h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><ul><li>禁用Openshfit默认的JenkinsPipeline机制，不在当前项目下面自动创建Jenkins</li><li>在创建一个新的project时，创建名为jenkins的service，同时将它指向公共的Jenkins服务。</li><li>同时为了在当前Project界面下能够跳转到jenkins的界面，再创建一个jenkins Route，支持跳转到jenkins进行查看运行日志与过程</li><li>项目要被jenkins控制，需要让公共jenkins具有操作当前项目的权限，所以还需要创建system:serviceaccount:jenkins:jenkins编辑当前Project的权限</li></ul><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ol><li><p>部署Jenkins作为公共的Jenkins,例如部署在jenkins project下</p></li><li><p>创建Project新建模板</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm create-bootstrap-project-template --name=bootstrap-project-template -o yaml &gt; project-template.yaml</span></span><br></pre></td></tr></table></figure><p>在以上导出的配置中添加默认的jenkins Service&#x2F;Route&#x2F;RoleBinding</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    name: jenkins</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  selector: &#123;&#125;</span><br><span class="line">  spec:</span><br><span class="line">    externalName: jenkins.jenkins.svc.cluster.local</span><br><span class="line">    type: ExternalName</span><br><span class="line">- apiVersion: route.openshift.io/v1</span><br><span class="line">  kind: Route</span><br><span class="line">  metadata:</span><br><span class="line">    name: jenkins</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  spec:</span><br><span class="line">    host: jenkins-jenkins.apps.example.com</span><br><span class="line">    to:</span><br><span class="line">      kind: Service</span><br><span class="line">      name: jenkins</span><br><span class="line">- apiVersion: authorization.openshift.io/v1</span><br><span class="line">  kind: RoleBinding</span><br><span class="line">  metadata:</span><br><span class="line">    name: edit</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  roleRef:</span><br><span class="line">    name: edit</span><br><span class="line">  subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: jenkins</span><br><span class="line">    namespace: jenkins</span><br><span class="line">  userNames:</span><br><span class="line">  - system:serviceaccount:jenkins:jenkins</span><br></pre></td></tr></table></figure><p>结果展示:</p></li><li><p>将Openshift的Master中添加以下设置</p><ul><li>设置Project默认模板为<code>default/bootstrap-project-template</code></li><li>关闭JenkinsPipeline默认在project下创建的机制 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">projectConfig:</span><br><span class="line">  defaultNodeSelector: node-role.kubernetes.io/compute=true</span><br><span class="line">  projectRequestMessage: &#x27;&#x27;</span><br><span class="line">  projectRequestTemplate: &#x27;default/bootstrap-project-template&#x27;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">jenkinsPipelineConfig:</span><br><span class="line">  autoProvisionEnabled: false</span><br><span class="line">  templateNamespace: openshift</span><br><span class="line">  templateName: jenkins-ephemeral</span><br><span class="line">  serviceName: jenkins</span><br></pre></td></tr></table></figure></li></ul></li><li><p>在Jenkins中的系统管理-&gt;系统设置中的<code>OpenShift Jenkins Sync</code>中的<code>Namespace</code>中添加<code> $&#123;PROJECT_NAME&#125;</code>,之间是以空格分隔的.<br><img src="https://upload-images.jianshu.io/upload_images/5793257-2cf977f827e34e30.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="添加project名.png"></p></li></ol><p>结果展示:<br>在Testx中创建一个简单的PipelineConfigBuild进行测试</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: build.openshift.io/v1</span><br><span class="line">kind: BuildConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pipelinex</span><br><span class="line">  namespace: testx</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    jenkinsPipelineStrategy:</span><br><span class="line">      jenkinsfile: |-</span><br><span class="line">        pipeline &#123;</span><br><span class="line">          agent any</span><br><span class="line">          stages &#123;</span><br><span class="line">            stage(&quot;测试&quot;)&#123;</span><br><span class="line">              steps &#123;</span><br><span class="line">                echo &quot;打印一下&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    type: JenkinsPipeline</span><br></pre></td></tr></table></figure><p>在Testx项目下创建以上的BuildConfig,<code>前提是testx项目名已在jenkins中的系统设置中的OpenShift Jenkins Sync中添加</code><br>Testx项目下的PipelineJenkins可以使用Jenkins项目下的Jenkins服务来执行Pipeline<br><img src="https://upload-images.jianshu.io/upload_images/5793257-456412979fcf01ab.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Testx项目下可以使用Jenkins项目下的Jenkins服务来执行Pipeline"></p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://www.10tiao.com/html/360/201903/2663491580/1.html">DevOps的核心内功心法：OpenShift中实现共享Jenkins</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-HPA（Horizontal-Pod-Autoscaler）自动伸缩过程及算法</title>
      <link href="/openshift/Openshift-HPA%EF%BC%88Horizontal-Pod-Autoscaler%EF%BC%89%E8%87%AA%E5%8A%A8%E4%BC%B8%E7%BC%A9%E8%BF%87%E7%A8%8B%E5%8F%8A%E7%AE%97%E6%B3%95/"/>
      <url>/openshift/Openshift-HPA%EF%BC%88Horizontal-Pod-Autoscaler%EF%BC%89%E8%87%AA%E5%8A%A8%E4%BC%B8%E7%BC%A9%E8%BF%87%E7%A8%8B%E5%8F%8A%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h3 id="1、HPA介绍"><a href="#1、HPA介绍" class="headerlink" title="1、HPA介绍"></a>1、HPA介绍</h3><p>HPA（Horizontal Pod Autoscaler）是Openshift中的一个非常重要的对象，它定义了系统如何根据收集对应的Pod的状态（CPU&#x2F;Memory）对DeploymentConfig、ReplicationController对象进行扩容与缩容。</p><ul><li>HPA依赖于收集到的Pod资源的使用状态，所以要使HPA生效，Openshift必须安装好cluster metrics应用。</li><li>被监控的pod必须设置好了<code>spec.containers.resources.requests</code>属性，HPA才能正常工作。</li><li>仅支持CPU&#x2F;Memory使用率的判断，如果自定义监控项，只能使用经验值，不能使用使用率。</li><li>支持对象：DeploymentConfig、ReplicationController、Deployment、Replica Set。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/b23a0c243555bd1450f97e1a9938f81e0566fcecdfc7a13f43d91343cfe8e011.png" alt="HPA实现Pod伸缩"></li></ul><h3 id="2-HPA伸缩过程及算法"><a href="#2-HPA伸缩过程及算法" class="headerlink" title="2. HPA伸缩过程及算法"></a>2. HPA伸缩过程及算法</h3><blockquote><p>HPA进行伸缩过程</p></blockquote><ol><li>收集该HPA控制下所有Pod最近的cpu使用情况（CPU utilization）</li><li>对比在扩容条件里记录的cpu限额（CPUUtilization）</li><li>调整实例数（必须要满足不超过最大&#x2F;最小实例数）</li><li>每隔30s做一次自动扩容的判断<br>说明：</li></ol><ul><li>CPU utilization的计算方法是用cpu usage（最近一分钟的平均值，通过heapster可以直接获取到）除以cpu request（这里cpu request就是我们在创建容器时制定的cpu使用核心数）得到一个平均值，这个平均值可以理解为：平均每个Pod CPU核心的使用占比。</li><li>最重要的步骤为3，这里即为HPA的算法，计算当前需要启动几个Pod<blockquote><p>HPA进行伸缩算法</p></blockquote></li></ul><p>分为三种情况：</p><ol><li>普通情况下启动Pod数量计算方式<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TargetNumOfPods = ceil(sum(CurrentPodsCPUUtilization) / Target)</span><br></pre></td></tr></table></figure>说明：</li></ol><ul><li>ceil()表示取大于或等于某数的最近一个整数</li></ul><p><strong>例子：</strong><br>我们有一个集群实例数是3 pods，同时Pod的cpu资源的Request为1.4。cpu限额，即Target是CPU使用率为80%，当cpu的使用量CurrentPodsCPUUtilization为1.1,1.4，1.3时，要扩容成多少个呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceil（（1.1+1.4+1.3）/1.4/0.8）= 4 </span><br></pre></td></tr></table></figure><p>所以扩容成四个实例。</p><ol start="2"><li><p>实例刚启动时及刚完成扩容&#x2F;缩容，会有一段冷却时间<br>由于启动实例时cpu的使用度会陡增，所以自动扩容会等待一段时间以收集准确的运行时监控数据。每次扩容后冷却3分钟才能再次进行扩容，而缩容则要等5分钟后。这是因为自动扩容使用保守的方法，尽可能满足pods业务的正常使用，所以扩容的优先级要大于缩容。</p></li><li><p>当前Pod Cpu使用率与目标使用率接近时，不会触发扩容<br>当满足以下条件才会真正触发扩容&#x2F;缩容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">avg(CurrentPodsConsumption) / Target &gt;1.1 或 &lt;0.9</span><br></pre></td></tr></table></figure><p>这是为了避免出现频繁的扩容缩容。<br>扩容条件的相对与绝对度量<br><strong>例子：</strong><br>我们有一个集群实例数是3 pods，同时Pod的cpu资源的Request为1.5。cpu限额，即Target是CPU使用率为80%，当cpu的使用量CurrentPodsCPUUtilization为1.1,1.4，1.3时，会不会发生扩容，要扩容成多少个呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceil（（1.1+1.4+1.3）/1.5/0.8）= 4 </span><br></pre></td></tr></table></figure><p>按照我们1的说法，它再添加一个pod。但是我们再来算下当前Pod使用率与目标使用率情况。</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(1.1 + 1.4 + 1.3)/3/1.5 = 0.84444 #当前Pod CPU平均使用率</span><br><span class="line">0.84444 / 0.8 = 1.055555 &lt; 1.1 #当前Pod CPU平均使用率与目标CPU使用率比</span><br></pre></td></tr></table></figure><p>综上：<code>1.0555 &lt; 1.1</code>，当前HPA并不会发生扩容，所以最终Pod数仍然是<strong>3</strong>个。</p><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><blockquote><p>为 dc&#x2F;nginx-demo 创建一个 HPA （最小为1个pod，最多为3个pod，cpu使用率目标值为80%）</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc autoscale dc/nginx-demo--min=1 --max=3 --cpu-percent=80</span><br></pre></td></tr></table></figure><p>查看当前hpa状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@demo ~]# oc delete hpa hpa-resource-metrics-memory </span><br><span class="line">horizontalpodautoscaler &quot;hpa-resource-metrics-memory&quot; deleted</span><br><span class="line">[root@demo ~]# oc describe hpa nginx-demo </span><br><span class="line">Name:                                                  nginx-demo</span><br><span class="line">Namespace:                                             testmysql</span><br><span class="line">Labels:                                                &lt;none&gt;</span><br><span class="line">Annotations:                                           &lt;none&gt;</span><br><span class="line">CreationTimestamp:                                     Wed, 06 Jun 2018 10:36:57 +0800</span><br><span class="line">Reference:                                             DeploymentConfig/nginx-demo</span><br><span class="line">Metrics:                                               ( current / target )</span><br><span class="line">  resource cpu on pods  (as a percentage of request):  0% (0) / 80%</span><br><span class="line">Min replicas:                                          1</span><br><span class="line">Max replicas:                                          3</span><br><span class="line">Conditions:</span><br><span class="line">  Type            Status  Reason            Message</span><br><span class="line">  ----            ------  ------            -------</span><br><span class="line">  AbleToScale     True    ReadyForNewScale  the last scale time was sufficiently old as to warrant a new scale</span><br><span class="line">  ScalingActive   True    ValidMetricFound  the HPA was able to succesfully calculate a replica count from cpu resource utilization (percentage of request)</span><br><span class="line">  ScalingLimited  True    TooFewReplicas    the desired replica count is more than the maximum replica count</span><br><span class="line">Events:           &lt;none&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>为dc&#x2F;nginx-demo创建一个HPA(最小为1个pod，最多为3个pod，memory使用率目标值50%）</p></blockquote><p>与CPU使用率作为目标值不同，<strong>memory使用率不能使用oc autoscale命令来创建，只能通过yaml文件来创建</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># hpa-memory.yml</span><br><span class="line">apiVersion: autoscaling/v2beta1</span><br><span class="line">kind: HorizontalPodAutoscaler</span><br><span class="line">metadata:</span><br><span class="line">  name: hpa-resource-metrics-memory </span><br><span class="line">spec:</span><br><span class="line">  scaleTargetRef:</span><br><span class="line">    apiVersion: apps.openshift.io/v1</span><br><span class="line">    kind: DeploymentConfig</span><br><span class="line">    name: nginx-demo</span><br><span class="line">  minReplicas: 1 </span><br><span class="line">  maxReplicas: 3 </span><br><span class="line">  metrics:</span><br><span class="line">  - type: Resource</span><br><span class="line">    resource:</span><br><span class="line">      name: memory</span><br><span class="line">      targetAverageUtilization: 50 </span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f hpa-memory.yml</span><br></pre></td></tr></table></figure><p>查看当前hpa状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@demo~]# oc describe hpa hpa-resource-metrics-memory </span><br><span class="line">Name:                                                     hpa-resource-metrics-memory</span><br><span class="line">Namespace:                                                testmysql</span><br><span class="line">Labels:                                                   &lt;none&gt;</span><br><span class="line">Annotations:                                              &lt;none&gt;</span><br><span class="line">CreationTimestamp:                                        Wed, 06 Jun 2018 10:28:59 +0800</span><br><span class="line">Reference:                                                DeploymentConfig/nginx-demo</span><br><span class="line">Metrics:                                                  ( current / target )</span><br><span class="line">  resource memory on pods  (as a percentage of request):  1% (1347584) / 50%</span><br><span class="line">Min replicas:                                             1</span><br><span class="line">Max replicas:                                             3</span><br><span class="line">Conditions:</span><br><span class="line">  Type            Status  Reason              Message</span><br><span class="line">  ----            ------  ------              -------</span><br><span class="line">  AbleToScale     True    ReadyForNewScale    the last scale time was sufficiently old as to warrant a new scale</span><br><span class="line">  ScalingActive   True    ValidMetricFound    the HPA was able to succesfully calculate a replica count from memory resource utilization (percentage of request)</span><br><span class="line">  ScalingLimited  False   DesiredWithinRange  the desired count is within the acceptable range</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason          Age              From                       Message</span><br><span class="line">  ----     ------          ----             ----                       -------</span><br><span class="line">  Warning  FailedGetScale  5m (x6 over 8m)  horizontal-pod-autoscaler  no matches for apps/, Kind=DeploymentConfig</span><br><span class="line">  Warning  FailedGetScale  4m (x3 over 5m)  horizontal-pod-autoscaler  no matches for apps/, Kind=ReplicationController</span><br><span class="line">  Warning  FailedGetScale  3m               horizontal-pod-autoscaler  replicationcontrollers/scale.autoscaling &quot;nginx-demo&quot; not found</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Network-QoS——Pod网络控制</title>
      <link href="/openshift/Openshift-Network-QoS%E2%80%94%E2%80%94Pod%E7%BD%91%E7%BB%9C%E6%8E%A7%E5%88%B6/"/>
      <url>/openshift/Openshift-Network-QoS%E2%80%94%E2%80%94Pod%E7%BD%91%E7%BB%9C%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-7366303e398086f1.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="限速安全行驶"></p><h2 id="Pod网络（速）控制的必要性"><a href="#Pod网络（速）控制的必要性" class="headerlink" title="Pod网络（速）控制的必要性"></a>Pod网络（速）控制的必要性</h2><p>高速公路上，当流量大时，如果汽车仍然不限制速度的话，将会很容易发生车祸，我们都会自觉地减速缓慢通过，只有减速才能安全行驶。<br>在平台的集群中也是一样，一台主机上会有大量容器运行，容器相当于高速速上的汽车，对外的网络通信都使用主机出口这条高速路，如果某（几）个容器突然访问流量大增，而且没有作任何网络限速，会占用了主机的网络，严重影响其它容器的网络，进而影响其它业务。</p><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ul><li>Openshift打开多租户网络模式<br>修改&#x2F;etc&#x2F;origin&#x2F;master&#x2F;master-config.yaml将<strong>networkPluginName</strong>设置为<code>redhat/openshift-ovs-multitenant</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  hostSubnetLength: 9</span><br><span class="line">  networkPluginName: redhat/openshift-ovs-multitenant</span><br><span class="line">  serviceNetworkCIDR: 172.30.0.0/16</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li></ul><ul><li>如果已存在的集群，切换网络策略，请参考<a href="https://www.jianshu.com/p/22ad366b2aad">Openshift网络插件动态切换</a></li></ul><h2 id="为Pod添加网络限速标记"><a href="#为Pod添加网络限速标记" class="headerlink" title="为Pod添加网络限速标记"></a>为Pod添加网络限速标记</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line"> annotations:</span><br><span class="line">   kubernetes.io/ingress-bandwidth: 1M</span><br><span class="line">   kubernetes.io/egress-bandwidth: 1M</span><br><span class="line">spec:</span><br><span class="line">    containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br></pre></td></tr></table></figure><p><code>说明</code>: </p><ul><li>kubernetes.io&#x2F;ingress-bandwidth设置的是 <code>(出端口）下行</code>的网速限制</li><li>kubernetes.io&#x2F;egress-bandwidth设置的是 <code>(入端口）上行</code>的网速限制</li><li>网络限制单位必须是<code>M</code>，实际单位对应的是<code>Mb</code></li></ul><h2 id="为DeploymentConfig添加限速标记"><a href="#为DeploymentConfig添加限速标记" class="headerlink" title="为DeploymentConfig添加限速标记"></a>为DeploymentConfig添加限速标记</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: test</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    deploymentconfig: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        kubernetes.io/egress-bandwidth: 0.5M</span><br><span class="line">        kubernetes.io/ingress-bandwidth: 0.5M</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">        deploymentconfig: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - image: nginx</span><br><span class="line">          name: nginx</span><br></pre></td></tr></table></figure><p><code>说明</code>:</p><ul><li>因为限速是面向Pod的所以需要要Pod对应的template中添加网络上下行速度限制。</li></ul><h2 id="测试-上行与下行都限制为0-5M"><a href="#测试-上行与下行都限制为0-5M" class="headerlink" title="测试(上行与下行都限制为0.5M)"></a>测试(上行与下行都限制为0.5M)</h2><blockquote><p>Pod访问外网</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@demo ~]# oc rsh op-java-sample-13-7bmj7</span><br><span class="line">sh-4.2$ wget https://xxxx.com/xx.zip</span><br><span class="line">--2018-07-10 08:31:26--  https://xxxx.com/xx.zip</span><br><span class="line">Resolving xxxx.com (xxxx.com)... 117.211.167.14</span><br><span class="line">Connecting to xxxx.com (xxxx.com)|117.211.167.14|:443... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: unspecified [application/zip]</span><br><span class="line">Saving to: &#x27;xx.zip.2&#x27;</span><br><span class="line"></span><br><span class="line">  14% [               &lt;=&gt;                                                 ] 211,857     57.2KB/s           </span><br></pre></td></tr></table></figure><p><code>说明</code>:<br>下载速度为57.2KB&#x2F;s，恰好是被限的500Kb</p><blockquote><p>外部访问Pod</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@demo ~]# wget http://10.131.1.32:8080/20180416.db</span><br><span class="line">--2018-07-10 16:50:02--  http://10.131.1.32:8080/20180416.db</span><br><span class="line">Connecting to 10.131.1.32:8080... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 10698784 (10M) [application/octet-stream]</span><br><span class="line">Saving to: ‘20180416.db.1’</span><br><span class="line"></span><br><span class="line"> 9% [               &lt;=&gt;                                                 ]1,056,888   58.3KB/s  eta 4m 10s </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>说明</code><br>10.131.1.32为Pod在集群下的IP，从主机访问Pod的服务下载文件，速度为58.3KB&#x2F;s，恰好是被限的500Kb</p><blockquote><p>同一个Poroject下的Pod间访问</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sh-4.2$ wget http://10.131.1.32:8080/20180416.db</span><br><span class="line">--2018-07-10 08:54:50--  http://10.131.1.32:8080/20180416.db</span><br><span class="line">Connecting to 10.131.1.32:8080... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 10698784 (10M) [application/octet-stream]</span><br><span class="line">Saving to: &#x27;20180416.db&#x27; </span><br><span class="line"></span><br><span class="line">13% [======================&gt;                                       ] 1,480,482   57.6KB/s  eta 47s</span><br></pre></td></tr></table></figure><p><code>说明</code>:</p><ul><li>Pod间网络访问也会受到Pod网络配置的控制</li><li>同时在测试过程中发现，刚开始测试时网络是很高的，但是3-5s后会降到被限制的网速</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Route证书HTTPS配置</title>
      <link href="/openshift/Openshift-Route%E8%AF%81%E4%B9%A6HTTPS%E9%85%8D%E7%BD%AE/"/>
      <url>/openshift/Openshift-Route%E8%AF%81%E4%B9%A6HTTPS%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>后台应用为http服务<br>Termination Type:  Edge<br>Insecure Traffic:     Allow</p><p>后台应用为https服务<br>Termination Type:  Passthrough<br>Insecure Traffic:     None</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Nginx-Router替换默认Haproxy-Router</title>
      <link href="/openshift/Openshift-Nginx-Router%E6%9B%BF%E6%8D%A2%E9%BB%98%E8%AE%A4Haproxy-Router/"/>
      <url>/openshift/Openshift-Nginx-Router%E6%9B%BF%E6%8D%A2%E9%BB%98%E8%AE%A4Haproxy-Router/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-bd84acb1f36a9e24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="openshift-nginx"></p><h2 id="什么是Router"><a href="#什么是Router" class="headerlink" title="什么是Router"></a>什么是Router</h2><ul><li>Router在Openshift集群的一个不可非常重要的组件，它作为外部请求访问集群内部资源的入口，为Openshift上的应用提供边缘负载均衡。</li><li>Router可以为应用提供HTTP和websocket流量的负载均衡，同时支持HTTPS连接。Openshift上有一个特殊的资源叫Route，通过它可以方便地配置Router。</li><li>Openshift集群默认使用Haproxy应用作为Router的实现，它通过容器的形式运行在相应的Node上，同时Router Pod网络使用的宿主机的网络，即<code>hostNetwork=true</code>。</li><li><strong>除了Haproxy,我们还可以使用Nginx来实现Router，这也是本文的重点。</strong></li><li>不管是Haproxy还是Nginx方案都是使用了软件负载均衡器，还可以使用<a href="https://www.jianshu.com/p/d883857e7af3">F5等硬件负载均衡器来替换Router</a>，达到性能的提升。</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-8a8f0a81354c762c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Nginx作为Router的原理图"></p><h2 id="Nginx-Router与默认Router比较"><a href="#Nginx-Router与默认Router比较" class="headerlink" title="Nginx Router与默认Router比较"></a>Nginx Router与默认Router比较</h2><p><img src="https://upload-images.jianshu.io/upload_images/5793257-3a86858333973d7a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Nginx官方比较表格"></p><h2 id="如何替换Openshift默认Router"><a href="#如何替换Openshift默认Router" class="headerlink" title="如何替换Openshift默认Router"></a>如何替换Openshift默认Router</h2><h4 id="卸载当前Router"><a href="#卸载当前Router" class="headerlink" title="卸载当前Router"></a>卸载当前Router</h4><ol><li>用system:admin登录集群<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc login -u system:admin</span><br></pre></td></tr></table></figure></li><li>选择default项目<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc project default</span><br></pre></td></tr></table></figure></li><li>备份现有的Router<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get -o yaml service/router dc/router clusterrolebinding/router-router-role serviceaccount/router &gt; default-router-backup.yaml</span><br></pre></td></tr></table></figure></li><li>删除当前Router<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc delete -f default-router-backup.yaml</span><br></pre></td></tr></table></figure></li></ol><h4 id="安装Nginx-Router"><a href="#安装Nginx-Router" class="headerlink" title="安装Nginx-Router"></a>安装Nginx-Router</h4><p>使用镜像<code>xhuaustc/nginx-openshift-router:1.15</code>部署nginx router</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm router router --images=xhuaustc/nginx-openshift-router:1.15  --type=&#x27;&#x27; --selector=&#x27;node-role.kubernetes.io/infra=true&#x27;</span><br></pre></td></tr></table></figure><h4 id="添加Stub-Status页面的查看权限"><a href="#添加Stub-Status页面的查看权限" class="headerlink" title="添加Stub Status页面的查看权限"></a>添加Stub Status页面的查看权限</h4><p>在Router Pod所部署的结点开通1936端口的访问权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo iptables -I OS_FIREWALL_ALLOW -p tcp -m tcp --dport 1936 -j ACCEPT </span><br></pre></td></tr></table></figure><p>在浏览器下查看以下链接<code>$ROUTER_IP:1936/stub_status</code></p><h4 id="添加Prometheus监控支持"><a href="#添加Prometheus监控支持" class="headerlink" title="添加Prometheus监控支持"></a>添加Prometheus监控支持</h4><ol><li>运行如下命令，添加nginx exporter<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ oc patch dc/router -p &#x27;spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx/nginx-prometheus-exporter:0.1.0</span><br><span class="line">        name: nginx-prometheus-exporter</span><br><span class="line">        ports:</span><br><span class="line">        - name: prometheus</span><br><span class="line">          containerPort: 9113</span><br><span class="line">        args:</span><br><span class="line">          - -web.listen-address</span><br><span class="line">          - :9113</span><br><span class="line">          - -nginx.scrape-uri</span><br><span class="line">          - http://127.0.0.1:1936/stub_status&#x27;</span><br></pre></td></tr></table></figure></li><li>在router service添加exporter想着的标注<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc annotate service router --overwrite prometheus.io/port=9113 prometheus.io/scrape=true</span><br></pre></td></tr></table></figure>此时openshift集群中的prometheus就可以发现nginx exporter的数据</li></ol><h4 id="卸载Nginx-Router"><a href="#卸载Nginx-Router" class="headerlink" title="卸载Nginx Router"></a>卸载Nginx Router</h4><p>和卸载之前默认的Router一样，只需要将对应的Object删除即可</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc delete service/router dc/router clusterrolebinding/router-router-role serviceaccount/router</span><br></pre></td></tr></table></figure><h2 id="Nginx-Router性能测试"><a href="#Nginx-Router性能测试" class="headerlink" title="Nginx Router性能测试"></a>Nginx Router性能测试</h2><p>测试环境： </p><ul><li>Openshift 3.11 网络插件为ovs-subnet</li><li>openshift集群物理环境配置为：3 master + 2 Router Node + 2 Computer Node。每台物理机的配置都是cpu 48核&#x2F;内存 384G 网卡为10Gbps</li><li>访问方式，在ab测试机器上，直接在&#x2F;etc&#x2F;hosts中绑定 应用域名 与 Router1的IP</li><li>应用为一个Nginx页面，页面大小为3.2KB，Pod数为10</li><li>Router节点系统配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_max_syn_backlog = 65536</span><br><span class="line">net.core.netdev_max_backlog =  36768</span><br><span class="line">net.core.somaxconn = 36768</span><br><span class="line"> </span><br><span class="line">net.core.wmem_default = 8588608</span><br><span class="line">net.core.rmem_default = 8588608</span><br><span class="line">net.core.rmem_max = 16877216</span><br><span class="line">net.core.wmem_max = 16877216</span><br><span class="line"> </span><br><span class="line">net.ipv4.tcp_synack_retries = 2</span><br><span class="line">net.ipv4.tcp_syn_retries = 2</span><br><span class="line"> </span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line"> </span><br><span class="line">net.ipv4.tcp_mem = 94500000 915000000 927000000</span><br><span class="line">net.ipv4.tcp_max_orphans = 3376800</span><br><span class="line">net.ipv4.ip_local_port_range = 1024  65535</span><br></pre></td></tr></table></figure></li><li>Router环境变量配置<ul><li>WORKER_RLIMIT_NOFILE: 65535</li><li>KEEPALIVE_REQUESTS: 10000000</li><li>WORKER_PROCESSES: 8</li><li>WORKER_CPU_AFFINITY: 10000000  01000000  00100000  00010000  00001000  00000100  00000010  00000001 </li><li>ROUTER_MAX_CONNECTIONS: 80000</li></ul></li><li>Route配置Annotations <code>nginx.router.openshift.io/keepalive: 300</code></li></ul><p>测试工具： wrk<br>测试命令行：<code>wrk  -t 40 -c 5000 -d 30s  http://xx.com/index.html</code></p><table><thead><tr><th>Router类型</th><th>Type</th><th>页面大小</th><th>RPS</th><th>超时数量</th></tr></thead></table><ul><li>|Svc | 4KB | 58901| 3062&#x2F;2364808<br>F5 | Router| 4KB | 29848 | 15854&#x2F;898446<br>Haproxy | Router| 4KB | 32313| 3702&#x2F;972665<br>Nginx | Router| 4KB | 33943| 3535&#x2F;1021704</li><li>|Svc | 500B | 222033 |  42&#x2F;6683188<br>F5 | Router| 500B | 115435| 10829&#x2F;3473097<br>Haproxy | Router| 500B | 48245| 7484&#x2F;1452092<br>Nginx| Router| 500B | 166592| 2479&#x2F;5014470</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-1147e78a70e539db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Nginx Plus版本的Dashboard"></p><h2 id="测试结果说明"><a href="#测试结果说明" class="headerlink" title="测试结果说明"></a>测试结果说明</h2><ul><li>F5所在的测试环境与Haproxy&#x2F;Nginx Router的环境有些不一样，F5在使用千M网连接着集群，F5作部分参考</li><li>SVC实际为iptables作负载均衡，所以理论上性能是最好的，测试结果也验证了这一点</li><li>对于4KB的页面，Haproxy&#x2F;Nginx结果相关不大</li><li>对于500B的页面，Nginx的性能明显高于其它测试环境</li><li>就性能而言，Nginx相对于默认的Router确实有提高</li></ul><p>后序还会对配置做进一步完善优化，到时对测试数据再作更新。<br>说实话，对Nginx Router还是很期待的。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.nginx.com/blog/openshift-ecosystem-implementing-the-nginx-proxy-model-on-red-hat-openshift/">OpenShift Ecosystem: Implementing the NGINX Proxy Model on Red Hat OpenShift</a><br><a href="https://www.nginx.com/blog/introducing-nginx-and-nginx-plus-routers-for-openshift/">Introducing NGINX and NGINX Plus Routers for OpenShift Container Platform 3.10</a><br><a href="https://www.nginx.com/resources/datasheets/nginx-plus-router-openshift/">NGINX Plus Router for OpenShift</a><br> <a href="https://github.com/nginxinc/nginx-openshift-router">nginxinc&#x2F;nginx-openshift-router</a><br><a href="https://github.com/nginxinc/nginx-openshift-router/blob/master/docs/nginx-oss-router-install.md">nginx-openshift-router&#x2F;docs&#x2F;nginx-oss-router-install.md</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Service不仅仅能负载Pod，它还能负载VM等外部服务</title>
      <link href="/openshift/Openshift-Service%E4%B8%8D%E4%BB%85%E4%BB%85%E8%83%BD%E8%B4%9F%E8%BD%BDPod%EF%BC%8C%E5%AE%83%E8%BF%98%E8%83%BD%E8%B4%9F%E8%BD%BDVM%E7%AD%89%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1/"/>
      <url>/openshift/Openshift-Service%E4%B8%8D%E4%BB%85%E4%BB%85%E8%83%BD%E8%B4%9F%E8%BD%BDPod%EF%BC%8C%E5%AE%83%E8%BF%98%E8%83%BD%E8%B4%9F%E8%BD%BDVM%E7%AD%89%E5%A4%96%E9%83%A8%E6%9C%8D%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>Service</strong>是Openshift最核心的概念，它可以为一组具有相同功能的Pod提供一个统一的入口，并且将请求负载均衡分发到后端的各个Pod应用上。同时Service在集群下的IP是不变的，保证了请求的可靠性。</li><li>Service仅仅只能负载一组Pod吗？<strong>No。它还可以对接VM的服务，甚至是物理机的服务。</strong><blockquote><p>Service负载Pod</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      name: nginx</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8080</span><br><span class="line">      nodePort: 38080</span><br></pre></td></tr></table></figure></li><li>selector：Label选择器，将选择指定Label的Pod作为被负载Pod</li><li>type：Service的类型，指定Service的访问方式，默认为ClusterIP。<ul><li>ClusterIP：虚拟的服务IP地址，该IP可以被集群下的Pod访问</li><li>NodePort：使用宿主机的端口，通过访问任意Node的对应端口，就能访问Service的端口</li><li>LoadBalancer：使用外部负载均衡器完成到服务的负载分发，需要在.spec.status.loadBalancer指定外部负载均衡器的IP地址，同时定义nodePort和clusterIP。</li></ul></li><li>port：Service监听的端口号</li><li>targetPort：需要转发到后端Pod的端口号</li><li>nodePort：当type&#x3D;NodePort时，指定映射到物理机的端口（范围30000-32767）<blockquote><p>Service负载集群外部Service（可以是VM，物理机等）</p></blockquote></li></ul><ol><li>创建一个无Label Selector的Service（即无法选择后端的Pod，系统不会自动创建Endpoint，需要手动创建Endpoint）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-out</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      name: nginx-out</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8080</span><br><span class="line">  type: ClusterIP</span><br></pre></td></tr></table></figure></li><li>创建Endpoint指向后端服务（该Endpoint的name必须与Service的name相同）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: Endpoints</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-out</span><br><span class="line">subsets:</span><br><span class="line">  - addresses:</span><br><span class="line">      - ip: 192.168.0.6</span><br><span class="line">    ports:</span><br><span class="line">      - port: 8080</span><br></pre></td></tr></table></figure>集群中的pod访问Service nginx-out:80，请求最终会被指向192.168.0.6:8080。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-6f08bffa97a7276e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Service指向外部服务"></li></ol><blockquote><p>实战：将外部的Jenkins用Openshift的Service接管，并创建Route来访问Jenkins服务</p></blockquote><ul><li>Jenkins服务： <code>192.168.0.6:8080</code></li><li>route的Hostname：<code>jenkins.apps.openshift.com</code></li></ul><ol><li>创建project jenkins<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc new-project jenkins</span><br></pre></td></tr></table></figure></li><li>创建jenkinsvm Service<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkinsvm</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 8080</span><br><span class="line">      name: jenkinsvm</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 8080</span><br><span class="line">  type: ClusterIP</span><br></pre></td></tr></table></figure></li><li>创建Endpoints<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: Endpoints</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-out</span><br><span class="line">subsets:</span><br><span class="line">  - addresses:</span><br><span class="line">      - ip: 192.168.0.6</span><br><span class="line">    ports:</span><br><span class="line">      - port: 8080</span><br></pre></td></tr></table></figure></li><li>创建Route<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">spec:</span><br><span class="line">  host: jenkins.apps.openshift.com</span><br><span class="line">  port: </span><br><span class="line">    targetPort: jenkinsvm</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">    name: jenkinsvm</span><br><span class="line">    weight: 100</span><br></pre></td></tr></table></figure><img src="https://upload-images.jianshu.io/upload_images/5793257-7bb03f148429a6ab.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="使用Openshift的Service访问的集群外部的Jenkins服务"></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenShift制作NginxLB-Operator实战</title>
      <link href="/openshift/OpenShift%E5%88%B6%E4%BD%9CNginxLB-Operator%E5%AE%9E%E6%88%98/"/>
      <url>/openshift/OpenShift%E5%88%B6%E4%BD%9CNginxLB-Operator%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>近期需要在OpenShift集群中部署Nginx服务做为负载均衡器，负载集群外部服务，如NTP、DNS、项目App等。因为不同的服务的配置都是不一样的，不仅后台服务的IP不一样，而且使用的协议也不一样，HTTP&#x2F;TCP&#x2F;UDP都有可能，如果按照传统的方式来实施的话，每一个应用单独定义Nginx配置，分别部署，每增加一个新的应用被负载都需要做一次复杂的过程，那么有没有办法能够让这过程变得简单呢，甚至能够自动化处理，我们只需要提供最简单的信息？<br>下面我们来分析下常用的几种方法。</p><h2 id="打包方案选择"><a href="#打包方案选择" class="headerlink" title="打包方案选择"></a>打包方案选择</h2><h3 id="1-Template"><a href="#1-Template" class="headerlink" title="1. Template"></a>1. Template</h3><p>对于OpenShift熟悉的朋友，会马上想到使用Template模板来实现。<br>Template模板是OpenShift特有的应用打包方式，它描述了一组对象，同时对这些对象的配置可以进行参数化处理，生成OpenShift 容器平台创建的对象列表。在模板中可以设置所有在项目中有权限创建的任何资源。</p><p><strong>不足之处：</strong></p><ul><li>OpenShift特有，如果是使用OpenShift容器平台的话，这个不足可忽略。</li><li>无法保证线上资源状态始终与参数设定的结果一致，如手动增加rc的副本数时，不会自动恢复到与参数设定的副本数。</li><li>在创建的时候设置参数，如果在应用运行时对参数动态更新的话，则需要使用脚本命令使用所有的参数，重新生成资源列表。参数需要额外管理，不可靠。</li><li>如果应用有创建的顺序有依赖，则无法满足。</li><li>无法根据参数的不同对资源进行条件控制。</li></ul><h3 id="2-Helm"><a href="#2-Helm" class="headerlink" title="2. Helm"></a>2. Helm</h3><p>对于Kubernetes熟悉的朋友，会马上想到使用Helm来实现。<br>Helm是Kubernetes生态系统中的一个软件包管理工具，与Template类似。</p><p><strong>不足之处：</strong></p><ul><li>需要额外部署Helm客户端及Tiller。</li><li>需要额外管理helm中的charts资源。</li><li>无法保证线上资源状态始终与参数设定的结果一致。</li><li>如果应用有创建的顺序有依赖，则无法满足。</li><li>参数更新时，需要手动执行helm脚本</li></ul><h3 id="3-创建Ansible-playbook"><a href="#3-创建Ansible-playbook" class="headerlink" title="3. 创建Ansible playbook"></a>3. 创建Ansible playbook</h3><p>对于熟悉各种自动化工具的运维开发，会想到使用自动化配置管理工具来做，如ansible。<br>利用ansible的k8s模块，创建各种资源，而且可以充分发挥ansible强大的控制功能。</p><p><strong>不足之处：</strong></p><ul><li>需要额外部署Ansible，及对ansible访问集群的访问认证。</li><li>需要额外管理ansible的playbook文件。</li><li>无法保证线上资源状态始终与参数设定的结果一致。</li><li>参数更新时，需要手动执行ansible playbook脚本</li></ul><h3 id="4-operator"><a href="#4-operator" class="headerlink" title="4. operator"></a>4. operator</h3><p><strong>Operator即为今天的主角，我将给予更加详细的介绍。</strong><br>Operator是由coreOS公司（已被RedHat收购）开发的一种打包，部署和管理Kubernetes&#x2F;OpenShift应用的方法。Kubernetes&#x2F;OpenShift应用是一个部署在集群上并使用Kubernetes&#x2F;OpenShift API和kubectl&#x2F;oc工具进行管理的应用程序。Operator类似于Helm和Template，但是比它们都更加灵活，更加强大，更加方便。<br>Operator本质上是一个自定义的控制器。它会在集群中运行一个Pod与Kubernetes&#x2F;OpenShift API Server交互，并通过CRD引入新的资源类型，这些新创建的资源类型与集群上的资源类型如Pod等交互方式是一样的。同时Operator会监听自定义的资源类型对象的创建与变化，并开始循环执行，保证应用处于被定义的状态。<br>为什么说Operator能够更好地解决这类问题呢？因为它不仅能够很好地满足自定义打包的需求，同时也弥补了以上三种方式的不足。<br>使用Operator-sdk能够非常方便地创建自定义的Operator，它支持三种类型：go、ansible、helm。</p><ul><li>go类型，它的实现更加灵活，可以随心所欲，扩展性也最强，构建出的operator镜像也不大，但是它对于编程能力要求高，同时没有ansible和helm类型拿来即用，可读性也不及ansible与helm类型。</li><li>ansible类型，它使用ansible的playbook方式来定义应用的构建与保证应用的状态，它的实现也很灵活，依赖于ansible的模块，但是这使得构建出的operator镜像较大，一般为600多M，因为它包含了ansible应用及默认的各个模块。</li><li>helm类型，它使用helm的charts方式来定义应用的构建与保证应用的状态，它的镜像一般为200多M，但是它的灵活度不及另外两种类型。</li></ul><p>一般情况下，以上三种方式都能够满足要求，建议大家使用自己最熟悉的方式。构建方式并不是我们的约束点，我们最关心的是能够部署按要求的应用，并保证应用一直处于稳定的状态。</p><h2 id="构建分析"><a href="#构建分析" class="headerlink" title="构建分析"></a>构建分析</h2><h3 id="1-资源类型"><a href="#1-资源类型" class="headerlink" title="1. 资源类型"></a>1. 资源类型</h3><ul><li>deployment，运行Nginx应用</li><li>service，运行Nginx service</li><li>configmap，设置Nginx负载均衡上游及协议类型等配置</li><li>route，对于HTTP协议可以设置指定的域名</li><li>NginxLB，添加的CRD资源对象名</li></ul><h3 id="2-参数设置"><a href="#2-参数设置" class="headerlink" title="2. 参数设置"></a>2. 参数设置</h3><ul><li>nginx_image, 指定Nginx应用镜像</li><li>size，Nginx应用运行的副本数</li><li>loadbalancers，设定的负载均衡参数配置列表</li><li>loadbalancers[].protocol，负载均衡网络协议，支持HTTP&#x2F;TCP&#x2F;UDP</li><li>loadbalancers[].port，负载均衡Nginx监听的端口</li><li>loadbalancers[].nodeport，如果负载均衡使用nodeport方式对外提供服务，则可以用该参数指定nodeport端口号</li><li>loadbalancers[].upstreams，负载均衡上游服务列表</li><li>loadbalancers[].hostname，对于HTTP协议，可以指定hostname来创建OpenShift Route资源</li></ul><p>最终需要实现的NginxLB资源的参数例子为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: fcloudy.com/v1alpha1</span><br><span class="line">kind: NginxLB</span><br><span class="line">metadata:</span><br><span class="line">  name: example-nginxlb</span><br><span class="line">spec:</span><br><span class="line">  nginx_image: &quot;docker.io/xhuaustc/nginx:alpine&quot;</span><br><span class="line">  size: 2</span><br><span class="line">  loadbalancers:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 53</span><br><span class="line">      nodeport: 32287</span><br><span class="line">      upstreams:</span><br><span class="line">        - 192.168.4.5:53</span><br><span class="line">        - 192.168.5.3:53</span><br><span class="line">    - protocol: HTTP</span><br><span class="line">      port: 80</span><br><span class="line">      upstreams:</span><br><span class="line">        - 192.168.4.5:80</span><br><span class="line">      hostname: xx.nginx.fcloudy.com</span><br></pre></td></tr></table></figure><p>以下为NginxLB Operator相关资源的关系</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7230190271328cef3262646ab94bfcc24d6d1448e9d90d87531971e5fcefe7a7.png" alt="NginxLB Operator资源关系">  </p><h3 id="3-Operator类型"><a href="#3-Operator类型" class="headerlink" title="3. Operator类型"></a>3. Operator类型</h3><ul><li>选择ansible类型，使用它的主要是与集群运维及自动化运维等技术栈统一。</li></ul><h2 id="制作Operator"><a href="#制作Operator" class="headerlink" title="制作Operator"></a>制作Operator</h2><p>通用步骤与说明可以参考<a href="https://www.jianshu.com/p/0590c2ef67e0">OpenShift 通过Operator SDK制作Operator</a>，本案例的具体操作如下</p><ol><li>新建一个operator项目（type&#x3D;ansible 资源类型为NginxLB)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ operator-sdk new nginxlb-operator --api-version=fcloudy.com/v1alpha1 --kind=NginxLB --type=ansible</span><br></pre></td></tr></table></figure></li><li>在roles&#x2F;nginxlb&#x2F;templates中添加模板文件nginx-deployment.yaml.j2、nginx-svc.yaml.j2、nginx-cm.yaml.j2及nginx-route.yaml.j2<br><strong>nginx-deployment.yaml.j2</strong><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">nginxlb:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;</span><br><span class="line">    <span class="attr">app:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;</span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;</span><br><span class="line">  <span class="attr">namespace:</span> &#123;&#123; <span class="string">meta.namespace</span> &#125;&#125;</span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> &#123;&#123; <span class="string">size</span> &#125;&#125;</span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">nginxlb:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;</span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">nginxlb:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;</span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; nginx_image | default(&#x27;docker.io/xhuaustc/nginx:alpine&#x27;) &#125;&#125;</span>&quot;</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/etc/nginx/nginx.conf</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx-config-hgj4i</span></span><br><span class="line">          <span class="attr">subPath:</span> <span class="string">nginx.conf</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">defaultMode:</span> <span class="number">420</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">nginx.conf</span></span><br><span class="line">                <span class="attr">path:</span> <span class="string">nginx.conf</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx-config-hgj4i</span></span><br></pre></td></tr></table></figure><strong>nginx-svc.yaml.j2</strong><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;<span class="string">-&#123;&#123;</span> <span class="string">item.port</span> <span class="string">&#125;&#125;-nginx-service</span></span><br><span class="line">  <span class="attr">namespace:</span> &#123;&#123; <span class="string">meta.namespace</span> &#125;&#125;</span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> &#123;&#123; <span class="string">item.protocol</span> <span class="string">|</span> <span class="string">lower</span> &#125;&#125;<span class="string">-&#123;&#123;</span> <span class="string">item.port</span> <span class="string">|</span> <span class="string">lower</span> <span class="string">&#125;&#125;</span></span><br><span class="line">      <span class="attr">port:</span> &#123;&#123; <span class="string">item.port</span> &#125;&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">item.protocol</span> <span class="string">==</span> <span class="string">&#x27;HTTP&#x27;</span> <span class="string">%</span>&#125;</span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line">      <span class="attr">protocol:</span> &#123;&#123; <span class="string">item.protocol</span> &#125;&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">item.nodeport</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">%</span>&#125;</span><br><span class="line">      <span class="attr">nodePort:</span> &#123;&#123; <span class="string">item.nodeport</span>&#125;&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">nginxlb:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">item.nodeport</span> <span class="string">is</span> <span class="string">defined</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br></pre></td></tr></table></figure><strong>nginx-cm.yaml.j2</strong><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> &#123;&#123; <span class="string">meta.namespace</span> &#125;&#125;</span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">nginx.conf:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    worker_processes  1;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">    <span class="string">error_log</span>  <span class="string">/var/log/nginx/error.log</span> <span class="string">warn;</span></span><br><span class="line">    <span class="string">pid</span>        <span class="string">/var/run/nginx.pid;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">events</span> &#123;</span><br><span class="line">        <span class="string">worker_connections</span>  <span class="number">1024</span><span class="string">;</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="string">stream&#123;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">for</span> <span class="string">lb</span> <span class="string">in</span> <span class="string">loadbalancers</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">lb.protocol</span> <span class="string">in</span> [<span class="string">&quot;TCP&quot;</span>, <span class="string">&quot;UDP&quot;</span>] <span class="string">%</span>&#125;</span><br><span class="line">      <span class="string">upstream</span> &#123;&#123;<span class="string">meta.name</span>&#125;&#125;<span class="string">-&#123;&#123;lb.protocol&#125;&#125;-&#123;&#123;lb.port&#125;&#125;&#123;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">for</span> <span class="string">upstream</span> <span class="string">in</span> <span class="string">lb.upstreams</span> <span class="string">%</span>&#125;</span><br><span class="line">          <span class="string">server</span> &#123;&#123;<span class="string">upstream</span>&#125;&#125;<span class="string">;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endfor</span> <span class="string">%</span>&#125;</span><br><span class="line">      <span class="string">&#125;</span></span><br><span class="line">      <span class="string">server</span> &#123;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">lb.protocol</span> <span class="string">in</span> [<span class="string">&quot;UDP&quot;</span>] <span class="string">%</span>&#125;</span><br><span class="line">      <span class="string">listen</span> &#123;&#123;<span class="string">lb.port</span>&#125;&#125; <span class="string">udp;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">else</span> <span class="string">%</span>&#125;</span><br><span class="line">        <span class="string">listen</span> &#123;&#123;<span class="string">lb.port</span>&#125;&#125;<span class="string">;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">        <span class="string">proxy_pass</span> &#123;&#123;<span class="string">meta.name</span>&#125;&#125;<span class="string">-<span class="template-variable">&#123;&#123;lb.protocol&#125;&#125;</span></span><span class="string">-<span class="template-variable">&#123;&#123;lb.port&#125;&#125;</span></span><span class="string">;</span></span><br><span class="line">      &#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endfor</span> <span class="string">%</span>&#125;</span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">http</span> &#123;</span><br><span class="line">        <span class="string">include</span>       <span class="string">/etc/nginx/mime.types;</span></span><br><span class="line">        <span class="string">default_type</span>  <span class="string">application/octet-stream;</span></span><br><span class="line"></span><br><span class="line">        <span class="string">log_format</span>  <span class="string">main</span>  <span class="string">&#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;</span></span><br><span class="line">                          <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line">                          <span class="string">&#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">        <span class="string">access_log</span>  <span class="string">/var/log/nginx/access.log</span>  <span class="string">main;</span></span><br><span class="line"></span><br><span class="line">        <span class="string">sendfile</span>        <span class="string">on;</span></span><br><span class="line">        <span class="comment">#tcp_nopush     on;</span></span><br><span class="line"></span><br><span class="line">        <span class="string">keepalive_timeout</span>  <span class="number">65</span><span class="string">;</span></span><br><span class="line"></span><br><span class="line">        <span class="string">gzip</span>  <span class="string">on;</span></span><br><span class="line">        </span><br><span class="line">        &#123;<span class="string">%</span> <span class="string">for</span> <span class="string">lb</span> <span class="string">in</span> <span class="string">loadbalancers</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">if</span> <span class="string">lb.protocol</span> <span class="string">in</span> [<span class="string">&quot;HTTP&quot;</span>] <span class="string">%</span>&#125;</span><br><span class="line">      <span class="string">upstream</span> &#123;&#123;<span class="string">meta.name</span>&#125;&#125;<span class="string">-<span class="template-variable">&#123;&#123;lb.protocol&#125;&#125;</span></span><span class="string">-<span class="template-variable">&#123;&#123;lb.port&#125;&#125;</span></span>&#123;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">for</span> <span class="string">upstream</span> <span class="string">in</span> <span class="string">lb.upstreams</span> <span class="string">%</span>&#125;</span><br><span class="line">          <span class="string">server</span> &#123;&#123;<span class="string">upstream</span>&#125;&#125;<span class="string">;</span></span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endfor</span> <span class="string">%</span>&#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="string">server</span> &#123;</span><br><span class="line">        <span class="string">listen</span> &#123;&#123;<span class="string">lb.port</span>&#125;&#125;<span class="string">;</span></span><br><span class="line">        <span class="string">location</span> <span class="string">/</span> &#123;</span><br><span class="line">          <span class="string">proxy_pass</span> <span class="string">http://<span class="template-variable">&#123;&#123;meta.name&#125;&#125;</span></span><span class="string">-<span class="template-variable">&#123;&#123;lb.protocol&#125;&#125;</span></span><span class="string">-<span class="template-variable">&#123;&#123;lb.port&#125;&#125;</span></span><span class="string">;</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endif</span> <span class="string">%</span>&#125;</span><br><span class="line">&#123;<span class="string">%</span> <span class="string">endfor</span> <span class="string">%</span>&#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><strong>nginx-route.yaml.j2</strong><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">route.openshift.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Route</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;<span class="string">-&#123;&#123;</span> <span class="string">item.port</span> <span class="string">&#125;&#125;-nginx-route</span></span><br><span class="line">  <span class="attr">namespace:</span> &#123;&#123; <span class="string">meta.namespace</span> &#125;&#125;</span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; item.hostname &#125;&#125;</span>&quot;</span></span><br><span class="line">  <span class="attr">port:</span></span><br><span class="line">      <span class="attr">targetPort:</span> &#123;&#123; <span class="string">item.protocol</span> <span class="string">|</span> <span class="string">lower</span> &#125;&#125;<span class="string">-&#123;&#123;</span> <span class="string">item.port</span> <span class="string">|</span> <span class="string">lower</span> <span class="string">&#125;&#125;</span></span><br><span class="line">  <span class="attr">to:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line">    <span class="attr">name:</span> &#123;&#123; <span class="string">meta.name</span> &#125;&#125;<span class="string">-&#123;&#123;</span> <span class="string">item.port</span> <span class="string">&#125;&#125;-nginx-service</span></span><br></pre></td></tr></table></figure></li><li>在roles&#x2F;nginxlb&#x2F;tasks&#x2F;main.yaml中添加执行任务<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">create</span> <span class="string">nginx</span> <span class="string">configmap</span></span><br><span class="line">  <span class="attr">k8s:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">    <span class="attr">definition:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; lookup(&#x27;template&#x27;, &#x27;nginx-cm.yaml.j2&#x27;) | from_yaml &#125;&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">create</span> <span class="string">nginx</span> <span class="string">DeploymentConfig</span></span><br><span class="line">  <span class="attr">k8s:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">    <span class="attr">definition:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; lookup(&#x27;template&#x27;, &#x27;nginx-dc.yaml.j2&#x27;) | from_yaml &#125;&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">create</span> <span class="string">nginx</span> <span class="string">service</span></span><br><span class="line">  <span class="attr">k8s:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">    <span class="attr">definition:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; lookup(&#x27;template&#x27;, &#x27;nginx-svc.yaml.j2&#x27;) | from_yaml &#125;&#125;</span>&quot;</span></span><br><span class="line">  <span class="attr">with_items:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; loadbalancers &#125;&#125;</span>&quot;</span></span><br><span class="line">      </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">create</span> <span class="string">nginx</span> <span class="string">route</span></span><br><span class="line">  <span class="attr">k8s:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">    <span class="attr">definition:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; lookup(&#x27;template&#x27;, &#x27;nginx-route.yaml.j2&#x27;) | from_yaml &#125;&#125;</span>&quot;</span></span><br><span class="line">  <span class="attr">when:</span> <span class="string">item.hostname</span> <span class="string">is</span> <span class="string">defined</span></span><br><span class="line">  <span class="attr">with_items:</span> <span class="string">&quot;<span class="template-variable">&#123;&#123; loadbalancers &#125;&#125;</span>&quot;</span>   </span><br></pre></td></tr></table></figure></li><li>构建nginx-lb operator镜像，并推送到镜像仓库<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">operator-sdk build docker.io/xhuaustc/nginxlb-operator:v0.0.1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker push docker.io/xhuaustc/nginxlb-operator:v0.0.1</span></span><br></pre></td></tr></table></figure></li><li>operator-sdk默认是只能在operator应用所在的namespace下创建资源，如果需要在集群下全局的namespace都能使用NginxLB资源，需要对deploy&#x2F;operator.yaml作修改。<ul><li>将WATCH_NAMESPACE值设置为””</li><li>更新为步骤4中构建的镜像<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginxlb-operator</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">nginxlb-operator</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginxlb-operator</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">nginxlb-operator</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">ansible</span></span><br><span class="line">          <span class="attr">command:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">/usr/local/bin/ao-logs</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">/tmp/ansible-operator/runner</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">stdout</span></span><br><span class="line">          <span class="comment"># Replace this with the built image name</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&quot;docker.io/xhuaustc/nginxlb-operator:v0.0.1&quot;</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">&quot;Always&quot;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp/ansible-operator/runner</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">runner</span></span><br><span class="line">            <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">operator</span></span><br><span class="line">          <span class="comment"># Replace this with the built image name</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">&quot;docker.io/xhuaustc/nginxlb-operator:v0.0.1&quot;</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">&quot;Always&quot;</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/tmp/ansible-operator/runner</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">runner</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">WATCH_NAMESPACE</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">OPERATOR_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">&quot;nginxlb-operator&quot;</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">runner</span></span><br><span class="line">          <span class="attr">emptyDir:</span> &#123;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul></li><li>更新deploy&#x2F;role.yaml与deploy&#x2F;role_binding.yaml<ul><li>role.yaml与role_binding.yaml中的kind: Role更新为kind: ClusterRole</li><li>role_binding.yaml中的kind: RoleBinding更新为kind: ClusterRoleBinding</li><li>添加额外的权限，如route资源类型的权限等<br><strong>role.yaml</strong><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginxlb-operator</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">services</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">endpoints</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">persistentvolumeclaims</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">events</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">configmaps</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">secrets</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">apps</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">deployments</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">daemonsets</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">replicasets</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">statefulsets</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">extensions</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">deployments</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">daemonsets</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">replicasets</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">statefulsets</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">deployments/finalizers</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">route.openshift.io</span></span><br><span class="line">  <span class="attr">attributeRestrictions:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">monitoring.coreos.com</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">servicemonitors</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">apps</span></span><br><span class="line">  <span class="attr">resourceNames:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nginxlb-operator</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">deployments/finalizers</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">fcloudy.com</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br></pre></td></tr></table></figure><strong>role_binding.yaml</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginxlb-operator</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: nginxlb-operator</span><br><span class="line">  namespace: nginxlb-operator</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nginxlb-operator</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>至此完成了NginxLB Operator的制作，制作的结果输出为：</li></ul></li><li>Operator镜像：docker.io&#x2F;xhuaustc&#x2F;nginxlb-operator:v0.0.1</li><li>deploy中的yaml配置文件：<br>operator.yaml<br>role.yaml<br>role_binding.yaml<br>service_account.yaml<br>crds&#x2F;fcloudy_v1alpha1_nginxlb_crd.yaml</li></ol><h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><ol><li>创建nginxlb-operator项目<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc new-project nginxlb-operator --display=NginxLBOperator</span><br></pre></td></tr></table></figure></li><li>部署nginxlb-operator<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc create -f deploy/crds/fcloudy_v1alpha1_nginxlb_crd.yaml</span><br><span class="line">[root@master ~]# oc create -f deploy/</span><br></pre></td></tr></table></figure></li><li>查看nginxlb-operator运行状态<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc get pod</span><br><span class="line">NAME                                READY     STATUS    RESTARTS   AGE</span><br><span class="line">nginxlb-operator-85c77c8cdc-c2gpp   2/2       Running   10         1m</span><br></pre></td></tr></table></figure></li><li>新建NginxLB项目<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc new-project nginxlb --display-name=NginxLB</span><br></pre></td></tr></table></figure></li><li>使用NginxLB创建负载均衡器Nginx应用<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cat &lt;&lt; EOF | oc create -f -</span><br><span class="line">apiVersion: fcloudy.com/v1alpha1</span><br><span class="line">kind: NginxLB</span><br><span class="line">metadata:</span><br><span class="line">  name: example-nginxlb</span><br><span class="line">spec:</span><br><span class="line">  size: 2</span><br><span class="line">  loadbalancers:</span><br><span class="line">  - nodeport: 32289</span><br><span class="line">    port: 8123</span><br><span class="line">    protocol: TCP</span><br><span class="line">    upstreams:</span><br><span class="line">    - 192.168.4.5:123</span><br><span class="line">    - 192.168.5.3:123</span><br><span class="line">  - hostname: xx.nginx.fcloudy.com</span><br><span class="line">    port: 8080</span><br><span class="line">    protocol: HTTP</span><br><span class="line">    upstreams:</span><br><span class="line">    - 192.168.4.5:80</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>查看NginxLB资源状态<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc get all </span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/example-nginxlb-6788db776-42rsz   1/1       Running   0          5s</span><br><span class="line">pod/example-nginxlb-6788db776-8cxm9   1/1       Running   0          5s</span><br><span class="line"></span><br><span class="line">NAME                                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/example-nginxlb-8080-nginx-service   ClusterIP   172.30.167.107   &lt;none&gt;        8080/TCP         2s</span><br><span class="line">service/example-nginxlb-8123-nginx-service   NodePort    172.30.108.138   &lt;none&gt;        8123:32289/TCP   3s</span><br><span class="line"></span><br><span class="line">NAME                              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/example-nginxlb   2         2         2            2           5s</span><br><span class="line"></span><br><span class="line">NAME                                        DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/example-nginxlb-6788db776   2         2         2         5s</span><br><span class="line"></span><br><span class="line">NAME                                                        HOST/PORT              PATH      SERVICES                             PORT        TERMINATION   WILDCARD</span><br><span class="line">route.route.openshift.io/example-nginxlb-8080-nginx-route   xx.nginx.fcloudy.com             example-nginxlb-8080-nginx-service   http-8080                 None</span><br></pre></td></tr></table></figure></li><li>更新NginxLB  example-nginxlb，将size更新为1，只使用一个Nginx应用副本<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc patch NginxLB example-nginxlb -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;size&quot;:1&#125;&#125;&#x27;  --type=merge</span><br><span class="line">nginxlb.mbcloud.com/example-nginxlb patched</span><br><span class="line">[root@master ~]# oc get pod </span><br><span class="line">NAME                              READY     STATUS    RESTARTS   AGE</span><br><span class="line">example-nginxlb-6788db776-8cxm9   1/1       Running   0          2m</span><br></pre></td></tr></table></figure></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>以上实例只是对一种CRD进行控制与管理，其实一个Operator可以同时管理与控制多个CRD。</li><li>Operator能够非常灵活地实现对资源的重新管理及控制，方便对应用生命周期管理。</li><li>使用Operator-sdk，我们可以轻松创建自己的Operator。</li></ul><p>参考文章<br><a href="https://www.openshift.com/learn/topics/operators">https://www.openshift.com/learn/topics/operators</a><br><a href="https://coreos.com/operators/">https://coreos.com/operators/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
            <tag> operator </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-Web-Console自定义界面</title>
      <link href="/openshift/Openshift-Web-Console%E8%87%AA%E5%AE%9A%E4%B9%89%E7%95%8C%E9%9D%A2/"/>
      <url>/openshift/Openshift-Web-Console%E8%87%AA%E5%AE%9A%E4%B9%89%E7%95%8C%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-88a49de2aa0c9c74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Openshift Web Console页面自定义"></p><h2 id="什么是Openshift-WebConsole"><a href="#什么是Openshift-WebConsole" class="headerlink" title="什么是Openshift WebConsole"></a>什么是Openshift WebConsole</h2><ul><li>Openshift WebConsole是Openshift提供的一个web界面端，类似到Kubernetes的Dashboard。很多操作都可以在WebConsole端去处理与显示。</li><li>部署完成Openshift后，会有一个openshift-web-console的project，在这个project中有一个openshift-web-console应用，该应用便是Openshift WebConsole。</li></ul><h2 id="自定义Openshift-WebConsole原理"><a href="#自定义Openshift-WebConsole原理" class="headerlink" title="自定义Openshift WebConsole原理"></a>自定义Openshift WebConsole原理</h2><p>Openshift WebConsole前端使用的是Google的AngularJS技术，并且它在设置的时候提供了扩展的入口。<br>WebConsole在应用启动时会去读取configmap(webconsole-config)中的配置，而webconsole-config的配置中可以设置导入的自定义css与js文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">extensions:</span><br><span class="line">  properties: &#123;&#125;</span><br><span class="line">  scriptURLs:</span><br><span class="line">  - https://www.example.com/webconsole.js</span><br><span class="line">  stylesheetURLs:</span><br><span class="line">  - https://www.example.com/webconsole.css</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>需要注意的是，自定义的css与js文件链接必须是https链接。在webconsole网站运行时，会去Load自定义的js与css，所有的自定义配置都设置在自定义的css与js文件中，达到最终希望达到的效果。</p><h2 id="各类具体操作"><a href="#各类具体操作" class="headerlink" title="各类具体操作"></a>各类具体操作</h2><blockquote><p>修改icon logo</p></blockquote><p>在css文件中添加如下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#header-logo &#123;</span><br><span class="line">  background-image: url(&quot;https://www.example.com/images/logo.png&quot;);</span><br><span class="line">  width: 300px;</span><br><span class="line">  height: 40px;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>项目左侧导航目录汉化<br>Project页面中左侧导航栏的显示是放在window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION这个全局变量中，对条目的汉化只需要在js中重新赋值即可</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(function() &#123;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[0].label=&quot;概览&quot;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[1].label=&quot;应用&quot;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[2].label=&quot;构建&quot;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[3].label=&quot;资源&quot;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[4].label=&quot;存储&quot;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[5].label=&quot;监控&quot;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION[6].label=&quot;商店&quot;</span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure><blockquote><p>项目左侧导航栏添加新目录</p></blockquote><ul><li>添加一个单独的menu菜单<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(function() &#123;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION.push(&#123;</span><br><span class="line">  label: &quot;Dashboard&quot;, </span><br><span class="line">  iconClass: &quot;fa fa-dashboard&quot;, </span><br><span class="line">  href: &quot;/dashboard&quot;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure></li><li>添加一个带有子目录的菜单<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">(function() &#123;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.PROJECT_NAVIGATION.splice(2, 0, &#123; </span><br><span class="line">  label: &quot;Git&quot;,</span><br><span class="line">  iconClass: &quot;fa fa-code&quot;,</span><br><span class="line">  secondaryNavSections: [ </span><br><span class="line">    &#123;</span><br><span class="line">      items: [</span><br><span class="line">        &#123;</span><br><span class="line">          label: &quot;Branches&quot;,</span><br><span class="line">          href: &quot;/git/branches&quot;,</span><br><span class="line">          prefixes: [</span><br><span class="line">            &quot;/git/branches/&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      header: &quot;Collaboration&quot;,</span><br><span class="line">      items: [</span><br><span class="line">        &#123;</span><br><span class="line">          label: &quot;Pull Requests&quot;,</span><br><span class="line">          href: &quot;/git/pull-requests&quot;,</span><br><span class="line">          prefixes: [</span><br><span class="line">            &quot;/git/pull-requests/&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;);</span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure><blockquote><p>顶部右侧导航栏添加新目录</p></blockquote></li></ul><p>右侧顶部栏的APP入口默认是隐藏的，给它赋值后</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(function() &#123;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.APP_LAUNCHER_NAVIGATION = [</span><br><span class="line">&#123;</span><br><span class="line">  title: &quot;Sharing Videos&quot;,</span><br><span class="line">  iconClass: &quot;fa fa-video-camera&quot;,</span><br><span class="line">  href: &quot;https://yun.baidu.com/s/1xIwYILHQebEHZOcW4yvsAw&quot;,</span><br><span class="line">  tooltip: &quot;一键部署Openshift相关视频&quot;</span><br><span class="line">&#125;];</span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure><blockquote><p>Categories中给自定义模板添加图标</p></blockquote><ol><li>css文件中新建icon的样式<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">.icon-nexus3&#123;</span><br><span class="line">  background-image: url(https://www.example.com/nexus3.png);</span><br><span class="line">  width: 80px;</span><br><span class="line">  height: 80px;</span><br><span class="line">  background-size: 100% 100%;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>在对应的模板文件中指定图标样式<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Template</span><br><span class="line">labels:</span><br><span class="line">  template: nexus3-template</span><br><span class="line">metadata:</span><br><span class="line">  name: nexus3</span><br><span class="line">  annotations:</span><br><span class="line">    description: Sonatype Nexus 3 template</span><br><span class="line">    tags: ci,nexus,jenkins</span><br><span class="line">    iconClass: icon-nexus3</span><br><span class="line">objects:</span><br><span class="line">  ......</span><br></pre></td></tr></table></figure><blockquote><p>设置特色应用导航页</p></blockquote></li></ol><p>什么是特色应用导航页，看图展示</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-a8879554be20e3dd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="特色应用导航页"><br>我们可以把常用的一些特殊应用入口放在Catalog页面，方便管理与使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">(function() &#123;</span><br><span class="line">window.OPENSHIFT_CONSTANTS.SAAS_OFFERINGS = [&#123;</span><br><span class="line">  title: &quot;Dashboard&quot;,                         // The text label</span><br><span class="line">  icon: &quot;fa fa-dashboard&quot;,                    // The icon you want to appear</span><br><span class="line">  url: &quot;http://example.com/dashboard&quot;,        // Where to go when this item is clicked</span><br><span class="line">  description: &quot;Open application dashboard.&quot;  // Short description</span><br><span class="line">&#125;, &#123;</span><br><span class="line">  title: &quot;System Status&quot;,</span><br><span class="line">  icon: &quot;fa fa-heartbeat&quot;,</span><br><span class="line">  url: &quot;http://example.com/status&quot;,</span><br><span class="line">  description: &quot;View system alerts and outages.&quot;</span><br><span class="line">&#125;, &#123;</span><br><span class="line">  title: &quot;Manage Account&quot;,</span><br><span class="line">  icon: &quot;pficon pficon-user&quot;,</span><br><span class="line">  url: &quot;http://example.com/account&quot;,</span><br><span class="line">  description: &quot;Update email address or password.&quot;</span><br><span class="line">&#125;];</span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure><blockquote><p>修改登录页面</p></blockquote><ol><li>获取登录模板<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm create-login-template &gt; /etc/origin/master/login.html</span><br></pre></td></tr></table></figure></li><li>保留默认登录模板form结构的前提下，修改&#x2F;etc&#x2F;origin&#x2F;master&#x2F;login.html页面</li><li>将login.html的路径添加到&#x2F;etc&#x2F;origin&#x2F;master&#x2F;master-config.yaml文件中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">oauthConfig:</span><br><span class="line">  ...</span><br><span class="line">  templates:</span><br><span class="line">    login: /etc/origin/master/login.html</span><br></pre></td></tr></table></figure></li><li>重启master api<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master-restart api</span><br></pre></td></tr></table></figure></li><li>浏览器访问页面</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-6c5b3243b9a63fa8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="登陆界面"></p><h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p><a href="https://docs.okd.io/latest/install_config/web_console_customization.html">Openshit官方文档：自定义web console</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift-gitlab-redmine-testlink集成</title>
      <link href="/openshift/Openshift-gitlab-redmine-testlink%E9%9B%86%E6%88%90/"/>
      <url>/openshift/Openshift-gitlab-redmine-testlink%E9%9B%86%E6%88%90/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-516381a7fd4fbe9f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="openshift testlink redmine"></p><p>Gitlab:使用Git作为代码管理工具，并在此基础上搭建起来的web服务。<br>Redmine:项目管理和bug跟踪工具。<br>TestLink:基于web的<a href="https://baike.baidu.com/item/%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B">测试用例</a>管理系统，主要功能是测试用例的创建、管理和执行，并且还提供了一些简单的统计功能。<br>Redmine作为项目问题及bug收集汇总的地方，gitlab及testlink通过调用redmine的api进行对问题进行更新。那第它们之间是怎么配置的呢？下面就一起来配置下。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-afd2cb693ddfc008.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p><h2 id="Redmine部署与插件安装"><a href="#Redmine部署与插件安装" class="headerlink" title="Redmine部署与插件安装"></a>Redmine部署与插件安装</h2><p>相关配置在github项目：<a href="https://github.com/xhuaustc/redmine-openshift">https://github.com/xhuaustc/redmine-openshift</a></p><ul><li><p>Dockerfile中更新了docker-entrypoint.sh文件，更新了数据库的编码（mysql: utf8mb4 )</p><p><strong>创建镜像</strong></p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t harbor.local.com/public/redmine .</span><br><span class="line">$ docker push harbor.local.com/public/redmine</span><br></pre></td></tr></table></figure><ul><li>在openshift上创建新的项目</li></ul><p><strong>创建工程</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc new-project redmine</span><br></pre></td></tr></table></figure><p>允许redmine项目中的pod使用root用户运行</p><p><strong>创建工程</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm policy add-scc-to-user anyuid -z  default -n redmine</span><br></pre></td></tr></table></figure><p>在新建的redmine工程中基于模板文件redmine-mysql-ephemeral.yaml在openshift上创建应用。<br>注意：</p><ul><li>需要更新redmine的Deployment中的template.spec.containers[0].image为刚刚自己创建的镜像harbor.local.com&#x2F;public&#x2F;redmine</li><li>创建应用时添加环境变量REDMINE_PLUGINS_MIGRATE为1</li><li>添加环境变量GITLAB_USERNAME及GITLAB_PASSWORD。这两个参数用于redmine的gitlab_callback插件拉取代码。</li></ul><p>将git中的plugins目录文件导入到名字为redmine-file-data的PVC中</p><h2 id="Testlink安装"><a href="#Testlink安装" class="headerlink" title="Testlink安装"></a>Testlink安装</h2><p>基础镜像php56：<a href="https://github.com/sclorg/s2i-php-container/tree/master/5.6">https://github.com/sclorg/s2i-php-container/tree/master/5.6</a></p><p>Testlink代码：<a href="https://github.com/xhuaustc/testlink-code.git">https://github.com/xhuaustc/testlink-code.git</a></p><p>Mysql数据库：创建Data Stores(Mysql)</p><h2 id="Gitlab（9-3-11）安装"><a href="#Gitlab（9-3-11）安装" class="headerlink" title="Gitlab（9.3.11）安装"></a>Gitlab（9.3.11）安装</h2><p>当前gitlab使用9.3.11版本，主要是因为9.4以上的gitlab版本与redmine集成有兼容问题。</p><p>对应的模板文件路径：<a href="https://gitlab.com/gitlab-org/omnibus-gitlab/blob/9.3.11+ce.0/docker/openshift-template.json">https://gitlab.com/gitlab-org/omnibus-gitlab/blob/9.3.11+ce.0/docker/openshift-template.json</a></p><p>安装部署如<a href="https://www.jianshu.com/p/bb43aa93a8d5">Openshift上安装Gitlab</a></p><p>至此完成了gitlab+redmine+testlink的安装，接下来就是通过配置，使它们之间能够完成问题的管理。</p><h2 id="Gitlab-redmine-Testlink集成"><a href="#Gitlab-redmine-Testlink集成" class="headerlink" title="Gitlab + redmine + Testlink集成"></a>Gitlab + redmine + Testlink集成</h2><p>一、准备环境创建项目：gitlab项目test， redmine项目test， testlink项目test<br>二、设置redmine。<br>1、管理 -&gt; 插件 -&gt; Redmine GitLab Hook plugin配置</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-90bb4cfbba87c77d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p><p>2、开启api设置<br>管理 -&gt; 配置 -&gt; API</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-41ca8f6c32366fc2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p><p>3、版本库设置<br>管理 -&gt; 配置 -&gt; 版本库</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f74db8b0322805ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p><p>记录版本库管理网页服务API密钥：例如l1D2z8DJXiL4lFNSl2O4</p><p>三、gitlab配置</p><p>1、在test代码库中，Settings -&gt; Integrations</p><p>添加webhook：<a href="http://redmine-redmine..apps.local/gitlab_hook?project_id=test&key=l1D2z8DJXiL4lFNSl2O4">http://redmine-redmine.apps.local/gitlab_hook?project_id&#x3D;test&amp;key&#x3D;l1D2z8DJXiL4lFNSl2O4</a></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-07e457a461d5b889.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Gitlab Hook"></p><p>2、开启Redmine:Settings -&gt; Integrations -&gt; Redmine</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-5c80a0895fc1f3a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Gitlab testlink"><br>四、配置testlink</p><p>1、查看redmine API访问key<br>点击我的账号，右边栏显示key</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f3a47bc90dae28a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"><br>2、配置testlink的代码追踪<br>设置testlink的语言为简体中文<br>点击项目主页中的：缺陷跟踪系统管理<br>添加一个redmine的追踪</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-2ada9b9eb778dde1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="testlink添加redmine追踪"></p><p>其中apikey就是redmine下用户对应的Key.</p><h2 id="通过以上集成配置后的世界是怎样的呢？"><a href="#通过以上集成配置后的世界是怎样的呢？" class="headerlink" title="通过以上集成配置后的世界是怎样的呢？"></a>通过以上集成配置后的世界是怎样的呢？</h2><ul><li>创建测试case</li></ul><ol><li>redmine上创建bug issue</li><li>在testlink上同步redmine的issue id</li><li>testlink将自动同步问题内容</li></ol><ul><li>开发人员提交代码</li></ul><ol><li>开发人员使用约定格式的commit msg提交代码</li><li>状态会自动同步redmine，并反映到testlink</li><li>测试人员根据testlink上的信息，对相关问题进行测试验证</li></ol><ul><li>testlink上添加评论</li></ul><ol><li>测试人员testlink上添加评论</li><li>redmine对应的issue下会自动同步评论</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift3-9上部署Prometheus+Grafana实现集群的监控与告警</title>
      <link href="/openshift/Openshift3-9%E4%B8%8A%E9%83%A8%E7%BD%B2Prometheus+Grafana%E5%AE%9E%E7%8E%B0%E9%9B%86%E7%BE%A4%E7%9A%84%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%91%8A%E8%AD%A6/"/>
      <url>/openshift/Openshift3-9%E4%B8%8A%E9%83%A8%E7%BD%B2Prometheus+Grafana%E5%AE%9E%E7%8E%B0%E9%9B%86%E7%BE%A4%E7%9A%84%E7%9B%91%E6%8E%A7%E4%B8%8E%E5%91%8A%E8%AD%A6/</url>
      
        <content type="html"><![CDATA[<h2 id="Openshift从3-9版本开始官方支持Prometheus和Grafana"><a href="#Openshift从3-9版本开始官方支持Prometheus和Grafana" class="headerlink" title="Openshift从3.9版本开始官方支持Prometheus和Grafana"></a>Openshift从3.9版本开始官方支持Prometheus和Grafana</h2><blockquote><p>从官方部署脚本 <strong><a href="https://github.com/openshift/openshift-ansible">openshift-ansible</a></strong> 中的目录playbooks下的列表 中可以看到相关部署脚本<br><strong><a href="https://github.com/openshift/openshift-ansible/tree/release-3.9/playbooks/openshift-prometheus">openshift-prometheus</a></strong><br><strong><a href="https://github.com/openshift/openshift-ansible/tree/release-3.9/playbooks/openshift-grafana">openshift-grafana</a></strong></p></blockquote><p>既然官方支持，部署安装就十分简单了。</p><h2 id="部署安装Prometheus"><a href="#部署安装Prometheus" class="headerlink" title="部署安装Prometheus"></a>部署安装Prometheus</h2><blockquote><p>&#x2F;etc&#x2F;ansible&#x2F;hosts添加配置</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line">openshift_hosted_prometheus_deploy=true</span><br></pre></td></tr></table></figure><blockquote><p>执行安装</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook  playbooks/openshift-prometheus/config.yml</span><br></pre></td></tr></table></figure><blockquote><p>打开宿主机的9100端口（kubernetes-nodes-exporter）</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m shell -a &#x27;iptables -A OS_FIREWALL_ALLOW -p tcp -m state --state NEW -m tcp --dport 9100 -j ACCEPT; service iptables save&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>完成</p></blockquote><p>查看下资源状态</p><blockquote><p>prometheus会默认部署在新创建的project中：openshift-metrics<br>1个statefulset资源：prometheus<br>1个DaemonSet资源：prometheus-node-exporter<br>4个Service资源：alertmanager 、alerts、prometheus、prometheus-node-exporter<br>3个route资源：alertmanager、alerts、prometheus<br>3个ServiceAccount：prometheus、prometheus-node-exporter、prometheus-reader </p></blockquote><h2 id="部署安装Grafana"><a href="#部署安装Grafana" class="headerlink" title="部署安装Grafana"></a>部署安装Grafana</h2><p><strong><code>注意，3.9-release分支下的grafana安装脚本有问题，请使用最新master分支下的脚本进行安装</code></strong></p><blockquote><p>检查节点的label</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc get node -l node-role.kubernetes.io/infra=true</span><br></pre></td></tr></table></figure><p>如果没有node-role.kubernetes.io&#x2F;infra&#x3D;true标签的Node节点的话，需要给Node配置标签</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc label node nodename1 node-role.kubernetes.io/infra=true</span><br></pre></td></tr></table></figure><blockquote><p>&#x2F;etc&#x2F;ansible&#x2F;hosts添加配置</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line">grafana_namespace=openshift-grafana</span><br><span class="line">grafana_user=grafana</span><br><span class="line">grafana_password=grafana</span><br><span class="line">grafana_datasource_name=&quot;default&quot;</span><br><span class="line">grafana_prometheus_namespace=&quot;openshift-metrics&quot;</span><br><span class="line">grafana_prometheus_sa=prometheus</span><br><span class="line">grafana_node_exporter=false</span><br><span class="line">grafana_graph_granularity=&quot;2m&quot;</span><br></pre></td></tr></table></figure><blockquote><p>执行安装</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-grafana/config.yml</span><br></pre></td></tr></table></figure><blockquote><p>完成</p></blockquote><p>查看下资源状态</p><blockquote><p>1个deployment：grafana<br>1个service: grafana<br>1个route: grafana<br>1个serviceaccount: grafana<br>1个configmap:grafana-config </p></blockquote><p>最终效果图<br><img src="https://upload-images.jianshu.io/upload_images/5793257-47d86fb6b96ea48e.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="展示图1"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-a529a2c71988ad60.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="展示图2"></p><p>补充：<br>grafana admin密码丢失，如何重置？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grafana-cli admin reset-admin-password --homepath &quot;/usr/share/grafana&quot; admin</span><br></pre></td></tr></table></figure><p>prometheus中配置内存使用率(node_memory_requests_total是我自己写的exporter监控数据)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(node_memory_requests_total) by(node_name) / sum(label_replace(machine_memory_bytes, &#x27;node_name&#x27;, &quot;$1&quot;, &quot;instance&quot;, &quot;(.*)&quot; )) by (node_name)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift3-9部署手册</title>
      <link href="/openshift/Openshift3-9%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/"/>
      <url>/openshift/Openshift3-9%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<p><em>说明：本文主要介绍通过Ansible来部署Openshift 3.9</em></p><h2 id="一、准备"><a href="#一、准备" class="headerlink" title="一、准备"></a>一、准备</h2><h4 id="系统准备"><a href="#系统准备" class="headerlink" title="系统准备"></a>系统准备</h4><table><thead><tr><th>节点类型</th><th>说明</th></tr></thead><tbody><tr><td>Masters</td><td><br>物理主机或者虚拟机<br> 系统：Fedora 21, CentOS 7.3, 7.4或者7.5<br> 最少4vCPU<br>最少16GB内存<br>&#x2F;var&#x2F;最少40GB空间 <br>&#x2F;usr&#x2F;local&#x2F;bin最少1GB空间<br>容器临时目录最少1GB空间<br> &amp;nbsp;</td></tr><tr><td>Nodes</td><td><br>物理主机或者虚拟机<br> 系统：Fedora 21, CentOS 7.3, 7.4或者7.5<br> NetworkManager版本1.0以上<br>最少1vCPU<br>最少8GB内存<br>&#x2F;var&#x2F;最少15GB空间 <br>&#x2F;usr&#x2F;local&#x2F;bin最少1GB空间<br>容器临时目录最少1GB空间<br> &amp;nbsp;</td></tr><tr><td>额外的etcd节点</td><td><br>最少20GB用来存储etcd数据 <br>&amp;nbsp;</td></tr></tbody></table><p><em>注：在安装时可以通过ansible_inventory的配置忽略以上系统要求</em><br>扩展：对于生产部署时，Master的配置要求计算规则如下：每1000个pods需要额外的1核CPU和1.5GB内存。因此如果要满足支持2000个pods的话，Master节点需要在最低配置2核CPU和16GB内存的基础上再加2核CPU和3GB内存，共4核CPU 19GB内存。</p><h4 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h4><ol><li><p>关闭防火墙及selinux</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/&quot; /etc/selinux/config</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure></li><li><p>更改yum源 base74 、 openshift-3.9 、 epel 、 updates 和 extras。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> #/etc/yum.repos.d/all.repo</span><br><span class="line">[base]</span><br><span class="line">name=CentOS-$releasever - Base</span><br><span class="line">baseurl=http://mirrors.ustc.edu.cn/centos/$releasever/os/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">[updates]</span><br><span class="line">name=CentOS-$releasever - Updates</span><br><span class="line">baseurl=http://mirrors.ustc.edu.cn/centos/$releasever/updates/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">[extras]</span><br><span class="line">name=CentOS-$releasever - Extras</span><br><span class="line">baseurl=http://mirrors.ustc.edu.cn/centos/$releasever/extras/$basearch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">[openshift-3.9]</span><br><span class="line">name=Openshift 3.9</span><br><span class="line">baseurl=http://mirrors.ustc.edu.cn/centos/$releasever/paas/$basearch/openshift-origin39/</span><br><span class="line">gpgcheck=0</span><br><span class="line">[epel]</span><br><span class="line">name=Centos EPEL</span><br><span class="line">baseurl=http://mirrors.ustc.edu.cn/epel/7/$basearch/</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure><p> 清除缓存</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum makecache</span><br></pre></td></tr></table></figure></li></ol><h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><ol><li><p>安装需要的软件包</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install vim git ansible wget java-1.8.0-openjdk httpd-tools python-passlib docker -y</span><br></pre></td></tr></table></figure></li><li><p>下载openshift ansible部署脚本</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/openshift/openshift-ansible.git -b release-3.9</span><br></pre></td></tr></table></figure></li><li><p>禁用ansible脚本中的指定repo</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/enabled=1/enabled=0/g&#x27; ./roles/openshift_repos/templates/CentOS-OpenShift-Origin.repo.j2</span><br></pre></td></tr></table></figure></li><li><p>设置hostsname<br> a. 在 &#x2F;etc&#x2F;hosts 添加ip映射</p><pre><code># /etc/hosts192.168.2.3 openshift</code></pre><p> b. 更新本机hostname</p><pre><code> hostnamectl set-hostname --static openshift</code></pre></li><li><p>设置本地ssh无密钥登录</p><pre><code> ssh-keygen -t rsa ssh-copy-id -i ~/.ssh/id_rsa.pub root@openshift #或将id_rsa.pub内容添加到~/.ssh/authorized_keys中</code></pre></li><li><p>配置ansible hosts</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">etcd</span><br><span class="line">nfs</span><br><span class="line"></span><br><span class="line">[OSEv3:vars]</span><br><span class="line">ansible_ssh_user=root</span><br><span class="line">openshift_deployment_type=origin</span><br><span class="line">deployment_type=origin</span><br><span class="line">openshift_release=v3.9</span><br><span class="line">  </span><br><span class="line">#如果使用自己的镜像的话/etc/sysconfig/docker中会添加ADD_REGISTRY=&#x27;--add-registry harbor.apps.com&#x27;</span><br><span class="line">#oreg_url=harbor.apps.com/openshift/origin-$&#123;component&#125;:$&#123;version&#125;</span><br><span class="line">#system_images_registry=harbor.apps.com</span><br><span class="line">#openshift_examples_modify_imagestreams=true</span><br><span class="line">#openshift_docker_additional_registries=harbor.apps.com</span><br><span class="line">#openshift_service_catalog_image_prefix=harbor.apps.com/openshift/origin-</span><br><span class="line">#openshift_metrics_image_prefix=harbor.apps.com/openshift/origin-</span><br><span class="line">#openshift_logging_image_prefix=harbor.apps.com/openshift/origin-</span><br><span class="line">#ansible_service_broker_image_prefix=harbor.apps.com/openshift/origin-</span><br><span class="line">#ansible_service_broker_etcd_image_prefix=harbor.apps.com/openshift/origin-</span><br><span class="line">#openshift_metrics_image_version=v3.9</span><br><span class="line">   </span><br><span class="line">openshift_enable_service_catalog=false</span><br><span class="line">template_service_broker_install=false</span><br><span class="line">ansible_service_broker_install=false</span><br><span class="line"></span><br><span class="line">openshift_master_identity_providers=[&#123;&#x27;name&#x27;: &#x27;htpasswd_auth&#x27;, &#x27;login&#x27;:&#x27;true&#x27;,&#x27;challenge&#x27;: &#x27;true&#x27;, &#x27;kind&#x27;: &#x27;HTPasswdPasswordIdentityProvider&#x27;&#125;]</span><br><span class="line">openshift_master_htpasswd_file=/etc/origin/master/htpasswd</span><br><span class="line">openshift_enable_unsupported_configurations=True</span><br><span class="line">openshift_docker_options=&quot;-l warn --ipv6=false --insecure-registry=0.0.0.0/0 --registry-mirror=https://docker.mirrors.ustc.edu.cn --log-opt max-size=1M --log-opt max-file=3&quot;</span><br><span class="line">openshift_disable_check=memory_availability,disk_availability,package_availability,package_update,docker_image_availability,docker_storage_driver,docker_storage</span><br><span class="line">openshift_master_default_subdomain=apps.openshift</span><br><span class="line"></span><br><span class="line">openshift_metrics_install_metrics=true</span><br><span class="line">openshift_hosted_metrics_public_url=https://hawkular-metrics.apps.openshift/hawkular/metrics</span><br><span class="line"></span><br><span class="line">openshift_logging_install_logging=true</span><br><span class="line">openshift_hosted_etcd_storage_kind=nfs</span><br><span class="line">openshift_hosted_etcd_storage_nfs_options=&quot;*(rw,root_squash,sync,no_wdelay)&quot;</span><br><span class="line">openshift_hosted_etcd_storage_nfs_directory=/nfs-data </span><br><span class="line">openshift_hosted_etcd_storage_volume_name=etcd-vol2 </span><br><span class="line">openshift_hosted_etcd_storage_access_modes=[&quot;ReadWriteOnce&quot;]</span><br><span class="line">openshift_hosted_etcd_storage_volume_size=1G</span><br><span class="line">openshift_hosted_etcd_storage_labels=&#123;&#x27;storage&#x27;: &#x27;etcd&#x27;&#125;</span><br><span class="line"></span><br><span class="line">ansible_service_broker_image_prefix=registry.access.redhat.com/openshift3/ose-</span><br><span class="line">ansible_service_broker_registry_url=registry.access.redhat.com</span><br><span class="line">ansible_service_broker_registry_user=&lt;user_name&gt;</span><br><span class="line">ansible_service_broker_registry_password=&lt;password&gt;</span><br><span class="line">ansible_service_broker_registry_organization=&lt;organization&gt;</span><br><span class="line"></span><br><span class="line">[masters]</span><br><span class="line">openshift</span><br><span class="line">[etcd]</span><br><span class="line">openshift</span><br><span class="line">[nfs]</span><br><span class="line">openshift</span><br><span class="line">[nodes]</span><br><span class="line">openshift openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;infra&#x27;, &#x27;zone&#x27;:&#x27;default&#x27;&#125;&quot; openshift_schedulable=true</span><br></pre></td></tr></table></figure></li><li><p>如果要修改为自己的镜像仓库的话，还需要更改几个yaml文件</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># roles/openshift_web_console/defaults/main.yml（去掉docker.io/）</span><br><span class="line">openshift_web_console_image_dict:</span><br><span class="line">    origin:</span><br><span class="line">        prefix: &quot;openshift/origin-&quot;</span><br><span class="line">        version: &quot;&#123;&#123; openshift_image_tag &#125;&#125;&quot;</span><br><span class="line">        image_name: &quot;web-console&quot;</span><br></pre></td></tr></table></figure></li><li><p>执行安装脚本</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/prerequisites.yml</span><br><span class="line">ansible-playbook playbooks/deploy_cluster.yml</span><br></pre></td></tr></table></figure></li><li><p>创建管理员账号</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -b /etc/origin/master/htpasswd admin admin</span><br><span class="line">oc adm policy add-cluster-role-to-user cluster-admin admin</span><br></pre></td></tr></table></figure></li></ol><h2 id="三、展示"><a href="#三、展示" class="headerlink" title="三、展示"></a>三、展示</h2><p><img src="https://upload-images.jianshu.io/upload_images/5793257-8f4ad7cf1d2c6187.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/800" alt="首页展示"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-944a3554b28d7ce8.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/800" alt="项目主页展示"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-4ee2dbe47aefd23f.JPG?imageMogr2/auto-orient/strip%7CimageView2/2/w/800" alt="镜像仓库页展示"></p><p>参考文章<br> <a href="https://docs.openshift.com/container-platform/3.9/install_config/install/advanced_install.html">Openshift 3.9官方高级安装手册</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift上使用shell-operator创建自己的operator</title>
      <link href="/openshift/Openshift%E4%B8%8A%E4%BD%BF%E7%94%A8shell-operator%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84operator/"/>
      <url>/openshift/Openshift%E4%B8%8A%E4%BD%BF%E7%94%A8shell-operator%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84operator/</url>
      
        <content type="html"><![CDATA[<p>shell operator是由Falnt公司开发并开源的。Flant公司是一家致力于提供解决所有基础设施问题的解决方案的公司。他们自称是提供DevOps-as-a-Service的服务。</p><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><ul><li>一个简单的任务：监听项目创建与删除事件，并发出告警。</li><li>一种简单的解决方法：定时脚本cron，每隔一段时间（如1min)获取对Openshift集群的所有项目，并将它与上次获取的结果值进行比较，得到新创建的项目及删除的项目<br>该方法的缺点：<ul><li>不及时</li><li>性能差，很多时候并没有操作项目，但仍然需要不断执行脚本</li><li>如果1min内即创建了新项目，又把这个项目删除了，则无法监测到</li></ul></li><li>另一种解决方法：事件驱动，即订阅来自Kubernetes对象的事件，如果有对Project操作就触发告警。<br>很明显这种方法解决了定时任务的所有问题。</li><li>该很么做呢？会不会非常复杂。不会。使用shell-operator项目就可以非常简单地实现。shell-operator项目地址：<a href="https://github.com/flant/shell-operator">https://github.com/flant/shell-operator</a></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/d0fe4d67a8079a423049f59d014669cfca81428fe57d7d439109da88b15c4278.png" alt="Shell Operator">  </p><h2 id="实现部骤"><a href="#实现部骤" class="headerlink" title="实现部骤"></a>实现部骤</h2><ol><li>创建shell-operator项目<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project shell-operator</span></span><br></pre></td></tr></table></figure></li><li>为该项目创建serviceAccount <code>monitor-namespaces-acc</code>，将给它授予获取全局namespace的权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: monitor-namespaces-acc</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: monitor-namespaces</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources: [&quot;namespaces&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">oc adm policy add-cluster-role-to-user monitor-namespaces -z monitor-namespaces-acc</span></span></span><br></pre></td></tr></table></figure></li><li>创建一个configmap，其中data中的内容为hook脚本<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  shell-hook.sh: |-</span><br><span class="line">    #!/usr/bin/env bash</span><br><span class="line"></span><br><span class="line">    if [[ $1 == &quot;--config&quot; ]] ; then</span><br><span class="line">      cat &lt;&lt;EOF</span><br><span class="line">      &#123;&quot;onKubernetesEvent&quot;:[</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;:&quot;OnCreateDeleteNamespace&quot;,</span><br><span class="line">          &quot;kind&quot;: &quot;namespace&quot;,</span><br><span class="line">          &quot;event&quot;:[&quot;add&quot;, &quot;delete&quot;]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;:&quot;OnModifiedNamespace&quot;,</span><br><span class="line">          &quot;kind&quot;: &quot;namespace&quot;,</span><br><span class="line">          &quot;event&quot;:[&quot;update&quot;],</span><br><span class="line">          &quot;jqFilter&quot;: &quot;.metadata.labels&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    EOF</span><br><span class="line">    else</span><br><span class="line">      bindingName=$(jq -r &#x27;.[0].binding&#x27; $BINDING_CONTEXT_PATH)</span><br><span class="line">      resourceEvent=$(jq -r &#x27;.[0].resourceEvent&#x27; $BINDING_CONTEXT_PATH)</span><br><span class="line">      resourceName=$(jq -r &#x27;.[0].resourceName&#x27; $BINDING_CONTEXT_PATH)</span><br><span class="line">      if [[ $bindingName == &quot;OnModifiedNamespace&quot; ]] ; then</span><br><span class="line">        echo &quot;Namespace $resourceName labels were modified&quot;</span><br><span class="line">      else</span><br><span class="line">        if [[ $resourceEvent == &quot;add&quot; ]] ; then</span><br><span class="line">          echo &quot;Namespace $resourceName was created&quot;</span><br><span class="line">        else</span><br><span class="line">          echo &quot;Namespace $resourceName was deleted&quot;</span><br><span class="line">        fi</span><br><span class="line">      fi</span><br><span class="line">    fi</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: hooks</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>运行shell-operator应用<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: apps.openshift.io/v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    run: shell-operator</span><br><span class="line">  name: shell-operator</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    run: shell-operator</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: shell-operator</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccount: monitor-namespaces-acc</span><br><span class="line">      containers:</span><br><span class="line">        - image: &#x27;flant/shell-operator:latest-alpine3.9&#x27;</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: shell-operator</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /hooks</span><br><span class="line">              name: hooks-no934</span><br><span class="line">      volumes:</span><br><span class="line">        - configMap:</span><br><span class="line">            defaultMode: 511</span><br><span class="line">            name: hooks</span><br><span class="line">          name: hooks-no934</span><br><span class="line">  triggers:</span><br><span class="line">    - type: ConfigChange</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><code>说明</code>：</li></ol><ul><li>应用启动使用<code>monitor-namespaces-acc</code>serviceAccount</li><li>将configmap内容挂载到deployment应用的&#x2F;hooks目录中</li><li>挂载文件需要给可执行权限<code>defaultMode: 511</code></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8f597a775b089d5a235c7cfffb06bd6480472b5f48088ad3adc5c1e811317da3.png" alt="Shell Operator">  </p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><ol><li>创建一个project&#x2F;删除该project<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project  operator-test</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc delete project operator-test</span></span><br></pre></td></tr></table></figure></li><li>查看shell-operator的日志</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ebccd14bd490a25abf898d6f1f1022ff76cf567b9107bf9c48df955ea4938bf1.png" alt="operator日志">  </p><h2 id="额外补充"><a href="#额外补充" class="headerlink" title="额外补充"></a>额外补充</h2><p>Shell Operator支持绑定三种hook触发类型</p><ul><li>onStartup<br>onStartup类型只有一个参数：”onStartup”设置绑定顺序<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;onStartup&quot;:10&#125;</span><br></pre></td></tr></table></figure></li><li>schedule<br>schedule绑定用于周期性运行，支持秒级粒度定义计划<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;schedule&quot;: [</span><br><span class="line">   &#123;&quot;name&quot;:&quot;every 10 min&quot;,</span><br><span class="line">    &quot;crontab&quot;:&quot;0 */10 * * * *&quot;,</span><br><span class="line">    &quot;allowFailure&quot;:true</span><br><span class="line">   &#125;,</span><br><span class="line">   &#123;&quot;name&quot;:&quot;Every Monday at 8:05&quot;,</span><br><span class="line">    &quot;crontab&quot;:&quot;0 5 8 * * 1&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>onKubernetesEvent<br>监听Kubernetes事件促发<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;onKubernetesEvent&quot;: [</span><br><span class="line">  &#123;&quot;name&quot;:&quot;Execute on changes of namespace labels&quot;,</span><br><span class="line">   &quot;kind&quot;: &quot;namespace&quot;,</span><br><span class="line">   &quot;event&quot;:[&quot;update&quot;],</span><br><span class="line">   &quot;jqFilter&quot;:&quot;.metadata.labels&quot;</span><br><span class="line">  &#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="将镜像带的kubectl命令行替换成oc命令行"><a href="#将镜像带的kubectl命令行替换成oc命令行" class="headerlink" title="将镜像带的kubectl命令行替换成oc命令行"></a>将镜像带的kubectl命令行替换成oc命令行</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ cat Dockerfile-oc</span><br><span class="line">FROM ubuntu:18.04</span><br><span class="line">ADD ./oc /bin/oc</span><br><span class="line">ADD ./shell-operator /</span><br><span class="line">RUN apt-get update &amp;&amp; \</span><br><span class="line">    apt-get install -y ca-certificates wget jq &amp;&amp; \</span><br><span class="line">    rm -rf /var/lib/apt/lists &amp;&amp; \</span><br><span class="line">    chmod +x /bin/oc &amp;&amp; \</span><br><span class="line">    mkdir /hooks</span><br><span class="line">WORKDIR /</span><br><span class="line">ENV SHELL_OPERATOR_WORKING_DIR /hooks</span><br><span class="line">ENTRYPOINT [&quot;/shell-operator&quot;]</span><br><span class="line">CMD [&quot;start&quot;]</span><br><span class="line">$ docker build -f Dockerfile-oc -t docker.io/xhuaustc/shell-operator-oc:latest-3.11 .</span><br></pre></td></tr></table></figure><p>其中<code>oc</code>从镜像openshift&#x2F;origin-cli中导出，而<code>shell-operator</code>从镜像flant&#x2F;shell-operator中导出<br>最终镜像保存在：<a href="docker.io/xhuaustc/shell-operator-oc:latest-3.11">docker.io&#x2F;xhuaustc&#x2F;shell-operator-oc:latest-3.11</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>以上是使用configmap的方式向operator-shell注入自定义的钩子代码，非常灵活，最原始的operator-shell就能够满足各种不种的需求，十分方便。</li><li>shell-operator项目为我们自定义operator提供了一种非常便利的方式。同时它不仅仅支持bash，也可以支持python，需要在镜像中安装python包。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> Dockerfile</span></span><br><span class="line">FROM flant/shell-operator:latest</span><br><span class="line">RUN apk --no-cache add python</span><br></pre></td></tr></table></figure>钩子代码的环境使用python<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env python</span></span><br></pre></td></tr></table></figure></li><li>有了这个监控后，就可以非常方便地对Openshift&#x2F;Kubernetes的资源进行控制，想像空间可以很大。<ol><li>例子：有些项目的应用创建有先后关系，就可以方便地使用shell operator进行编排</li><li>例子：不同项目 <code>dev/sit/uat</code> 对不同的用户组 <code>dev/test/ops</code> 会有不同的权限 <code>view/admin/image-puller</code> ，就可以使用项目名格式给不同用户组授予不同的权限</li></ol></li><li>与CRD结合，真正构建自己的operator，想像空间就变得更大了</li><li>shell-operator项目地址：<a href="https://github.com/flant/shell-operator">https://github.com/flant/shell-operator</a></li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="http://dockone.io/article/8984">Shell-operator：用于简化Kubernetes operator的创建</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift上搭建Jenkins-Gitlab-Sonarqube自动构建</title>
      <link href="/openshift/Openshift%E4%B8%8A%E6%90%AD%E5%BB%BAJenkins-Gitlab-Sonarqube%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"/>
      <url>/openshift/Openshift%E4%B8%8A%E6%90%AD%E5%BB%BAJenkins-Gitlab-Sonarqube%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<p>#Jenkins系统配置详情</p><h1 id="安装插件列表："><a href="#安装插件列表：" class="headerlink" title="安装插件列表："></a>安装插件列表：</h1><p>Git Parameter Plug-In</p><p>Gitlab Hook Plugin</p><p>SonarQube Scanner for Jenkins</p><p>JaCoCo plugin</p><p>Maven Integration plugin</p><h1 id="Jenkins配置详情："><a href="#Jenkins配置详情：" class="headerlink" title="Jenkins配置详情："></a>Jenkins配置详情：</h1><h3 id="Jenkins-gt-系统管理-gt-系统配置"><a href="#Jenkins-gt-系统管理-gt-系统配置" class="headerlink" title="Jenkins-&gt;系统管理-&gt;系统配置"></a>Jenkins-&gt;系统管理-&gt;系统配置</h3><ul><li>SonarQube servers配置</li></ul><p>Name:  SonarqubeServer</p><p>Server URL: <a href="http://sonarqube-sonarqube.apps.test.openshift.com/">http://sonarqube-sonarqube.apps.test.openshift.com</a></p><p>Server version: 5.3 or higher</p><p>Server authentication token: $TOKEN(从SonarQube Server上创建）</p><h3 id="Jenkins-gt-系统管理-gt-Global-Tool-Configuration"><a href="#Jenkins-gt-系统管理-gt-Global-Tool-Configuration" class="headerlink" title="Jenkins-&gt;系统管理-&gt;Global Tool Configuration"></a><strong>Jenkins-&gt;系统管理-&gt;Global Tool Configuration</strong></h3><ul><li>Maven Configuration</li></ul><p>Default settings provider: Use default maven settings</p><p>Default global settings provider: Global settings file on filesystem</p><p>File Path: &#x2F;var&#x2F;lib&#x2F;jenkins&#x2F;maven&#x2F;settings.xml</p><ul><li>JDK配置</li></ul><p>JDK别名：jdk8</p><p>JAVA_HOME:  &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0</p><ul><li>SonarQube Scanner配置</li></ul><p>#Openshift+Gitlab+Jenkins实现自动构建（区分分支）<br>主要知识点：</p><p>1、jenkins的插件gitlab Hook plugin</p><p>2、gitlab的WebHook配置</p><p>1、在Jenkins上安装Gitlab Hook Plugin插件。</p><p>插件所在网址：<a href="https://github.com/elvanja/jenkins-gitlab-hook-plugin">https://github.com/elvanja/jenkins-gitlab-hook-plugin</a><br>2、gitlab上配置WebHook</p><p>在gitlab project中进入Webhooks配置，在URL栏填如下格式的链接即可：”<a href="http://your_server:port/gitlab/build_now/$job_name">http://your_server:port/gitlab/build_now/$job_name</a>“</p><h1 id="在sonarqube上创建新的project进行代码扫描"><a href="#在sonarqube上创建新的project进行代码扫描" class="headerlink" title="在sonarqube上创建新的project进行代码扫描"></a>在sonarqube上创建新的project进行代码扫描</h1><p>在jenkins的job的构建中添加sona scanner的配置。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-48ea7f08e3a00d6b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"><br>执行jenkins的job后就可以在sonar网站上看到代码的扫描结果。如下图：<br><img src="https://upload-images.jianshu.io/upload_images/5793257-607948104f20ca42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片.png"></p><p>SonarQube Scanner Name:  SonarScanner</p><p>自动安装： True</p><p>Install from maven Central:  SonarQube Scanner 3.0.3.778</p><ul><li>Maven配置</li></ul><p>Maven Name:  MbcloudMaven</p><p>自动安装： True</p><p>Install From Apache:  3.5.2</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift上搭建NFS-StorageClass，别再说存储使用不方便</title>
      <link href="/openshift/Openshift%E4%B8%8A%E6%90%AD%E5%BB%BANFS-StorageClass%EF%BC%8C%E5%88%AB%E5%86%8D%E8%AF%B4%E5%AD%98%E5%82%A8%E4%BD%BF%E7%94%A8%E4%B8%8D%E6%96%B9%E4%BE%BF/"/>
      <url>/openshift/Openshift%E4%B8%8A%E6%90%AD%E5%BB%BANFS-StorageClass%EF%BC%8C%E5%88%AB%E5%86%8D%E8%AF%B4%E5%AD%98%E5%82%A8%E4%BD%BF%E7%94%A8%E4%B8%8D%E6%96%B9%E4%BE%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="动态存储是什么"><a href="#动态存储是什么" class="headerlink" title="动态存储是什么"></a>动态存储是什么</h2><p>Openshift持久化存储（PV）有两种，一种是静态的，另一种是动态。</p><ul><li>静态存储：需要管理员手动创建PV，供PVC挂载调用</li><li>动态存储：通过一个称作 Storage Class的对象由存储系统根据PVC的要求自动创建。</li></ul><h2 id="StorageClass是什么"><a href="#StorageClass是什么" class="headerlink" title="StorageClass是什么"></a>StorageClass是什么</h2><ul><li>StorageClass是Openshfit中的一个资源对象，它主要用于描述请求的存储，并提供按需传递动态预配置存储的参数的方法。 </li><li>StorageClass对象还可以用作控制不同级别的存储和对存储的访问的管理机制。</li><li>有了StorageClass后，管理员无需手动创建PV。Openshift的使用者在创建PVC时只需要指定StorageClass,会自动按照对应的StorageClass配置，调用对应的Dynamic provisioning来创建需要的存储</li></ul><h2 id="没有StorageClass时代，如何使用NFS"><a href="#没有StorageClass时代，如何使用NFS" class="headerlink" title="没有StorageClass时代，如何使用NFS"></a>没有StorageClass时代，如何使用NFS</h2><p>每次需要手动创建PV，一句话：麻烦。</p><h2 id="StorageClass时代来了"><a href="#StorageClass时代来了" class="headerlink" title="StorageClass时代来了"></a>StorageClass时代来了</h2><p>一次配置，永久自动，无需手动创建PV，一句话：方便。</p><h2 id="NFS-Provisioner原理"><a href="#NFS-Provisioner原理" class="headerlink" title="NFS Provisioner原理"></a>NFS Provisioner原理</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/eedb4b5d912f074be0ca3455ddb9e3d1c80f2567c8e963e094dadb920c6de54e.png" alt="NFS Provisioner原理">  </p><ol><li>新建PVC时，指定为默认驱动，或者指定storageclass为nfs storage</li><li>运行nfs client provisioner的pod会根据配置，在共享的NFS目录下创建新的文件夹，同时创建新的PV指向该文件夹</li><li>将新建的PVC与2中新建的PV关联，完成PVC的创建</li><li>该PVC就可以被调用的Pod挂载了。</li></ol><h2 id="NFS-StorageClass具体配置步骤"><a href="#NFS-StorageClass具体配置步骤" class="headerlink" title="NFS StorageClass具体配置步骤"></a>NFS StorageClass具体配置步骤</h2><ol><li>准备NFS服务<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install nfs -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /nfsdata/share</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chown</span> nfsnobody:nfsnobody /nfsdata/share</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> 700 /nfsdata/share</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#开放nfs访问的端口</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iptables -A INPUT -p tcp --dport 111 -j ACCEPT</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iptables -A INPUT -p udp --dport 111 -j ACCEPT</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iptables -A INPUT -p tcp --dport 2049 -j ACCEPT</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">iptables -A INPUT -p udp --dport 2049 -j ACCEPT</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 配置NFS</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;/nfsdata/share *(rw,async,no_root_squash)&quot;</span> &gt;&gt; /etc/exports</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">exportfs -a <span class="comment">#加载共享目录配置</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">showmount -e <span class="comment">#查看当前可用的共享目录</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 启动NFS</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart nfs</span></span><br></pre></td></tr></table></figure></li><li>确定Provisioner安装的project（默认为default）<br>如果使用default project的话<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc project default</span></span><br></pre></td></tr></table></figure>如果希望将它部署在自定义的project中，则新建project<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project nfs-provisoner</span></span><br></pre></td></tr></table></figure></li><li>如果安装的project不是default的话，需要更改配置rbac.yaml,再设置权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> rbac.yaml</span></span><br><span class="line">kind: ServiceAccount</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: run-nfs-client-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">    # replace with namespace where provisioner is deployed</span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">NAMESPACE=`oc project -q`</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i<span class="string">&#x27;&#x27;</span> <span class="string">&quot;s/namespace:.*/namespace: <span class="variable">$NAMESPACE</span>/g&quot;</span> ./deploy/rbac.yaml</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f deploy/rbac.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm policy add-scc-to-user hostmount-anyuid system:serviceaccount:<span class="variable">$NAMESPACE</span>:nfs-client-provisioner</span></span><br></pre></td></tr></table></figure></li><li>更新deploy&#x2F;deployment.yaml，设置NFS Server的配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">kind: Deployment</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          image: docker.io/xhuaustc/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: &lt;YOUR NFS SERVER HOSTNAME&gt;</span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /nfsdata/share</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: &lt;YOUR NFS SERVER HOSTNAME&gt;</span><br><span class="line">            path: /nfsdata/share</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>创建storageclass<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">  annotations:</span><br><span class="line">    storageclass.kubernetes.io/is-default-class: &quot;true&quot; # 设置该storageclass为PVC创建时默认使用的存储机制</span><br><span class="line">provisioner: fuseim.pri/ifs # 匹配deployment中的环境变量&#x27;PROVISIONER_NAME&#x27;</span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: &quot;true&quot; # &quot;false&quot; 删除PVC时不会保留数据，&quot;true&quot;将保留PVC数据</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ol><h2 id="NFS-StorageClass使用"><a href="#NFS-StorageClass使用" class="headerlink" title="NFS StorageClass使用"></a>NFS StorageClass使用</h2><ol><li>创建PVC<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: managed-nfs-storage</span><br><span class="line">    volume.beta.kubernetes.io/storage-provisioner: fuseim.pri/ifs</span><br><span class="line">  name: testpvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>如果storageclass中设置了<code>storageclass.kubernetes.io/is-default-class: &quot;true&quot; </code>，可以更简单地创建PVC<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>查看PVC<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pv</span></span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                            STORAGECLASS          REASON    AGE</span><br><span class="line">pvc-fb952566-4bed-11e9-9007-525400ad3b43   1Gi        RWO            Delete           Bound      test/hello-pvc                 managed-nfs-storage             5m</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pvc</span></span><br><span class="line">hello-pvc   Bound     pvc-fb952566-4bed-11e9-9007-525400ad3b43   1Gi        RWO            managed-nfs-storage   4m</span><br></pre></td></tr></table></figure></li><li>如果storageclass中设置了<code>archiveOnDelete: &quot;true&quot; </code>，在删除PVC时，会将数据目录归档<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> /nfsdata/share</span></span><br><span class="line">test-hello-pvc-pvc-fb952566-4bed-11e9-9007-525400ad3b43</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc delete pvc hello-pvc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> /nfsdata/share</span></span><br><span class="line">archived-test-hello-pvc-pvc-fb952566-4bed-11e9-9007-525400ad3b43</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#数据目录被改名为以archived开头的文件夹，同时删除了对应的PV和PVC</span></span></span><br></pre></td></tr></table></figure></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>有了NFS StorageClass后，创建存储就非常简单方便了。<br>Openshift NFS动态存储代码 <a href="https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client">https://github.com/kubernetes-incubator/external-storage/tree/master/nfs-client</a></p><p>引用自：<a href="https://mp.weixin.qq.com/s/HgDCDgYjkX5en7ORNeG0yA">https://mp.weixin.qq.com/s/HgDCDgYjkX5en7ORNeG0yA</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift上部署OpenLDAP实战：为账号一统</title>
      <link href="/openshift/Openshift%E4%B8%8A%E9%83%A8%E7%BD%B2OpenLDAP%E5%AE%9E%E6%88%98%EF%BC%9A%E4%B8%BA%E8%B4%A6%E5%8F%B7%E4%B8%80%E7%BB%9F/"/>
      <url>/openshift/Openshift%E4%B8%8A%E9%83%A8%E7%BD%B2OpenLDAP%E5%AE%9E%E6%88%98%EF%BC%9A%E4%B8%BA%E8%B4%A6%E5%8F%B7%E4%B8%80%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e60fb0abd0e0caf4d3aa7e8af7aed3351833e817820f6e8d418b08ae170223ac.png" alt="统一账号">  </p><p>Openshift上部署OpenLDAP也并不仅仅只是为了部署，更重要的是要用它来为各种应用统一账号管理。比如GitLab，Gogs, Nexus, Sonarqube等等，同时结合之前的Openshift使用OpenLDAP做账号管理。理想的世界是，一套Openshift，各种应用，它们的用户认证都在一套OpenLDAP上，同时这套OpenLDAP也是非常方便地部署在Openshift上。</p><p>为账号一统的第一步，就是我们需要部署OpenLDAP，这也是该篇主题。以下是之前分享的几篇与OpenLDAP有关的文章。</p><p><a href="https://www.jianshu.com/p/d7fbeb12d138">CentOS上搭建双主高可用OpenLDAP Server</a><br><a href="https://www.jianshu.com/p/5e1aba303779">Openshift使用OpenLDAP作为统一用户认证</a><br><a href="https://www.jianshu.com/p/b5df1eb1f4de">CentOS上OpenLDAP Server使用cn&#x3D;config方式配置</a></p><p>之前分享的与Openldap相关的几篇文章中，它的部署都是在虚拟机中进行的。那么在Openshift上能否完成部署呢，如果可以的话，那么那些复杂的部署我们都可以将它封装到镜像中去，岂不是更方便？那就一起来操作吧。</p><h2 id="应用要求点"><a href="#应用要求点" class="headerlink" title="应用要求点"></a>应用要求点</h2><ol><li>方便自定义域及管理员用户名与密码<br> 通过<code>环境变量</code>及<code>secret</code>进行自定义配置</li><li>对pod添加健康检查，如果发现问题，主动重启恢复<br>监听389端口</li><li>数据持久化，pod重启后，该pod自动恢复数据<br>持久化目录为：数据目录 <code>/var/lib/ldap</code>, 配置目录  <code>/etc/openldap</code></li></ol><p>以上是在Openshift运行Openldap的最基本的要求了，如果更苛刻点，需要添加Openldap的监控、Openldap的日志审计、多pod高可用方案等。</p><h2 id="制作镜像"><a href="#制作镜像" class="headerlink" title="制作镜像"></a>制作镜像</h2><p>如果不希望自己构建，可以直接使用构建好的镜像：<a href="docker.io/xhuaustc/openldap-2441-centos7:latest">docker.io&#x2F;xhuaustc&#x2F;openldap-2441-centos7:latest</a><br>步骤如下：</p><ol><li>基础镜像centos:centos7</li><li>安装openldap相关应用：openldap, openldap-clients, openldap-servers</li><li>部署：根据环境变量更新openldap的配置文件，并初始化基础结构，最后启动openldap<br> 运行：启动openldap</li></ol><p><code>说明</code>,部署与运行的区别在于该应用是否是第一次启动。如果是第一次启动的话，相关配置还未更新。在第一次配置更新后，在持久化文件夹中创建一个新文件，来标记已完成配置更新。以后的每次启动都会检查该文件，如果存在，则不作初始化操作，而直接运行openldap</p><p>对应的Dockerfile参考：<a href="https://github.com/openshift/openldap/blob/master/2.4.41/Dockerfile">https://github.com/openshift/openldap/blob/master/2.4.41/Dockerfile</a></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:centos7</span><br><span class="line"></span><br><span class="line"># OpenLDAP server image for OpenShift Origin</span><br><span class="line">#</span><br><span class="line"># Volumes:</span><br><span class="line"># * /var/lib/ldap/data - Datastore for OpenLDAP</span><br><span class="line"># * /etc/openldap/     - Config directory for slapd</span><br><span class="line"># Environment:</span><br><span class="line"># * $OPENLDAP_ADMIN_PASSWORD         - OpenLDAP administrator password</span><br><span class="line"># * $OPENLDAP_DEBUG_LEVEL (Optional) - OpenLDAP debugging level, defaults to 256</span><br><span class="line"></span><br><span class="line">MAINTAINER Steve Kuznetsov &lt;skuznets@redhat.com&gt;</span><br><span class="line"></span><br><span class="line">LABEL io.k8s.description=&quot;OpenLDAP is an open source implementation of the Lightweight Directory Access Protocol.&quot; \</span><br><span class="line">      io.k8s.display-name=&quot;OpenLDAP 2.4.41&quot; \</span><br><span class="line">      io.openshift.expose-services=&quot;389:ldap,636:ldaps&quot; \</span><br><span class="line">      io.openshift.tags=&quot;directory,ldap,openldap,openldap2441&quot; \</span><br><span class="line">      io.openshift.non-scalable=&quot;true&quot;</span><br><span class="line"></span><br><span class="line"># Add defaults for config</span><br><span class="line">COPY ./contrib/config /opt/openshift/config</span><br><span class="line">COPY ./contrib/lib /opt/openshift/lib</span><br><span class="line"># Add startup scripts</span><br><span class="line">COPY run-*.sh /usr/local/bin/</span><br><span class="line">COPY contrib/*.ldif /usr/local/etc/openldap/</span><br><span class="line">COPY contrib/*.schema /usr/local/etc/openldap/</span><br><span class="line">COPY contrib/DB_CONFIG /usr/local/etc/openldap/</span><br><span class="line"></span><br><span class="line"># Install OpenLDAP Server, give it permissionst to bind to low ports</span><br><span class="line">RUN yum install -y openldap openldap-servers openldap-clients &amp;&amp; \</span><br><span class="line">    yum clean all -y &amp;&amp; \</span><br><span class="line">    setcap &#x27;cap_net_bind_service=+ep&#x27; /usr/sbin/slapd &amp;&amp; \</span><br><span class="line">    mkdir -p /var/lib/ldap &amp;&amp; \</span><br><span class="line">    chmod a+rwx -R /var/lib/ldap &amp;&amp; \</span><br><span class="line">    mkdir -p /etc/openldap &amp;&amp; \</span><br><span class="line">    chmod a+rwx -R /etc/openldap &amp;&amp; \</span><br><span class="line">    mkdir -p /var/run/openldap &amp;&amp; \</span><br><span class="line">    chmod a+rwx -R /var/run/openldap &amp;&amp; \</span><br><span class="line">    chmod -R a+rw /opt/openshift </span><br><span class="line"></span><br><span class="line"># Set OpenLDAP data and config directories in a data volume</span><br><span class="line">VOLUME [&quot;/var/lib/ldap&quot;, &quot;/etc/openldap&quot;]</span><br><span class="line"></span><br><span class="line"># Expose default ports for ldap and ldaps</span><br><span class="line">EXPOSE 389 636</span><br><span class="line"></span><br><span class="line">CMD [&quot;/usr/local/bin/run-openldap.sh&quot;]</span><br></pre></td></tr></table></figure><p>对应的部署及运行脚本参考：<br><a href="https://github.com/openshift/openldap/blob/master/2.4.41/run-openldap.sh">https://github.com/openshift/openldap/blob/master/2.4.41/run-openldap.sh</a><br>但是有所修改，如果用root用户启动时，会先初始化openldap配置。原来的脚本如果用root用户启动时，会报错，而用非root用户启动，则自定义配置无法生效。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Reduce maximum number of number of open file descriptors to 1024</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">otherwise slapd consumes two orders of magnitude more of RAM</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">see https://github.com/docker/docker/issues/8231</span></span><br><span class="line">ulimit -n 1024</span><br><span class="line"></span><br><span class="line">OPENLDAP_ROOT_PASSWORD=$&#123;OPENLDAP_ROOT_PASSWORD:-admin&#125;</span><br><span class="line">OPENLDAP_ROOT_DN_PREFIX=$&#123;OPENLDAP_ROOT_DN_PREFIX:-&#x27;cn=Manager&#x27;&#125;</span><br><span class="line">OPENLDAP_ROOT_DN_SUFFIX=$&#123;OPENLDAP_ROOT_DN_SUFFIX:-&#x27;dc=example,dc=com&#x27;&#125;</span><br><span class="line">OPENLDAP_DEBUG_LEVEL=$&#123;OPENLDAP_DEBUG_LEVEL:-256&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Only run <span class="keyword">if</span> no config has happened fully before</span></span><br><span class="line">if [ ! -f /etc/openldap/CONFIGURED ]; then</span><br><span class="line"></span><br><span class="line">    user=`id | grep -Po &quot;(?&lt;=uid=)\d+&quot;`</span><br><span class="line">    if (( user == 0 ))</span><br><span class="line">    then</span><br><span class="line">        # We are root, we can use user input!</span><br><span class="line">        # Bring in default databse config</span><br><span class="line">        cp /usr/local/etc/openldap/DB_CONFIG /var/lib/ldap/DB_CONFIG</span><br><span class="line">        </span><br><span class="line">if [ -f /opt/openshift/config/slapd.d/cn\=config/olcDatabase\=\&#123;0\&#125;config.ldif ]</span><br><span class="line">        then</span><br><span class="line">            # Use provided default config, get rid of current data</span><br><span class="line">            rm -rf /var/lib/ldap/*</span><br><span class="line">            rm -rf /etc/openldap/*</span><br><span class="line">            # Bring in associated default database files</span><br><span class="line">            mv -f /opt/openshift/lib/* /var/lib/ldap</span><br><span class="line">            mv -f /opt/openshift/config/* /etc/openldap</span><br><span class="line">        else</span><br><span class="line">            # Something has gone wrong with our image build</span><br><span class="line">            echo &quot;FAILURE: Default configuration files from /contrib/ are not present in the image at /opt/openshift.&quot;</span><br><span class="line">            exit 1</span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">        # start the daemon in another process and make config changes</span><br><span class="line">        slapd -h &quot;ldap:/// ldaps:/// ldapi:///&quot; -d $OPENLDAP_DEBUG_LEVEL &amp;</span><br><span class="line">        for ((i=30; i&gt;0; i--))</span><br><span class="line">        do</span><br><span class="line">            ping_result=`ldapsearch 2&gt;&amp;1 | grep &quot;Can.t contact LDAP server&quot;`</span><br><span class="line">            if [ -z &quot;$ping_result&quot; ]</span><br><span class="line">            then</span><br><span class="line">                break</span><br><span class="line">            fi</span><br><span class="line">            sleep 1</span><br><span class="line">        done</span><br><span class="line">        if [ $i -eq 0 ]</span><br><span class="line">        then</span><br><span class="line">            echo &quot;slapd did not start correctly&quot;</span><br><span class="line">            exit 1</span><br><span class="line">        fi</span><br><span class="line"></span><br><span class="line">        # Generate hash of password</span><br><span class="line">        OPENLDAP_ROOT_PASSWORD_HASH=$(slappasswd -s &quot;$&#123;OPENLDAP_ROOT_PASSWORD&#125;&quot;)</span><br><span class="line"></span><br><span class="line">        # Update configuration with root password, root DN, and root suffix</span><br><span class="line">        sed -e &quot;s OPENLDAP_ROOT_PASSWORD $&#123;OPENLDAP_ROOT_PASSWORD_HASH&#125; g&quot; \</span><br><span class="line">            -e &quot;s OPENLDAP_ROOT_DN $&#123;OPENLDAP_ROOT_DN_PREFIX&#125; g&quot; \</span><br><span class="line">            -e &quot;s OPENLDAP_SUFFIX $&#123;OPENLDAP_ROOT_DN_SUFFIX&#125; g&quot; /usr/local/etc/openldap/first_config.ldif |</span><br><span class="line">            ldapmodify -Y EXTERNAL -H ldapi:/// -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line"></span><br><span class="line">        # add test schema</span><br><span class="line">        ldapadd -Y EXTERNAL -H ldapi:/// -f /usr/local/etc/openldap/testPerson.ldif -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line"></span><br><span class="line">        # add useful schemas</span><br><span class="line">        ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line">        ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line"></span><br><span class="line">        # load memberOf and refint modules</span><br><span class="line">        ldapadd -Y EXTERNAL -H ldapi:/// -f /usr/local/etc/openldap/load_modules.ldif -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line"></span><br><span class="line">        # configure memberOf module</span><br><span class="line">        ldapadd -Y EXTERNAL -H ldapi:/// -f /usr/local/etc/openldap/configure_memberof.ldif -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line"></span><br><span class="line">        # configure refint module</span><br><span class="line">        ldapadd -Y EXTERNAL -H ldapi:/// -f /usr/local/etc/openldap/configure_refint.ldif -d $OPENLDAP_DEBUG_LEVEL</span><br><span class="line"></span><br><span class="line">        # extract dc name from root DN suffix</span><br><span class="line">        dc_name=$(echo &quot;$&#123;OPENLDAP_ROOT_DN_SUFFIX&#125;&quot; | grep -Po &quot;(?&lt;=^dc\=)[\w\d]+&quot;)</span><br><span class="line">        # create base organization object</span><br><span class="line">        sed -e &quot;s OPENLDAP_SUFFIX $&#123;OPENLDAP_ROOT_DN_SUFFIX&#125; g&quot; \</span><br><span class="line">            -e &quot;s FIRST_PART $&#123;dc_name&#125; g&quot; \</span><br><span class="line">            usr/local/etc/openldap/base.ldif |</span><br><span class="line">            ldapadd -x -D &quot;$OPENLDAP_ROOT_DN_PREFIX,$OPENLDAP_ROOT_DN_SUFFIX&quot; -w &quot;$OPENLDAP_ROOT_PASSWORD&quot;</span><br><span class="line"></span><br><span class="line">        # stop the daemon</span><br><span class="line">        pid=$(ps -A | grep slapd | awk &#x27;&#123;print $1&#125;&#x27;)</span><br><span class="line">        kill -2 $pid || echo $?</span><br><span class="line"></span><br><span class="line">        # ensure the daemon stopped</span><br><span class="line">        for ((i=30; i&gt;0; i--))</span><br><span class="line">        do</span><br><span class="line">            exists=$(ps -A | grep $pid)</span><br><span class="line">            if [ -z &quot;$&#123;exists&#125;&quot; ]</span><br><span class="line">            then</span><br><span class="line">                break</span><br><span class="line">            fi</span><br><span class="line">            sleep 1</span><br><span class="line">        done</span><br><span class="line">        if [ $i -eq 0 ]</span><br><span class="line">        then</span><br><span class="line">            echo &quot;slapd did not stop correctly&quot;</span><br><span class="line">            exit 1</span><br><span class="line">        fi</span><br><span class="line">    else</span><br><span class="line">        # We are not root, we need to populate from the default bind-mount source</span><br><span class="line">        if [ -f /opt/openshift/config/slapd.d/cn\=config/olcDatabase\=\&#123;0\&#125;config.ldif ]</span><br><span class="line">        then</span><br><span class="line">            # Use provided default config, get rid of current data</span><br><span class="line">            rm -rf /var/lib/ldap/*</span><br><span class="line">            rm -rf /etc/openldap/*</span><br><span class="line">            # Bring in associated default database files</span><br><span class="line">            mv -f /opt/openshift/lib/* /var/lib/ldap</span><br><span class="line">            mv -f /opt/openshift/config/* /etc/openldap</span><br><span class="line">        else</span><br><span class="line">            # Something has gone wrong with our image build</span><br><span class="line">            echo &quot;FAILURE: Default configuration files from /contrib/ are not present in the image at /opt/openshift.&quot;</span><br><span class="line">            exit 1</span><br><span class="line">        fi</span><br><span class="line">    fi</span><br><span class="line"></span><br><span class="line">    # Test configuration files, log checksum errors. Errors may be tolerated and repaired by slapd so don&#x27;t exit</span><br><span class="line">    LOG=`slaptest 2&gt;&amp;1`</span><br><span class="line">    CHECKSUM_ERR=$(echo &quot;$&#123;LOG&#125;&quot; | grep -Po &quot;(?&lt;=ldif_read_file: checksum error on \&quot;).+(?=\&quot;)&quot;)</span><br><span class="line">    for err in $CHECKSUM_ERR</span><br><span class="line">    do</span><br><span class="line">        echo &quot;The file $&#123;err&#125; has a checksum error. Ensure that this file is not edited manually, or re-calculate the checksum.&quot;</span><br><span class="line">    done</span><br><span class="line"></span><br><span class="line">    rm -rf /opt/openshift/*</span><br><span class="line"></span><br><span class="line">    touch /etc/openldap/CONFIGURED</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Start the slapd service</span></span><br><span class="line">exec slapd -h &quot;ldap:/// ldaps:///&quot; -d $OPENLDAP_DEBUG_LEVEL</span><br></pre></td></tr></table></figure><p><code>说明</code>，本来我是准备按照之前部署经验自己写一个镜像构建，但是写到一半的时候，发现整个逻辑与openshift官方提供的差不多，所以就直接用官方的了。<br>从脚本中可以看到管理员(一般为cn&#x3D;Manager)密码数据库管理员(一般为cn&#x3D;config)密码是一样的，都是通过环境变量<code>OPENLDAP_ROOT_PASSWORD</code>配置。</p><table><thead><tr><th>变量名</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>OPENLDAP_ROOT_PASSWORD</td><td>OpenLDAP olcRootPW 密码</td><td>admin</td></tr><tr><td>OPENLDAP_ROOT_DN_SUFFIX</td><td>OpenLDAP olcSuffix 域前缀</td><td>dc&#x3D;example,dc&#x3D;com</td></tr><tr><td>OPENLDAP_ROOT_DN_PREFIX</td><td>OpenLDAP olcRootDN 前缀</td><td>cn&#x3D;Manager</td></tr><tr><td>OPENLDAP_DEBUG_LEVEL</td><td>OpenLDAP服务日志级别</td><td>256</td></tr></tbody></table><p>使用openshift&#x2F;openldap进行构建镜像操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/openshift/openldap.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> openldap</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> SKIP_SQUASH=1 &amp;&amp; make build    <span class="comment">#构建出的镜像名为：openshift/openldap-2441-centos7:latest</span></span></span><br></pre></td></tr></table></figure><h2 id="部署Openldap"><a href="#部署Openldap" class="headerlink" title="部署Openldap"></a>部署Openldap</h2><p>两种方法实现部署：<br>第一种. 使用openshift的client工具部署</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#创建项目</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project openldap --display-name=OpenLDAP</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#创建单独的serviceaccount为方便以root用户启动pod</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create serviceaccount openldap</span>  </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> <span class="comment">#为openldap serviceaccount赋予以root启动pod的权限</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm policy add-scc-to-user anyuid -z openldap</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#创建secret，设置openldap的域与密码</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create secret generic openldap --from-literal=OPENLDAP_ROOT_PASSWORD=admin --from-literal=OPENLDAP_ROOT_DN_SUFFIX=dc=fcloudy,dc=com</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 部署应用（默认会是以default serviceaccount运行）</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-app  --docker-image=xhuaustc/openldap-2441-centos7 --name=openldap</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#为应用设置环境变量，即为openldap的域与密码</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">env</span> --from=secret/openldap dc/openldap</span> </span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#为应用设置以openldap serviceaccount启动</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc apply -f -</span></span></span><br><span class="line">apiVersion: apps.openshift.io/v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  name: openldap</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccount: openldap</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>当然以上配置没有添加健康检查，以及持久化是使用的emptyDir。这个可以后序自己补充。</p><p>第二种：使用yaml配置文件部署，主要是DeploymentConfig的配置。添加了健康检查</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: apps.openshift.io/v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: openldap</span><br><span class="line">  name: openldap</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    app: openldap</span><br><span class="line">    deploymentconfig: openldap</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: openldap</span><br><span class="line">        deploymentconfig: openldap</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - env:</span><br><span class="line">            - name: OPENLDAP_ROOT_DN_SUFFIX</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  key: OPENLDAP_ROOT_DN_SUFFIX</span><br><span class="line">                  name: openldap</span><br><span class="line">            - name: OPENLDAP_ROOT_PASSWORD</span><br><span class="line">              valueFrom:</span><br><span class="line">                secretKeyRef:</span><br><span class="line">                  key: OPENLDAP_ROOT_PASSWORD</span><br><span class="line">                  name: openldap</span><br><span class="line">          image: &#x27;xhuaustc/openldap-2441-centos7:latest&#x27;</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          livenessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            initialDelaySeconds: 3</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            tcpSocket:</span><br><span class="line">              port: 389</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          name: openldap</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 389</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - containerPort: 636</span><br><span class="line">              protocol: TCP</span><br><span class="line">          readinessProbe:</span><br><span class="line">            failureThreshold: 3</span><br><span class="line">            initialDelaySeconds: 3</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            successThreshold: 1</span><br><span class="line">            tcpSocket:</span><br><span class="line">              port: 389</span><br><span class="line">            timeoutSeconds: 1</span><br><span class="line">          name: openldap</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 389</span><br><span class="line">              protocol: TCP</span><br><span class="line">            - containerPort: 636</span><br><span class="line">              protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /etc/openldap</span><br><span class="line">              name: openldap-volume-1</span><br><span class="line">            - mountPath: /var/lib/ldap</span><br><span class="line">              name: openldap-volume-2</span><br><span class="line">      volumes:</span><br><span class="line">        - emptyDir: &#123;&#125;</span><br><span class="line">          name: openldap-volume-1</span><br><span class="line">        - emptyDir: &#123;&#125;</span><br><span class="line">          name: openldap-volume-2</span><br><span class="line">  triggers:</span><br><span class="line">    - type: ConfigChange</span><br></pre></td></tr></table></figure><h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><p>按照以上部署的配置，管理员账号为：<code>cn=Manager,dc=fcloudy,dc=com</code>，密码为：<code>admin</code><br>使用LDAPBrowser连接</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f788b01780648fea64c18ecb22897973f3f1acd2a25bd7d5c48d721b99ff03b1.png" alt="连接设置">  </p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/a041f0464f2969b4f077bf44d3c5c595bf9314151f0a97df9f16960042c8f6b8.png" alt="连接成功">  </p><h2 id="最后一步，做成模板"><a href="#最后一步，做成模板" class="headerlink" title="最后一步，做成模板"></a>最后一步，做成模板</h2><p>将资源导出为模板文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">export</span> dc,svc,secret  --as-template=openldap &gt; openldap-template.yaml</span></span><br></pre></td></tr></table></figure><p>在此基础上手动编辑，最后得到可用的模板文件</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: template.openshift.io/v1</span><br><span class="line">kind: Template</span><br><span class="line">message: |-</span><br><span class="line">  OpenLDAP服务将会根据指定的参数创建</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    description: |-</span><br><span class="line">      OpenLDAP服务将会根据指定的参数创建</span><br><span class="line">  name: openldap</span><br><span class="line">objects:</span><br><span class="line">- apiVersion: apps.openshift.io/v1</span><br><span class="line">  kind: DeploymentConfig</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      app: openldap</span><br><span class="line">    name: openldap</span><br><span class="line">  spec:</span><br><span class="line">    replicas: 1</span><br><span class="line">    selector:</span><br><span class="line">      app: openldap</span><br><span class="line">      deploymentconfig: openldap</span><br><span class="line">    strategy:</span><br><span class="line">      type: Rolling</span><br><span class="line">    template:</span><br><span class="line">      metadata:</span><br><span class="line">        labels:</span><br><span class="line">          app: openldap</span><br><span class="line">          deploymentconfig: openldap</span><br><span class="line">      spec:</span><br><span class="line">        containers:</span><br><span class="line">        - env:</span><br><span class="line">          - name: OPENLDAP_ROOT_DN_SUFFIX</span><br><span class="line">            valueFrom:</span><br><span class="line">              secretKeyRef:</span><br><span class="line">                key: OPENLDAP_ROOT_DN_SUFFIX</span><br><span class="line">                name: openldap</span><br><span class="line">          - name: OPENLDAP_ROOT_PASSWORD</span><br><span class="line">            valueFrom:</span><br><span class="line">              secretKeyRef:</span><br><span class="line">                key: OPENLDAP_ROOT_PASSWORD</span><br><span class="line">                name: openldap</span><br><span class="line">          - name: OPENLDAP_ROOT_DN_PREFIX</span><br><span class="line">            valueFrom:</span><br><span class="line">              secretKeyRef:</span><br><span class="line">                key: OPENLDAP_ROOT_DN_PREFIX</span><br><span class="line">                name: openldap</span><br><span class="line">          - name: OPENLDAP_DEBUG_LEVEL</span><br><span class="line">            valueFrom:</span><br><span class="line">              secretKeyRef:</span><br><span class="line">                key: OPENLDAP_DEBUG_LEVEL</span><br><span class="line">                name: openldap</span><br><span class="line">          image: xhuaustc/openldap-2441-centos7:latest</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          name: openldap</span><br><span class="line">          ports:</span><br><span class="line">          - containerPort: 389</span><br><span class="line">            protocol: TCP</span><br><span class="line">          - containerPort: 636</span><br><span class="line">            protocol: TCP</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - mountPath: /etc/openldap</span><br><span class="line">            name: openldap-volume-1</span><br><span class="line">          - mountPath: /var/lib/ldap</span><br><span class="line">            name: openldap-volume-2</span><br><span class="line">        restartPolicy: Always</span><br><span class="line">        serviceAccount: openldap</span><br><span class="line">        serviceAccountName: openldap</span><br><span class="line">        volumes:</span><br><span class="line">        - emptyDir: &#123;&#125;</span><br><span class="line">          name: openldap-volume-1</span><br><span class="line">        - emptyDir: &#123;&#125;</span><br><span class="line">          name: openldap-volume-2</span><br><span class="line">    triggers:</span><br><span class="line">    - type: ConfigChange</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Service</span><br><span class="line">  metadata:</span><br><span class="line">    labels:</span><br><span class="line">      app: openldap</span><br><span class="line">    name: openldap</span><br><span class="line">  spec:</span><br><span class="line">    ports:</span><br><span class="line">    - name: 389-tcp</span><br><span class="line">      port: 389</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 389</span><br><span class="line">    - name: 636-tcp</span><br><span class="line">      port: 636</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 636</span><br><span class="line">    selector:</span><br><span class="line">      app: openldap</span><br><span class="line">      deploymentconfig: openldap</span><br><span class="line">    sessionAffinity: None</span><br><span class="line">    type: ClusterIP</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  stringData:</span><br><span class="line">    OPENLDAP_ROOT_DN_SUFFIX: $&#123;OPENLDAP_ROOT_DN_SUFFIX&#125;</span><br><span class="line">    OPENLDAP_ROOT_DN_PREFIX: $&#123;OPENLDAP_ROOT_DN_PREFIX&#125;</span><br><span class="line">    OPENLDAP_ROOT_PASSWORD: $&#123;OPENLDAP_ROOT_PASSWORD&#125;</span><br><span class="line">    OPENLDAP_DEBUG_LEVEL: $&#123;OPENLDAP_DEBUG_LEVEL&#125;</span><br><span class="line">  kind: Secret</span><br><span class="line">  metadata:</span><br><span class="line">    name: openldap</span><br><span class="line">  type: Opaque</span><br><span class="line">parameters:</span><br><span class="line">- description: Openldap Root DN Suffix</span><br><span class="line">  displayName: Openldap Root DN Suffix</span><br><span class="line">  name: OPENLDAP_ROOT_DN_SUFFIX</span><br><span class="line">  value: dc=example,dc=com</span><br><span class="line">- description: Openldap Root DN Manager Prefix</span><br><span class="line">  displayName: Openldap Root DN Manager Prefix</span><br><span class="line">  name: OPENLDAP_ROOT_DN_PREFIX</span><br><span class="line">  value: cn=Manager</span><br><span class="line">- description: Openldap Root Password</span><br><span class="line">  displayName: Openldap Root Password</span><br><span class="line">  name: OPENLDAP_ROOT_PASSWORD</span><br><span class="line">  from: &#x27;[a-zA-Z0-9]&#123;16&#125;&#x27;</span><br><span class="line">  generate: expression</span><br><span class="line">- description: Openldap Debug Level</span><br><span class="line">  displayName: Openldap Debug Level</span><br><span class="line">  name: OPENLDAP_DEBUG_LEVEL</span><br><span class="line">  value: &quot;256&quot;</span><br></pre></td></tr></table></figure><p>在Openshift上将模板导入，完成后，创建Openldap就非常简单了，看截图。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/25f96239cacb2e690a82afbc70df0f74508e4158ea8af3ef7539f50650c01f13.png" alt="Openshift模板创建OpenLDAP">  </p><p>ps：OpenLDAP的整个构建及部署过程可以作为Openshift的一种类型案例。当然该案例中没有使用PV、PVC做持久化。相信对Openshift有所了解的，在这个基础上做持久化应该不在话下。</p><p>千里之行，始于足下。完成OpenLDAP的部署，这只是一个开始，账号一统还有相当多的工作要去做。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift上部署awx——ansible-tower的社区版</title>
      <link href="/openshift/Openshift%E4%B8%8A%E9%83%A8%E7%BD%B2awx%E2%80%94%E2%80%94ansible-tower%E7%9A%84%E7%A4%BE%E5%8C%BA%E7%89%88/"/>
      <url>/openshift/Openshift%E4%B8%8A%E9%83%A8%E7%BD%B2awx%E2%80%94%E2%80%94ansible-tower%E7%9A%84%E7%A4%BE%E5%8C%BA%E7%89%88/</url>
      
        <content type="html"><![CDATA[<p>Ansible的大名，对做运维开发的工程师来说没有不知道的，它是开源的配置管理工具，也是最流行的自动化运维工具之一。Ansible tower是Ansible的图形界面化平台，它是RedHat公司的商业应用，也就是说Ansible tower是付费的。既然是RedHat的付费应用，可想而知，它具有很强大、实用的功能，另外它应该会有一个免费的社区版本。<br><strong>对，那就是awx</strong>。Ansible Tower的社区版，功能跟Ansible Tower一样强大，开源免费。</p><h2 id="部署安装Awx"><a href="#部署安装Awx" class="headerlink" title="部署安装Awx"></a>部署安装Awx</h2><p>安装文档：<a href="https://github.com/ansible/awx/blob/devel/INSTALL.md">https://github.com/ansible/awx/blob/devel/INSTALL.md</a></p><ol><li>clone下awx的代码<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/ansible/awx.git</span></span><br></pre></td></tr></table></figure></li><li>Openshift集群中创建部署awx的project<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project awx</span></span><br></pre></td></tr></table></figure></li><li>awx的project下创建PVC，默认pvc名为<code>postgresql</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: postgresql</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 10Gi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>配置<code>awx/installer/inventory</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Openshift Install</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Will need to <span class="built_in">set</span> -e openshift_password=developer -e docker_registry_password=$(oc <span class="built_in">whoami</span> -t)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">          or <span class="built_in">set</span> -e openshift_token=TOKEN</span></span><br><span class="line">openshift_host=127.0.0.1:8443 # openshift master</span><br><span class="line">openshift_project=awx # awx部署的project</span><br><span class="line">openshift_user=developer # openshift集群登录用户名</span><br><span class="line">openshift_skip_tls_verify=False</span><br><span class="line">openshift_pg_emptydir=False</span><br><span class="line">...</span><br><span class="line">admin_user=admin # awx登录用户名</span><br><span class="line">admin_password=password # awx登录密码</span><br></pre></td></tr></table></figure></li><li>执行部署awx脚本<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> awx/installer/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook -i inventory install.yml -e openshift_password=developer  -e docker_registry_password=$(oc <span class="built_in">whoami</span> -t)</span></span><br></pre></td></tr></table></figure></li><li>访问查看<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/421e2b3c033b8f652d26b300c6d447b0bc6585cb245ec87e08613473c2df0771.png" alt="登录界面"></li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/37b183c819e588066dd1d87a4be6443510fe583998e02b03f5f584d7a022ffd7.png" alt="awx界面">  </p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://bhirsch.org/2017/09/08/exploring-a-containerized-awx/#content">https://bhirsch.org/2017/09/08/exploring-a-containerized-awx/#content</a><br><a href="https://github.com/ansible/awx">https://github.com/ansible/awx</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift中Elasticsearch索引自动清理工具：Curator</title>
      <link href="/openshift/Openshift%E4%B8%ADElasticsearch%E7%B4%A2%E5%BC%95%E8%87%AA%E5%8A%A8%E6%B8%85%E7%90%86%E5%B7%A5%E5%85%B7%EF%BC%9ACurator/"/>
      <url>/openshift/Openshift%E4%B8%ADElasticsearch%E7%B4%A2%E5%BC%95%E8%87%AA%E5%8A%A8%E6%B8%85%E7%90%86%E5%B7%A5%E5%85%B7%EF%BC%9ACurator/</url>
      
        <content type="html"><![CDATA[<h2 id="Openshift-3-11版本"><a href="#Openshift-3-11版本" class="headerlink" title="Openshift 3.11版本"></a>Openshift 3.11版本</h2><h2 id="Openshift-3-10版本"><a href="#Openshift-3-10版本" class="headerlink" title="Openshift 3.10版本"></a>Openshift 3.10版本</h2><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://docs.openshift.com/container-platform/3.11/install_config/aggregate_logging.html#configuring-curator">Openshift官方文档curator配置</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift中的Prometheus-Operator如何添加新的应用监控</title>
      <link href="/openshift/Openshift%E4%B8%AD%E7%9A%84Prometheus-Operator%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%9A%84%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7/"/>
      <url>/openshift/Openshift%E4%B8%AD%E7%9A%84Prometheus-Operator%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%9A%84%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-31f5b940882dd3e3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Prometheus和Openshift"></p><ol><li>prometheus使用的配置文件在<code>openshift-monitoring/secret/prometheus-k8s</code>中。<br>有添加<code>ServiceMonitor</code>时会动态更新该文件</li><li>为<code>system:serviceaccount:openshift-monitoring:prometheus-k8s</code>添加应用所在project的<code>view</code>权限<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc policy add-role-to-user view system:serviceaccount:openshift-monitoring:prometheus-k8s -n myproject</span></span><br></pre></td></tr></table></figure></li><li>查看prometheus的配置，查看对于servicemonitor的过滤器<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ oc get prometheus k8s -o yaml</span><br><span class="line">...</span><br><span class="line">  serviceMonitorSelector:</span><br><span class="line">    matchExpressions:</span><br><span class="line">    - key: k8s-app</span><br><span class="line">      operator: Exists</span><br></pre></td></tr></table></figure></li></ol><ul><li><code>serviceMonitorSelector</code>表示，只有设置了<code>k8s-app</code>的Label的serviceMonitor的状态才能被该prometheus监听到</li></ul><ol start="4"><li>添加<code>servicemonitor</code> <em>按照3的说明，serviceMonitor必须设置<code>k8s-app</code>Label</em><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: monitoring.coreos.com/v1</span><br><span class="line">kind: ServiceMonitor</span><br><span class="line">metadata:</span><br><span class="line">  name: my-cluster-kafka</span><br><span class="line">  namespace: openshift-monitoring</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: prometheus</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      strimzi.io/name: my-cluster-kafka-bootstrap</span><br><span class="line">  namespaceSelector:</span><br><span class="line">    any: true</span><br><span class="line">  endpoints:</span><br><span class="line">  - port: metrics</span><br></pre></td></tr></table></figure></li></ol><ul><li>selector：匹配的exporter的service的Label</li><li>namespaceSelector：匹配exporter所在的namespace。any为匹配所有的namespace</li><li>endpoints：对应为exporter服务port名</li></ul><p><strong>注意</strong>：经过实验serviceMonitor必须创建在prometheus相同的project下，默认为<code>openshift-monitoring</code><br>另外如果OpenShift网络开启的是多租房&#x2F;NetworkPolicy模式，需要确保prometheus访问exporter节点的网络通畅。</p><p>原理部分可参考：<br><a href="https://docs.okd.io/latest/install_config/prometheus_cluster_monitoring.html#configuring-etcd-monitoring">官方手册 Prometheus Cluster Monitoring</a>，包含对Openshift集群etcd的监控的详细操作<br><a href="https://www.twblogs.net/a/5c0ac5abbd9eee6fb37bf73d">使用Prometheus Operator優雅的監控Kubernetes</a><br><a href="https://www.cnblogs.com/sammyliu/p/10155442.html">基于 Prometheus 的集群监控</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift中集群ElasticSearch的运维</title>
      <link href="/openshift/Openshift%E4%B8%AD%E9%9B%86%E7%BE%A4ElasticSearch%E7%9A%84%E8%BF%90%E7%BB%B4/"/>
      <url>/openshift/Openshift%E4%B8%AD%E9%9B%86%E7%BE%A4ElasticSearch%E7%9A%84%E8%BF%90%E7%BB%B4/</url>
      
        <content type="html"><![CDATA[<p>大家都知道，Openshift集成了EFK(Elasticsearch + Fluentd + Kibana)作为集群的日志管理平台。我们该怎样去维护ElasticSearch.</p><blockquote><ol><li>找到ES所在的pod</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc get pod -l component=es -o name -n logging | cut -d/ -f2</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>查看所有ES索引</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc exec $es-pod-name -- curl -s --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca https://localhost:9200/_cat/indices?v</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>清理所有3月份的ES索引</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc exec $es-pod-name -- curl -s --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XDELETE https://localhost:9200/*.2018.03.*</span><br></pre></td></tr></table></figure><p><em><code>curl可以加-k这样就不需要--cacert参数</code></em></p><blockquote><ol start="4"><li>打开Kibana，显示错误<code>Elasticsearch is still initializing the kibana index</code><br>解决办法：删除kibana的索引，重新进入kibana</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc exec $es-pod-name -- curl -s --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XDELETE https://localhost:9200/.kibana</span><br></pre></td></tr></table></figure><blockquote><ol start="5"><li>确认ES集群的工作状态</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- health</span><br></pre></td></tr></table></figure><blockquote><ol start="6"><li>停止ES节点分片平衡</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- curl --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XPUT https://localhost:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot;: &#123;&quot;cluster.routing.allocation.enable&quot;:&quot;none&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>6.开启ES节点分片平衡</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc exec $es-pod-name -c elasticsearch -- curl --cert /etc/elasticsearch/secret/admin-cert --key /etc/elasticsearch/secret/admin-key --cacert /etc/elasticsearch/secret/admin-ca -XPUT https://localhost:9200/_cluster/settings -d &#x27;&#123;&quot;transient&quot;: &#123;&quot;cluster.routing.allocation.enable&quot;:&quot;all&quot;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="7"><li>ES扩容</li></ol></blockquote><p><a href="https://www.jianshu.com/p/1c74e560303b">OpenShift自带的日志搜索引擎ES服务的扩容</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift之NetApp-SolidFire集成及测试</title>
      <link href="/openshift/Openshift%E4%B9%8BNetApp-SolidFire%E9%9B%86%E6%88%90%E5%8F%8A%E6%B5%8B%E8%AF%95/"/>
      <url>/openshift/Openshift%E4%B9%8BNetApp-SolidFire%E9%9B%86%E6%88%90%E5%8F%8A%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-35f0b85780505eaa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="openshift netapp"></p><h2 id="什么是NetApp-SolidFire"><a href="#什么是NetApp-SolidFire" class="headerlink" title="什么是NetApp SolidFire?"></a>什么是NetApp SolidFire?</h2><p><strong>NetApp</strong>公司是一家存储和数据管理公司,主要提供软件，系统和服务来管理和存储数据，包括其专有的Data ONTAP操作系统。NetApp公司主要向全球数据密集型企业提供统一存储解决方案其 Data ONTAP是全球首屈一指的存储操作系统，公司存储解决方案涵盖了专业化的硬件、软件和服务，为开放网络环境提供了无缝的存储管理。——(来自搜狗百科)<br><strong>SolidFire</strong>成立于2010年，是一家全闪存阵列的存储厂商，其存储控制器基于标准的x86服务器，最大可扩展到100个节点，2015年12月，SolidFire被NetApp收购；2017年6月，NetApp基于SolidFire推出超融合一体机。<br><strong>SolidFire</strong>提供分布式块存储，类似于ceph rbd，非常灵活，支持动态扩缩容，具有良好的性能。同时具有很多企业特性：如快照，组快照，丰富的API，非常灵活的QOS配置等。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-529ac9d881796804.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Solidfire的Reporting界面"></p><h2 id="什么是Trident"><a href="#什么是Trident" class="headerlink" title="什么是Trident?"></a>什么是Trident?</h2><p>NetApp是CNCF的金牌会员，它开发的Trident是一款开源存储配置程序和流程编排程序。<br>在没有Trident的环境下，K8s&#x2F;Openshift环境要使用NetApp存储，就需要，手动在NetApp控制台上创建volume，并设置创建PV，再创建PVC。这些过程需要在两个平台切换操作，而且很麻烦。<br>部署了Trident后，配置好相应的storageclass，K8s&#x2F;Openshift平台就可以直接通过storageclass动态自动创建PVC。K8s&#x2F;Openshift平台通过Trident控制器调用NetApp设备的API从而达到控制NetApp设备目的，如创建volume，并自动创建PV，及PVC，进而让Pod能够使用，此过程是自动的，对平台使用者是无感知的。<br>Trident本身也是以Pod的形式在K8s&#x2F;Openshift平台上运行的。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-354138a6e12b4246.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="trident架构图"></p><h2 id="Openshift上部署与使用Trident"><a href="#Openshift上部署与使用Trident" class="headerlink" title="Openshift上部署与使用Trident"></a>Openshift上部署与使用Trident</h2><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><ol><li>用system:admin登录集群<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc login -u system:admin</span><br></pre></td></tr></table></figure></li><li>集群能够访问SolidFire机器的MVIP(管理VIP)及SVIP(存储SVIP)<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ telnet $MVIP 443</span><br><span class="line">$ telnet $SVIP 3260</span><br></pre></td></tr></table></figure></li><li>安装基本包<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m package -a &#x27;name=lsscsi,iscsi-initiator-utils,sg3_utils,device-mapper-multipath state=present&#x27;</span><br><span class="line">$ ansible all -m shell -a &#x27;mpathconf --enable --with_multipathd y&#x27;</span><br><span class="line">$ ansible all -m service -a &#x27;name=iscsid enabled=true state=started&#x27;</span><br><span class="line">$ ansible all -m service -a &#x27;name=multipathd enabled=true state=started&#x27;</span><br><span class="line">$ ansible all -m service -a &#x27;name=iscsi enabled=true state=started&#x27;</span><br></pre></td></tr></table></figure></li></ol><h4 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h4><ol start="4"><li><p>下载安装文件，并解压</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://github.com/NetApp/trident/releases/download/v18.10.0/trident-installer-18.10.0.tar.gz</span><br><span class="line">$ tar -xf trident-installer-18.10.0.tar.gz</span><br><span class="line">$ cd trident-installer</span><br></pre></td></tr></table></figure></li><li><p>配置安装backend.json文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cp sample-input/backend-solidfire.json setup/backend.json</span><br><span class="line"># 修改里面的配置</span><br><span class="line">$ cat setup/backend.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;version&quot;: 1,</span><br><span class="line">    &quot;storageDriverName&quot;: &quot;solidfire-san&quot;,</span><br><span class="line">    &quot;Endpoint&quot;: &quot;https://&#123;&#123;用户名&#125;&#125;:&#123;&#123;密码&#125;&#125;@&#123;&#123;管理VIP&#125;&#125;/json-rpc/11.0&quot;,</span><br><span class="line">    &quot;SVIP&quot;: &quot;&#123;&#123;存储VIP&#125;&#125;:3260&quot;,</span><br><span class="line">    &quot;TenantName&quot;: &quot;trident&quot;,</span><br><span class="line">    &quot;UseCHAP&quot;: true,</span><br><span class="line">    &quot;InitiatorIFace&quot;: &quot;default&quot;,</span><br><span class="line">    &quot;Types&quot;: [&#123;&quot;Type&quot;: &quot;Bronze&quot;, &quot;Qos&quot;: &#123;&quot;minIOPS&quot;: 1000, &quot;maxIOPS&quot;: 2000, &quot;burstIOPS&quot;: 4000&#125;&#125;,</span><br><span class="line">              &#123;&quot;Type&quot;: &quot;Silver&quot;, &quot;Qos&quot;: &#123;&quot;minIOPS&quot;: 4000, &quot;maxIOPS&quot;: 6000, &quot;burstIOPS&quot;: 8000&#125;&#125;,</span><br><span class="line">              &#123;&quot;Type&quot;: &quot;Gold&quot;, &quot;Qos&quot;: &#123;&quot;minIOPS&quot;: 6000, &quot;maxIOPS&quot;: 8000, &quot;burstIOPS&quot;: 10000&#125;&#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>创建trident project</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc new-project trident</span><br></pre></td></tr></table></figure></li><li><p>安装检查</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./tridentctl install --dry-run -n trident</span><br></pre></td></tr></table></figure><p>这个步骤会模拟安装过程进行执行一遍，并会删除所有资源。通过模拟对整个环境进行全面的检测。以下是执行的日志</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">[root@master02 trident-installer]# ./tridentctl install --dry-run -n trident -d</span><br><span class="line">DEBU Initialized logging.                          logLevel=debug</span><br><span class="line">DEBU Running outside a pod, creating CLI-based client. </span><br><span class="line">DEBU Initialized Kubernetes CLI client.            cli=oc flavor=openshift namespace=trident version=1.11.0+d4cacc0</span><br><span class="line">DEBU Validated installation environment.           installationNamespace=trident kubernetesVersion=</span><br><span class="line">DEBU Deleted Kubernetes configmap.                 label=&quot;app=trident-installer.netapp.io&quot; namespace=trident</span><br><span class="line">DEBU Namespace exists.                             namespace=trident</span><br><span class="line">DEBU Deleted Kubernetes object by YAML.           </span><br><span class="line">DEBU Deleted installer cluster role binding.      </span><br><span class="line">DEBU Deleted Kubernetes object by YAML.           </span><br><span class="line">DEBU Deleted installer cluster role.              </span><br><span class="line">DEBU Deleted Kubernetes object by YAML.           </span><br><span class="line">DEBU Deleted installer service account.           </span><br><span class="line">DEBU Removed security context constraint user.     scc=privileged user=trident-installer</span><br><span class="line">DEBU Created Kubernetes object by YAML.           </span><br><span class="line">INFO Created installer service account.            serviceaccount=trident-installer</span><br><span class="line">DEBU Created Kubernetes object by YAML.           </span><br><span class="line">INFO Created installer cluster role.               clusterrole=trident-installer</span><br><span class="line">DEBU Created Kubernetes object by YAML.           </span><br><span class="line">INFO Created installer cluster role binding.       clusterrolebinding=trident-installer</span><br><span class="line">INFO Added security context constraint user.       scc=privileged user=trident-installer</span><br><span class="line">DEBU Created Kubernetes configmap from directory.  label=&quot;app=trident-installer.netapp.io&quot; name=trident-installer namespace=trident path=/root/trident-installer/setup</span><br><span class="line">INFO Created installer configmap.                  configmap=trident-installer</span><br><span class="line">DEBU Created Kubernetes object by YAML.           </span><br><span class="line">INFO Created installer pod.                        pod=trident-installer</span><br><span class="line">INFO Waiting for Trident installer pod to start.  </span><br><span class="line">DEBU Trident installer pod not yet started, waiting.  increment=280.357322ms message=&quot;pod not yet started (Pending)&quot;</span><br><span class="line">DEBU Trident installer pod not yet started, waiting.  increment=523.702816ms message=&quot;pod not yet started (Pending)&quot;</span><br><span class="line">DEBU Trident installer pod not yet started, waiting.  increment=914.246751ms message=&quot;pod not yet started (Pending)&quot;</span><br><span class="line">DEBU Trident installer pod not yet started, waiting.  increment=1.111778662s message=&quot;pod not yet started (Pending)&quot;</span><br><span class="line">DEBU Pod started.                                  phase=Succeeded</span><br><span class="line">INFO Trident installer pod started.                namespace=trident pod=trident-installer</span><br><span class="line">DEBU Getting logs.                                 cmd=&quot;oc --namespace=trident logs trident-installer -f&quot;</span><br><span class="line">DEBU Initialized logging.                          logLevel=debug</span><br><span class="line">DEBU Running in a pod, creating API-based client.  namespace=trident</span><br><span class="line">DEBU Initialized Kubernetes API client.            cli=oc flavor=openshift namespace=trident version=v1.11.0+d4cacc0</span><br><span class="line">DEBU Validated installation environment.           installationNamespace=trident kubernetesVersion=v1.11.0+d4cacc0</span><br><span class="line">DEBU Parsed requested volume size.                 quantity=2Gi</span><br><span class="line">DEBU Dumping RBAC fields.                          ucpBearerToken= ucpHost= useKubernetesRBAC=true</span><br><span class="line">DEBU Namespace exists.                             namespace=trident</span><br><span class="line">DEBU PVC does not exist.                           pvc=trident</span><br><span class="line">DEBU PV does not exist.                            pv=trident</span><br><span class="line">INFO Starting storage driver.                      backend=/setup/backend.json</span><br><span class="line">DEBU config: &#123;&quot;Endpoint&quot;:&quot;https://admin:root1234@99.248.106.82/json-rpc/11.0&quot;,&quot;InitiatorIFace&quot;:&quot;default&quot;,&quot;SVIP&quot;:&quot;99.248.82.55:3260&quot;,&quot;TenantName&quot;:&quot;trident&quot;,&quot;Types&quot;:[&#123;&quot;Qos&quot;:&#123;&quot;burstIOPS&quot;:4000,&quot;maxIOPS&quot;:2000,&quot;minIOPS&quot;:1000&#125;,&quot;Type&quot;:&quot;Bronze&quot;&#125;,&#123;&quot;Qos&quot;:&#123;&quot;burstIOPS&quot;:8000,&quot;maxIOPS&quot;:6000,&quot;minIOPS&quot;:4000&#125;,&quot;Type&quot;:&quot;Silver&quot;&#125;,&#123;&quot;Qos&quot;:&#123;&quot;burstIOPS&quot;:10000,&quot;maxIOPS&quot;:8000,&quot;minIOPS&quot;:6000&#125;,&quot;Type&quot;:&quot;Gold&quot;&#125;],&quot;UseCHAP&quot;:true,&quot;storageDriverName&quot;:&quot;solidfire-san&quot;,&quot;version&quot;:1&#125; </span><br><span class="line">DEBU Storage prefix is absent, will use default prefix. </span><br><span class="line">DEBU Parsed commonConfig: &#123;Version:1 StorageDriverName:solidfire-san BackendName: Debug:false DebugTraceFlags:map[] DisableDelete:false StoragePrefixRaw:[] StoragePrefix:&lt;nil&gt; SerialNumbers:[] DriverContext: LimitVolumeSize:&#125; </span><br><span class="line">DEBU Initializing storage driver.                  driver=solidfire-san</span><br><span class="line">DEBU Configuration defaults                        Size=1G StoragePrefix= UseCHAP=true</span><br><span class="line">DEBU Parsed into solidfireConfig                   DisableDelete=false StorageDriverName=solidfire-san Version=1</span><br><span class="line">DEBU Decoded to &amp;&#123;CommonStorageDriverConfig:0xc42064e0a0 TenantName:trident EndPoint:https://admin:root1234@99.248.106.82/json-rpc/11.0 SVIP:99.248.82.55:3260 InitiatorIFace:default Types:0xc4206d26e0 LegacyNamePrefix: AccessGroups:[] UseCHAP:true DefaultBlockSize:0 SolidfireStorageDriverConfigDefaults:&#123;CommonStorageDriverConfigDefaults:&#123;Size:1G&#125;&#125;&#125; </span><br><span class="line">DEBU Set default block size.                       defaultBlockSize=512</span><br><span class="line">DEBU Using SF API version from config file.        version=11.0</span><br><span class="line">DEBU Initializing SolidFire API client.            cfg=&quot;&#123;trident https://admin:root1234@99.248.106.82/json-rpc/11.0  99.248.82.55:3260 default 0xc4206d26e0  [] 512 map[]&#125;&quot; endpoint=&quot;https://admin:root1234@99.248.106.82/json-rpc/11.0&quot; svip=&quot;99.248.82.55:3260&quot;</span><br><span class="line">ERRO Error detected in API response.               ID=637 code=500 message=xUnknownAccount name=xUnknownAccount</span><br><span class="line">DEBU Account not found, creating.                  error=&quot;device API error: xUnknownAccount&quot; tenantName=trident</span><br><span class="line">DEBU Created account.                              accountID=0 tenantName=trident</span><br><span class="line">DEBU SolidFire driver initialized.                 AccountID=2 InitiatorIFace=default</span><br><span class="line">DEBU Using CHAP, skipped Volume Access Group logic.  AccessGroups=&quot;[]&quot; SVIP=&quot;99.248.82.55:3260&quot; UseCHAP=true driver=solidfire-san</span><br><span class="line">DEBU Added pool for SolidFire backend.             attributes=&quot;map[media:&#123;Offers: ssd&#125; IOPS:&#123;Min: 1000, Max: 2000&#125; snapshots:&#123;Offer:  true&#125; clones:&#123;Offer:  true&#125; encryption:&#123;Offer:  false&#125; provisioningType:&#123;Offers: thin&#125; backendType:&#123;Offers: solidfire-san&#125;]&quot; backend=solidfire_99.248.82.55 pool=Bronze</span><br><span class="line">DEBU Added pool for SolidFire backend.             attributes=&quot;map[clones:&#123;Offer:  true&#125; encryption:&#123;Offer:  false&#125; provisioningType:&#123;Offers: thin&#125; backendType:&#123;Offers: solidfire-san&#125; media:&#123;Offers: ssd&#125; IOPS:&#123;Min: 4000, Max: 6000&#125; snapshots:&#123;Offer:  true&#125;]&quot; backend=solidfire_99.248.82.55 pool=Silver</span><br><span class="line">DEBU Added pool for SolidFire backend.             attributes=&quot;map[snapshots:&#123;Offer:  true&#125; clones:&#123;Offer:  true&#125; encryption:&#123;Offer:  false&#125; provisioningType:&#123;Offers: thin&#125; backendType:&#123;Offers: solidfire-san&#125; media:&#123;Offers: ssd&#125; IOPS:&#123;Min: 6000, Max: 8000&#125;]&quot; backend=solidfire_99.248.82.55 pool=Gold</span><br><span class="line">DEBU Storage driver initialized.                   driver=solidfire-san</span><br><span class="line">INFO Storage driver loaded.                        driver=solidfire-san</span><br><span class="line">INFO Dry run completed, no problems found.        </span><br><span class="line">DEBU Received EOF from pod logs.                   container= pod=trident-installer</span><br><span class="line">INFO Waiting for Trident installer pod to finish. </span><br><span class="line">DEBU Pod finished.                                 phase=Succeeded</span><br><span class="line">INFO Trident installer pod finished.               namespace=trident pod=trident-installer</span><br><span class="line">DEBU Deleted Kubernetes pod.                       label=&quot;app=trident-installer.netapp.io&quot; namespace=trident</span><br><span class="line">INFO Deleted installer pod.                        pod=trident-installer</span><br><span class="line">DEBU Deleted Kubernetes configmap.                 label=&quot;app=trident-installer.netapp.io&quot; namespace=trident</span><br><span class="line">INFO Deleted installer configmap.                  configmap=trident-installer</span><br><span class="line">INFO In-cluster installation completed.           </span><br><span class="line">DEBU Deleted Kubernetes object by YAML.           </span><br><span class="line">INFO Deleted installer cluster role binding.      </span><br><span class="line">DEBU Deleted Kubernetes object by YAML.           </span><br><span class="line">INFO Deleted installer cluster role.              </span><br><span class="line">DEBU Deleted Kubernetes object by YAML.           </span><br><span class="line">INFO Deleted installer service account.           </span><br><span class="line">INFO Removed security context constraint user.     scc=privileged user=trident-installer</span><br></pre></td></tr></table></figure></li><li><p>正式安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./tridentctl install -n trident</span><br></pre></td></tr></table></figure><p>该步骤是真正的执行。会创建serviceaccount, clusterrolebinding,configmap配置，trident-install pod（该pod在部署完trident deployment后会删除）等， 并会创建一个pv与trident pvc进行初始化操作，最终会创建trident deployment，完成trident的安装。</p></li></ol><ul><li>trident的安装支持自定义一些配置。</li><li>–etcd-image可指定etcd的镜像（默认是quay.io&#x2F;coreos&#x2F;etcd，下载会比较慢）</li><li>–trident-image指定trident的镜像</li><li>–volume-size指定trident持久存储的大小（默认为2GiB）</li><li>–volume-name指定volume名字（默认是etcd-vol）</li><li>–pv指定pv名字（默认是trident）</li><li>–pvc指定pvc名字（默认是trident）</li><li>–generate-custom-yaml将使用的所有配置进行导出到一个setup文件夹，不会对集群做任何操作</li><li>–use-custom-yaml安装setup下的所有yaml文件进行部署trident</li></ul><p>以下是执行的日志</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@master02 trident-installer]# ./tridentctl install -n trident </span><br><span class="line">INFO Created installer service account.            serviceaccount=trident-installer</span><br><span class="line">INFO Created installer cluster role.               clusterrole=trident-installer</span><br><span class="line">INFO Created installer cluster role binding.       clusterrolebinding=trident-installer</span><br><span class="line">INFO Added security context constraint user.       scc=privileged user=trident-installer</span><br><span class="line">INFO Created installer configmap.                  configmap=trident-installer</span><br><span class="line">INFO Created installer pod.                        pod=trident-installer</span><br><span class="line">INFO Waiting for Trident installer pod to start.  </span><br><span class="line">INFO Trident installer pod started.                namespace=trident pod=trident-installer</span><br><span class="line">INFO Starting storage driver.                      backend=/setup/backend.json</span><br><span class="line">INFO Storage driver loaded.                        driver=solidfire-san</span><br><span class="line">INFO Starting Trident installation.                namespace=trident</span><br><span class="line">INFO Created service account.                     </span><br><span class="line">INFO Created cluster role.                        </span><br><span class="line">INFO Created cluster role binding.                </span><br><span class="line">INFO Added security context constraint user.       scc=anyuid user=trident</span><br><span class="line">INFO Created PVC.                                 </span><br><span class="line">INFO Controller serial numbers.                    serialNumbers=&quot;4BZXJB2,85Q8JB2,4BXXJB2,4BXTJB2&quot;</span><br><span class="line">INFO Created iSCSI CHAP secret.                    secret=trident-chap-solidfire-99-248-82-55-trident</span><br><span class="line">INFO Created PV.                                   pv=trident</span><br><span class="line">INFO Waiting for PVC to be bound.                  pvc=trident</span><br><span class="line">INFO Created Trident deployment.                  </span><br><span class="line">INFO Waiting for Trident pod to start.            </span><br><span class="line">INFO Trident pod started.                          namespace=trident pod=trident-57ccdff48f-gtflx</span><br><span class="line">INFO Waiting for Trident REST interface.          </span><br><span class="line">INFO Trident REST interface is up.                 version=18.10.0</span><br><span class="line">INFO Trident installation succeeded.              </span><br><span class="line">INFO Waiting for Trident installer pod to finish. </span><br><span class="line">INFO Trident installer pod finished.               namespace=trident pod=trident-installer</span><br><span class="line">INFO Deleted installer pod.                        pod=trident-installer</span><br><span class="line">INFO Deleted installer configmap.                  configmap=trident-installer</span><br><span class="line">INFO In-cluster installation completed.           </span><br><span class="line">INFO Deleted installer cluster role binding.      </span><br><span class="line">INFO Deleted installer cluster role.              </span><br><span class="line">INFO Deleted installer service account.           </span><br><span class="line">INFO Removed security context constraint user.     scc=privileged user=trident-installer</span><br></pre></td></tr></table></figure><ol start="9"><li>添加第一个backend<br>执行完install后，trident并不会安装之前配置的backend，需要另外再单独添加。（个人觉得netapp这点考虑得有点多余，因为dry-run的时候已经对backend.json作了检查了，直接install将它添加上岂不是更方便）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ./tridentctl -n trident create backend -f setup/backend.json</span><br><span class="line">$ ./tridentctl -n trident get backend</span><br><span class="line">+------------------------+----------------+--------+---------+</span><br><span class="line">|          NAME          | STORAGE DRIVER | ONLINE | VOLUMES |</span><br><span class="line">+------------------------+----------------+--------+---------+</span><br><span class="line">| solidfire_99.248.82.55 | solidfire-san  | true   |       0 |</span><br><span class="line">+------------------------+----------------+--------+---------+</span><br></pre></td></tr></table></figure></li><li>添加基本的storageclass<br>将sample-input&#x2F;storage-class-basic.yaml.templ中的__BACKEND_TYPE__用指定的backend中的STORAGE DRIVER值替换（此例中为solidfire-san）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat sample-input/storage-class-basic.yaml.templ</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: basic</span><br><span class="line">provisioner: netapp.io/trident</span><br><span class="line">parameters:</span><br><span class="line">  backendType: &quot;__BACKEND_TYPE__&quot;</span><br><span class="line">$ sed &quot;s/__BACKEND_TYPE__/solidfire-san/&quot; sample-input/storage-class-basic.yaml.templ | oc create -f -</span><br></pre></td></tr></table></figure></li><li>根据backend中的Type创建对应的storageclass<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat storage-class-gold.yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: gold</span><br><span class="line">  annotations:</span><br><span class="line">    storageclass.kubernetes.io/is-default-class: &quot;true&quot;</span><br><span class="line">provisioner: netapp.io/trident</span><br><span class="line">parameters:</span><br><span class="line">  storagePools: &quot;solidfire_99.248.82.55:Gold&quot; # solidfire_99.248.82.55为backend name;Gold为指定的Type</span><br><span class="line">$ oc create -f storage-class-gold.yaml</span><br></pre></td></tr></table></figure>查看当前的storageclass<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ oc get sc</span><br><span class="line">NAME             PROVISIONER         AGE</span><br><span class="line">basic            netapp.io/trident   2h</span><br><span class="line">gold (default)   netapp.io/trident   1h</span><br></pre></td></tr></table></figure></li></ol><h4 id="使用：创建PVC"><a href="#使用：创建PVC" class="headerlink" title="使用：创建PVC"></a>使用：创建PVC</h4><ol start="12"><li>创建第一个PVC<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ cat test-pvc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: gold</span><br><span class="line">    volume.beta.kubernetes.io/storage-provisioner: netapp.io/trident</span><br><span class="line">    trident.netapp.io/reclaimPolicy: &quot;Retain&quot;</span><br><span class="line">  name: testpvc</span><br><span class="line">  namespace: test</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">$ oc create -f test-pvc.yaml</span><br></pre></td></tr></table></figure>PVC创建的说明:</li></ol><ul><li>volume.beta.kubernetes.io&#x2F;storage-class为10，11步创建的storageclass</li><li>volume.beta.kubernetes.io&#x2F;storage-provisioner指定为netapp的trident</li><li>trident.netapp.io&#x2F;reclaimPolicy指定创建PV的reclaimPolicy,默认为”Delete”,支持”Delete”和”Retain”，不支持”Recycle”</li><li>accessModes因SolidFire是块存储，只支持ReadWriteOnce</li></ul><h2 id="SolidFire功能测试"><a href="#SolidFire功能测试" class="headerlink" title="SolidFire功能测试"></a>SolidFire功能测试</h2><h4 id="快照恢复数据"><a href="#快照恢复数据" class="headerlink" title="快照恢复数据"></a>快照恢复数据</h4><p>创建快照</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-7c04a9c2802cf178.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="创建快照"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-a65c4e5f82c39048.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="基于已有快照恢复pvc数据"></p><h4 id="基于快照创建新的PVC"><a href="#基于快照创建新的PVC" class="headerlink" title="基于快照创建新的PVC"></a>基于快照创建新的PVC</h4><p>指定快照，创建新的存储</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-ada9845dafb2247c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="基于已有快照恢复volume"></p><p>查看新建的volume的IQN</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-aa7f04acfa16677c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="查看新建的volume的IQN"></p><p>基于新的volume创建PV</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ cat test-clone-pv.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    pv.kubernetes.io/provisioned-by: netapp.io/trident</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: gold</span><br><span class="line">  name: test-dd-testxx-volume</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 100Gi</span><br><span class="line">  iscsi:</span><br><span class="line">    chapAuthDiscovery: true</span><br><span class="line">    chapAuthSession: true</span><br><span class="line">    fsType: ext4</span><br><span class="line">    iqn: iqn.2010-01.com.solidfire:fs69.test-dd-testxx-volume.169</span><br><span class="line">    iscsiInterface: default</span><br><span class="line">    lun: 0</span><br><span class="line">    secretRef:</span><br><span class="line">      name: trident-chap-solidfire-99-248-82-55-trident</span><br><span class="line">      namespace: trident</span><br><span class="line">    targetPortal: 99.248.82.55:3260</span><br><span class="line">  persistentVolumeReclaimPolicy: Delete</span><br><span class="line">  storageClassName: gold</span><br><span class="line">$ oc create -f test-clone-pv.yaml</span><br></pre></td></tr></table></figure><p>创建pvc使用手动创建的pv</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ cat test-clone-pvc.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: test111x</span><br><span class="line">  namespace: test-dd</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 100Gi</span><br></pre></td></tr></table></figure><h4 id="组快照"><a href="#组快照" class="headerlink" title="组快照"></a>组快照</h4><p>组快照与快照类似，不同之处，它把多个存储卷在同一时间的数据做快照，从而避免数据不一致的情况。同时在恢复的时候，也同时将备份时刻的数据进行恢复。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-e81f4837d26e6f4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="组快照创建.png"></p><h4 id="克隆已有的pvc数据"><a href="#克隆已有的pvc数据" class="headerlink" title="克隆已有的pvc数据"></a>克隆已有的pvc数据</h4><p>添加annotations配置trident.netapp.io&#x2F;cloneFromPVC: test-pvc,创建新的pvc基于已有的PVC test-pvc</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    trident.netapp.io/cloneFromPVC: test-pvc</span><br><span class="line">  name: test-clone-pvc</span><br><span class="line">  namespace: test-dd</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 100Gi</span><br><span class="line">  storageClassName: gold</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="SolidFire性能测试"><a href="#SolidFire性能测试" class="headerlink" title="SolidFire性能测试"></a>SolidFire性能测试</h2><p>测试环境说明</p><ul><li>openshift 3.11物理机部署：<code>3 Masters</code>   <code>4 Nodes</code></li><li>SolidFire 4台Node：型号SF9605 <code>每台Node上为10块SSD盘，每个Node的IOPS为5w，集群最高IOPS 20w</code></li><li>每块PV存储设置为gold类型storageclass：<code>&#123;&quot;Type&quot;: &quot;Gold&quot;, &quot;Qos&quot;: &#123;&quot;minIOPS&quot;: 6000, &quot;maxIOPS&quot;: 8000, &quot;burstIOPS&quot;: 10000&#125;&#125;</code></li></ul><h4 id="dd测试"><a href="#dd测试" class="headerlink" title="dd测试"></a>dd测试</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 测试命令</span><br><span class="line">$ dd if=/dev/zero of=/data/dd.test bs=4k count=200000 oflag=direct</span><br></pre></td></tr></table></figure><ol><li>单个pod，单个pv作dd命令测试<br>创建deployment进行测试<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">$ cat test0-pvc.yaml</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    volume.beta.kubernetes.io/storage-class: gold</span><br><span class="line">    volume.beta.kubernetes.io/storage-provisioner: netapp.io/trident</span><br><span class="line">  name: test0</span><br><span class="line">  namespace: test-dd</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 10Gi</span><br><span class="line">$ oc create -f test0-pvc.yaml ## 创建测试的存储</span><br><span class="line">$ cat dd.yaml</span><br><span class="line">apiVersion: apps.openshift.io/v1</span><br><span class="line">kind: DeploymentConfig</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    run: ddtest</span><br><span class="line">  name: ddtest</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    run: ddtest</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: ddtest</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - command:</span><br><span class="line">        - /bin/bash</span><br><span class="line">        - &#x27;-c&#x27;</span><br><span class="line">        - |</span><br><span class="line">          #/bin/bash</span><br><span class="line">          dd if=/dev/zero of=/data/out.test1 bs=4k count=200000 oflag=direct</span><br><span class="line">        image: tools/iqperf:latest</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        name: ddtest</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /data</span><br><span class="line">          name: volume-spq10</span><br><span class="line">      volumes:</span><br><span class="line">      - name: volume-spq10</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: test0</span><br><span class="line">  triggers:</span><br><span class="line">  - type: ConfigChange</span><br><span class="line">$ oc create -f dd.yaml</span><br></pre></td></tr></table></figure>在webconsole上查看日志如下<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">200000+0 records in</span><br><span class="line">200000+0 records out</span><br><span class="line">819200000 bytes (819 MB) copied, 68.8519 s, 11.9 MB/s</span><br></pre></td></tr></table></figure>NetApp的管理平台上查看集群IO状态，如图（只需要看11:32时间以后部分）</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-c6beba1161c6231c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="单个pod，单个pv作dd命令测试.png"></p><p><strong>IOPS为2908</strong><br>2. 1个pod，1个pv，8个dd进程<br>将1中的deploymentconfig中的command内容更新为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">- command:</span><br><span class="line">  - &#x27;/bin/bash&#x27;</span><br><span class="line">  - &#x27;-c&#x27;</span><br><span class="line">  - |</span><br><span class="line">    #/bin/bash</span><br><span class="line">    for i in &#123;1..8&#125;</span><br><span class="line">    do </span><br><span class="line">      dd if=/dev/zero of=/data/dd.test$i bs=4k count=200000 oflag=direct &amp;</span><br><span class="line">    done    </span><br><span class="line">    sleep 1000000</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><img src="https://upload-images.jianshu.io/upload_images/5793257-69dde54612e04fa2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="1个pod，1个pv，8个dd进程.png"></p><p><strong>IOPS为10000</strong></p><p><strong>额外补充</strong></p><ul><li>1个pod，1个pv，50-&gt;150个dd进程，bs&#x3D;512，在netapp控制台将volume的max iops设置为200000，最终测试结果，该volume的写iops最大为40000。<br>也就是该版本solidfire下，单个volume最大写iops为4w。</li><li>同样方法测试读，单个volume最大达到写iops为7.5w。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ dd if=/data/out.test1 of=/dev/zero bs=512 count=20000000 iflag=direct</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li>8个pod，8个pv同时使用dd命令测试<br>创建statefulset，设置volumeClaimTemplates批量创建存储<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">$ cat dd-statefulset.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: testdd</span><br><span class="line">  namespace: test-dd</span><br><span class="line">spec:</span><br><span class="line">  serviceName: testdd</span><br><span class="line">  replicas: 8</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: testdd</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: testdd</span><br><span class="line">    spec:</span><br><span class="line">      terminationGracePeriodSeconds: 10</span><br><span class="line">      containers:</span><br><span class="line">        - name: testdd</span><br><span class="line">          containers:</span><br><span class="line">          - command:</span><br><span class="line">            - /bin/bash</span><br><span class="line">            - &#x27;-c&#x27;</span><br><span class="line">            - |</span><br><span class="line">              #!/bin/bash</span><br><span class="line">              dd if=/dev/zero of=/data/out.test1 bs=4k count=2000000 oflag=direct</span><br><span class="line">          image: &#x27;harbor.apps.it.mbcloud.com/tools/iqperf:latest&#x27;</span><br><span class="line">          imagePullPolicy: Always</span><br><span class="line">          name: testdd</span><br><span class="line">          image: &#x27;tools/dd:latest&#x27;</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: data</span><br><span class="line">              mountPath: /data</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">    - metadata:</span><br><span class="line">        name: data</span><br><span class="line">      spec:</span><br><span class="line">        accessModes:</span><br><span class="line">          - ReadWriteOnce</span><br><span class="line">        storageClassName: gold</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            storage: 100Gi</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-655dc33f7fe0242b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt=" 8个pod，8个pv同时使用dd命令测试.png"></p><p><strong>IOPS为33883</strong><br>4. 8个pod，8个pv同时每个pod启用8个dd进程，共64个dd进程测试<br>更改3中statefulset的command命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">- command:</span><br><span class="line">  - &#x27;/bin/bash&#x27;</span><br><span class="line">  - &#x27;-c&#x27;</span><br><span class="line">  - |</span><br><span class="line">    #/bin/bash</span><br><span class="line">    for i in &#123;1..8&#125;</span><br><span class="line">    do </span><br><span class="line">      dd if=/dev/zero of=/data/dd.test$i bs=4k count=200000 oflag=direct &amp;</span><br><span class="line">    done    </span><br><span class="line">    sleep 1000000</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><img src="https://upload-images.jianshu.io/upload_images/5793257-6268348d577035e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="8个pod，8个pv同时每个pod启用8个dd进程，共64个dd进程测试.png"></p><p><strong>IOPS为76832</strong>达到了gold Type下设置的IOPS上限<br>5. 50个pod，50个pv同时每个pod启用3个dd进程，共150个dd进程测试</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-7e5519d21a4a57db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="图片.png"></p><p>此时单个PV存储的详情<br><img src="https://upload-images.jianshu.io/upload_images/5793257-0cac53c3f6320d32.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="图片.png"></p><p><strong>IOPS为205545</strong>达到了gold Type下设置的IOPS上限<br>综合结果如下：</p><table><thead><tr><th>pod数</th><th>pv数</th><th>dd进程数</th><th>IOPS</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>2908</td></tr><tr><td>1</td><td>1</td><td>8</td><td>10000</td></tr><tr><td>8</td><td>8</td><td>8</td><td>33883</td></tr><tr><td>8</td><td>8</td><td>64</td><td>76832</td></tr><tr><td>50</td><td>50</td><td>150</td><td>205545</td></tr></tbody></table><h4 id="数据库测试"><a href="#数据库测试" class="headerlink" title="数据库测试"></a>数据库测试</h4><p>测试工具<code>mydbtest</code><br>测试配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -uapp -h172.30.213.17 -papp app -e &quot;create table t_mytest(col1 int);&quot;</span><br><span class="line">$ cat test.conf</span><br><span class="line">option</span><br><span class="line"></span><br><span class="line">name app</span><br><span class="line"></span><br><span class="line">loop 20000</span><br><span class="line"></span><br><span class="line">user app/app@172.30.213.17:3306:app</span><br><span class="line"></span><br><span class="line">declare</span><br><span class="line"></span><br><span class="line">a int 10 30000</span><br><span class="line"></span><br><span class="line">begin</span><br><span class="line"></span><br><span class="line">#select * from t_mytest where col1 = :a; # 查询</span><br><span class="line">insert into t_mytest set col1 = :a;  # 插入</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>执行测试过程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./mydbtest_64.bin query=test.conf  degree=40</span><br></pre></td></tr></table></figure><p>执行结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 插入数据</span><br><span class="line">2019-01-23 17:59:35 Total  tran=20000=312/s, qtps=40000=624/s, ela=64046 ms, avg=3202 us</span><br><span class="line">Summary: SQL01 exec=800000, rows=0=0/e, avg=65 us</span><br><span class="line">Summary: SQL02 exec=800000, rows=800000=100/e, avg=3135 us</span><br><span class="line">Summary: exec=12307/s, qtps=24615/s</span><br><span class="line"></span><br><span class="line"># 创建完索引后，读数据（参考意义不大）</span><br><span class="line">2019-01-23 17:56:31 Total  tran=20000=3835/s, qtps=40000=7670/s, ela=5203 ms, avg=260 us</span><br><span class="line">Summary: SQL01 exec=800000, rows=22668078=2833/e, avg=174 us</span><br><span class="line">Summary: SQL02 exec=800000, rows=0=0/e, avg=69 us</span><br><span class="line">Summary: exec=133333/s, qtps=266666/s</span><br></pre></td></tr></table></figure><p>插入的qtps为24615&#x2F;s,性能不错。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift之服务网格Istio</title>
      <link href="/openshift/Openshift%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BCIstio/"/>
      <url>/openshift/Openshift%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BCIstio/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-446ecfa3826c2ba1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Openshift Istio"></p><h2 id="什么是服务网格？"><a href="#什么是服务网格？" class="headerlink" title="什么是服务网格？"></a>什么是服务网格？</h2><p>服务网络就是指构成应用程序的微服务网络以及应用之间的交互。随着规模和复杂性的增长，服务网格越来越难以理解和管理。它的需求包括服务发现、负载均衡、故障恢复、指标收集和监控以及通常更加复杂的运维需求，例如 A&#x2F;B 测试、金丝雀发布、限流、访问控制和端到端认证等。</p><h2 id="Istio是什么？"><a href="#Istio是什么？" class="headerlink" title="Istio是什么？"></a>Istio是什么？</h2><p>Istio 是一个用来连接、管理和保护微服务的开放平台。Istio 提供一种简单的方式来为已部署的服务建立网络，该网络具有负载均衡、服务间认证、监控等功能，而不需要对服务的代码做任何改动。想要让服务支持 Istio，只需要在您的环境中部署一个特殊的 sidecar，使用 Istio 控制平面功能配置和管理代理，拦截微服务之间的所有网络通信。</p><h2 id="Istio能做什么？"><a href="#Istio能做什么？" class="headerlink" title="Istio能做什么？"></a>Istio能做什么？</h2><p>Istio 提供了一个完整的解决方案，通过为整个服务网格提供行为洞察和操作控制来满足微服务应用程序的多样化需求。它在服务网络中统一提供了许多关键功能：</p><ul><li>流量管理。控制服务之间的流量和API调用的流向，使得调用更可靠，并使网络在恶劣情况下更加健壮。</li><li>服务身份和安全。为网格中的服务提供可验证身份，并提供保护服务流量的能力，使其可以在不同可信度的网络上流转。</li><li>策略执行。将组织策略应用于服务之间的互动，确保访问策略得以执行，资源在消费者之间良好分配。可以通过通过配置网格而不是修改应用程序代码来完成策略的更改。</li><li>遥测：了解服务之间的依赖关系，以及它们之间流量的本质和流向，从而提供快速识别问题的能力。</li></ul><h2 id="Istio的基本架构"><a href="#Istio的基本架构" class="headerlink" title="Istio的基本架构"></a>Istio的基本架构</h2><p>Istio 服务网格逻辑上分为数据平面和控制平面。</p><ul><li>Envoy（数据平面Proxy）</li><li>Mixer(负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。)</li><li>Pilot(Envoy sidecar 提供服务发现功能，为智能路由（例如 A&#x2F;B 测试、金丝雀部署等）和弹性（超时、重试、熔断器等）提供流量管理功能。)</li><li>Citadel(通过内置身份和凭证管理可以提供强大的服务间和最终用户身份验证。)</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-bd1c964fc107321c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/8600" alt="Istio架构图"></p><h2 id="什么是Red-Hat-OpenShift服务网格？"><a href="#什么是Red-Hat-OpenShift服务网格？" class="headerlink" title="什么是Red Hat OpenShift服务网格？"></a>什么是Red Hat OpenShift服务网格？</h2><ul><li>Red Hat OpenShift服务网格是一个平台，它提供了对服务网格的行为监控和操作，提供了连接、保护和监控微服务应用程序的统一方式。</li><li>基于开源Istio项目，Red Hat OpenShift服务网格在现有的应用程序上添加了一个透明层，而不需要对服务代码进行任何更改。通过在整个环境中部署一个特殊的sidecar proxy，拦截微服务之间的所有网络通信，通过使用控制平面的配置，管理服务网格，可以达到服务的网络控制。</li><li>Red Hat OpenShift Service Mesh能够简单地实现服务发现、负载均衡、服务间的认证、故障恢复、统计、监控，同时也提供了复杂的功能，包括A&#x2F;B测试、金丝雀发布、速率限制、访问控制和端到端认证。</li><li>当前最新版本的Openshift Service Mesh为 Technology Preview 7（技术预览版7）。它增了3scale Istio Adapter，同时相关软件服务版本为Istio 1.11、Kiali 0.13.x、Jaeger 1.9.0</li></ul><h2 id="Red-Hat-OpenShift-Service-Mesh当前问题"><a href="#Red-Hat-OpenShift-Service-Mesh当前问题" class="headerlink" title="Red Hat OpenShift Service Mesh当前问题"></a>Red Hat OpenShift Service Mesh当前问题</h2><ul><li>Red Hat OpenShift Service Mesh不支持网络多租户</li><li>Red Hat OpenShift Service Mesh不支持IPV6</li><li>istio-init容器需要有privileged权限，或者至少需要root并具有NET管理功能。因为istio-init需要配置Pod中的iptable规则来拦截网络连接。</li></ul><h2 id="安装Red-Hat-OpenShift-Service-MeshOpenShift-Service-Mesh"><a href="#安装Red-Hat-OpenShift-Service-MeshOpenShift-Service-Mesh" class="headerlink" title="安装Red Hat OpenShift Service MeshOpenShift Service Mesh"></a>安装Red Hat OpenShift Service MeshOpenShift Service Mesh</h2><h4 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h4><ul><li>Openshift 3.11</li><li>oc命令行工具与Openshift集群版本匹配</li><li>执行oc命令时，必须使用集群管理员账号</li><li>配置所有Node节点系统参数</li><li>安装的版本为0.7.0<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/sysctl.d/99-elasticsearch.conf </span><br><span class="line">vm.max_map_count = 262144</span><br><span class="line">$ sysctl vm.max_map_count=262144</span><br></pre></td></tr></table></figure></li><li>相关镜像<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/istio-operator:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/openshift-ansible:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/citadel:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/proxyv2:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/pilot:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/mixer:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/galley:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/sidecar-injector:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/proxy-init:0.7.0</span><br><span class="line">registry.access.redhat.com/openshift-istio-tech-preview/kiali:0.13.0</span><br><span class="line">registry.access.redhat.com/distributed-tracing-tech-preview/jaeger-elasticsearch:5.6.10</span><br><span class="line">registry.access.redhat.com/distributed-tracing-tech-preview/jaeger-agent:1.9.0</span><br><span class="line">registry.access.redhat.com/distributed-tracing-tech-preview/jaeger-collector:1.9.0</span><br><span class="line">registry.access.redhat.com/distributed-tracing-tech-preview/jaeger-query:1.9.0</span><br><span class="line">docker.io/grafana/grafana:5.4.0</span><br><span class="line">docker.io/prom/prometheus:v2.3.1</span><br></pre></td></tr></table></figure></li></ul><h4 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h4><ol><li>创建CRD文件<code>istio-installation.yaml</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">$ cat istio-installation.yaml</span><br><span class="line">apiVersion: &quot;istio.openshift.com/v1alpha1&quot;</span><br><span class="line">kind: &quot;Installation&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;istio-installation&quot;</span><br><span class="line">spec:</span><br><span class="line">  deployment_type: openshift</span><br><span class="line">  istio:</span><br><span class="line">    authentication: true</span><br><span class="line">    community: false</span><br><span class="line">    prefix: registry.access.redhat.com/openshift-istio-tech-preview/</span><br><span class="line">    version: 0.7.0</span><br><span class="line">  jaeger:</span><br><span class="line">    prefix: registry.access.redhat.com/distributed-tracing-tech-preview/</span><br><span class="line">    version: 1.9.0</span><br><span class="line">    elasticsearch_memory: 1Gi</span><br><span class="line">  kiali:</span><br><span class="line">    username: username</span><br><span class="line">    password: password</span><br><span class="line">    prefix: registry.access.redhat.com/openshift-istio-tech-preview/</span><br><span class="line">    version: 0.13.0</span><br><span class="line">  launcher:</span><br><span class="line">    openshift:</span><br><span class="line">      user: user</span><br><span class="line">      password: password</span><br><span class="line">    github:</span><br><span class="line">      username: username</span><br><span class="line">      token: token</span><br><span class="line">    catalog:</span><br><span class="line">      filter: booster.mission.metadata.istio</span><br><span class="line">      branch: v71</span><br><span class="line">      repo: https://github.com/fabric8-launcher/launcher-booster-catalog.git</span><br><span class="line">  threeScale:</span><br><span class="line">    enabled: false</span><br><span class="line">    prefix: registry.access.redhat.com/openshift-istio-tech-preview/</span><br><span class="line">    version: 0.2.0</span><br><span class="line">    adapter:</span><br><span class="line">      listenAddr: 3333</span><br><span class="line">      logLevel: info</span><br><span class="line">      logJSON: true</span><br><span class="line">      reportMetrics: true</span><br><span class="line">      metricsPort: 8080</span><br><span class="line">      cacheTTLSeconds: 300</span><br><span class="line">      cacheRefreshSeconds: 180</span><br><span class="line">      cacheEntriesMax: 1000</span><br><span class="line">      cacheRefreshRetries: 1</span><br><span class="line">      allowInsecureConn: false</span><br><span class="line">      clientTimeoutSeconds: 10</span><br></pre></td></tr></table></figure><strong>注意</strong><br><code>metadata.name</code>必须是<code>istio-installation</code><br><code>spec.launcher.openshift.user</code>和<code>spec.launcher.openshift.password</code>为openshift集群对应的用户名和密码<br><code>spec.launcher.github.username</code>和<code>spec.launcher.github.token</code>为github对应的账号信息<br>以上是最全的安装，当前也有最简安装的配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cat istio-installation.yaml</span><br><span class="line">apiVersion: &quot;istio.openshift.com/v1alpha1&quot;</span><br><span class="line">kind: &quot;Installation&quot;</span><br><span class="line">metadata:</span><br><span class="line">  name: &quot;istio-installation&quot;</span><br></pre></td></tr></table></figure></li><li>安装istio operator相关文件准备<br>相关的配置文件在github上<a href="https://github.com/Maistra/openshift-ansible/tree/maistra-0.7/istio">https://github.com/Maistra/openshift-ansible/tree/maistra-0.7/istio</a><br>相关文件配置列表如下<br><a href="https://github.com/Maistra/openshift-ansible/blob/maistra-0.7/istio/cr-full.yaml" title="cr-full.yaml">cr-full.yaml</a><br><a href="https://github.com/Maistra/openshift-ansible/blob/maistra-0.7/istio/cr-kiali.yaml" title="cr-kiali.yaml">cr-kiali.yaml</a><br><a href="https://github.com/Maistra/openshift-ansible/blob/maistra-0.7/istio/cr-minimal.yaml" title="cr-minimal.yaml">cr-minimal.yaml</a><br><a href="https://github.com/Maistra/openshift-ansible/blob/maistra-0.7/istio/istio_community_operator_template.yaml" title="istio_community_operator_template.yaml">istio_community_operator_template.yaml</a><br><a href="https://github.com/Maistra/openshift-ansible/blob/maistra-0.7/istio/istio_product_operator_template.yaml" title="istio_product_operator_template.yaml">istio_product_operator_template.yaml</a><br><a href="https://github.com/Maistra/openshift-ansible/blob/maistra-0.7/istio/master-config.patch" title="master-config.patch">master-config.patch</a></li><li>安装istio operator<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc new-project istio-operator</span><br><span class="line">$ oc new-app -f istio_product_operator_template.yaml --param=OPENSHIFT_ISTIO_MASTER_PUBLIC_URL=&lt;master public url&gt; --param=OPENSHIFT_ISTIO_PREFIX=registry.access.redhat.com/openshift-istio-tech-preview/</span><br></pre></td></tr></table></figure></li></ol><ul><li>OPENSHIFT_ISTIO_MASTER_PUBLIC_URL为openshift集群对外的master地址，例如：<a href="https://master.example.com:8443/">https://master.example.com:8443</a></li><li>OPENSHIFT_ISTIO_PREFIX为openshift istio的镜像前缀，如果将准备中的镜像都导入到了自己的私有仓库中，就可以使用它换成自己的镜像仓库地址</li></ul><ol start="4"><li>验证operator安装是否成功<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ oc logs -n istio-operator $(oc -n istio-operator get pods -l name=istio-operator --output=jsonpath=&#123;.items..metadata.name&#125;)</span><br><span class="line"></span><br><span class="line">time=&quot;2019-02-11T05:28:25Z&quot; level=info msg=&quot;Go Version: go1.9.4&quot;</span><br><span class="line">time=&quot;2019-02-11T05:28:25Z&quot; level=info msg=&quot;Go OS/Arch: linux/amd64&quot;</span><br><span class="line">time=&quot;2019-02-11T05:28:25Z&quot; level=info msg=&quot;operator-sdk Version: 0.0.5+git&quot;</span><br><span class="line">time=&quot;2019-02-11T05:28:25Z&quot; level=info msg=&quot;Metrics service istio-operator created&quot;</span><br><span class="line">time=&quot;2019-02-11T05:28:25Z&quot; level=info msg=&quot;Watching resource istio.openshift.com/v1alpha1, kind Installation, namespace istio-operator, resyncPeriod 0&quot;</span><br><span class="line">time=&quot;2019-02-11T05:33:10Z&quot; level=info msg=&quot;Installing istio for Installation istio-installation&quot;</span><br></pre></td></tr></table></figure>有类似如上的输出就说明安装好了。</li><li>部署控制平面CONTROL PLANE<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f istio-installation.yaml -n istio-operator</span><br></pre></td></tr></table></figure>其中istio-installation.yaml为第一步创建的文件。<br>该步骤将创建istio-system项目，并调用operator中的ansible任务完成istio的安装。可以通过观察名为openshift-ansible-istio-installer-job的pod的状态，来确认安装的进度，如果它的状态为completed,说明安装完成。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ oc get pods -n istio-system</span><br><span class="line">NAME                                          READY     STATUS      RESTARTS   AGE</span><br><span class="line">3scale-istio-adapter-7df4db48cf-sc98s         1/1       Running     0          13s</span><br><span class="line">elasticsearch-0                               1/1       Running     0          29s</span><br><span class="line">grafana-c7f5cc6b6-vg6db                       1/1       Running     0          33s</span><br><span class="line">istio-citadel-d6d6bb7bb-jgfwt                 1/1       Running     0          1m</span><br><span class="line">istio-egressgateway-69448cf7dc-b2qj5          1/1       Running     0          1m</span><br><span class="line">istio-galley-f49696978-q949d                  1/1       Running     0          1m</span><br><span class="line">istio-ingressgateway-7759647fb6-pfpd5         1/1       Running     0          1m</span><br><span class="line">istio-pilot-7595bfd696-plffk                  2/2       Running     0          1m</span><br><span class="line">istio-policy-779454b878-xg7nq                 2/2       Running     2          1m</span><br><span class="line">istio-sidecar-injector-6655b6ffdb-rn69r       1/1       Running     0          1m</span><br><span class="line">istio-telemetry-dd9595888-8xjz2               2/2       Running     2          1m</span><br><span class="line">jaeger-agent-gmk72                            1/1       Running     0          25s</span><br><span class="line">jaeger-collector-7f644df9f5-dbzcv             1/1       Running     1          25s</span><br><span class="line">jaeger-query-6f47bf4777-h4wmh                 1/1       Running     1          25s</span><br><span class="line">kiali-7cc48b6cbb-74gcf                        1/1       Running     0          17s</span><br><span class="line">openshift-ansible-istio-installer-job-fbtfj   0/1       Completed   0          2m</span><br><span class="line">prometheus-5f9fd67f8-r6b86                    1/1       Running     0          1m</span><br><span class="line"></span><br><span class="line">$ oc get pods -n devex</span><br><span class="line">NAME                          READY     STATUS    RESTARTS   AGE</span><br><span class="line">configmapcontroller-1-8rr6w   1/1       Running   0          1m</span><br><span class="line">launcher-backend-2-2wg86      1/1       Running   0          1m</span><br><span class="line">launcher-frontend-2-jxjsd     1/1       Running   0          1m</span><br></pre></td></tr></table></figure></li><li>配置master-config，使得应用能够自动注入istio-proxy sidecar<br>在master-config.yaml文件所在目录下新建文件master-config.patch，内容见下面的代码块<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ cd /etc/origin/master/</span><br><span class="line">$ cat master-config.patch</span><br><span class="line">admissionConfig:</span><br><span class="line">  pluginConfig:</span><br><span class="line">    MutatingAdmissionWebhook:</span><br><span class="line">      configuration:</span><br><span class="line">        apiVersion: apiserver.config.k8s.io/v1alpha1</span><br><span class="line">        kubeConfigFile: /dev/null</span><br><span class="line">        kind: WebhookAdmission</span><br><span class="line">    ValidatingAdmissionWebhook:</span><br><span class="line">      configuration:</span><br><span class="line">        apiVersion: apiserver.config.k8s.io/v1alpha1</span><br><span class="line">        kubeConfigFile: /dev/null</span><br><span class="line">        kind: WebhookAdmission</span><br><span class="line">$ cp -p master-config.yaml master-config.yaml.prepatch</span><br><span class="line">$ oc ex config patch master-config.yaml.prepatch -p &quot;$(cat master-config.patch)&quot; &gt; master-config.yaml</span><br><span class="line">$ /usr/local/bin/master-restart api &amp;&amp; /usr/local/bin/master-restart controllers</span><br></pre></td></tr></table></figure></li><li>创建自动注入istio-proxy的deployment，需要满足以下两个条件</li></ol><ul><li>所在project下的容器需要privileged与anyuid的scc<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc adm policy add-scc-to-user anyuid -z &lt;service account&gt; -n &lt;namespace&gt;</span><br><span class="line">oc adm policy add-scc-to-user privileged -z &lt;service account&gt; -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure><service account>默认为default<br><namespace>为需要istio控制的project</li><li>deployment中添加annotations <code>sidecar.istio.io/inject: &quot;true&quot;</code><br>例如<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: sleep</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        sidecar.istio.io/inject: &quot;true&quot;</span><br><span class="line">      labels:</span><br><span class="line">        app: sleep</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: sleep</span><br><span class="line">        image: tutum/curl</span><br><span class="line">        command: [&quot;/bin/sleep&quot;,&quot;infinity&quot;]</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br></pre></td></tr></table></figure></li></ul><h2 id="卸载Red-Hat-OpenShift-Service-Mesh"><a href="#卸载Red-Hat-OpenShift-Service-Mesh" class="headerlink" title="卸载Red Hat OpenShift Service Mesh"></a>卸载Red Hat OpenShift Service Mesh</h2><ol><li>删除自定义资源<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc delete -n istio-operator installation istio-installation</span><br></pre></td></tr></table></figure></li><li>删除operator<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc process -f istio_product_operator_template.yaml | oc delete -f -</span><br></pre></td></tr></table></figure></li></ol><h2 id="升级Red-Hat-OpenShift-Service-Mesh"><a href="#升级Red-Hat-OpenShift-Service-Mesh" class="headerlink" title="升级Red Hat OpenShift Service Mesh"></a>升级Red Hat OpenShift Service Mesh</h2><p>目前Red Hat OpenShift Service Mesh不支持升级，如果需要使用新版本的Service Mesh，只能通过先卸载再安装的方式。</p><h2 id="实战Bookinfo"><a href="#实战Bookinfo" class="headerlink" title="实战Bookinfo"></a>实战Bookinfo</h2><p>目前Istio的测试例子几本都是用Bookinfo这个应用，它也是istio项目官方的测试例子，同样Red Hat Openshift Service Mesh也是用这个例子来做演练。<br>这个Bookinfo应用包含有4个微服务，分别是：</p><ul><li>productpage，该页面会去调用details和reviews服务</li><li>details，该服务获取书的信息</li><li>reviews，该服务包括对书的评价，它会调用rating服务</li><li>ratings，该服务包括书的评分<br>同时reviews服务有三个版本：<br>v1版本不调用 ratings服务<br>v2版本，调用ratings服务，同时给评星显示五个黑色的星星<br>v3版本，调用ratings服务，同时给评星显示五个红色的星星</li></ul><h4 id="安装Bookinfo应用"><a href="#安装Bookinfo应用" class="headerlink" title="安装Bookinfo应用"></a>安装Bookinfo应用</h4><ol><li>为bookinfo应用单独创建一个project<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc new-project myproject</span><br></pre></td></tr></table></figure></li><li>为myproject项目的容器默认添加privileged与anyuid scc<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm policy add-scc-to-user anyuid -z default -n myproject</span><br><span class="line">$ oc adm policy add-scc-to-user privileged -z default -n myproject</span><br></pre></td></tr></table></figure></li><li>在myproject项目下部署应用<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc apply -n myproject -f https://raw.githubusercontent.com/Maistra/bookinfo/master/bookinfo.yaml</span><br></pre></td></tr></table></figure></li><li>为bookinfo创建ingress gateway，使得外部能够访问到bookinfo服务<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc apply -n myproject -f https://raw.githubusercontent.com/Maistra/bookinfo/master/bookinfo-gateway.yaml</span><br></pre></td></tr></table></figure></li><li>获得ingress gateway的请求域名<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get route -n istio-system istio-ingressgateway -o jsonpath=&#x27;&#123;.spec.host&#125;&#x27;</span><br><span class="line">istio-ingressgateway-istio-system.apps.example.com</span><br></pre></td></tr></table></figure></li><li>浏览器中访问：<a href="http://istio-ingressgateway-istio-system.apps.example.com/productpage">http://istio-ingressgateway-istio-system.apps.example.com/productpage</a></li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-4bcaa6d154fbd260.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="ratings v1"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-12a901d86bf6225d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="ratings v2"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-68b12208ca6c828c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="ratings v3"></p><p>至此，Bookinfo应用已成功部署好了。</p><h4 id="添加额外的规则"><a href="#添加额外的规则" class="headerlink" title="添加额外的规则"></a>添加额外的规则</h4><ol><li>不启用mutual TLS<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">$ curl -o destination-rule-all.yaml https://raw.githubusercontent.com/istio/istio/release-1.0/samples/bookinfo/networking/destination-rule-all.yaml</span><br><span class="line">$ oc apply -f destination-rule-all.yaml</span><br><span class="line"></span><br><span class="line">$ cat destination-rule-all.yaml</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: productpage</span><br><span class="line">spec:</span><br><span class="line">  host: productpage</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  host: reviews</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">  - name: v3</span><br><span class="line">    labels:</span><br><span class="line">      version: v3</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  host: ratings</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">  - name: v2-mysql</span><br><span class="line">    labels:</span><br><span class="line">      version: v2-mysql</span><br><span class="line">  - name: v2-mysql-vm</span><br><span class="line">    labels:</span><br><span class="line">      version: v2-mysql-vm</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  host: details</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li><li>启用mutual TLS<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">$ curl -o destination-rule-all-mtls.yaml https://raw.githubusercontent.com/istio/istio/release-1.0/samples/bookinfo/networking/destination-rule-all-mtls.yaml</span><br><span class="line">$ oc apply -f destination-rule-all-mtls.yaml</span><br><span class="line"></span><br><span class="line">$ cat destination-rule-all-mtls.yaml</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: productpage</span><br><span class="line">spec:</span><br><span class="line">  host: productpage</span><br><span class="line">  trafficPolicy:</span><br><span class="line">    tls:</span><br><span class="line">      mode: ISTIO_MUTUAL</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: reviews</span><br><span class="line">spec:</span><br><span class="line">  host: reviews</span><br><span class="line">  trafficPolicy:</span><br><span class="line">    tls:</span><br><span class="line">      mode: ISTIO_MUTUAL</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">  - name: v3</span><br><span class="line">    labels:</span><br><span class="line">      version: v3</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: ratings</span><br><span class="line">spec:</span><br><span class="line">  host: ratings</span><br><span class="line">  trafficPolicy:</span><br><span class="line">    tls:</span><br><span class="line">      mode: ISTIO_MUTUAL</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">  - name: v2-mysql</span><br><span class="line">    labels:</span><br><span class="line">      version: v2-mysql</span><br><span class="line">  - name: v2-mysql-vm</span><br><span class="line">    labels:</span><br><span class="line">      version: v2-mysql-vm</span><br><span class="line">---</span><br><span class="line">apiVersion: networking.istio.io/v1alpha3</span><br><span class="line">kind: DestinationRule</span><br><span class="line">metadata:</span><br><span class="line">  name: details</span><br><span class="line">spec:</span><br><span class="line">  host: details</span><br><span class="line">  trafficPolicy:</span><br><span class="line">    tls:</span><br><span class="line">      mode: ISTIO_MUTUAL</span><br><span class="line">  subsets:</span><br><span class="line">  - name: v1</span><br><span class="line">    labels:</span><br><span class="line">      version: v1</span><br><span class="line">  - name: v2</span><br><span class="line">    labels:</span><br><span class="line">      version: v2</span><br><span class="line">---</span><br></pre></td></tr></table></figure></li><li>列出所有的目标规则<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get destinationrules -o yaml</span><br></pre></td></tr></table></figure></li></ol><h4 id="删除Bookinfo应用"><a href="#删除Bookinfo应用" class="headerlink" title="删除Bookinfo应用"></a>删除Bookinfo应用</h4><ol><li>下载清除Bookinfo的脚本代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -o cleanup.sh https://raw.githubusercontent.com/Maistra/bookinfo/master/cleanup.sh &amp;&amp; chmod +x ./cleanup.sh</span><br></pre></td></tr></table></figure></li><li>执行cleanup.sh<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ./cleanup.sh</span><br><span class="line">namespace ? [default] myproject</span><br></pre></td></tr></table></figure></li><li>确认清除完成<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ oc get virtualservices -n myproject</span><br><span class="line">No resources found.</span><br><span class="line">$ oc get gateway -n myproject</span><br><span class="line">No resources found.</span><br><span class="line">$ oc get pods -n myproject</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure></li></ol><h2 id="RedHat-Openshift-Service-Mesh扩展组件"><a href="#RedHat-Openshift-Service-Mesh扩展组件" class="headerlink" title="RedHat Openshift Service Mesh扩展组件"></a>RedHat Openshift Service Mesh扩展组件</h2><p>**RedHat Openshift Service Mesh的全量安装，还包括以下组件：分布式追踪Jaeger、Istio可视化工具Kiali、Prometheus监控及Grafana监控展示。下面分别介绍各个组件的功能与使用。<br>请确保上一步安装的Bookinfo应用正常访问。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-9e5f49204f159071.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Openshift Service Mesh扩展组件"></p><h4 id="分布式追踪Jaeger"><a href="#分布式追踪Jaeger" class="headerlink" title="分布式追踪Jaeger"></a>分布式追踪Jaeger</h4><p>Jaeger是Uber开源的分布式跟踪系统，现在已经成为CNCF的开源项目，其灵感来源于Google的Dapper和twitter的Zipkin，从2016年开始该系统在Uber内部得到了广泛的应用。 Jaege在设计上参考了Google的Dapper。</p><ol><li>访问并刷新几次bookinfo页面:<a href="http://istio-ingressgateway-istio-system.apps.example.com/productpage">http://istio-ingressgateway-istio-system.apps.example.com/productpage</a></li><li>打开jaeger页面<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get route -n istio-system jaeger-query -o jsonpath=&#x27;&#123;.spec.host&#125;&#x27;</span><br><span class="line">jaeger-query-istio-system.apps.example.com</span><br></pre></td></tr></table></figure></li><li>浏览器访问<a href="https://jaeger-query-istio-system.apps.example.com/">https://jaeger-query-istio-system.apps.example.com</a></li><li>jaeger页面的左侧Service选择productpage，并点击<code>Find Traces</code>按钮，将在右侧显示轨迹列表</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-6d0ccd8aab18fb7c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="jaeger主页"><br>5. 点击列表中的一条轨迹，将打开该轨迹的详细视图</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-c9d6ed080338b04e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="轨迹详细视图"></p><ul><li>从上图中可以看出，该追踪轨迹是由多个嵌套块组成。每个嵌套都对应一个Bookinfo服务的调用，所有的这些都是为了响应<code>/productpage</code>请求而执行的。</li><li>该请求总共耗时46.23ms,详情服务（detail）耗时1.76ms，评论服务（reviews）耗时32.28ms，评分服务（ratings）耗时17.41ms。</li><li>每个请求都是由调用客户端与服务端组成，例如：productpage details.myproject.svc.cluster.local:9080，即表示productpage服务调用了details服务。</li></ul><h4 id="Kiali"><a href="#Kiali" class="headerlink" title="Kiali"></a>Kiali</h4><p>Kiali为网格管理和可观察性提供了良好的用户体验的可视化工具。Kiali 提供以下功能：</p><ul><li>服务拓扑图</li><li>分布式跟踪</li><li>指标度量收集和图标</li><li>配置校验</li><li>健康检查和显示</li><li>服务发现</li></ul><ol><li>查看Kiali域名地址<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get route -n istio-system kiali -o jsonpath=&#x27;&#123;.spec.host&#125;&#x27;</span><br><span class="line">kiali-istio-system.apps.example.com</span><br></pre></td></tr></table></figure></li><li>浏览器访问 <a href="https://kiali-istio-system.apps.example.com/">https://kiali-istio-system.apps.example.com</a></li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-9dddde967b1c3524.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="kiali登录界面"><br>使用安装istio时的istio-installation.yaml中配置的kiali的用户名和密码登录，如：username，password<br>3. OverView页面</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-a60b2d56e5abbdd1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="kiali overview页面"><br>可查看各project的运行状况。<br>4. Graph页面<br>在Graph页面上选择Namespace为myproject，可查看bookinfo这个项目的微服务关系图。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-54e9b5d9cd7062e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Kiali Graph页面"></p><ul><li>在Graph页面中能够看到一个包含所有微服务的图表，在页面上可以方便看到这些服务的相互交互关系。</li><li>点击Legend按钮，可以查看每个节点图标代表的含义</li><li>鼠标悬停在某个节点上，能够看到该节点相关的调用关系</li><li>点击节点，展示该节点相关调用关系的详情</li></ul><ol start="5"><li>Service页面<br>Service页面可以查看项目的微服务列表，及服务相关的额外信息，如：健康状态、请求错误率。</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-9ff1aed27b233342.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Kiali Service页面"></p><ul><li>点击具体服务，可查看服务的详情信息</li></ul><ol start="6"><li>Istio Config 页面<br>Istio Config页面，可以查看当前运行的Istio配置信息，包括熔断器，规则、网关、故障注入、路由、路由规则、虚拟服务。</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-bd21055912f7d082.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Istio Config 页面"></p><ul><li>点击具体的信息条目查看详情</li><li>只能查看，不能修改</li></ul><ol start="7"><li>分布式追踪器链接<br>分布式追踪器链接,跳转到对应的Jaeger页面</li></ol><h4 id="Prometheus监控"><a href="#Prometheus监控" class="headerlink" title="Prometheus监控"></a>Prometheus监控</h4><p>Prometheus是一个开源的服务工具包，可以按指定的时间间隔从配置的目标中获取监控数据，同时它还支持告警。经常使用Grafana来展示相关数据。</p><ol><li>查看Prometheus页面地址<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get route -n istio-system prometheus -o jsonpath=&#x27;&#123;.spec.host&#125;&#x27;</span><br><span class="line">prometheus-istio-system.apps.example.com</span><br></pre></td></tr></table></figure></li><li>浏览器访问<a href="http://prometheus-istio-system.apps.example.com/">http://prometheus-istio-system.apps.example.com</a></li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-dc80a9760d6d6568.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Prometheus监控"></p><h4 id="Grafana监控展示"><a href="#Grafana监控展示" class="headerlink" title="Grafana监控展示"></a>Grafana监控展示</h4><p>Grafana是一个开源的监控展示工具，它可以与很多不同的数据源连接，如Mysql, InfluxDB,Prometheus等。图表丰富美观，同时也有告警功能。</p><ol><li>查看Grafana页面地址<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ oc get route -n istio-system grafana -o jsonpath=&#x27;&#123;.spec.host&#125;&#x27;</span><br><span class="line">grafana-istio-system.apps.example.com</span><br></pre></td></tr></table></figure></li><li>浏览器访问<a href="http://grafana-istio-system.apps.example.com/">http://grafana-istio-system.apps.example.com</a></li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-3d3215177d9bbf53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Grafana监控展示"></p><ol start="3"><li>选择Istio Mesh Dashboard查看网格服务监控情况</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-038479faa6ade121.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Istio Mesh Dashboard"></p><ol start="4"><li>在Istio Mesh Dashboard页面下点击相关Service，查看对应Service的监控详情</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-d248bca5187a7a45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Istio Service详情"></p><ol start="5"><li>RedHat Openshift Service Mesh Grafana默认的监控图表，不仅仅只有应用服务的监控，同时也有Istio相关组件的监控(Mixer,Pilot)。所有的监控图表如下：</li></ol><ul><li>Istio Galley Dashboard</li><li>Istio Mesh Dashboard</li><li>Istio Performance Dashboard</li><li>Istio Service Dashboard</li><li>Istio Workload Dashboard</li><li>Mixer Dashboard</li><li>Pilot Dashboard</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>Istio 目前是在服务网格的产品中最为火热的产品，目前最新版本为1.1.0</li><li>随着服务网格越来越火热，相关的周边应用也不断出现，分布式追踪工具Jaeger，Istio配置管理工具Kiali及监控Prometheus与Grafana也让服务网格更加的完整，可靠。</li><li>与之前Openshift 3.10版本手动安装Istio相比，在Openshift 3.11版本通过Istio-operator安装部署，更加方便也更加稳定。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openshift.com/container-platform/3.11/servicemesh-install/servicemesh-install.html">Openshift官方文档之：Service Mesh</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift使用OpenLDAP作为统一用户认证</title>
      <link href="/openshift/Openshift%E4%BD%BF%E7%94%A8OpenLDAP%E4%BD%9C%E4%B8%BA%E7%BB%9F%E4%B8%80%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/"/>
      <url>/openshift/Openshift%E4%BD%BF%E7%94%A8OpenLDAP%E4%BD%9C%E4%B8%BA%E7%BB%9F%E4%B8%80%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-08cd631159dee900.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LDAP+Openshift.png"></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Openshift默认的用户认证是使用HTPasswd，之前的部署方式也都是使用了HTPasswd的方式。其实Openshift官方默认支持LDAP协议，可以很容易地将OpenLDAP与Openshift进行集成，使用OpenLDAP集中管理用户。</p><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><ol><li>centos 7.4</li><li>openshift 3.10</li><li>openldap 2.4.44</li></ol><p><a href="https://www.jianshu.com/p/b5df1eb1f4de">openldap安装与使用介绍</a><br><a href="https://www.jianshu.com/p/f97558a48a13">Openshift集群3.9升级到3.10</a></p><h1 id="用户账号配置及验证登录"><a href="#用户账号配置及验证登录" class="headerlink" title="用户账号配置及验证登录"></a>用户账号配置及验证登录</h1><blockquote><p>Openshift中配置验证方式为LDAPPasswordIdentityProvider</p></blockquote><p><code>LDAP URL说明</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ldapurl     = scheme &quot;://&quot; [hostport] [&quot;/&quot;[dn [&quot;?&quot; [attributes] [&quot;?&quot; [scope][&quot;?&quot; [filter] [&quot;?&quot; extensions]]]]]]</span><br><span class="line">scheme   = &quot;ldap&quot;</span><br><span class="line">hostport  = hostport from Section 5 of [RFC 1738]</span><br><span class="line">dn           = distinguishedName from Section 3 of [1]</span><br><span class="line">attributes = attrdesc *(&quot;,&quot; attrdesc)</span><br><span class="line">scope      = &quot;base&quot; / &quot;one&quot; / &quot;sub&quot;</span><br><span class="line">filter     = filter from Section 4 of [4]     </span><br><span class="line">extensions = extension *(&quot;,&quot; extension)</span><br><span class="line">    extension  = [&quot;!&quot;] extype [&quot;=&quot; exvalue]</span><br><span class="line">    extype     = token / xtoken</span><br><span class="line">    exvalue    = LDAPString from section 4.1.2 of [2]</span><br><span class="line">    token      = oid from section 4.1 of [3]</span><br><span class="line">    xtoken     = (&quot;X-&quot; / &quot;x-&quot;) token&lt;/pre&gt;</span><br><span class="line"># 例子：</span><br><span class="line"># ldap://host.com:6666/o=UniversityofMichigan,c=US??sub?(cn=BabsJensen)</span><br><span class="line"># ldap://host.com:6666/o=UniversityofMichigan,c=US?mail??(sn=MBU)</span><br></pre></td></tr></table></figure><table><thead><tr><th>scope类型</th><th>说明</th></tr></thead><tbody><tr><td>base</td><td>表示把基准DN作为搜索对象。例如：cn&#x3D;yanzong,ou&#x3D;Ops,dc&#x3D;shuyun,dc&#x3D;com 的基准DN是dc&#x3D;shuyun,dc&#x3D;com</td></tr><tr><td>one</td><td>表示把基准DN的第一层作为搜索对象，如上个例子中的ou&#x3D;Ops为搜索对象。</td></tr><tr><td>sub</td><td>表示把基准DN及以下的整棵树都作为搜索对象。</td></tr></tbody></table><p>使用person对象中的mail作为登录的用户名，同时使用dn作为用户的id,用户的显示名为person对象中的cn，同时只允许带有<code>sn=MBC</code>的用户登录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># /etc/origin/master/master-config.yaml</span><br><span class="line">oauthConfig:</span><br><span class="line">  identityProviders:</span><br><span class="line">  - challenge: true</span><br><span class="line">    login: true</span><br><span class="line">    mappingMethod: claim</span><br><span class="line">    name: my_ldap_provider</span><br><span class="line">    provider:</span><br><span class="line">      apiVersion: v1</span><br><span class="line">      attributes:</span><br><span class="line">        email:</span><br><span class="line">        - mail</span><br><span class="line">        id:</span><br><span class="line">        - dn</span><br><span class="line">        name:</span><br><span class="line">        - cn</span><br><span class="line">        preferredUsername:</span><br><span class="line">        - uid</span><br><span class="line">      bindDN: &#x27;&#x27;</span><br><span class="line">      bindPassword: &#x27;&#x27;</span><br><span class="line">      ca: &#x27;&#x27;</span><br><span class="line">      insecure: true</span><br><span class="line">      kind: LDAPPasswordIdentityProvider</span><br><span class="line">      url: ldap://192.168.0.2:389/ou=users,dc=example,dc=com?mail??(sn=MBC)</span><br></pre></td></tr></table></figure><p>重启openshift服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># master-restart controllers api</span><br><span class="line"># master-restart controllers controllers</span><br></pre></td></tr></table></figure><blockquote><p>在openldap中创建对应的用户</p></blockquote><p>创建用户密码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># slappasswd -s test</span><br><span class="line">&#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br></pre></td></tr></table></figure><p>使用创建的密码及用户信息添加openldap账号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ cat users.ldif</span><br><span class="line">dn: ou=users,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: users</span><br><span class="line"></span><br><span class="line">dn: cn=Michael,ou=users,dc=example,dc=com</span><br><span class="line">objectClass: person</span><br><span class="line">objectClass: organizationalPerson</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">cn: Michael</span><br><span class="line">sn: MBC</span><br><span class="line">displayName: Michael MBC</span><br><span class="line">mail: michael@example.com</span><br><span class="line">userPassword: &#123;SSHA&#125;5rMM/3f8Ki13IyarGTtwzieoTu7KMgwc</span><br></pre></td></tr></table></figure><p>至此就可以通过：用户名<code>michael@example.com</code>，密码：<code>test</code>进行登录openshift。登录成功后，openshift会自动创建一个普通用户，用户id为<code>cn=Michael,ou=users,dc=example,dc=com</code></p><h3 id="解决了登录，是否就完全OK了呢-openshift与openldap的集成就到此为止了吗？当然不是。"><a href="#解决了登录，是否就完全OK了呢-openshift与openldap的集成就到此为止了吗？当然不是。" class="headerlink" title="解决了登录，是否就完全OK了呢?openshift与openldap的集成就到此为止了吗？当然不是。"></a>解决了登录，是否就完全OK了呢?openshift与openldap的集成就到此为止了吗？当然不是。</h3><h1 id="用户组配置及同步"><a href="#用户组配置及同步" class="headerlink" title="用户组配置及同步"></a>用户组配置及同步</h1><blockquote><p>在openldap中创建对应的组对象，并将用户Michael设置为组成员</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat groups.ldif</span><br><span class="line">dn: ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: groups</span><br><span class="line"></span><br><span class="line">dn: cn=admins,ou=groups,dc=example,dc=com</span><br><span class="line">objectClass: groupOfNames</span><br><span class="line">cn: admins</span><br><span class="line">owner: cn=Manager,dc=example,dc=com</span><br><span class="line">description: Administrators Group</span><br><span class="line">member: cn=Michael,ou=users,dc=example,dc=com</span><br></pre></td></tr></table></figure><blockquote><p>openshift同步openldap上的组与用户信息</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ cat rfc2307_config.yaml</span><br><span class="line">kind: LDAPSyncConfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">url: ldap://192.168.0.2:389 </span><br><span class="line">insecure: true</span><br><span class="line">rfc2307:</span><br><span class="line">    groupsQuery:</span><br><span class="line">        baseDN: &quot;ou=groups,dc=example,dc=com&quot;</span><br><span class="line">        scope: sub</span><br><span class="line">        derefAliases: never</span><br><span class="line">        filter: (objectclass=groupOfNames)</span><br><span class="line">    groupUIDAttribute: dn</span><br><span class="line">    groupNameAttributes: [ cn ]</span><br><span class="line">    groupMembershipAttributes: [ member ]</span><br><span class="line">    usersQuery:</span><br><span class="line">        baseDN: &quot;ou=users,dc=example,dc=com&quot;</span><br><span class="line">        scope: sub</span><br><span class="line">        derefAliases: never</span><br><span class="line">        pageSize: 0</span><br><span class="line">    userUIDAttribute: dn</span><br><span class="line">    userNameAttributes: [ dn ]</span><br><span class="line">    tolerateMemberNotFoundErrors: true</span><br><span class="line">    tolerateMemberOutOfScopeErrors: true</span><br></pre></td></tr></table></figure><p>执行同步</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm  groups sync --sync-config=rfc2307_config.yaml --confirm</span><br></pre></td></tr></table></figure><blockquote><p>结果展示</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@allinone ~]# oc get group </span><br><span class="line">NAME      USERS</span><br><span class="line">admins    cn=Michael,ou=users,dc=example,dc=com</span><br><span class="line">[root@allinone ~]#</span><br><span class="line">[root@allinone ~]# oc get user</span><br><span class="line">NAME                                     UID                                    FULL NAME   IDENTITIES</span><br><span class="line">cn=Michael,ou=users,dc=example,dc=com    bf612e04-b592-11e8-8841-5254501db2dc   Michael     my_ldap_provider:cn=Michael,ou=users,dc=example,dc=com</span><br></pre></td></tr></table></figure><p>通过给admins这个group授权，admins组下面的成员也都具有了对应的权限，实现了权限的管理。 </p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift各组件Master-Node-Etcd-Router-Registry证书维护</title>
      <link href="/openshift/Openshift%E5%90%84%E7%BB%84%E4%BB%B6Master-Node-Etcd-Router-Registry%E8%AF%81%E4%B9%A6%E7%BB%B4%E6%8A%A4/"/>
      <url>/openshift/Openshift%E5%90%84%E7%BB%84%E4%BB%B6Master-Node-Etcd-Router-Registry%E8%AF%81%E4%B9%A6%E7%BB%B4%E6%8A%A4/</url>
      
        <content type="html"><![CDATA[<p>Openshift集群正常运行过程中，各个组件:Master、Node、Etcd、Router、Registry之前相互通信交互，它们之间都是通过加密协议通信。那么问题来了，对于tls证书是有有效期的，突然有一天，证书过期了怎么办？集群是不是就无法正常运行了呢？<br>现在我们就来看下，怎么能够让加密证书持续有效。</p><ul><li>安装时，将证书有效期设置为很长，100年够不够</li><li>快速查看当前集群所有证书的有效期</li><li>证书过期了，我们该如何进行更新证书</li></ul><h2 id="安装时指定证书的有效期"><a href="#安装时指定证书的有效期" class="headerlink" title="安装时指定证书的有效期"></a>安装时指定证书的有效期</h2><p>默认情况下，<code>etcd证书</code>、<code>openshift证书</code>的有效期为5年，<code>kubelet证书</code>、<code>私有镜像仓库registry证书</code>、<code>Route证书</code>的有效期为2年。在集群安装时可以通过设置ansible&#x2F;hosts中的参数来指定证书的有效期</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line">openshift_hosted_registry_cert_expire_days=730</span><br><span class="line">openshift_ca_cert_expire_days=1825</span><br><span class="line">openshift_node_cert_expire_days=730</span><br><span class="line">openshift_master_cert_expire_days=730</span><br><span class="line">etcd_ca_default_days=1825</span><br></pre></td></tr></table></figure><h2 id="查看当前集群所有证书的有效期"><a href="#查看当前集群所有证书的有效期" class="headerlink" title="查看当前集群所有证书的有效期"></a>查看当前集群所有证书的有效期</h2><ol><li>确保ansible&#x2F;hosts中的参数有如下信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openshift_is_atomic=false</span><br><span class="line">ansible_distribution=centos</span><br></pre></td></tr></table></figure></li><li>检查<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-checks/certificate_expiry/easy-mode.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#执行完成后可在roles/openshift_certificate_expiry/defaults/main.yml</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#中的openshift_certificate_expiry_html_report_path</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#所在路径下（默认是/tmp/cert-expiry-report.html）查看所有证书的过期时间</span></span></span><br></pre></td></tr></table></figure>它将会展示出所有<code>Master oc证书</code>、<code>etcd证书</code>、<code>kube证书</code>、<code>router默认证书</code>、<code>私有镜像仓库registry证书</code>的过期时间</li></ol><p><img src="https://upload-images.jianshu.io/upload_images/5793257-69c36cb81c3c4ffc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="证书过期时间详情展示部分图"></p><h2 id="更新证书"><a href="#更新证书" class="headerlink" title="更新证书"></a>更新证书</h2><p>更新证书方法可以只针对<code>Master oc证书</code>、<code>etcd证书</code>、<code>kube证书</code>、<code>router默认证书</code>、<code>私有镜像仓库registry证书</code>中的一种进行更新，也可以全部进行更新。</p><ol><li>确保ansible&#x2F;hosts中的参数有如下信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openshift_master_cluster_hostname=master.example.com</span><br><span class="line">openshift_master_cluster_public_hostname=master.example.com</span><br></pre></td></tr></table></figure></li><li>重新生成证书进行更新</li></ol><ul><li>全部一次性更新  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/redeploy-certificates.yml</span></span><br></pre></td></tr></table></figure><ul><li>只更新master CA证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-master/redeploy-openshift-ca.yml</span></span><br></pre></td></tr></table></figure></li><li>只更新etcd CA证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-etcd/redeploy-ca.yml</span></span><br></pre></td></tr></table></figure></li><li>只更新master Certificates证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-master/redeploy-certificates.yml</span></span><br></pre></td></tr></table></figure></li><li>只更新etcd Certificates证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-etcd/redeploy-certificates.yml</span><br></pre></td></tr></table></figure></li><li>只更新node Certificates证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-node/redeploy-certificates.yml</span><br></pre></td></tr></table></figure></li><li>只更新私有镜像仓库Rgistry Certificates证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-hosted/redeploy-registry-certificates.yml</span><br></pre></td></tr></table></figure></li><li>只更新Router Certificates证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-hosted/redeploy-router-certificates.yml</span><br></pre></td></tr></table></figure></li><li>只更新etcd Certificates证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-etcd/redeploy-certificates.yml</span><br></pre></td></tr></table></figure></li></ul></li></ul><ol start="3"><li>使用自定义Master CA证书</li></ol><ul><li>安装时使用自定义证书<ol><li>将证书的写在inventory的配置参数中 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/ansible/hosts</span></span><br><span class="line">...</span><br><span class="line">[OSEv3.vars]</span><br><span class="line">...</span><br><span class="line">openshift_master_ca_certificate=&#123;&#x27;certfile&#x27;: &#x27;&lt;/path/to/ca.crt&gt;&#x27;, &#x27;keyfile&#x27;:   &#x27;&lt;/path/to/ca.key&gt;&#x27;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li>执行正常部署 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook  playbooks/deploy_cluster.yml</span></span><br></pre></td></tr></table></figure></li></ol></li><li>已运行集群，更新自定义证书<ol><li>同上面的1步骤，将证书的写在inventory的配置参数中</li><li>运行更新Master CA证书playbook <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-master/redeploy-openshift-ca.yml</span></span><br></pre></td></tr></table></figure></li></ol></li></ul><h2 id="更新完成后遇到的问题"><a href="#更新完成后遇到的问题" class="headerlink" title="更新完成后遇到的问题"></a>更新完成后遇到的问题</h2><ol><li>allinone的集群下更新所有证书时，在重启docker那一步中，卡住了。</li><li>Router重启一直报错。解决办法：删除secret router-crt证书，让它自动更新。</li></ol><h2 id="EFK证书更新"><a href="#EFK证书更新" class="headerlink" title="EFK证书更新"></a>EFK证书更新</h2><p>相关文件：<a href="https://docs.openshift.com/container-platform/3.9/install_config/aggregate_logging.html#fluentd-redeploy-certs">https://docs.openshift.com/container-platform/3.9/install_config&#x2F;aggregate_logging.html#fluentd-redeploy-certs</a></p><p>通过重新部署EFK来更新证书。</p><ol><li>删除旧证书<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -r /etc/origin/logging</span></span><br></pre></td></tr></table></figure></li><li>确保在inventory文件中设置好了EFK证书相关的配置</li><li>执行EFK重新部署脚本 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> openshift-ansible</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/openshift-logging/config.yml</span></span><br></pre></td></tr></table></figure>该命令执行会出现如下错误信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">RUNNING HANDLER [openshift_logging_elasticsearch : Checking current health for &#123;&#123; _es_node &#125;&#125; cluster] ***</span><br><span class="line">Friday 14 December 2018 07:53:44 +0000 (0:00:01.571) 0:05:01.710 *******</span><br><span class="line">[WARNING]: Consider using the get_url or uri module rather than running curl.</span><br><span class="line">If you need to use command because get_url or uri is insufficient you can add</span><br><span class="line">warn=False to this command task or set command_warnings=False in ansible.cfg to</span><br><span class="line">get rid of this message.</span><br><span class="line"></span><br><span class="line">fatal: [ec2-34-207-171-49.compute-1.amazonaws.com]: FAILED! =&gt; &#123;&quot;changed&quot;: true, &quot;cmd&quot;: [&quot;curl&quot;, &quot;-s&quot;, &quot;-k&quot;, &quot;--cert&quot;, &quot;/tmp/openshift-logging-ansible-3v1NOI/admin-cert&quot;, &quot;--key&quot;, &quot;/tmp/openshift-logging-ansible-3v1NOI/admin-key&quot;, &quot;https://logging-es.openshift-logging.svc:9200/_cluster/health?pretty&quot;], &quot;delta&quot;: &quot;0:00:01.024054&quot;, &quot;end&quot;: &quot;2018-12-14 02:53:33.467642&quot;, &quot;msg&quot;: &quot;non-zero return code&quot;, &quot;rc&quot;: 7, &quot;start&quot;: &quot;2018-12-14 02:53:32.443588&quot;, &quot;stderr&quot;: &quot;&quot;, &quot;stderr_lines&quot;: [], &quot;stdout&quot;: &quot;&quot;, &quot;stdout_lines&quot;: []&#125;</span><br><span class="line">RUNNING HANDLER [openshift_logging_elasticsearch : Set Logging message to manually restart] ***</span><br><span class="line">Friday 14 December 2018 07:53:46 +0000 (0:00:01.557) 0:05:03.268 *******</span><br></pre></td></tr></table></figure></li><li>通过删除以下pod，来完成密钥的刷新<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc delete pod --all -n openshift-logging</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ul><li>OpenShift 3.10版本起删除了单独更新Node证书的脚本。</li><li>OpenShift 3.11版本前更新证书会重启Docker；而在OpenShift 3.11后期版本优化了更新证书过程，不再重启Docker。</li><li>如果集群证书已经过期了怎么办？<br>一旦集群证书过期，OpenShift中的各组件的交互都会报错，包括WebConsole。此时一定要及时更新集群的证书。但是如果此时直接运行更新证书的脚本，它会检查证书是否过期，如果过期会报错，并终止更新。此时需要在ansible inventory文件中添加变量：<code>openshift_certificate_expiry_fail_on_warn=flase</code>，再运行更新证书脚本即可。如果ca证书也需要更新的话，需要额外添加变量：<code>openshift_redeploy_openshift_ca=true</code>，再运行更新证书脚本即可。</li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://docs.openshift.com/container-platform/3.11/install_config/redeploying_certificates.html#install-config-cert-expiry">官方更新Openshfit证书</a><br><a href="https://docs.openshift.com/container-platform/3.11/install/configuring_inventory_file.html#advanced-install-custom-certificates">安装时指定证书的过期时间</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift实现Etcd一键备份与一键恢复脚本</title>
      <link href="/openshift/Openshift%E5%AE%9E%E7%8E%B0Etcd%E4%B8%80%E9%94%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E4%B8%80%E9%94%AE%E6%81%A2%E5%A4%8D%E8%84%9A%E6%9C%AC/"/>
      <url>/openshift/Openshift%E5%AE%9E%E7%8E%B0Etcd%E4%B8%80%E9%94%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E4%B8%80%E9%94%AE%E6%81%A2%E5%A4%8D%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-a8804e63f4e97efd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Openshift etcd"></p><p>一键备份etcd脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat backup_etcd.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">export ETCD_POD_MANIFEST=&quot;/etc/origin/node/pods/etcd.yaml&quot;</span><br><span class="line">export ETCD_EP=$(grep https $&#123;ETCD_POD_MANIFEST&#125; | cut -d &#x27;/&#x27; -f3)</span><br><span class="line">oc login -u system:admin</span><br><span class="line">export ETCD_POD=$(oc get pods -n kube-system | grep -o -m 1 &#x27;\S*etcd\S*&#x27;)</span><br><span class="line">oc project kube-system</span><br><span class="line">oc exec $&#123;ETCD_POD&#125; -c etcd -- /bin/sh -c &quot;ETCDCTL_API=3 etcdctl --cert /etc/etcd/peer.crt --key /etc/etcd/peer.key --cacert /etc/etcd/ca.crt --endpoints $ETCD_EP snapshot save /var/lib/etcd/snapshot.db&quot;</span><br><span class="line"></span><br><span class="line">today_date=$(date +%Y%m%d)</span><br><span class="line">mkdir -p /backup/$&#123;today_date&#125;/etcd</span><br><span class="line">mv /var/lib/etcd/snapshot.db /backup/$&#123;today_date&#125;/etcd/snapshot.db</span><br><span class="line"></span><br><span class="line">ls /backup/$&#123;today_date&#125;/etcd/</span><br><span class="line">echo &quot;success backup etcd&quot;</span><br></pre></td></tr></table></figure><p>一键恢复etcd脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat restore_etcd.sh </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">snapshot_file_dir=$1</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">echo &quot;Please input snapshot file path&quot;</span><br><span class="line">exit 2</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">export ETCD_POD_MANIFEST=&quot;/etc/origin/node/pods/etcd.yaml&quot;</span><br><span class="line">mv $&#123;ETCD_POD_MANIFEST&#125; .</span><br><span class="line">rm -rf /var/lib/etcd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 获取etcd相关初始化配置项</span></span></span><br><span class="line">ETCD_CONFIG_FILE=&quot;/etc/etcd/etcd.conf&quot;</span><br><span class="line">etcd_data_dir=$(grep ^ETCD_DATA_DIR= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line">etcd_name=$(grep ^ETCD_NAME= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line">etcd_initial_cluster=$(grep ^ETCD_INITIAL_CLUSTER= $ETCD_CONFIG_FILE|awk -F&#x27;ETCD_INITIAL_CLUSTER=&#x27; &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">etcd_initial_cluster_token=$(grep ^ETCD_INITIAL_CLUSTER_TOKEN= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line">etcd_initial_advertise_peer_urls=$(grep ^ETCD_INITIAL_ADVERTISE_PEER_URLS= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 恢复etcd数据</span></span></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl snapshot restore $snapshot_file_dir --data-dir $etcd_data_dir --name $etcd_name --initial-cluster &quot;$etcd_initial_cluster&quot; --initial-cluster-token &quot;$etcd_initial_cluster_token&quot; --initial-advertise-peer-urls $etcd_initial_advertise_peer_urls --skip-hash-check=true</span><br><span class="line"></span><br><span class="line">chown -R etcd.etcd /var/lib/etcd/</span><br><span class="line">restorecon -Rv /var/lib/etcd</span><br><span class="line"></span><br><span class="line">mv etcd.yaml $ETCD_POD_MANIFEST</span><br></pre></td></tr></table></figure><p>一键整理etcd数据，解决证书问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat reset.sh </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">oc login -u system:admin</span><br><span class="line"></span><br><span class="line">projects=$(oc get projects | awk &#x27;&#123;print $1&#125;&#x27; | grep -v kube-system|grep -v NAME)</span><br><span class="line"></span><br><span class="line">for project in $(echo $projects)</span><br><span class="line">do</span><br><span class="line">  oc delete secret $(oc get secret -n $project | grep token | awk &#x27;&#123;print $1&#125;&#x27;) -n $project</span><br><span class="line">  oc delete pod $(oc get pod -n $project | grep -v NAME | awk &#x27;&#123;print $1&#125;&#x27;) -n $project --force --grace-period=0</span><br><span class="line">done</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift开启Calico-BGP-与-OVS性能PK</title>
      <link href="/openshift/Openshift%E5%BC%80%E5%90%AFCalico-BGP-%E4%B8%8E-OVS%E6%80%A7%E8%83%BDPK/"/>
      <url>/openshift/Openshift%E5%BC%80%E5%90%AFCalico-BGP-%E4%B8%8E-OVS%E6%80%A7%E8%83%BDPK/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-d626dda51d450902.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="openshiftcalico"></p><h2 id="Openshift网络方案选择"><a href="#Openshift网络方案选择" class="headerlink" title="Openshift网络方案选择"></a>Openshift网络方案选择</h2><ul><li>大家都知道K8S在网络插件选择上有很多种，默认的是Flannel，但是它的性能一般，互联网中使用最多的是Calico BGP，因为它的性能非常好。</li><li>而对于Openshift，官方只支持ovs一种网络方案，同时RedHat也表示ovs在Openshift平台上运行是最合适的。但是ovs的网络性能怎样呢？因为ovs方案对数据需要进行加包，解包的过程，性能肯定是会受影响的。同时经过实测，在万兆网络中的损耗近50%，虽然在绝大部分场景下ovs已经够用了，但是但是跟几乎无损耗的Calico BGP比起来还是逊色不少。</li><li>很庆幸，Openshift虽然官方不作Calico网络方案的支持，但还是很体贴地把它加入到了Openshift的安装脚本中，从而让大家都能方便地使用Calico网络方案，包括IPIP及BGP方案。</li></ul><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><ol><li>在ansible hosts中设置关闭openshift默认的sdn方案，开启calico方案<br>&#x2F;etc&#x2F;ansible&#x2F;hosts<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line">os_sdn_network_plugin_name=cni</span><br><span class="line">openshift_use_calico=true</span><br><span class="line">openshift_use_openshift_sdn=false</span><br></pre></td></tr></table></figure></li><li>设置Calico网络配置<br>openshift-ansible&#x2F;roles&#x2F;calico&#x2F;defaults&#x2F;main.yaml<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">calico_ip_autodetection_method: &quot;first-found&quot;</span><br><span class="line">ip_pools:</span><br><span class="line">  apiVersion: projectcalico.org/v3</span><br><span class="line">  kind: IPPoolList</span><br><span class="line">  items:</span><br><span class="line">  - apiVersion: projectcalico.org/v3</span><br><span class="line">    kind: IPPool</span><br><span class="line">    metadata:</span><br><span class="line">      name: default-ipv4-ippool</span><br><span class="line">    spec:</span><br><span class="line">      cidr: &quot;&#123;&#123; openshift_cluster_network_cidr &#125;&#125;&quot;</span><br><span class="line">      ipipMode: Always  #默认是为Always，为IPIP模式</span><br><span class="line">      natOutgoing: true</span><br><span class="line">      nodeSelector: &quot;all()&quot;</span><br></pre></td></tr></table></figure><strong>配置说明（正确开启calico bgp网络的关键）：</strong><br>calico_ip_autodetection_method<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">calico_ip_autodetection_method: &quot;interface=eth0&quot;</span><br><span class="line"># 默认为“first-found”，如果各主机网络设备名不一样，可以使用正则</span><br><span class="line"># calico_ip_autodetection_method: &quot;interface=(eth0|eth1)&quot;</span><br></pre></td></tr></table></figure>spec.ipipMode<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipipMode: Always  #默认是为Always，为IPIP模式；Never为开启BGP模式</span><br></pre></td></tr></table></figure>完整配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">cni_conf_dir: &quot;/etc/cni/net.d/&quot;</span><br><span class="line">cni_bin_dir: &quot;/opt/cni/bin/&quot;</span><br><span class="line"></span><br><span class="line">calico_url_policy_controller: &quot;quay.io/calico/kube-controllers:v3.5.0&quot;</span><br><span class="line">calico_node_image: &quot;quay.io/calico/node:v3.5.0&quot;</span><br><span class="line">calico_cni_image: &quot;quay.io/calico/cni:v3.5.0&quot;</span><br><span class="line">calicoctl_image: &quot;quay.io/calico/ctl:v3.5.0&quot;</span><br><span class="line">calico_upgrade_image: &quot;quay.io/calico/upgrade:v1.0.5&quot;</span><br><span class="line">calico_ip_autodetection_method: &quot;interface=eth0&quot;</span><br><span class="line"># 默认为“first-found”，如果各主机网络设备名不一样，可以使用正则</span><br><span class="line"># calico_ip_autodetection_method: &quot;interface=(eth0|eth1)&quot;</span><br><span class="line">use_calico_etcd: False</span><br><span class="line"></span><br><span class="line"># Configure the IP Pool(s) from which Pod IPs will be chosen.</span><br><span class="line">ip_pools:</span><br><span class="line">  apiVersion: projectcalico.org/v3</span><br><span class="line">  kind: IPPoolList</span><br><span class="line">  items:</span><br><span class="line">  - apiVersion: projectcalico.org/v3</span><br><span class="line">    kind: IPPool</span><br><span class="line">    metadata:</span><br><span class="line">      name: default-ipv4-ippool</span><br><span class="line">    spec:</span><br><span class="line">      cidr: &quot;&#123;&#123; openshift_cluster_network_cidr &#125;&#125;&quot;</span><br><span class="line">      ipipMode: Never #默认是为Always，为IPIP模式；Never为开启BGP模式</span><br><span class="line">      natOutgoing: true</span><br><span class="line">      nodeSelector: &quot;all()&quot;</span><br><span class="line"></span><br><span class="line"># Options below are only valid for legacy Calico v2 installations,</span><br><span class="line"># and have been superceded by options above for Calico v3.</span><br><span class="line">calico_ipv4pool_ipip: &quot;always&quot;</span><br></pre></td></tr></table></figure></li><li>正常执行Openshift安装脚本<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/prerequisites.yml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook playbooks/deploy_cluster.yml</span></span><br></pre></td></tr></table></figure></li><li>查看网络<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">[root@master1 ~]# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link/ether 52:54:fc:dd:fc:ed brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.0.3/24 brd 192.168.0.255 scope global dynamic eth0</span><br><span class="line">       valid_lft 86262sec preferred_lft 86262sec</span><br><span class="line">    inet6 fe80::248:584e:2626:2269/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN </span><br><span class="line">    link/ether 02:42:46:89:5d:d0 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: cali252a8913dc3@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP </span><br><span class="line">    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet6 fe80::ecee:eeff:feee:eeee/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: cali6d8bb449db0@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP </span><br><span class="line">    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 1</span><br><span class="line">    inet6 fe80::ecee:eeff:feee:eeee/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: cali9efe4d704f6@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP </span><br><span class="line">    link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff link-netnsid 2</span><br><span class="line">    inet6 fe80::ecee:eeff:feee:eeee/64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">[root@master1 ~]# ip route</span><br><span class="line">default via 192.168.0.1 dev eth0 proto static metric 100 </span><br><span class="line">10.128.113.64/26 via 192.168.0.7 dev eth0 proto bird </span><br><span class="line">10.128.141.128/26 via 192.168.0.4 dev eth0 proto bird </span><br><span class="line">10.129.8.0/26 via 192.168.0.9 dev eth0 proto bird </span><br><span class="line">10.129.182.192/26 via 192.168.0.8 dev eth0 proto bird </span><br><span class="line">10.129.200.0/26 via 192.168.0.6 dev eth0 proto bird </span><br><span class="line">10.130.193.128/26 via 192.168.0.10 dev eth0 proto bird </span><br><span class="line">blackhole 10.131.9.192/26 proto bird </span><br><span class="line">10.131.9.206 dev cali252a8913dc3 scope link </span><br><span class="line">10.131.9.207 dev cali6d8bb449db0 scope link </span><br><span class="line">10.131.9.208 dev cali9efe4d704f6 scope link </span><br><span class="line">10.131.42.192/26 via 192.168.0.11 dev eth0 proto bird </span><br><span class="line">10.131.148.0/26 via 192.168.0.5 dev eth0 proto bird </span><br><span class="line">172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 </span><br><span class="line">192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.3 metric 100 </span><br></pre></td></tr></table></figure></li></ol><p>说明：如果要部署路由反射（RR）模式，可参考<a href="https://www.jianshu.com/p/1ea22c6d26fd">OpenShift支持Calico BGP 路由反射（RR）模式</a></p><h2 id="网络性能测试"><a href="#网络性能测试" class="headerlink" title="网络性能测试"></a>网络性能测试</h2><p>测试环境为公有云平台上的虚拟机<br>###iperf测试Pod吞吐量</p><h4 id="测试方法与步骤"><a href="#测试方法与步骤" class="headerlink" title="测试方法与步骤"></a>测试方法与步骤</h4><ol><li>部署iperf服务端<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project <span class="built_in">test</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc run iperf-server --image=registry.dcs.cmbchina.cn:9443/tools/iperf3 -- -s</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod -o wide</span></span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">iperf-server-1-r6z2x   1/1       Running   0          3m        10.131.2.76  node1</span><br></pre></td></tr></table></figure></li><li>部署iperf客户端<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc run iperf-client --image=registry.dcs.cmbchina.cn:9443/tools/iperf3 -n project-e --<span class="built_in">command</span> -- <span class="built_in">sleep</span> 10000</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod -o wide | grep qperf</span></span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">iperf-client-3-gtr2l   1/1       Running   0          2h        10.130.0.70   node2</span><br><span class="line">qperf-server-1-xxmhz   1/1       Running   0          4h        10.128.2.59    node1</span><br></pre></td></tr></table></figure></li><li>iperf3客户端测试iperf3(pod)吞吐量<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsh iperf-client-3-gtr2l</span></span><br><span class="line"><span class="meta prompt_">  $ </span><span class="language-bash">iperf3 -c 10.131.2.76</span> </span><br></pre></td></tr></table></figure></li></ol><h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>ovs网络方案测试结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Connecting to host 10.130.0.51, port 5201</span><br><span class="line">[  4] local 10.129.0.50 port 42924 connected to 10.130.0.51 port 5201</span><br><span class="line">[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd</span><br><span class="line">[  4]   0.00-1.00   sec   282 MBytes  2.36 Gbits/sec  1406    638 KBytes       </span><br><span class="line">[  4]   1.00-2.00   sec   326 MBytes  2.74 Gbits/sec  2484    797 KBytes       </span><br><span class="line">[  4]   2.00-3.00   sec   324 MBytes  2.71 Gbits/sec  2136    692 KBytes       </span><br><span class="line">[  4]   3.00-4.00   sec   314 MBytes  2.63 Gbits/sec  3907    744 KBytes       </span><br><span class="line">[  4]   4.00-5.00   sec   323 MBytes  2.71 Gbits/sec  1539    811 KBytes       </span><br><span class="line">[  4]   5.00-6.00   sec   323 MBytes  2.71 Gbits/sec  1996    685 KBytes       </span><br><span class="line">[  4]   6.00-7.00   sec   318 MBytes  2.67 Gbits/sec  1085    891 KBytes       </span><br><span class="line">[  4]   7.00-8.00   sec   286 MBytes  2.40 Gbits/sec  2534    744 KBytes       </span><br><span class="line">[  4]   8.00-9.00   sec   336 MBytes  2.82 Gbits/sec  1856    793 KBytes       </span><br><span class="line">[  4]   9.00-10.00  sec   256 MBytes  2.14 Gbits/sec  2256    452 KBytes       </span><br><span class="line">- - - - - - - - - - - - - - - - - - - - - - - - -</span><br><span class="line">[ ID] Interval           Transfer     Bandwidth       Retr</span><br><span class="line">[  4]   0.00-10.00  sec  3.01 GBytes  2.59 Gbits/sec  21199             sender</span><br><span class="line">[  4]   0.00-10.00  sec  3.01 GBytes  2.59 Gbits/sec                  receiver</span><br><span class="line"></span><br><span class="line">iperf Done.</span><br></pre></td></tr></table></figure><p>calico bgp网络方案测试结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Connecting to host 10.129.8.3, port 5201</span><br><span class="line">[  4] local 10.130.193.131 port 46222 connected to 10.129.8.3 port 5201</span><br><span class="line">[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd</span><br><span class="line">[  4]   0.00-1.00   sec   735 MBytes  6.17 Gbits/sec  204    655 KBytes       </span><br><span class="line">[  4]   1.00-2.00   sec   914 MBytes  7.67 Gbits/sec  353    818 KBytes       </span><br><span class="line">[  4]   2.00-3.00   sec  1.01 GBytes  8.70 Gbits/sec    0   1.44 MBytes       </span><br><span class="line">[  4]   3.00-4.00   sec  1.02 GBytes  8.76 Gbits/sec  465   1.87 MBytes       </span><br><span class="line">[  4]   4.00-5.00   sec  1.02 GBytes  8.79 Gbits/sec  184   2.20 MBytes       </span><br><span class="line">[  4]   5.00-6.00   sec  1.03 GBytes  8.81 Gbits/sec  596   1.33 MBytes       </span><br><span class="line">[  4]   6.00-7.00   sec  1012 MBytes  8.49 Gbits/sec   17   1.28 MBytes       </span><br><span class="line">[  4]   7.00-8.00   sec  1.02 GBytes  8.79 Gbits/sec   46   1.31 MBytes       </span><br><span class="line">[  4]   8.00-9.00   sec  1.01 GBytes  8.69 Gbits/sec   87   1.26 MBytes       </span><br><span class="line">[  4]   9.00-10.00  sec  1.02 GBytes  8.73 Gbits/sec  133   1.21 MBytes       </span><br><span class="line">- - - - - - - - - - - - - - - - - - - - - - - - -</span><br><span class="line">[ ID] Interval           Transfer     Bandwidth       Retr</span><br><span class="line">[  4]   0.00-10.00  sec  9.73 GBytes  8.36 Gbits/sec  2085             sender</span><br><span class="line">[  4]   0.00-10.00  sec  9.73 GBytes  8.36 Gbits/sec                  receiver</span><br><span class="line"></span><br><span class="line">iperf Done.</span><br></pre></td></tr></table></figure><table><thead><tr><th>网络方案</th><th>传输数据量</th><th>传输速率</th></tr></thead><tbody><tr><td>ovs方案</td><td>3.01 GB</td><td>2.59 Gb</td></tr><tr><td>calico bgp方案</td><td>9.73 GB</td><td>8.36 Gb</td></tr></tbody></table><h3 id="qperf测试网络带宽与延时"><a href="#qperf测试网络带宽与延时" class="headerlink" title="qperf测试网络带宽与延时"></a>qperf测试网络带宽与延时</h3><h4 id="测试方法与步骤-1"><a href="#测试方法与步骤-1" class="headerlink" title="测试方法与步骤"></a>测试方法与步骤</h4><ol><li>部署qperf服务端<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc run qperf-server --image=registry.dcs.cmbchina.cn:9443/tools/qperf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod -o wide</span></span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">qperf-server-1-xxmhz   1/1       Running   0          4h        10.128.2.59    node1</span><br></pre></td></tr></table></figure></li><li>部署qperf客户端<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc run qperf-client --image=registry.dcs.cmbchina.cn:9443/tools/qperf --<span class="built_in">command</span> -- <span class="built_in">sleep</span> 10000</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod -o wide -n project-e | grep qperf</span></span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">qperf-client-2-7jmvb   1/1       Running   0          4h        10.130.2.224   node2</span><br><span class="line">qperf-server-1-xxmhz   1/1       Running   0          4h        10.128.2.59    node1</span><br></pre></td></tr></table></figure></li><li>qperf客户端测试qperf(pod)带宽与延时<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsh qperf-client-2-7jmvb</span></span><br><span class="line"><span class="meta prompt_">  $ </span><span class="language-bash">qperf 10.128.2.59 -t 10 -oo msg_size:8:256K:*2 tcp_bw tcp_lat</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="测试结果-1"><a href="#测试结果-1" class="headerlink" title="测试结果"></a>测试结果</h4><p>ovs网络方案qperf测试结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">tcp_bw:</span><br><span class="line">    bw  =  15 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  26.4 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  40.7 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  59.5 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  76.1 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  194 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  239 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  256 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  258 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  262 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  259 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  250 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  272 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  291 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  272 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  282 MB/sec</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  34.2 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  34.3 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  33.9 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  33.4 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  34.1 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  34.1 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  34.2 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  34.8 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  46.3 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  56 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  86.5 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  133 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  219 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  435 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  733 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  1.27 ms</span><br></pre></td></tr></table></figure><p>calico bgp网络方案qperf测试结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">tcp_bw:</span><br><span class="line">    bw  =  17 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  32.1 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  39.4 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  81.7 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  141 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  297 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  703 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  790 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  845 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  708 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  830 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  884 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  768 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  787 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  749 MB/sec</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw  =  780 MB/sec</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  95.8 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  71.5 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  69.1 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  69.6 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  72.7 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  84 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  93.3 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  86.3 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  145 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  139 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  158 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  171 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  198 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  459 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  593 us</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency  =  881 us</span><br></pre></td></tr></table></figure><table><thead><tr><th>包大小</th><th>ovs方案带宽</th><th>calico bgp方案带宽</th><th>ovs方案时延</th><th>calico bgp方案时延</th></tr></thead><tbody><tr><td>msg_size</td><td>ovs tcp_bw</td><td>calico bgp tcp_bw</td><td>ovs tcp_lat</td><td>calico bgp tcp_lat</td></tr><tr><td>8bytes</td><td>15 MB&#x2F;sec</td><td>17 MB&#x2F;sec</td><td>34.2 us</td><td>95.8 us</td></tr><tr><td>16bytes</td><td>26.4 MB&#x2F;sec</td><td>32.1 MB&#x2F;sec</td><td>34.4 us</td><td>71.5 us</td></tr><tr><td>32bytes</td><td>40.7 MB&#x2F;sec</td><td>39.4 MB&#x2F;sec</td><td>33.9 us</td><td>69.1 us</td></tr><tr><td>64bytes</td><td>59.5MB&#x2F;sec</td><td>81.7 MB&#x2F;sec</td><td>33.4 us</td><td>69.6 us</td></tr><tr><td>128bytes</td><td>76.1 MB&#x2F;sec</td><td>141 MB&#x2F;sec</td><td>34.1 us</td><td>72.7 us</td></tr><tr><td>256bytes</td><td>194 MB&#x2F;sec</td><td>297 MB&#x2F;sec</td><td>34.1 us</td><td>84 us</td></tr><tr><td>512bytes</td><td>239 MB&#x2F;sec</td><td>703 MB&#x2F;sec</td><td>34.2 us</td><td>93.3 us</td></tr><tr><td>1KiB</td><td>256 MB&#x2F;sec</td><td>790 MB&#x2F;sec</td><td>34.8 us</td><td>86.3 us</td></tr><tr><td>2KiB</td><td>258 MB&#x2F;sec</td><td>845 MB&#x2F;sec</td><td>46.3 us</td><td>145 us</td></tr><tr><td>4KiB</td><td>262 MB&#x2F;sec</td><td>708 MB&#x2F;sec</td><td>56 us</td><td>139 us</td></tr><tr><td>8KiB</td><td>259 MB&#x2F;sec</td><td>830 MB&#x2F;sec</td><td>86.5 us</td><td>158 us</td></tr><tr><td>16KiB</td><td>250 MB&#x2F;sec</td><td>884 MB&#x2F;sec</td><td>133 us</td><td>171 us</td></tr><tr><td>32KiB</td><td>272 MB&#x2F;sec</td><td>768 MB&#x2F;sec</td><td>219 us</td><td>198 us</td></tr><tr><td>64KiB</td><td>291 MB&#x2F;sec</td><td>787 MB&#x2F;sec</td><td>435 us</td><td>459 us</td></tr><tr><td>128KiB</td><td>272 MB&#x2F;sec</td><td>749 MB&#x2F;sec</td><td>733 us</td><td>593 us</td></tr><tr><td>256KiB</td><td>282 MB&#x2F;sec</td><td>780 MB&#x2F;sec</td><td>1.27 ms</td><td>881 us</td></tr></tbody></table><h3 id="结果总结"><a href="#结果总结" class="headerlink" title="结果总结"></a>结果总结</h3><p>从测试的数据中可以看到<strong>对于小包传输，Calico BGP的优势并不明显，同时它的网络延时甚至会更高,而对于大包传输，Calico BGP网络方案明显好于ovs方案</strong>。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-8cda3aa4c3dd47a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="欢迎关注"></p><hr><p>文章已结束，以下并没有内容了。<br>#</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift排错技巧——From-Redhat大客户交流会</title>
      <link href="/openshift/Openshift%E6%8E%92%E9%94%99%E6%8A%80%E5%B7%A7%E2%80%94%E2%80%94From-Redhat%E5%A4%A7%E5%AE%A2%E6%88%B7%E4%BA%A4%E6%B5%81%E4%BC%9A/"/>
      <url>/openshift/Openshift%E6%8E%92%E9%94%99%E6%8A%80%E5%B7%A7%E2%80%94%E2%80%94From-Redhat%E5%A4%A7%E5%AE%A2%E6%88%B7%E4%BA%A4%E6%B5%81%E4%BC%9A/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-4766b75bdae75d55.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="redhat"></p><p>今天参加Redhat大客户交流会，有一个主题是Redhat的小伙伴介绍Openshift的排错技巧。这个还是很值得参考的，于是将内容发在了这里，以便更多的小伙伴能够从中受益。当然Redhat小伙伴列出的也只是一部分，同时有些排错细节PPT中也并没有具体写，这篇中我就不扩展了。以下为PPT的内容。</p><h2 id="OpenShift排错技巧"><a href="#OpenShift排错技巧" class="headerlink" title="OpenShift排错技巧"></a>OpenShift排错技巧</h2><ol><li>环境基本信息收集</li><li>日志等级</li><li>应用程序</li><li>OC客户端排错</li><li>镜像仓库</li><li>网络</li><li>路由</li><li>Installer</li><li>DNS</li><li>Etcd</li></ol><h2 id="日志等级"><a href="#日志等级" class="headerlink" title="日志等级"></a>日志等级</h2><p>openshift service log:<br>&#x2F;etc&#x2F;origin&#x2F;master&#x2F;master.env #同时作用于API和Controllers<br>DEBUG_LOGLEVEL&#x3D;4</p><p>&#x2F;etc&#x2F;sysconfig&#x2F;atomic-openshift-node<br>OPTIONS&#x3D;–loglevel&#x3D;4</p><p>错误等级</p><ul><li>0 - Errors and warning only</li><li>2 - Normal information</li><li>4 - Debugging-level information</li><li>6 - API-level debugging information (request &#x2F; response)</li><li>8 - Body-level API debugging information</li></ul><p>Docker Log level<br>&#x2F;etc&#x2F;sysconfig&#x2F;docker –log-level&#x3D;debug</p><p>Etcd Log level<br># source &#x2F;etc&#x2F;etcd&#x2F;etcd.conf<br># curl –cert $ETCD_PEER_CERT_FILE –key $ETCD_PEER_KEY_FILE –cacert $ETCD_TRUSTED_CA_FILE $ETCD_ADVERTISE_CLIENT_URLS&#x2F;config&#x2F;local&#x2F;log -XPUT -d ‘{“Level”:”DEBUG”}’</p><p>Get Log<br># &#x2F;usr&#x2F;local&#x2F;bin&#x2F;master-logs etcd etcd &gt; $(hostname)-etcd.log 2&gt;&amp;1</p><p>OpenShift Builder Pod Logs<br>BUILD_LOGLEVEL in BC&#x2F;env ## BC的环境变量中设置</p><h2 id="应用日志"><a href="#应用日志" class="headerlink" title="应用日志"></a>应用日志</h2><p>三个不同阶段： build errors, deployment errors 和applications errors</p><p>Build Errors<br># oc logs bc&#x2F;<build_pod></p><p>Deployment Errors<br># oc get status -o wide -n <project><br># oc get events -o wide -n <project></p><p>Application Errors<br># oc logs pod&#x2F;<pod> -p<br># oc debug pod&#x2F;<POD_NAME><br>deploy a version of this pod without liveness and rediness probes as well as setting the entrypoint to the shell.</p><h2 id="OC客户端"><a href="#OC客户端" class="headerlink" title="OC客户端"></a>OC客户端</h2><p>oc客户端日志等级<br># oc whoami –loglevel&#x3D;8</p><p>Setting this value between 6 and 8 will provide extensive logging</p><p>API requests being send (loglevel 6)<br>headers (loglevel 7)<br>responses received (loglevel 8)</p><h2 id="OpenShift-Registry"><a href="#OpenShift-Registry" class="headerlink" title="OpenShift Registry"></a>OpenShift Registry</h2><p>健康检查<br>基本的健康检查、保证Registry正常运行并且正常响应其对应的service地址</p><p># RegistryAddr&#x3D;$(oc get svc docker-registry -n default -o jsonpath&#x3D;{.spec.clusterIP}:{.spec.ports[0].port})</p><p># curl -vk https:&#x2F;&#x2F;$RegistryAddr&#x2F;healthz</p><p>测试镜像仓库<br>docker login -u openshift -p $(oc whoami -t) <registry_ip>:<port><br>docker pull&#x2F;tag&#x2F;push</p><p>如果使用存储<br># oc rsh $(oc get pods -o name -l docker-registry -n default)</p><h2 id="OpenShift-Networking"><a href="#OpenShift-Networking" class="headerlink" title="OpenShift Networking"></a>OpenShift Networking</h2><p>Debugging External Access to an HTTP Service<br>Debugging Node to Node Networking<br>Debugging Local Networking</p><p>使用NetWorking Diagnostics Tool检查网络状况<br><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/sdn_troubleshooting.html">https://docs.openshift.com/container-platform/3.11/admin_guide/sdn_troubleshooting.html</a></p><h2 id="OpenShift-Routing"><a href="#OpenShift-Routing" class="headerlink" title="OpenShift Routing"></a>OpenShift Routing</h2><p>分段检查 定位问题 curl pod &#x2F; svc</p><p>$ oc logs dc&#x2F;router -n default<br>$ oc get dc&#x2F;router -o yaml default<br>$ oc get route <NAME_OF_ROUTE> -n <PROJECT><br>$ oc get endpoints –all-namespaces<br>$ oc exec -it $ROUTER_POD – ls -la<br>$ oc exec -it $ROUTER_POD – find &#x2F;var&#x2F;lib&#x2F;haproxy -regex  “.*(.map|config.*|.json)“ -print -exec cat {} ; &gt; haproxy_configs_and_maps</p><p>router log</p><p>Router健康状态查看<br><a href="http://admin/">http://admin</a>:<stats-password>@<master-ip>:1936&#x2F;haproxy_stats</p><p>enable access log to syslog server</p><h2 id="OpenShift-Installer"><a href="#OpenShift-Installer" class="headerlink" title="OpenShift Installer"></a>OpenShift Installer</h2><p>OpenShift Ansible Playbooks</p><p># ansible-playbook <PLAYBOOK> -vvv | tee ansible.logs</p><p>如果在某一个task上失败，可以访问github上的源码查找对应task具体操作步骤：<br>Access the Git Hub Install Repo: openshift&#x2F;openshift-ansible</p><h2 id="OpenShift-DNS"><a href="#OpenShift-DNS" class="headerlink" title="OpenShift DNS"></a>OpenShift DNS</h2><p>Dnsmasq 是一个小型的DNS缓存服务器。它可以根据缓存来响应DNS查询或将其转发到外部真实的DNS服务器上，它安装在每个节点上。</p><p>Skydns是一个建立在ETCD之上的DNS服务器，它嵌入在节点的进程中，主要负责相应内部service的解析。</p><p>NetworkManager会启动origin dispatcher &#x2F;etc&#x2F;NetworkManager&#x2F;dispatcher.d&#x2F;99-origin-dns.sh以配置&#x2F;etc&#x2F;resolv.conf和一些其他文件</p><p>NetworkManager<br>请确定NetworkManger服务正常运行<br>请查看&#x2F;etc&#x2F;NetworkManager&#x2F;dispatch.d&#x2F;99-origin-dns.sh为可执行<br>请确定&#x2F;etc&#x2F;resolv.conf文件包含主机的私网IP，并且有正确的search域。&#x2F;etc&#x2F;resolv.conf是由NetworkManager服务生成的</p><p>请检查dnsmasq服务是否ok<br>systemctl status dnsmasq -l</p><h2 id="OpenShift-Etcd"><a href="#OpenShift-Etcd" class="headerlink" title="OpenShift Etcd"></a>OpenShift Etcd</h2><p>设置etcd变量<br># source &#x2F;etc&#x2F;etcd&#x2F;etcd.conf<br># export ETCDCTL_API&#x3D;3</p><p>Set endpoint variable to include all etcd endpoints<br># ETCD_ALL_ENDPOINTS&#x3D;$(etcdctl –cert&#x3D;$ETCD_PEER_CERT_FILE –key $ETCD_PEER_KEY_FILE –cacert $ETCD_TRUSTED_CA_FILE –endpoints&#x3D;$ETCD_LISTEN_CLIENT_URLS –write-out&#x3D;fields member list  | awk ‘&#x2F;ClientURL&#x2F;{printf”%s%s”, sep, $3; sep&#x3D;”,”}’)</p><p>check health of etcd<br># etcdctl –cert&#x3D;$ETCD_PEER_CERT_FILE –key $ETCD_PEER_KEY_FILE –cacert $ETCD_TRUSTED_CA_FILE –endpoints&#x3D;$ETCD_LISTEN_CLIENT_URLS –write-out&#x3D;table endpoint status</p><p># etcdctl –cert&#x3D;$ETCD_PEER_CERT_FILE –key $ETCD_PEER_KEY_FILE –cacert $ETCD_TRUSTED_CA_FILE –endpoints&#x3D;$ETCD_LISTEN_CLIENT_URLS –write-out&#x3D;table endpoint health</p><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><p>推荐<br>Red Hat OpenShift Container Platform Life Cycle Policy<br><a href="https://access.redhat.com/support/policy/updates/openshift">https://access.redhat.com/support/policy/updates/openshift</a></p><p>OpenShift Container Platform Tested Integrations supported configuration<br><a href="https://access.redhat.com/articles/2176281">https://access.redhat.com/articles/2176281</a></p><p>不推荐</p><ol><li>Master节点和Infra节点混用</li><li>外部负载均衡和openshift节点混用</li><li>单独升级某个组件版本</li><li>service ip</li></ol><h2 id="排错指南推荐"><a href="#排错指南推荐" class="headerlink" title="排错指南推荐"></a>排错指南推荐</h2><p>Troubleshooting OpenShift Container Platform: Cluster Metrics<br><a href="https://access.redhat.com/articles/2448341">https://access.redhat.com/articles/2448341</a></p><p>Troubleshooting OpenShift Container Platform 3.x: Aggregating Container Logging<br><a href="https://access.redhat.com/articles/3136551">https://access.redhat.com/articles/3136551</a></p><p>Troubleshooting OpenShift Container Platform: Middleware Containers<br><a href="https://access.redhat.com/articles/3135421">https://access.redhat.com/articles/3135421</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift模板之项目创建模板（资源限制）</title>
      <link href="/openshift/Openshift%E6%A8%A1%E6%9D%BF%E4%B9%8B%E9%A1%B9%E7%9B%AE%E5%88%9B%E5%BB%BA%E6%A8%A1%E6%9D%BF%EF%BC%88%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%EF%BC%89/"/>
      <url>/openshift/Openshift%E6%A8%A1%E6%9D%BF%E4%B9%8B%E9%A1%B9%E7%9B%AE%E5%88%9B%E5%BB%BA%E6%A8%A1%E6%9D%BF%EF%BC%88%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>Openshift创建project时，可以按照设定的模板来创建，这就省去了很多初始化的工作。<br>###文件内容(template.yaml)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Template</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  name: project-request</span><br><span class="line">objects:</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: Project</span><br><span class="line">  metadata:</span><br><span class="line">    annotations:</span><br><span class="line">      openshift.io/description: $&#123;PROJECT_DESCRIPTION&#125;</span><br><span class="line">      openshift.io/display-name: $&#123;PROJECT_DISPLAYNAME&#125;</span><br><span class="line">      openshift.io/requester: $&#123;PROJECT_REQUESTING_USER&#125;</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  spec: &#123;&#125;</span><br><span class="line">  status: &#123;&#125;</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: ResourceQuota</span><br><span class="line">  metadata:</span><br><span class="line">    name: $&#123;PROJECT_NAME&#125;-quota</span><br><span class="line">  spec:</span><br><span class="line">    hard:</span><br><span class="line">      pods: 10</span><br><span class="line">      requests.cpu: 4000m</span><br><span class="line">      requests.memory: 8Gi</span><br><span class="line">      resourcequotas: 1</span><br><span class="line">      requests.storage: 25Gi</span><br><span class="line">      persistentvolumeclaims: 5</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  kind: LimitRange</span><br><span class="line">  metadata: </span><br><span class="line">    name: $&#123;PROJECT_NAME&#125;-limits</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">  spec: </span><br><span class="line">    limits: </span><br><span class="line">      - </span><br><span class="line">        type: Container</span><br><span class="line">        max: </span><br><span class="line">          cpu: 4000m</span><br><span class="line">          memory: 1024Mi</span><br><span class="line">        min: </span><br><span class="line">          cpu: 10m</span><br><span class="line">          memory: 5Mi</span><br><span class="line">        default: </span><br><span class="line">          cpu: 4000m</span><br><span class="line">          memory: 1024Mi</span><br><span class="line">        defaultRequest:</span><br><span class="line">          cpu: 100m</span><br><span class="line">          memory: 512Mi</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  groupNames:</span><br><span class="line">  - system:serviceaccounts:$&#123;PROJECT_NAME&#125;</span><br><span class="line">  kind: RoleBinding</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: system:image-pullers</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  roleRef:</span><br><span class="line">    name: system:image-puller</span><br><span class="line">  subjects:</span><br><span class="line">  - kind: SystemGroup</span><br><span class="line">    name: system:serviceaccounts:$&#123;PROJECT_NAME&#125;</span><br><span class="line">  userNames: null</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  groupNames: null</span><br><span class="line">  kind: RoleBinding</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: system:image-builders</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  roleRef:</span><br><span class="line">    name: system:image-builder</span><br><span class="line">  subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: builder</span><br><span class="line">  userNames:</span><br><span class="line">  - system:serviceaccount:$&#123;PROJECT_NAME&#125;:builder</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  groupNames: null</span><br><span class="line">  kind: RoleBinding</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: system:deployers</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  roleRef:</span><br><span class="line">    name: system:deployer</span><br><span class="line">  subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: deployer</span><br><span class="line">  userNames:</span><br><span class="line">  - system:serviceaccount:$&#123;PROJECT_NAME&#125;:deployer</span><br><span class="line">- apiVersion: v1</span><br><span class="line">  groupNames: null</span><br><span class="line">  kind: RoleBinding</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: null</span><br><span class="line">    name: admin</span><br><span class="line">    namespace: $&#123;PROJECT_NAME&#125;</span><br><span class="line">  roleRef:</span><br><span class="line">    name: admin</span><br><span class="line">  subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: $&#123;PROJECT_ADMIN_USER&#125;</span><br><span class="line">  userNames:</span><br><span class="line">  - $&#123;PROJECT_ADMIN_USER&#125;</span><br><span class="line">parameters:</span><br><span class="line">- name: PROJECT_NAME</span><br><span class="line">- name: PROJECT_DISPLAYNAME</span><br><span class="line">- name: PROJECT_DESCRIPTION</span><br><span class="line">- name: PROJECT_ADMIN_USER</span><br><span class="line">- name: PROJECT_REQUESTING_USER</span><br></pre></td></tr></table></figure><h3 id="将它导入模板"><a href="#将它导入模板" class="headerlink" title="将它导入模板"></a>将它导入模板</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc create -f template.yaml -n default</span><br></pre></td></tr></table></figure><h3 id="将它设为Project默认配置"><a href="#将它设为Project默认配置" class="headerlink" title="将它设为Project默认配置"></a>将它设为Project默认配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#/etc/origin/master/master-config.yaml</span><br><span class="line">...</span><br><span class="line">projectConfig:</span><br><span class="line">  projectRequestTemplate: &quot;default/project-request&quot;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><h3 id="重启Master，使配置生效"><a href="#重启Master，使配置生效" class="headerlink" title="重启Master，使配置生效"></a>重启Master，使配置生效</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart atomic-openshift-master</span><br></pre></td></tr></table></figure><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc new-project tem-test</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift生产环境部署配置事项</title>
      <link href="/openshift/Openshift%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%BA%8B%E9%A1%B9/"/>
      <url>/openshift/Openshift%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%E4%BA%8B%E9%A1%B9/</url>
      
        <content type="html"><![CDATA[<h2 id="1-主机配置推荐"><a href="#1-主机配置推荐" class="headerlink" title="1. 主机配置推荐"></a>1. 主机配置推荐</h2><ul><li>master 16核 32GB 网卡带宽不低于1Gb。<br>CPU x86_64架构，核数和主机数线性递增，每增加一台主机增加0.1核。5台主机4.5核，总的核数为4+0.1 * 主机数<br>内存与主机数线性递增，每增一台主机增加200M内存，5台8G，总的内存数为7+0.2 * 主机数</li><li>node 40核 256GB  网卡带宽不低于1Gb<br>根据应用场景估算</li></ul><h2 id="2-磁盘目录挂载"><a href="#2-磁盘目录挂载" class="headerlink" title="2. 磁盘目录挂载"></a>2. 磁盘目录挂载</h2><ul><li>master<br>磁盘格式：xfs ftype&#x3D;1<br>&#x2F; : 10GB<br>&#x2F;var&#x2F;log ：50GB<br>&#x2F;var&#x2F;lib&#x2F;docker：100GB 做raid高可用<br>&#x2F;var&#x2F;lib&#x2F;etcd [ssd]：20GB 做raid高可用<br>&#x2F;var ：50GB 可根据实际进行调整，主要emptyDir的存储在&#x2F;var&#x2F;lib&#x2F;origin目录下</li><li>node<br>磁盘格式：xfs ftype&#x3D;1<br>&#x2F; : 10GB<br>&#x2F;var&#x2F;log ：50GB<br>&#x2F;var&#x2F;lib&#x2F;docker：100GB 做raid高可用<br>&#x2F;var ：50GB 可根据实际进行调整，主要emptyDir的存储在&#x2F;var&#x2F;lib&#x2F;origin目录下<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkfs.xfs -n ftype=1 /path/to/your/device</span><br></pre></td></tr></table></figure>说明：xfs文件格式，docker overlay2存储设备必须设置<code>ftype=1</code>。</li></ul><h2 id="3-关闭swap"><a href="#3-关闭swap" class="headerlink" title="3. 关闭swap"></a>3. 关闭swap</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">cat /etc/fstab ## 注释掉swap</span><br></pre></td></tr></table></figure><h2 id="4-打开seLinux-enabled"><a href="#4-打开seLinux-enabled" class="headerlink" title="4. 打开seLinux enabled"></a>4. 打开seLinux enabled</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#x27;s/SELINUX=disabled/SELINUX=permissive/&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure><h2 id="5-设置系统参数"><a href="#5-设置系统参数" class="headerlink" title="5. 设置系统参数"></a>5. 设置系统参数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/sysctl.conf </span><br><span class="line"># 禁用整个系统所有接口的IPv6</span><br><span class="line">net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">net.netfilter.nf_conntrack_max = 1000000</span><br><span class="line">$ lsmod | grep conntrack || modprobe ip_conntrack</span><br><span class="line">$ sysctl -w net.netfilter.nf_conntrack_max=1000000</span><br><span class="line">$ sysctl -p /etc/sysctl.conf</span><br></pre></td></tr></table></figure><h2 id="6-更改resolve-conf"><a href="#6-更改resolve-conf" class="headerlink" title="6. 更改resolve.conf"></a>6. 更改resolve.conf</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/resolv.conf</span><br><span class="line">search cluster.local</span><br><span class="line">nameserver 192.168.0.2</span><br></pre></td></tr></table></figure><h2 id="7-时间同步"><a href="#7-时间同步" class="headerlink" title="7. 时间同步"></a>7. 时间同步</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m package -a &#x27;name=chrony state=present&#x27;</span><br><span class="line"></span><br><span class="line">## chronyd服务端配置</span><br><span class="line">$ cat /etc/chrony.conf</span><br><span class="line">server 55.15.226.193 iburst</span><br><span class="line">allow 55.15.226.0/24</span><br><span class="line">local stratum 10</span><br></pre></td></tr></table></figure><p>强制同步时间</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## chrony客户端配置</span><br><span class="line">chronyc sources -v</span><br><span class="line">systemctl stop chronyd</span><br><span class="line">chronyd -q &#x27;pool 55.15.226.193 iburst&#x27;</span><br></pre></td></tr></table></figure><h2 id="8-创建docker-用户组"><a href="#8-创建docker-用户组" class="headerlink" title="8.创建docker 用户组"></a>8.创建docker 用户组</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groupadd docker</span><br></pre></td></tr></table></figure><p>将普通用户添加到docker用户组</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod -aG docker $&#123;USER&#125;</span><br></pre></td></tr></table></figure><h2 id="9-docker设置"><a href="#9-docker设置" class="headerlink" title="9. docker设置"></a>9. docker设置</h2><p>&#x2F;etc&#x2F;sysconfig&#x2F;docker-storage<br>DOCKER_STORAGE_OPTIONS&#x3D;”–storage-driver overlay2 “<br>&#x2F;etc&#x2F;sysconfig&#x2F;docker<br>OPTIONS&#x3D;” –log-opt max-size&#x3D;1M –log-opt max-file&#x3D;3 –live-restore&#x3D;true “</p><p>设置docker与kubelet的<code>cgroup driver</code>为systemd。OpenShift默认安装就是设置的systemd，而社区版的kubelet默认是cgroupfs，需要注意。。</p><h2 id="10-网卡配置"><a href="#10-网卡配置" class="headerlink" title="10. 网卡配置"></a>10. 网卡配置</h2><ul><li>配置网卡多队列：<code>ethtool -l eth0</code>查看网卡多队列Combined数</li><li><strong>NetworkManager</strong>, 是一个提供网络检测和配置网络的工具，在Node节点需要使用它来自动配置节点的dnsmasq作为默认的网络入口。</li><li>网络设备的配置中**&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth***默认<code>NM_CONTROLLED</code>是被设置为<code>yes</code>,如果它被设置为<code>no</code>，那么NetworkManager应用将不会去自动创建dnsmasq相关的配置，所以此时需要手动配置dnsmasq。</li></ul><p>添加文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/dnsmasq.d/origin-upstream-dns.conf</span><br><span class="line">server=192.168.0.2</span><br><span class="line">$ cat /etc/origin/node/resolv.conf</span><br><span class="line">nameserver 192.168.0.2</span><br></pre></td></tr></table></figure><h4 id="参考-install-config-network-using-firewalld"><a href="#参考-install-config-network-using-firewalld" class="headerlink" title="参考 install-config-network-using-firewalld"></a>参考 <a href="https://docs.okd.io/3.9/install_config/install/prerequisites.html#install-config-network-using-firewalld">install-config-network-using-firewalld</a></h4><h2 id="11-多网卡"><a href="#11-多网卡" class="headerlink" title="11. 多网卡"></a>11. 多网卡</h2><p>管理网：集群间组件通信，Node与Master节点通信网络<br>业务网：应用间网络通信，pod间网络通信<br>存储网：与存储设备网络通信<br>还可以将与外部镜像仓库的网络也考虑进去<br>每个网络，使用两张网卡做bond，提高网络性能及可用性。<br><code>其中管理网与业务网必须互通，否则部分组件服务将不可用。</code></p><h2 id="12-外部节点相关组件"><a href="#12-外部节点相关组件" class="headerlink" title="12.外部节点相关组件"></a>12.外部节点相关组件</h2><ul><li>时间同步服务（chronyd）</li><li>DNS(dnsmasq)</li><li>镜像仓库(docker-distribution)</li><li>负载均衡器（Haproxy）</li></ul><h2 id="13-外部镜像仓库授权"><a href="#13-外部镜像仓库授权" class="headerlink" title="13. 外部镜像仓库授权"></a>13. 外部镜像仓库授权</h2><p>将私有镜像仓库的CA文件拷贝到镜像仓库所在服务器的&#x2F;etc&#x2F;pki&#x2F;ca-trust&#x2F;source&#x2F;anchors&#x2F;目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m copy -a &#x27;src=registry.crt dest=/etc/pki/ca-trust/source/anchors/registry.crt&#x27;</span><br><span class="line">$ update-ca-trust </span><br></pre></td></tr></table></figure><p>为OpenShift节点设置默认的登录信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 在/etc/ansible/hosts中添加认证用户</span></span></span><br><span class="line">oreg_auth_user=&quot;&lt;用户名&gt;&quot;</span><br><span class="line">oreg_auth_password=&quot;&lt;密码&gt;&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc login &lt;镜像仓库url&gt; -u &lt;用户名&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible -m copy -a <span class="string">&#x27;src=/root/.docker dest=/var/lib/origin&#x27;</span> all</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible -m service -a <span class="string">&#x27;name=origin-node state=restarted&#x27;</span> all</span></span><br></pre></td></tr></table></figure><h2 id="14-内核优化（openshift安装会自动配置）"><a href="#14-内核优化（openshift安装会自动配置）" class="headerlink" title="14. 内核优化（openshift安装会自动配置）"></a>14. 内核优化（openshift安装会自动配置）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m package -a &#x27;name=tuned state=present&#x27;</span><br><span class="line">$ ansible all -m service -a &#x27;name=tuned state=started enabled=true&#x27;</span><br><span class="line">$ ansible all -m shell -a &#x27;tuned-adm profile throughput-performance&#x27;</span><br></pre></td></tr></table></figure><h2 id="15-ansible设置reserved。"><a href="#15-ansible设置reserved。" class="headerlink" title="15. ansible设置reserved。"></a>15. ansible设置reserved。</h2><p><strong>OpenShift官方推荐规则</strong><br>通常，它需要保留5％-10％的节点资源来保护节点，越高越安全。<br><strong>AWS的规则：</strong><br>内存预留值（AWS）:</p><p>Reserved memory &#x3D; 255MiB + 11MiB * MAX_POD_PER_INSTANCE</p><p>CPU预留值（AWS）:</p><ul><li>6% of the first core</li><li>1% of the next core (up to 2 cores)</li><li>0.5% of the next 2 cores (up to 4 cores)</li><li>0.25% of any cores above 4 cores</li></ul><p><strong>GKE的规则：</strong><br>内存预留值（GKE）:</p><ul><li>255 MiB of memory for machines with less than 1 GB of memory</li><li>25% of the first 4GB of memory</li><li>20% of the next 4GB of memory (up to 8GB)</li><li>10% of the next 8GB of memory (up to 16GB)</li><li>6% of the next 112GB of memory (up to 128GB)</li><li>2% of any memory above 128GB</li></ul><p>CPU预留值（GKE）::</p><ul><li>6% of the first core</li><li>1% of the next core (up to 2 cores)</li><li>0.5% of the next 2 cores (up to 4 cores)</li><li>0.25% of any cores above 4 cores</li></ul><p>例子：2 vCPU and 7.5GB</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Allocatable memory = 0.25 * 4 (first 4GB) + 0.2 * 3.5 (remaining 3.5GB)</span><br><span class="line">Allocatable CPU = 0.06 * 1 (first core) + 0.01 * 1 (second core)</span><br></pre></td></tr></table></figure><p><strong>Azure的规则：</strong><br>内存预留值（Azure）:</p><ul><li>255 MiB of memory for machines with less than 1 GB of memory</li><li>25% of the first 4GB of memory</li><li>20% of the next 4GB of memory (up to 8GB)</li><li>10% of the next 8GB of memory (up to 16GB)</li><li>6% of the next 112GB of memory (up to 128GB)</li><li>2% of any memory above 128GB</li></ul><p>CPU预留值（Azure）:</p><table><thead><tr><th>核数 core</th><th>预留 millicores</th></tr></thead><tbody><tr><td>1</td><td>60</td></tr><tr><td>2</td><td>100</td></tr><tr><td>4</td><td>140</td></tr><tr><td>8</td><td>180</td></tr><tr><td>16</td><td>260</td></tr><tr><td>32</td><td>420</td></tr><tr><td>64</td><td>740</td></tr><tr><td><strong>另外：</strong></td><td></td></tr><tr><td>Google和亚马逊产品的hard eviction threshold 为100MB，而AKS则为750MB。</td><td></td></tr></tbody></table><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line"></span><br><span class="line"># 节点配置低的话可参考</span><br><span class="line"></span><br><span class="line">openshift_node_kubelet_args=&#123;&#x27;pods-per-core&#x27;: [&#x27;10&#x27;], &#x27;max-pods&#x27;: [&#x27;250&#x27;], &#x27;image-gc-high-threshold&#x27;: [&#x27;85&#x27;], &#x27;image-gc-low-threshold&#x27;: [&#x27;80&#x27;], &#x27;system-reserved&#x27;:[&#x27;cpu=200m&#x27;, &#x27;memory=1G&#x27;], &#x27;kube-reserved&#x27;:[&#x27;cpu=200m&#x27;,&#x27;memory=1G&#x27;]&#125;</span><br><span class="line"></span><br><span class="line"># 节点配置高的话可参考</span><br><span class="line"></span><br><span class="line"> openshift_node_kubelet_args=&#123;&#x27;pods-per-core&#x27;: [&#x27;10&#x27;], &#x27;max-pods&#x27;: [&#x27;250&#x27;], &#x27;image-gc-high-threshold&#x27;: [&#x27;85&#x27;], &#x27;image-gc-low-threshold&#x27;: [&#x27;80&#x27;], &#x27;system-reserved&#x27;:[&#x27;cpu=500m&#x27;, &#x27;memory=1G&#x27;], &#x27;kube-reserved&#x27;:[&#x27;cpu=1&#x27;,&#x27;memory=2G&#x27;]&#125;</span><br></pre></td></tr></table></figure><h2 id="16-配置集群对master控制台的public域名证书及应用Route路由服务的域名证书"><a href="#16-配置集群对master控制台的public域名证书及应用Route路由服务的域名证书" class="headerlink" title="16. 配置集群对master控制台的public域名证书及应用Route路由服务的域名证书"></a>16. 配置集群对master控制台的public域名证书及应用Route路由服务的域名证书</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">openshift_master_cluster_hostname=master.example.com</span><br><span class="line">openshift_master_cluster_public_hostname=master_public.example.com</span><br><span class="line">openshift_master_default_subdomain=apps.example.com</span><br><span class="line">openshift_master_named_certificates=[&#123;&quot;certfile&quot;: &quot;/data/cert/master_public.example.com.crt&quot;, &quot;keyfile&quot;: &quot;/data/cert/master_public.example.com.key&quot;, &quot;names&quot;: [&quot;master_public.example.com&quot;], &quot;cafile&quot;: &quot;/data/cert/example.com_ca.crt&quot;&#125;]</span><br><span class="line">openshift_master_overwrite_named_certificates=true</span><br><span class="line">openshift_hosted_router_certificate=&#123;&quot;certfile&quot;: &quot;/data/cert/apps.example.com.crt&quot;, &quot;keyfile&quot;: &quot;/data/cert/apps.example.com.key&quot;, &quot;cafile&quot;: &quot;/data/cert/example.com_ca.crt&quot;&#125;</span><br></pre></td></tr></table></figure><p>其中各证书的文件名不要使用与Master组件默认的名字重复，否则会覆盖掉组件间的自签证书。</p><p>另外可以自签证书生成长有效期的相关证书。<strong>自签证书步骤如下：</strong></p><ol><li>根证书创建<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out ca.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -x509 -days 36500 -key ca.key -out ca.crt -subj <span class="string">&quot;/C=CN/ST=shanxi/L=taiyuan/O=cn/OU=test/CN=example.com&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment">#或者 openssl req -new -x509 -days 36500 -key ca.key -out ca.crt 手动输入配置</span></span></span><br></pre></td></tr></table></figure></li><li>创建证书并使用根证书签发<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl genrsa -out app.key 2048</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl req -new -key app.key -out app.csr</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -req -<span class="keyword">in</span> app.csr -CA ca.crt -CAkey ca.key -out app.crt -days 3650  -CAcreateserial</span></span><br></pre></td></tr></table></figure></li><li>使用 Openssl 工具查看证书信息<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -dates</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -subject</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">openssl x509 -<span class="keyword">in</span> signed.crt -noout -text</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="17-添加集群自动审批证书签发请求"><a href="#17-添加集群自动审批证书签发请求" class="headerlink" title="17. 添加集群自动审批证书签发请求"></a>17. 添加集群自动审批证书签发请求</h2><p>OpenShift 3.11中默念Node的证书有效期为1年，满1年后会自动更新证书。更新证书时，该节点会向集群发送证书签发请求，批准之后才能继续添加到集群。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line">openshift_master_bootstrap_auto_approve=true</span><br></pre></td></tr></table></figure><p>说明：对于已经部署好的集群可以通过执行ansible-playbook来配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ansible-playbook -vvv openshift-ansible/playbooks/openshift-master/enable_bootstrap.yml -e openshift_master_bootstrap_auto_approve=<span class="literal">true</span></span></span><br></pre></td></tr></table></figure><h2 id="18-ansible中设置Docker存储type及Docker与etcd额外磁盘"><a href="#18-ansible中设置Docker存储type及Docker与etcd额外磁盘" class="headerlink" title="18. ansible中设置Docker存储type及Docker与etcd额外磁盘"></a>18. ansible中设置Docker存储type及Docker与etcd额外磁盘</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line"># Docker setup for extra disks on nodes</span><br><span class="line">container_runtime_docker_storage_setup_device=/dev/vdb</span><br><span class="line">container_runtime_docker_storage_type=overlay2</span><br><span class="line">openshift_node_local_quota_per_fsgroup=512Mi</span><br><span class="line"></span><br><span class="line">[masters:vars]</span><br><span class="line">container_runtime_extra_storage=[&#123;&#x27;device&#x27;: &#x27;/dev/vdc&#x27;, &#x27;path&#x27;: &#x27;/var/lib/origin/openshift.local.volumes&#x27;, &#x27;options&#x27;: &#x27;gquota&#x27;, &#x27;filesystem&#x27;: &#x27;xfs&#x27;, &#x27;format&#x27;: &#x27;True&#x27;&#125;, &#123;&#x27;device&#x27;: &#x27;/dev/vdd&#x27;, &#x27;path&#x27;: &#x27;/var/lib/etcd&#x27;, &#x27;hosts&#x27;: &#x27;masters&#x27;, &#x27;filesystem&#x27;: &#x27;xfs&#x27;, &#x27;format&#x27;: &#x27;True&#x27;&#125;]</span><br><span class="line"></span><br><span class="line">[nodes:vars]</span><br><span class="line">container_runtime_extra_storage=[&#123;&#x27;device&#x27;: &#x27;/dev/vdc&#x27;, &#x27;path&#x27;: &#x27;/var/lib/origin/openshift.local.volumes&#x27;, &#x27;options&#x27;: &#x27;gquota&#x27;, &#x27;filesystem&#x27;: &#x27;xfs&#x27;, &#x27;format&#x27;: &#x27;True&#x27;&#125;]</span><br></pre></td></tr></table></figure><h2 id="19-设置日志自动归档"><a href="#19-设置日志自动归档" class="headerlink" title="19. 设置日志自动归档"></a>19. 设置日志自动归档</h2><ol><li>journal日志归档<br>  减少<code>/var/log/journal</code>的日志，设置<code>/etc/systemd/journald.conf</code>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/systemd/journald.conf</span><br><span class="line">  [Journal]</span><br><span class="line"> Storage=persistent</span><br><span class="line"> Compress=yes</span><br><span class="line">#Seal=yes</span><br><span class="line">#SplitMode=uid</span><br><span class="line"> SyncIntervalSec=1s</span><br><span class="line"> RateLimitInterval=1s</span><br><span class="line"> RateLimitBurst=10000</span><br><span class="line"> SystemMaxUse=1G</span><br><span class="line"> SystemKeepFree=20%</span><br><span class="line"> SystemMaxFileSize=10M</span><br><span class="line">#RuntimeMaxUse=</span><br><span class="line">#RuntimeKeepFree=</span><br><span class="line">#RuntimeMaxFileSize=</span><br><span class="line"> MaxRetentionSec=3days</span><br><span class="line"> MaxFileSec=1day</span><br><span class="line"> ForwardToSyslog=False</span><br><span class="line">#ForwardToKMsg=no</span><br><span class="line">#ForwardToConsole=no</span><br><span class="line"> ForwardToWall=False</span><br><span class="line">#TTYPath=/dev/console</span><br><span class="line">#MaxLevelStore=debug</span><br><span class="line">#MaxLevelSyslog=debug</span><br><span class="line">#MaxLevelKMsg=notice</span><br><span class="line">#MaxLevelConsole=info</span><br><span class="line">#MaxLevelWall=emerg</span><br><span class="line">$ systemctl restart systemd-journald</span><br></pre></td></tr></table></figure>或者部署时更新以下文件内容(openshift 3.9以上)<br><code>roles/openshift_node/defaults/main.yml</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">journald_vars_to_replace:</span><br><span class="line">- &#123; var: Storage, val: persistent &#125;</span><br><span class="line">- &#123; var: Compress, val: yes &#125;</span><br><span class="line">- &#123; var: SyncIntervalSec, val: 1s &#125;</span><br><span class="line">- &#123; var: RateLimitInterval, val: 1s &#125;</span><br><span class="line">- &#123; var: RateLimitBurst, val: 10000 &#125;</span><br><span class="line">- &#123; var: SystemMaxUse, val: 1G &#125;</span><br><span class="line">- &#123; var: SystemKeepFree, val: 20% &#125;</span><br><span class="line">- &#123; var: SystemMaxFileSize, val: 10M &#125;</span><br><span class="line">- &#123; var: MaxRetentionSec, val: 3days &#125;</span><br><span class="line">- &#123; var: MaxFileSec, val: 1day &#125;</span><br><span class="line">- &#123; var: ForwardToSyslog, val: no &#125;</span><br><span class="line">- &#123; var: ForwardToWall, val: no &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li>message日志归档<br>只收集warning以上的日志<code>/etc/rsyslog.conf</code><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/rsyslog.conf</span><br><span class="line">*.warning;mail.none;authpriv.none;cron.none  /var/log/messages</span><br></pre></td></tr></table></figure>将message日志只保留最近三天的日志<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/messages</span><br><span class="line">&#123;</span><br><span class="line">  daily</span><br><span class="line">  rotate 3</span><br><span class="line">  sharedscripts</span><br><span class="line">  postrotate</span><br><span class="line">     /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">  endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>如果要设置普通用户可查看&#x2F;var&#x2F;log&#x2F;messages文件，需要在&#x2F;etc&#x2F;rsyslog.conf配置的前面添加messages文件可读权限<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$umask 0000</span><br></pre></td></tr></table></figure></li></ol><h2 id="20-定时清理主机上退出的容器、未被使用的卷和未被使用的镜像（发布非常频繁时需要）"><a href="#20-定时清理主机上退出的容器、未被使用的卷和未被使用的镜像（发布非常频繁时需要）" class="headerlink" title="20. 定时清理主机上退出的容器、未被使用的卷和未被使用的镜像（发布非常频繁时需要）"></a>20. 定时清理主机上退出的容器、未被使用的卷和未被使用的镜像（发布非常频繁时需要）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /usr/bin/prune_docker.sh</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">docker container prune -f # 删除所有退出状态的容器</span><br><span class="line">docker volume prune -f # 删除未被使用的数据卷</span><br><span class="line">docker image prune -f # 删除 dangling 或所有未被使用的镜像</span><br></pre></td></tr></table></figure><p>做为定时任务定期作清理</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crontab -l</span></span><br><span class="line">0 0 * * * /usr/bin/prune_docker.sh &gt;&gt; /var/log/prune_docker.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h2 id="21-定时清理私有镜像仓库（发布非常频繁时需要）"><a href="#21-定时清理私有镜像仓库（发布非常频繁时需要）" class="headerlink" title="21. 定时清理私有镜像仓库（发布非常频繁时需要）"></a>21. 定时清理私有镜像仓库（发布非常频繁时需要）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /usr/bin/cleanregistry.sh &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">!/bin/bash</span></span></span><br><span class="line">oc login -u admin -p password</span><br><span class="line">oc adm prune builds --orphans --keep-complete=25 --keep-failed=5 --keep-younger-than=60m --confirm</span><br><span class="line">oc adm prune deployments --orphans --keep-complete=25 --keep-failed=10 --keep-younger-than=60m --confirm</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">oc rollout latest docker-registry -n default</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">sleep 20</span></span></span><br><span class="line">oc adm prune images --keep-younger-than=400m --confirm</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">crontab -l</span></span></span><br><span class="line">0 0 * * * /usr/bin/cleanregistry.sh &gt;&gt; /var/log/cleanregistry.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h2 id="22-注释掉origin-accounting-conf文件中的DefaultIOAccounting"><a href="#22-注释掉origin-accounting-conf文件中的DefaultIOAccounting" class="headerlink" title="22. 注释掉origin-accounting.conf文件中的DefaultIOAccounting"></a>22. 注释掉origin-accounting.conf文件中的DefaultIOAccounting</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> /etc/systemd/system.conf.d/origin-accounting.conf</span></span><br><span class="line">[Manager]</span><br><span class="line">DefaultCPUAccounting=yes</span><br><span class="line">DefaultMemoryAccounting=yes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">systemd v230 or newer</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DefaultIOAccounting=<span class="built_in">yes</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Deprecated, remove <span class="keyword">in</span> future</span></span><br><span class="line">DefaultBlockIOAccounting=yes</span><br></pre></td></tr></table></figure><h2 id="23-Pod与Service网段规划"><a href="#23-Pod与Service网段规划" class="headerlink" title="23. Pod与Service网段规划"></a>23. Pod与Service网段规划</h2><ul><li>集群的Service网段</li><li>集群的Pod网段</li><li>根据主机的配置规划好每台主机上Pod的网段</li></ul><h2 id="24-Router环境变量优化"><a href="#24-Router环境变量优化" class="headerlink" title="24. Router环境变量优化"></a>24. Router环境变量优化</h2><p>ROUTER_THREADS 设置为CPU核数<br>ROUTER_MAX_CONNECTIONS 默认值是20000</p><h2 id="25-Router设置默认503页面（服务不存在）"><a href="#25-Router设置默认503页面（服务不存在）" class="headerlink" title="25. Router设置默认503页面（服务不存在）"></a>25. Router设置默认503页面（服务不存在）</h2><p>设置页面HTML，覆盖&#x2F;var&#x2F;lib&#x2F;haproxy&#x2F;conf&#x2F;error-page-503.http文件<br><code>补充</code>：<a href="https://www.jianshu.com/p/add9e0d2ed31">Openshift自定义Router配置</a></p><h2 id="26-计算节点优化配置"><a href="#26-计算节点优化配置" class="headerlink" title="26. 计算节点优化配置"></a>26. 计算节点优化配置</h2><ul><li>MTU值：通常的以太网设置为1450，在巨型帧以太网中设置为8950<br>node的配置文件中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">networkConfig:</span><br><span class="line">  mtu: 1450</span><br></pre></td></tr></table></figure></li><li>开启并行拉取镜像，提升效率。<br>node的配置文件中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeletArguments:</span><br><span class="line">  serialize-image-pulls:</span><br><span class="line">  - &quot;false&quot;</span><br></pre></td></tr></table></figure></li><li>容器清理：通过kubelet自动清理退出的容器<br>node的配置文件中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeletArguments:</span><br><span class="line">  minimum-container-ttl-duration:</span><br><span class="line">    - &quot;10s&quot;</span><br><span class="line">  maximum-dead-containers-per-container:</span><br><span class="line">    - &quot;1&quot;</span><br><span class="line">  maximum-dead-containers:</span><br><span class="line">    - &quot;20&quot;</span><br></pre></td></tr></table></figure><code>minimum-container-ttl-duration</code>: 容器可以进行垃圾收集的最低时长。 默认值为0，表示不限制。 可以使用单位后缀来指定此设置的值，例如h表示小时，m表示分钟，s表示秒。<br><code>maximum-dead-containers-per-container</code>：每个pod容器要保留的实例数。 预设值为1。<br><code>maximum-dead-containers</code>：节点中死容器总数的最大值。 默认值为-1，表示无限制。</li></ul><h2 id="27-证书的有效期设置更长年限（100年）"><a href="#27-证书的有效期设置更长年限（100年）" class="headerlink" title="27. 证书的有效期设置更长年限（100年）"></a>27. 证书的有效期设置更长年限（100年）</h2><p><strong>核心步骤是：</strong></p><ol><li>部署时设置主要ocp组件的过期时间，&#x2F;etc&#x2F;ansible&#x2F;hosts</li><li>更新部署脚本中所有生成证书的地方，设置长年限的过期时间</li></ol><p>具体操作参考笔者之前的文章：<a href="https://www.jianshu.com/p/b8864a733e67">OpenShift部署时如何延长组件证书的有效期</a></p><p>参考文章：<br><a href="https://www.cnblogs.com/sparkdev/p/8795141.html">linux journalctl 命令</a><br><a href="https://linux.cn/article-8227-1.html">配置 logrotate 的终极指导</a><br><a href="https://learnk8s.io/allocatable-resources">Allocatable memory and CPU in Kubernetes Nodes</a><br><a href="https://www.jianshu.com/p/81694b78a167">OpenShift容器云平台建设之部署前准备</a><br><a href="https://www.jianshu.com/p/924ac3f464a6">企业级容器云平台建设之功能汇总</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift的网络策略networkpolicy</title>
      <link href="/openshift/Openshift%E7%9A%84%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5networkpolicy/"/>
      <url>/openshift/Openshift%E7%9A%84%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5networkpolicy/</url>
      
        <content type="html"><![CDATA[<h2 id="开启networkpolicy"><a href="#开启networkpolicy" class="headerlink" title="开启networkpolicy"></a>开启networkpolicy</h2><ul><li>创建新集群时，在ansible的hosts的参数列表中添加os_sdn_network_plugin_name配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:vars]</span><br><span class="line">os_sdn_network_plugin_name=&#x27;redhat/openshift-ovs-networkpolicy</span><br></pre></td></tr></table></figure></li><li>如果已存在的集群，切换网络策略，请参考<a href="https://www.jianshu.com/p/22ad366b2aad">Openshift网络插件动态切换</a></li><li>ovs-networkpolicy网络策略下，pod也支持qos网络流量控制。详情请阅读：<a href="https://www.jianshu.com/p/a272faeba3d6">Openshift Network QoS——Pod网络控制</a></li></ul><p><code>说明：在Openshift容器平台只支持部分k8s networkpolicy v1版本特性，所以egress协议类型，IPBlock和podSelector与namespaceSelector的组合都不支持。</code></p><h2 id="NetworkPolicy配置规则"><a href="#NetworkPolicy配置规则" class="headerlink" title="NetworkPolicy配置规则"></a>NetworkPolicy配置规则</h2><p>样例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: test-network-policy</span><br><span class="line">  namespace: test</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      role: db</span><br><span class="line">  policyTypes:</span><br><span class="line">  - Ingress</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - namespaceSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          project: myproject</span><br><span class="line">    - podSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          role: frontend</span><br><span class="line">    ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 6379</span><br></pre></td></tr></table></figure><ul><li>podSelector: pod选择器，指定该networkpolicy对指定pod产生作用。默认当前project下的所有pod</li><li>policyTypes: Openshift只支持Ingress协议类型</li><li>ingress[].from[].namespaceSelector：namespace选择器，带有指定label的namespace允许访问受控制的pod</li><li>ingress[].from[].podSelector：pod选择器，指定同一个project下带有指定label的pod允许访问受控制的pod</li><li>ingress[].ports：受控制的端口</li><li>一个project下可以有多条NetworkPolicy规则，同时它们是或的关系</li><li>每个NetworkPolicy可以有多条ingress策略，同时它们也是或的关系</li></ul><h2 id="策略设置案例"><a href="#策略设置案例" class="headerlink" title="策略设置案例"></a>策略设置案例</h2><blockquote><p>默认策略</p></blockquote><p>在没有设置任何NetworkPolicy策略时，pod之间的网络与openshift-ovs-subnet一样，都是可以互相访问的</p><blockquote><p>对所有pod网络隔离</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/0c028a2bbe9b88741a614c95359f034ca5ca5acb4313c6a407783788531f8774.png" alt="对所有pod网络隔离">  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: deny-by-default</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">  ingress: []</span><br></pre></td></tr></table></figure><blockquote><p>只允许在同一个project下的所有pod可访问</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/138d50ab248945706ba4c3985540ca7937683c4e34172d1476aeb17a1b3f0f99.png" alt="只允许在同一个project下的pod可访问">  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: allow-same-namespace</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector: &#123;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>只允许同一个project下的指定pod可访问</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/876c9668dfa9121ef9b7ac131298ca5b604edb7167feab8c957f753cd9ea0d47.png" alt="只允许type=blue的pod访问当前project下的pod">  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: allow-same-namespace</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - podSelector:</span><br><span class="line">          matchLabels:</span><br><span class="line">              type: blue</span><br></pre></td></tr></table></figure><blockquote><p>只允许指定的namespace下的pod可访问</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/b785c70e5c9bd2baf4884bedfe2f15bee68ad2549d159e1436409b5c74017fde.png" alt="只允许指定的namespace下的pod可访问">  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc label namespace project-b name=project-b</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: allow-test-namespace</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - namespaceSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          name: project-b</span><br></pre></td></tr></table></figure><blockquote><p> 公开指定label的pod的HTTP和HTTPS端口</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/98822057a8c651768ee3e476e5efdf5bc6da7d64117ce5ecfa2a7d439de05b0e.png" alt="project-a下的type=red的pod的80和443端口对所有pod开放">  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: allow-http-and-https</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      type: red</span><br><span class="line">  ingress:</span><br><span class="line">  - ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 443</span><br></pre></td></tr></table></figure><blockquote><p>NetworkPolicy与Routers网络打通</p></blockquote><p>在ovs-multitenant模式下，router所在的default project对所有project中的pod都具有访问权限，但是这点在networkpolicy策略中并不适用。如果某个需要公开的服务设置了networkpolicy策略，那么也需要将它向router pod公开。</p><ul><li>一种方法是将需要公开的服务的端口对所有project公开<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: allow-to-database-service</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      role: database</span><br><span class="line">  ingress:</span><br><span class="line">  - ports:</span><br><span class="line">    - protocol: TCP</span><br><span class="line">      port: 5432</span><br></pre></td></tr></table></figure>该策略不仅允许router能访问该服务，同时也允许所有的pod能够访问该服务。通常这是没有问题的，因为有这种需求的服务是对外开放的。</li><li>另一种方法是只对default namespace进行公开<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ oc label namespace default name=default</span><br><span class="line">$ cat allow-from-default-namespace.yaml</span><br><span class="line">kind: NetworkPolicy</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: allow-from-default-namespace</span><br><span class="line">spec:</span><br><span class="line">  podSelector:</span><br><span class="line">  ingress:</span><br><span class="line">  - from:</span><br><span class="line">    - namespaceSelector:</span><br><span class="line">        matchLabels:</span><br><span class="line">          name: default</span><br></pre></td></tr></table></figure></li></ul><h2 id="给新建的project创建默认策略"><a href="#给新建的project创建默认策略" class="headerlink" title="给新建的project创建默认策略"></a>给新建的project创建默认策略</h2><p>在openshift project的默认配置中添加如下object</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">objects:</span><br><span class="line">...</span><br><span class="line">- apiVersion: networking.k8s.io/v1</span><br><span class="line">  kind: NetworkPolicy</span><br><span class="line">  metadata:</span><br><span class="line">    name: allow-from-same-namespace</span><br><span class="line">  spec:</span><br><span class="line">    podSelector:</span><br><span class="line">    ingress:</span><br><span class="line">    - from:</span><br><span class="line">      - podSelector: &#123;&#125;</span><br><span class="line">- apiVersion: networking.k8s.io/v1</span><br><span class="line">  kind: NetworkPolicy</span><br><span class="line">  metadata:</span><br><span class="line">    name: allow-from-default-namespace</span><br><span class="line">  spec:</span><br><span class="line">    podSelector:</span><br><span class="line">    ingress:</span><br><span class="line">    - from:</span><br><span class="line">      - namespaceSelector:</span><br><span class="line">          matchLabels:</span><br><span class="line">            name: default</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Openshift的networkpolicy功能只有当前最新k8s的networkpolicy的部分功能。它支持以下两种控制：</p><ul><li>同一个project下的指定pod对受控制的pod的访问</li><li>不同project下的所有pod对受控制的pod的访问</li></ul><p>不支持不同project下的指定pod对受控的pod的访问</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/managing_networking.html">Openshift官方文档：Managing Networking</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift私有仓库爆了，怎么办？？！！</title>
      <link href="/openshift/Openshift%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%88%86%E4%BA%86%EF%BC%8C%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%EF%BC%9F%EF%BC%81%EF%BC%81/"/>
      <url>/openshift/Openshift%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%88%86%E4%BA%86%EF%BC%8C%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%EF%BC%9F%EF%BC%81%EF%BC%81/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>像大家担心的那样，Openshift私有仓库磁盘爆了，使用率100%!!!<br>使用<code>oc adm prune</code>来作对openshift集群的清理，你敢吗？<br>会不会把需要的镜像也一并删了呢，要是如此，就只能像DBA一样走人了。<br>今天就来探讨下<code>oc adm prune</code>的用法。</p><h3 id="先给出答案"><a href="#先给出答案" class="headerlink" title="先给出答案"></a>先给出答案</h3><p>如你所料，我们最终的清理镜像的办法是<code>oc adm prune images</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc login -u admin -p admin</span><br><span class="line">oc adm prune images --keep-younger-than=400m --confirm</span><br></pre></td></tr></table></figure><p><code>注意</code>以上<code>oc adm prune images</code>命令只能在普通用户下执行，无法在system:admin用户下执行，所以必须先登录普通用户，同时用户拥有system:image-pruner权限。</p><h2 id="精减镜像命令oc-adm-prune-images的用法"><a href="#精减镜像命令oc-adm-prune-images的用法" class="headerlink" title="精减镜像命令oc adm prune images的用法"></a>精减镜像命令oc adm prune images的用法</h2><p>为了让镜像不占用过多的磁盘空间，需要对它全精减。很多时候，比如重复地构建镜像，会留下很多不必要的镜像层，而这些镜像层会占用非常多的空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm prune images [&lt;options&gt;]</span><br></pre></td></tr></table></figure><blockquote><p>options说明</p></blockquote><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>–all</td><td>默认:true，删除除了私有镜像仓库中的多余的镜像外，也删除ImageStream中连接外部镜像的ImageStream。如果只删除私有镜像仓库中的镜像则设置–all&#x3D;false</td></tr><tr><td>–certificate-authority</td><td>访问私有镜像仓库的证书，openshift中的路径在master节点中的&#x2F;etc&#x2F;origin&#x2F;master&#x2F;registry.crt。如果是在集群中的master节点执行命令，这个参数不需要添加</td></tr><tr><td>–confirm</td><td>确认执行，如果不加只是进行检查演练</td></tr><tr><td>–force-insecure</td><td>强制使用不安全的连接，不作证书检查</td></tr><tr><td>–keep-tag-revisions&#x3D;<N></td><td>默认:3，为每个ImageStream中的每个Tag保留N个镜像</td></tr><tr><td>–keep-younger-than&#x3D;<duration></td><td>默认:60m，不清理创建时间低于duration时间内的镜像，也不清理任何创建时间低于duration时间的对象引用的镜像</td></tr><tr><td>–prune-over-size-limit</td><td>清理同一个项目下超过指定LimitRanges的镜像，该先项不能与–keep-tag-revisions和–keep-younger-than同时使用</td></tr><tr><td>–registry-url</td><td>私有镜像链接，如果是在集群中的master节点执行命令，这个参数不需要添加</td></tr></tbody></table><blockquote><p>使用<code>--keep-tag-revisions</code>与<code>--keep-younger-than</code>来清理镜像，以下情况对应的镜像不会被清理</p></blockquote><ul><li>创建时间在<code>--keep-younger-than</code>指定的时间以内的所有Pod</li><li>创建时间在<code>--keep-younger-than</code>指定的时间以内的所有ImageStream</li><li>所有正在运行的Pod</li><li>所有状态为pending状态的Pod</li><li>所有的replication controllers</li><li>所有的build configurations</li><li>所有的builds</li><li>ImageStream的状态items下最近的<code>--keep-tag-revisions</code>镜像</li></ul><blockquote><p>使用<code>--prune-over-size-limit </code>清理超过指定Limit的镜像，以下情况下指向的镜像不会清理</p></blockquote><ul><li>所有正在运行的Pod</li><li>所有状态为pending状态的Pod</li><li>所有的replication controllers</li><li>所有的build configurations</li><li>所有的builds</li></ul><blockquote><p>注意：以下情况并不会真正删除镜像</p></blockquote><ol><li>手动删除image，这只会删除etcd中的数据，不会删除私有仓库中的镜像<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc delete image &lt;sha256:image-id&gt;</span><br></pre></td></tr></table></figure></li></ol><h1 id="oc-adm-prune用来清理deployments与builds"><a href="#oc-adm-prune用来清理deployments与builds" class="headerlink" title="oc adm prune用来清理deployments与builds"></a>oc adm prune用来清理deployments与builds</h1><p>当然<code>oc adm prune</code>并不仅仅只是用于清理镜像，它还用来清理deployments与builds</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm prune deployments/builds [&lt;options&gt;]</span><br></pre></td></tr></table></figure><blockquote><p>options说明</p></blockquote><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>–confirm</td><td>确认执行，如果不加只是进行检查演练</td></tr><tr><td>–orphans</td><td>清理所有的deploymentconfig&#x2F;buildconfig不存在的deployment&#x2F;build</td></tr><tr><td>–keep-complete&#x3D;<N></td><td>默认:5，保留最近N个成功的deployment&#x2F;build</td></tr><tr><td>–keep-failed&#x3D;<N></td><td>默认：1，保留最近N个出错的deployment&#x2F;build</td></tr><tr><td>–keep-younger-than&#x3D;<duration></td><td>默认:60m，不清理创建时间低于duration时间内的deployment&#x2F;build</td></tr></tbody></table><blockquote><p>实例：清理deployments&#x2F;builds</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc adm prune deployments --orphans --keep-complete=5 --keep-failed=1 --keep-younger-than=60m --confirm</span><br><span class="line">oc adm prune builds --orphans --keep-complete=5 --keep-failed=1 --keep-younger-than=60m --confirm</span><br></pre></td></tr></table></figure><h1 id="定时清理，做到永无后患"><a href="#定时清理，做到永无后患" class="headerlink" title="定时清理，做到永无后患"></a>定时清理，做到永无后患</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> cleanregistry.sh</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">date</span><br><span class="line">oc login -u admin -p password</span><br><span class="line">oc adm prune builds --orphans --keep-complete=25 --keep-failed=5 --keep-younger-than=60m --confirm</span><br><span class="line">oc adm prune deployments --orphans --keep-complete=25 --keep-failed=10 --keep-younger-than=60m --confirm</span><br><span class="line">oc adm prune images --keep-younger-than=400m --confirm</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">crontab -l</span></span><br><span class="line">0 0 * * * /usr/bin/cleanregistry.sh &gt;&gt; /var/log/cleanregistry.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://docs.okd.io/3.6/admin_guide/pruning_resources.html">Openshift官方文档#pruning_resources</a><br><a href="https://www.mankier.com/1/oc-adm-prune-images">oc-adm-prune-images命令行介绍</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift管理project【译自官方文档】</title>
      <link href="/openshift/Openshift%E7%AE%A1%E7%90%86project%E3%80%90%E8%AF%91%E8%87%AA%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E3%80%91/"/>
      <url>/openshift/Openshift%E7%AE%A1%E7%90%86project%E3%80%90%E8%AF%91%E8%87%AA%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E3%80%91/</url>
      
        <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>在OpenShift容器平台中，项目用于对相关对象进行分组和隔离。作为管理员，您可以授予开发人员对某些项目的访问权限，允许他们创建自己的项目，并授予他们在各个项目中的管理权限。</p><h3 id="创建一个新的Project"><a href="#创建一个新的Project" class="headerlink" title="创建一个新的Project"></a>创建一个新的Project</h3><p>可以允许开发人员创建自己的项目。开发人员可以通过web控制台或者oc new-project命令来创建新的project。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc new-project test-project</span><br></pre></td></tr></table></figure><h3 id="预定义project"><a href="#预定义project" class="headerlink" title="预定义project"></a>预定义project</h3><p>API服务器根据master-config.yaml文件的projectRequestTemplate参数标识的模板自动配置新的项目。如果未定义该参数，API服务器将创建一个默认模板，该模板使用请求的名称创建一个项目，并赋予创建该项目的用户该项目的“admin”角色。</p><h5 id="如何创建自定义的project模板呢？"><a href="#如何创建自定义的project模板呢？" class="headerlink" title="如何创建自定义的project模板呢？"></a>如何创建自定义的project模板呢？</h5><ol><li>导出当前默认的模板<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm create-bootstrap-project-template -o yaml &gt; template.yaml</span><br></pre></td></tr></table></figure></li><li>使用文本编辑工具编辑template.yaml文件，对默认的配置进行更新</li><li>导入更改后的模板<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc create -f template.yaml -n default</span><br></pre></td></tr></table></figure></li><li>修改master-config.yaml文件的projectRequestTemplate参数，指向新建的模板<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">projectConfig:</span><br><span class="line">  projectRequestTemplate: &quot;default/project-request&quot;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>在更改模板文件时，可以使用如下变量</li></ol><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>PROJECT_NAME</td><td>project名字，必填</td></tr><tr><td>PROJECT_DISPLAYNAME</td><td>project显示的名字，可以为空</td></tr><tr><td>PROJECT_DESCRIPTION</td><td>project说明， 可以为空</td></tr><tr><td>PROJECT_ADMIN_USER</td><td>管理用户的用户名</td></tr><tr><td>PROJECT_REQUESTING_USER</td><td>请求的用户的用户名</td></tr><tr><td>说明：要想调用创建新项目的api，请求的用户必须具有 self-provisioners 权限，默认情况下，所有通过认证的用户都具有该权限。</td><td></td></tr></tbody></table><h5 id="如何禁用自定义模板？"><a href="#如何禁用自定义模板？" class="headerlink" title="如何禁用自定义模板？"></a>如何禁用自定义模板？</h5><p>通过设置，也可以阻止通过认证的用户组使用自定义模板创建新项目。</p><ol><li>用具有”cluster-admin”权限的用户登录</li><li>查看self-provisioners权限的clusterrolebinding使用情况<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ oc  describe clusterrolebinding.rbac self-provisioners</span><br><span class="line"></span><br><span class="line">Name:self-provisioners</span><br><span class="line">Labels:&lt;none&gt;</span><br><span class="line">Annotations:rbac.authorization.kubernetes.io/autoupdate=true</span><br><span class="line">Role:</span><br><span class="line">  Kind:ClusterRole</span><br><span class="line">  Name:self-provisioner</span><br><span class="line">Subjects:</span><br><span class="line">  KindNameNamespace</span><br><span class="line">  -----------------</span><br><span class="line">  Groupsystem:authenticated:oauth</span><br></pre></td></tr></table></figure></li><li>从system:authenticated:oauth组中删除self-provisioner权限<ul><li>如果self-provisioners权限只绑定到了system:authenticated:oauth用户组，则运行下面的命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc patch clusterrolebinding.rbac self-provisioners -p &#x27;&#123;&quot;subjects&quot;: null&#125;&#x27;</span><br></pre></td></tr></table></figure></li><li>如果self-provisioners权限不仅绑定到了system:authenticated:oauth用户组，还绑定到了users,groups或者serviceaccounts ，则运行下面的命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm policy remove-cluster-role-from-group self-provisioner system:authenticated:oauth</span><br></pre></td></tr></table></figure></li></ul></li><li>在master-config.yaml文件中配置projectRequestMessage参数，当开发人员创建新的项目时，将会用设置的Message提示他该如何去创建项目<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">projectConfig:</span><br><span class="line">  ProjectRequestMessage: &quot;To request a project, contact your system administrator at projectname@example.com.&quot;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></li><li>更新self-provisioners cluster role binding以阻止自动更新角色，以下两种方式都能实现<ul><li>使用一个命令行  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc patch clusterrolebinding.rbac self-provisioners -p &#x27;&#123; &quot;metadata&quot;: &#123; &quot;annotations&quot;: &#123; &quot;rbac.authorization.kubernetes.io/autoupdate&quot;: &quot;false&quot; &#125; &#125; &#125;&#x27;</span><br></pre></td></tr></table></figure></li><li>使用命令行进行编辑<ol><li>运行如下命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc edit clusterrolebinding.rbac self-provisioners</span><br></pre></td></tr></table></figure> 2.在文件编辑界面下设置rbac.authorization.kubernetes.io&#x2F;autoupdate为false <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: authorization.openshift.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;false&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li></ol></li></ul></li></ol><h2 id="对project设置nodeselector"><a href="#对project设置nodeselector" class="headerlink" title="对project设置nodeselector"></a>对project设置nodeselector</h2><p>NodeSelector与Node的Label配合使用，可以用来控制pod的调度。</p><h5 id="设置集群级别的默认节点选择器"><a href="#设置集群级别的默认节点选择器" class="headerlink" title="设置集群级别的默认节点选择器"></a>设置集群级别的默认节点选择器</h5><p>修改master-config.yaml文件中的defaultNodeSelector参数，这个配置将会影响所有没有设置nodeSelector标记的pod</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">projectConfig:</span><br><span class="line">  defaultNodeSelector: &quot;type=user-node,region=east&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>重启master服务，让配置生效</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># master-restart api</span><br><span class="line"># master-restart controllers</span><br></pre></td></tr></table></figure><h5 id="设置项目级别的默认节点选择器"><a href="#设置项目级别的默认节点选择器" class="headerlink" title="设置项目级别的默认节点选择器"></a>设置项目级别的默认节点选择器</h5><p>在创建项目时可以指定 –node-selector来设置项目级别的节点选择器。例如，如果您有一个包含多个区域的OpenShift容器平台，您可以使用–node-selector来限制项目，使其只在特定区域的节点上部署pod。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc adm new-project myproject --node-selector=&#x27;type=user-node,region=east&#x27;</span><br></pre></td></tr></table></figure><p>一旦执行了以上命令，所有myproject项目的创建的pod都会带上’type&#x3D;user-node,region&#x3D;east’的nodeSelector<br><code>说明</code>:oc与oc adm两个命令都有 new-project子命令，但是–node-selector设置只有在cluster-admin用户下执行oc adm new-project时才有效<br>使用oc adm new-project创建的新的project将会添加一个annotation，也可以编辑project,修改该annotation</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    openshift.io/node-selector: type=user-node,region=east</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>也可以通过命令行来对annotation进行更新</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># oc patch namespace myproject -p &#x27;&#123;&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&quot;openshift.io/node-selector&quot;:&quot;node-role.kubernetes.io/infra=true&quot;&#125;&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure><ul><li>如果openshift&#x2F;node-selector设置为””,那么这个项目下的pod并不会设置nodeSelctor</li><li>如果开发人员在创建deployment时额外设置了另外的nodeSelector，那么pod在调度的时候会需要同时满足project设置的nodeSelector及deployment的nodeSelector</li></ul><h2 id="限制用户创建的project数"><a href="#限制用户创建的project数" class="headerlink" title="限制用户创建的project数"></a>限制用户创建的project数</h2><ul><li>通过设置master-config.yaml文件中的ProjectRequestLimit 可以限制用户的project数量。该配置将根据user用户的label进行设置project的最大数量</li><li>当前用户的将按照ProjectRequestLimit的设置的selector进行匹配，以第一个匹配为准设置maxProjects</li><li>如果ProjectRequestLimit没有设置selector，那么该maxProjects对所有用户生效</li><li>如果没有设置maxProjects，那么对于用户不限制project数</li></ul><p><code>例子</code>：以下配置为每个用户设置了2个项目的全局限制，同时为标签为level&#x3D;advanced的用户允许10个项目，为标签为level&#x3D;admin的用户允许无限制的项目。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">admissionConfig:</span><br><span class="line">  pluginConfig:</span><br><span class="line">    ProjectRequestLimit:</span><br><span class="line">      configuration:</span><br><span class="line">        apiVersion: v1</span><br><span class="line">        kind: ProjectRequestLimitConfig</span><br><span class="line">        limits:</span><br><span class="line">        - selector:</span><br><span class="line">            level: admin </span><br><span class="line">        - selector:</span><br><span class="line">            level: advanced </span><br><span class="line">          maxProjects: 10</span><br><span class="line">        - maxProjects: 2 </span><br></pre></td></tr></table></figure><p>重启master服务，让配置生效</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># master-restart api</span><br><span class="line"># master-restart controllers</span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/managing_projects.html">openshift官方文档：Managing Project</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift结合IaaS的LB与Nginx实现高可用可伸缩外部负载均衡器</title>
      <link href="/openshift/Openshift%E7%BB%93%E5%90%88IaaS%E7%9A%84LB%E4%B8%8ENginx%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E5%8F%AF%E4%BC%B8%E7%BC%A9%E5%A4%96%E9%83%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"/>
      <url>/openshift/Openshift%E7%BB%93%E5%90%88IaaS%E7%9A%84LB%E4%B8%8ENginx%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E5%8F%AF%E4%BC%B8%E7%BC%A9%E5%A4%96%E9%83%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul><li>Openshift在集群部署时需要额外提供一个负载均衡器，该负载均衡器对master api及router haproxy中的80与443服务进行负载，实现高可用。</li><li>如果在IaaS上部署Openshift集群的话，我们很自然地会使用IaaS的LB服务，直接对LB作TCP端口负载就解决问题了，既实现了需要的负载均衡，而且还有健康检查，负载高可用，非常方便。</li><li>但是我们的Openshift集群并不是部署在IaaS上，而是额外部署。IaaS上的LB无法直接将集群中的服务器作为监听器的后端进行负载，这时我们就需要在Openshift集群下额外独立部署负载均衡器。考虑到保证负载均衡器的高可用性，及监控等，这会是一个比较复杂的过程。</li><li>那么我们是否可以结合IaaS上的LB现有的机制，制定一套既方便部署，又高可用的方案呢？答案是肯定的。</li><li>该篇就是介绍如何结合IaaS的LB与代理应用Nginx实现Openshift高可用的外部负载均衡</li></ul><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><ul><li>负载均衡器应用，首先大家想到的最多的两款应用是：Nginx与Haproxy，我们选用了Nginx。</li><li>将IaaS的LB与Nginx结合的思路也很简单。在IaaS上部署两台主机，上面部署好代理应用，将代理的后端设置为Openshift的服务器，同时将这两台服务器作为IaaS上的LB的监听器的后台。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/99e8548e17dd783b39cd8dfd089a217d130bf80301d8622751b9308bfde27b04.png" alt="IaaS LB与Nginx结合提供外部负载"></li></ul><h2 id="部署操作"><a href="#部署操作" class="headerlink" title="部署操作"></a>部署操作</h2><blockquote><p>IaaS上资源准备</p></blockquote><ol><li><p>创建VPC <code>IaaS</code></p></li><li><p>创建私网 <code>IaaS</code></p></li><li><p>在私网下创建两台主机（instance1, instance2） <code>IaaS</code></p></li><li><p>创建一个LB <code>Iaas</code></p><blockquote><p>搭建应用与配置</p></blockquote></li><li><p>LB上创建三个监听器（8443&#x2F;TCP, 443&#x2F;TCP, 80&#x2F;TCP) <code>IaaS</code></p></li><li><p>LB的三个监听器的后端都配置为两台Instance <code>IaaS</code></p></li><li><p>在instance上安装nginx <code>Instance</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@i-8 root]# yum install nginx</span><br></pre></td></tr></table></figure></li><li><p>配置nginx <code>Instance</code><br>openshift route服务器IP: 99.3.1.11、99.3.1.12<br>openshift master服务器IP: 99.3.1.1、99.3.1.2、99.3.1.3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">[root@i-8 conf.d]# cat /etc/nginx/nginx.conf</span><br><span class="line">...</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line">stream&#123;</span><br><span class="line">    include /etc/nginx/conf.d/tcp.conf;</span><br><span class="line">&#125;</span><br><span class="line">http &#123;</span><br><span class="line">...</span><br><span class="line">[root@i-8 conf.d]# cat /etc/nginx/conf.d/tcp.conf</span><br><span class="line">upstream nginx80&#123;</span><br><span class="line">    server 99.3.1.11:80;</span><br><span class="line">    server 99.3.1.12:80;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    proxy_pass nginx80;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream nginx443&#123;</span><br><span class="line">    server 99.3.1.11:443;</span><br><span class="line">    server 99.3.1.12:443;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       443;</span><br><span class="line">    proxy_pass nginx443;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream nginx8443&#123;</span><br><span class="line">    server 99.3.1.1:8443;</span><br><span class="line">    server 99.3.1.2:8443;</span><br><span class="line">    server 99.3.1.3:8443;</span><br><span class="line">&#125;</span><br><span class="line">server &#123;</span><br><span class="line">    listen       8443;</span><br><span class="line">    proxy_pass nginx8443;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>启动nginx</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@i-8 root]# systemctl start nginx</span><br><span class="line">[root@i-8 root]# systemctl enable nginx</span><br></pre></td></tr></table></figure><p>至此一个可监控、高可用且具有弹性伸缩功能的外部负载均衡器就完成了。</p></li></ol><h2 id="演示方法"><a href="#演示方法" class="headerlink" title="演示方法"></a>演示方法</h2><p>与之前访问openshift的服务一样，<strong>只是将域名解析的IP指向IaaS的LB就可以了</strong>。<br>所有服务都能正常访问。同时对于不同的项目，可以通过创建不同的LB，来实现了负载均衡的扩容，Nginx应用也可以通过创建更多的Instance进行扩容。</p><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>感谢有朋友提出了以下问题：<br>“nginx不好用，除非nginx plus，否则一个master api不可用，还是会访问到那个节点。haproxy配置也很简单，可以有健康检查，如果熟悉的话，最好使用haproxy来作为代理应用。”<br>朋友提出的问题确实是一个很严重的问题，我对haproxy确实不太熟悉~~。<br>但是朋友说的这个问题其实不必太担心，因为nginx默认的轮询方式的请求按时间顺序逐一分配到不同的后端服务器，<strong>如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。</strong>所以nginx自己会对openshift的服务作了检查，来避免朋友提出的问题。<br>我也单独对nginx的这个健康检查作了验证，确实是有效的。<br><strong>再次感谢提出问题的朋友</strong>，后序我也找时间使用haproxy作下测试。</p><h2 id="Haproxy的配置"><a href="#Haproxy的配置" class="headerlink" title="Haproxy的配置"></a>Haproxy的配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">global</span><br><span class="line">    ......</span><br><span class="line">    maxconn  20000</span><br><span class="line">    nbthread 2</span><br><span class="line">    ......</span><br><span class="line">frontend f_8443 *:8443</span><br><span class="line">    use_backend b_8443</span><br><span class="line">    mode  tcp</span><br><span class="line"></span><br><span class="line">backend b_8443</span><br><span class="line">    mode  tcp</span><br><span class="line">    balance  roundrobin</span><br><span class="line">    server master1 99.3.1.1:8443</span><br><span class="line">    server master2 99.3.1.2:8443</span><br><span class="line">    server master3 99.3.1.3:8443</span><br><span class="line"></span><br><span class="line">frontend f_443 *:443</span><br><span class="line">    use_backend b_443</span><br><span class="line">    mode  tcp</span><br><span class="line"></span><br><span class="line">backend b_443</span><br><span class="line">    mode  tcp</span><br><span class="line">    balance  roundrobin</span><br><span class="line">    server infra1 99.3.1.11:443</span><br><span class="line">    server infra2 99.3.1.12:443</span><br><span class="line"></span><br><span class="line">frontend f_80 *:80</span><br><span class="line">    use_backend b_80</span><br><span class="line">    mode  tcp</span><br><span class="line"></span><br><span class="line">backend b_80</span><br><span class="line">    balance  roundrobin</span><br><span class="line">    server infra1 99.3.1.11:80</span><br><span class="line">    server infra2 99.3.1.12:80</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift网络插件动态切换</title>
      <link href="/openshift/Openshift%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E5%8A%A8%E6%80%81%E5%88%87%E6%8D%A2/"/>
      <url>/openshift/Openshift%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E5%8A%A8%E6%80%81%E5%88%87%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="Openshift-3-11版本"><a href="#Openshift-3-11版本" class="headerlink" title="Openshift 3.11版本"></a>Openshift 3.11版本</h1><h4 id="Openshift-SDN网络插件ovs-subnet-与-ovs-multitenant切换"><a href="#Openshift-SDN网络插件ovs-subnet-与-ovs-multitenant切换" class="headerlink" title="Openshift SDN网络插件ovs-subnet 与 ovs-multitenant切换"></a>Openshift SDN网络插件ovs-subnet 与 ovs-multitenant切换</h4><blockquote><ol><li>更改节点上的networkPluginName的配置</li></ol></blockquote><ul><li>master节点：<code>/etc/origin/master/master-config.yaml</code></li><li>node节点：<code>/etc/origin/node/node-config.yaml</code></li><li>将networkPluginName中的<code>redhat/openshift-ovs-subnet</code>换成<code>redhat/openshift-ovs-multitenant</code>,或者反过来。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m shell -a &#x27;sed -i &quot;s/openshift-ovs-subnet/openshift-ovs-multitenant/g&quot; /etc/origin/node/node-config.yaml&#x27;</span><br><span class="line">$ ansible masters  -m shell -a &#x27;sed -i &quot;s/openshift-ovs-subnet/openshift-ovs-multitenant/g&quot; /etc/origin/master/master-config.yaml&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>重启master节点上的origin-master-api和origin-master-controllers服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ansible masters -m shell -a &#x27;master-restart api&#x27; -f 1</span><br><span class="line">$ ansible masters -m shell -a &#x27;master-restart controllers&#x27; -f 1</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>停止节点上的origin-node服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m service -a &#x27;name=origin-node state=stopped&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="4"><li>在所有节点上重启Openshift SDN服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc delete pod --all -n openshift-sdn</span><br></pre></td></tr></table></figure><blockquote><ol start="5"><li>在所有节点上重启origin-node服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m service -a &#x27;name=origin-node state=started&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="6"><li>如果是从openshift sdn插件切换到第三方插件，需要清空将openshit sdn的特性</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ oc delete clusternetwork --all</span><br><span class="line">$ oc delete hostsubnets --all</span><br><span class="line">$ oc delete netnamespaces --all</span><br></pre></td></tr></table></figure><blockquote><ol start="7"><li>检查VNIDs</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get netnamespace</span><br></pre></td></tr></table></figure></li></ul><h4 id="Openshift-SDN网络插件ovs-multitenant-切换到-ovs-networkpolicy"><a href="#Openshift-SDN网络插件ovs-multitenant-切换到-ovs-networkpolicy" class="headerlink" title="Openshift SDN网络插件ovs-multitenant 切换到 ovs-networkpolicy"></a>Openshift SDN网络插件ovs-multitenant 切换到 ovs-networkpolicy</h4><blockquote><ol><li>下载切换脚本并更改执行权限</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -O https://raw.githubusercontent.com/openshift/origin/master/contrib/migration/migrate-network-policy.sh</span><br><span class="line">$ chmod a+x migrate-network-policy.sh</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>执行脚本，openshift使用cluster-admin权限的用户</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./migrate-network-policy.sh</span><br></pre></td></tr></table></figure><h1 id="Openshift-3-9版本"><a href="#Openshift-3-9版本" class="headerlink" title="Openshift 3.9版本"></a>Openshift 3.9版本</h1><h4 id="Openshift-SDN网络插件ovs-subnet-与-ovs-multitenant切换-1"><a href="#Openshift-SDN网络插件ovs-subnet-与-ovs-multitenant切换-1" class="headerlink" title="Openshift SDN网络插件ovs-subnet 与 ovs-multitenant切换"></a>Openshift SDN网络插件ovs-subnet 与 ovs-multitenant切换</h4><blockquote><ol><li>更改节点上的networkPluginName的配置</li></ol></blockquote><ul><li>master节点：<code>/etc/origin/master/master-config.yaml</code></li><li>node节点：<code>/etc/origin/node/node-config.yaml</code></li><li>将networkPluginName中的<code>redhat/openshift-ovs-subnet</code>换成<code>redhat/openshift-ovs-multitenant</code>,或者反过来。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m shell -a &#x27;sed -i &quot;s/openshift-ovs-subnet/openshift-ovs-multitenant/g&quot; /etc/origin/node/node-config.yaml&#x27;</span><br><span class="line">$ ansible masters  -m shell -a &#x27;sed -i &quot;s/openshift-ovs-subnet/openshift-ovs-multitenant/g&quot; /etc/origin/master/master-config.yaml&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>重启master节点上的origin-master-api和origin-master-controllers服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ansible masters -m service -a &#x27;name=origin-master-api state=restarted&#x27; -f 1</span><br><span class="line">$ ansible masters -m service -a &#x27;name=origin-master-controllers state=restarted&#x27; -f 1</span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>停止节点上的origin-node服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m service -a &#x27;name=origin-node state=stopped&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="4"><li>在所有节点上重启openvswitch服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m service -a &#x27;name=openvswitch state=restarted&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="5"><li>在所有节点上重启origin-node服务</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ansible all -m service -a &#x27;name=origin-node state=started&#x27;</span><br></pre></td></tr></table></figure><blockquote><ol start="6"><li>如果是从openshift sdn插件切换到第三方插件，需要清空将openshit sdn的特性</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ oc delete clusternetwork --all</span><br><span class="line">$ oc delete hostsubnets --all</span><br><span class="line">$ oc delete netnamespaces --all</span><br></pre></td></tr></table></figure><blockquote><ol start="7"><li>检查VNIDs</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc get netnamespace</span><br></pre></td></tr></table></figure></li></ul><h4 id="Openshift-SDN网络插件ovs-multitenant-切换到-ovs-networkpolicy-1"><a href="#Openshift-SDN网络插件ovs-multitenant-切换到-ovs-networkpolicy-1" class="headerlink" title="Openshift SDN网络插件ovs-multitenant 切换到 ovs-networkpolicy"></a>Openshift SDN网络插件ovs-multitenant 切换到 ovs-networkpolicy</h4><blockquote><ol><li>下载切换脚本并更改执行权限</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -O https://raw.githubusercontent.com/openshift/origin/master/contrib/migration/migrate-network-policy.sh</span><br><span class="line">$ chmod a+x migrate-network-policy.sh</span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>执行脚本，openshift使用cluster-admin权限的用户</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./migrate-network-policy.sh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift自定义Router成倍提升集群性能</title>
      <link href="/openshift/Openshift%E8%87%AA%E5%AE%9A%E4%B9%89Router%E6%88%90%E5%80%8D%E6%8F%90%E5%8D%87%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD/"/>
      <url>/openshift/Openshift%E8%87%AA%E5%AE%9A%E4%B9%89Router%E6%88%90%E5%80%8D%E6%8F%90%E5%8D%87%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么要自定义Router"><a href="#为什么要自定义Router" class="headerlink" title="为什么要自定义Router"></a>为什么要自定义Router</h2><ul><li>Openshift的Router节点其实就是一个Haproxy容器应用，这个已经不是什么秘密了。我们平常使用时，不需要关心Haproxy的配置，因为它的默认配置完全满足绝大多数情况的需求。</li><li>但是它的默认配置并没有把最大的性能发挥出来，这时就需要我们对Haproxy的配置进行自定义了。</li><li>如果你需要实现一些新的功能，比如说将Mysql通过Router对外提供服务等</li></ul><h2 id="怎样自定义Router"><a href="#怎样自定义Router" class="headerlink" title="怎样自定义Router"></a>怎样自定义Router</h2><ul><li>Router Pod根据haproxy-config模板创建haproxy.conf配置文件，默认文件为<code>/var/lib/haproxy/conf/haproxy-config.template</code></li><li>Router Haproxy镜像启动时会根据环境变量<code>TEMPLATE_FILE</code>来选择最终使用的模板文件</li><li>向Router Pod中放入自定义的模板文件，并将它的路径传给环境变量<code>TEMPLATE_FILE</code></li><li>模板文件中的相关函数</li></ul><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>processEndpointsForAlias(alias ServiceAliasConfig, svc ServiceUnit, action string) []Endpoint</td><td>返回所有可用的endpoints，如果action为shuffle，那返回结果会打乱顺序</td></tr><tr><td>env(variable, default …string) string</td><td>获取环境变量，如果没有环境变量，使用第二个参数的值，如果第二个参数没设置，返回空字符串</td></tr><tr><td>matchPattern(pattern, s string) bool</td><td>第一个参数是正则表达式，第二个参数为校验字符串，如果第二个参数满足正则规则，则返回True，否则返回False</td></tr><tr><td>isInteger(s string) bool</td><td>检查字符串是否为数字格式</td></tr><tr><td>firstMatch(s string, allowedValues …string) bool</td><td>将一个字符串在允许的字符串列表中从左到右匹配，返回最新匹配的字符串</td></tr><tr><td>matchValues(s string, allowedValues …string) bool</td><td>如果字符串与给定的一组字符串中的字符串有匹配，则返回True,否则返回False</td></tr><tr><td>generateRouteRegexp(hostname, path string, wildcard bool) string</td><td>生成一个 与主机名和路径匹配的正则表达式</td></tr><tr><td>genCertificateHostName(hostname string, wildcard bool) string</td><td>为匹配证书生成主机名</td></tr><tr><td>isTrue(s string) bool</td><td>如果给定的字符串中有’true’则返回True,否则False</td></tr></tbody></table><h2 id="自定义Router配置实战"><a href="#自定义Router配置实战" class="headerlink" title="自定义Router配置实战"></a>自定义Router配置实战</h2><ol><li><p>导出Router默认的模板文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc rsh router-1-pod -n default cat haproxy-config.template &gt; haproxy-config.template</span><br></pre></td></tr></table></figure></li><li><p>更改haproxy-config.template，添加nbthread支持 <code>3.10以上版本已添加了该变量</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">global</span><br><span class="line">  nbthread &#123;&#123;env &quot;ROUTER_NBTHREAD&quot; &quot;1&quot;&#125;&#125;</span><br><span class="line">  cpu-map auto:1/1-&#123;&#123;env &quot;ROUTER_NBTHREAD&quot; &quot;1&quot;&#125;&#125; 1-&#123;&#123;env &quot;ROUTER_NBTHREAD&quot; &quot;1&quot;&#125;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>环境变量，3.11版本主要更新以下两个<br><code>ROUTER_THREADS</code><br><code>ROUTER_MAX_CONNECTIONS</code> 默认值是20000</p></li><li><p>创建ConfigMap</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc create configmap customrouter --from-file=haproxy-config.template</span><br></pre></td></tr></table></figure></li><li><p>挂载ConfigMap，设置环境变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#### *3.9* 版本</span><br><span class="line">$ oc volumes dc/router --add --overwrite \</span><br><span class="line">    --name=config-volume \</span><br><span class="line">    --mount-path=/var/lib/haproxy/conf/custom \</span><br><span class="line">    --source=&#x27;&#123;&quot;configMap&quot;: &#123; &quot;name&quot;: &quot;customrouter&quot;&#125;&#125;&#x27;</span><br><span class="line">$ oc set env dc/router \</span><br><span class="line">    TEMPLATE_FILE=/var/lib/haproxy/conf/custom/haproxy-config.template</span><br><span class="line"></span><br><span class="line">#### *3.11* 版本</span><br><span class="line">$ oc set volumes dc/router --add --overwrite \</span><br><span class="line">    --name=config-volume \</span><br><span class="line">    --mount-path=/var/lib/haproxy/conf/custom \</span><br><span class="line">    --source=&#x27;&#123;&quot;configMap&quot;: &#123; &quot;name&quot;: &quot;customrouter&quot;&#125;&#125;&#x27;</span><br><span class="line">$ oc set env dc/router \</span><br><span class="line">    TEMPLATE_FILE=/var/lib/haproxy/conf/custom/haproxy-config.template</span><br></pre></td></tr></table></figure></li><li><p>等待Router自动重启，使用新的配置模板</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ oc rsh router-2-pod -n default cat haproxy.conf</span><br></pre></td></tr></table></figure></li></ol><h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p>通过设置环境变量ROUTER_NBTHREAD的值，使用Jmeter对应用进行压力测试</p><table><thead><tr><th>ROUTER_NBTHREAD</th><th>Avg(ms)</th><th>Min(ms)</th><th>Max(ms)</th><th>Error</th><th>TPS(&#x2F;s)</th></tr></thead><tbody><tr><td>1</td><td>194</td><td>0</td><td>8383</td><td>0</td><td>18322</td></tr><tr><td>2</td><td>133</td><td>0</td><td>15602</td><td>0</td><td>31160</td></tr><tr><td>4</td><td>127</td><td>0</td><td>7553</td><td>0</td><td>47049</td></tr><tr><td>8</td><td>138</td><td>0</td><td>14259</td><td>0</td><td>41995</td></tr><tr><td>16</td><td>163</td><td>0</td><td>10069</td><td>1(0%)</td><td>23979</td></tr><tr><td>从中可以看出，不同的nbthread对Router容量的影响非常大，当nbthread&#x3D;4时，容量达到默认的nbthread&#x3D;1的2倍。</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><p>参考文章：<br><a href="https://docs.openshift.com/container-platform/3.9/install_config/router/customized_haproxy_router.html">Openshift 自定义Router的haproxy配置</a><br><a href="https://developers.redhat.com/blog/2018/04/02/red-hat-openshift-container-platform-load-testing-tips/">Openshift 容器平台负载测试</a><br><a href="https://www.haproxy.com/blog/multithreading-in-haproxy/">Haproxy多线程</a><br><a href="http://coyee.com/article/12115-haproxy-performance-tweaks-sysctl-and-config">Haproxy性能优化</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift部署zalenium(容器化的selenium)及Python自动测试</title>
      <link href="/openshift/Openshift%E9%83%A8%E7%BD%B2zalenium(%E5%AE%B9%E5%99%A8%E5%8C%96%E7%9A%84selenium)%E5%8F%8APython%E8%87%AA%E5%8A%A8%E6%B5%8B%E8%AF%95/"/>
      <url>/openshift/Openshift%E9%83%A8%E7%BD%B2zalenium(%E5%AE%B9%E5%99%A8%E5%8C%96%E7%9A%84selenium)%E5%8F%8APython%E8%87%AA%E5%8A%A8%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是zalenium"><a href="#什么是zalenium" class="headerlink" title="什么是zalenium"></a>什么是zalenium</h2><p>zalenium是一个Selenium Grid扩展，用Docker容器动态扩展你的本地网格。它使用docker-selenium在本地运行Firefox和Chrome中的测试。官网地址 <a href="https://opensource.zalando.com/zalenium/">zalenium</a></p><h2 id="Openshift上部署zalenium"><a href="#Openshift上部署zalenium" class="headerlink" title="Openshift上部署zalenium"></a>Openshift上部署zalenium</h2><blockquote><p>创建zalenium项目</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc new-project zalenium --display-name=&quot;自动测试Selenium Grid&quot;</span><br></pre></td></tr></table></figure><blockquote><p>创建Service Account</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"># 创建ClusterRole</span><br><span class="line"># oc create -f zalenium-role.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;kind&quot;: &quot;ClusterRole&quot;,</span><br><span class="line">    &quot;apiVersion&quot;: &quot;v1&quot;,</span><br><span class="line">    &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;zalenium-role&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;rules&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;verbs&quot;: [</span><br><span class="line">                &quot;create&quot;,</span><br><span class="line">                &quot;list&quot;,</span><br><span class="line">                &quot;get&quot;,</span><br><span class="line">                &quot;delete&quot;,</span><br><span class="line">                &quot;exec&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;attributeRestrictions&quot;: null,</span><br><span class="line">            &quot;apiGroups&quot;: [</span><br><span class="line">                &quot;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;resources&quot;: [</span><br><span class="line">                &quot;pods&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;verbs&quot;: [</span><br><span class="line">                &quot;list&quot;,</span><br><span class="line">                &quot;create&quot;,</span><br><span class="line">                &quot;delete&quot;,</span><br><span class="line">                &quot;get&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;attributeRestrictions&quot;: null,</span><br><span class="line">            &quot;apiGroups&quot;: [</span><br><span class="line">                &quot;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;resources&quot;: [</span><br><span class="line">                &quot;services&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;verbs&quot;: [</span><br><span class="line">                &quot;create&quot;,</span><br><span class="line">                &quot;get&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;attributeRestrictions&quot;: null,</span><br><span class="line">            &quot;apiGroups&quot;: [</span><br><span class="line">                &quot;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;resources&quot;: [</span><br><span class="line">                &quot;pods/exec&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">     ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">oc create -f zalenium-role.json</span><br><span class="line">oc  create sa zalenium</span><br><span class="line">oc adm policy add-scc-to-user anyuid -z zalenium</span><br><span class="line">oc adm policy add-role-to-user zalenium-role -z zalenium</span><br></pre></td></tr></table></figure><blockquote><p>部署zalenium</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">oc run zalenium --image=dosel/zalenium \</span><br><span class="line">        --env=&quot;ZALENIUM_KUBERNETES_CPU_REQUEST=250m&quot; \</span><br><span class="line">        --env=&quot;ZALENIUM_KUBERNETES_CPU_LIMIT=500m&quot; \</span><br><span class="line">        --env=&quot;ZALENIUM_KUBERNETES_MEMORY_REQUEST=1Gi&quot; \</span><br><span class="line">        --overrides=&#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;spec&quot;: &#123;&quot;serviceAccount&quot;: &quot;zalenium&quot;&#125;&#125;&#125;&#125;&#x27; \</span><br><span class="line">        -l app=zalenium,role=hub --port=4444 -- \</span><br><span class="line">        start --desiredContainers 2 --seleniumImageName elgalu/selenium:latest</span><br></pre></td></tr></table></figure><blockquote><p>创建Service</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#创建相应的service</span><br><span class="line"># oc create -f zalenium-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    app: zalenium</span><br><span class="line">  name: zalenium</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: 4444-tcp</span><br><span class="line">    port: 4444</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 4444</span><br><span class="line">  - name: 4445-tcp</span><br><span class="line">    port: 4445</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 4445</span><br><span class="line">  selector:</span><br><span class="line">    app: zalenium</span><br><span class="line">    role: hub</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  type: ClusterIP</span><br><span class="line">status:</span><br><span class="line">loadBalancer: &#123;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>创建Router</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># oc create -f ./zalenium-route.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Route</span><br><span class="line">metadata:</span><br><span class="line">  name: zalenium</span><br><span class="line">  annotations:</span><br><span class="line">    haproxy.router.openshift.io/timeout: 60s</span><br><span class="line">spec:</span><br><span class="line">  host: zalenium.example.com</span><br><span class="line">  port:</span><br><span class="line">    targetPort: 4444-tcp</span><br><span class="line">  to:</span><br><span class="line">    kind: Service</span><br><span class="line">name: zalenium</span><br></pre></td></tr></table></figure><blockquote><p>访问被管理selenium状态</p></blockquote><p><code>http://zalenium-zalenium.demo.example.com/grid/admin/live</code><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7a8035a4b21e21b9c15699d8d212295c47d7b3990a76bedcc5b13446828ca887.png" alt="zalenium演示.PNG">  </p><h2 id="Python具体实现自动测试"><a href="#Python具体实现自动测试" class="headerlink" title="Python具体实现自动测试"></a>Python具体实现自动测试</h2><blockquote><p>安装selenium模块</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure><blockquote><p>代码</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.remote.remote_connection import RemoteConnection</span><br><span class="line"># 创建远程连接selenium grid</span><br><span class="line">remoteconnection = RemoteConnection(&#x27;http://zalenium-zalenium.demo.example.com/wd/hub&#x27;, keep_alive=False,</span><br><span class="line">                                    resolve_ip=False)</span><br><span class="line"></span><br><span class="line">driver = webdriver.Remote(command_executor=remoteconnection,</span><br><span class="line">                          desired_capabilities=&#123;</span><br><span class="line">                              &#x27;browserName&#x27;: &quot;chrome&quot;,</span><br><span class="line">                              &#x27;video&#x27;: &#x27;True&#x27;,</span><br><span class="line">                              &#x27;platform&#x27;: &#x27;LINUX&#x27;,</span><br><span class="line">                              &#x27;platformName&#x27;: &#x27;LINUX&#x27;</span><br><span class="line">                          &#125;)</span><br><span class="line">try:</span><br><span class="line">    driver.implicitly_wait(30)</span><br><span class="line">    driver.maximize_window()</span><br><span class="line">    driver.get(&quot;http://www.baidu.com&quot;)</span><br><span class="line">    assert u&#x27;百度一下，你就知道&#x27; in driver.title</span><br><span class="line">    kw_input = driver.find_element_by_id(&#x27;kw&#x27;)</span><br><span class="line">    su_button = driver.find_element_by_id(&#x27;su&#x27;)</span><br><span class="line">    kw_input.clear()</span><br><span class="line">   # 输入关键字Openshift</span><br><span class="line">    kw_input.send_keys(&#x27;Openshift&#x27;)</span><br><span class="line">    su_button.click()</span><br><span class="line"></span><br><span class="line">finally:</span><br><span class="line">    driver.quit()</span><br></pre></td></tr></table></figure><p><code>说明</code>：<br><code>创建RemoteConnection时需要设置keep_alive=False及设置resolve_ip=False。</code><br><code>resolve_ip默认为True，它会解析senelium grip服务器的ip,便通过Ip去访问。我们知道Openshift的应用是无法使用ip来访问的，必须使用域名。所以需要将resolve_ip设置为False。当然，如果我们部署zalenium中的service使用nodeport将4444端口暴露出去的resolve_ip可以使用默认值。</code></p><blockquote><p>查看自动测试结果</p></blockquote><p><code>http://zalenium-zalenium.demo.example.com/dashboard</code><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e774964ce53cd63c75b7d37d8188b22f8483ca5016cb63d4b54566a083054a4d.png" alt="zalenium演示结果.PNG">  </p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift部署测试环境oc-cluster-up</title>
      <link href="/openshift/Openshift%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83oc-cluster-up/"/>
      <url>/openshift/Openshift%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83oc-cluster-up/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc cluster up --base-dir=/root/openshift --public-hostname=master.douhua.com</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift集群3-9升级到3-10</title>
      <link href="/openshift/Openshift%E9%9B%86%E7%BE%A43-9%E5%8D%87%E7%BA%A7%E5%88%B03-10/"/>
      <url>/openshift/Openshift%E9%9B%86%E7%BE%A43-9%E5%8D%87%E7%BA%A7%E5%88%B03-10/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-f88bead92a86d374.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Openshift 升级中......"></p><h3 id="更新方法与策略：自动升级方法"><a href="#更新方法与策略：自动升级方法" class="headerlink" title="更新方法与策略：自动升级方法"></a>更新方法与策略：自动升级方法</h3><blockquote><p>下载openshift-ansible的脚本代码<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/openshift/openshift-ansible.git </span><br><span class="line">git checkout  release-3.10</span><br></pre></td></tr></table></figure><br>将master上的&#x2F;etc&#x2F;origin&#x2F;master&#x2F;htpasswd备份到&#x2F;root&#x2F;htpasswd</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp master1:/etc/origin/master/htpasswd /root/htpasswd</span><br></pre></td></tr></table></figure><blockquote><p>openshift_master_identity_providers中的filename去掉</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># /etc/ansible/hosts</span><br><span class="line">openshift_master_identity_providers=[&#123;&#x27;name&#x27;: &#x27;htpasswd_auth&#x27;, &#x27;login&#x27;:&#x27;true&#x27;,&#x27;challenge&#x27;: &#x27;true&#x27;, &#x27;kind&#x27;: &#x27;HTPasswdPasswordIdentityProvider&#x27;&#125;]</span><br><span class="line">openshift_master_htpasswd_file=/root/htpasswd</span><br></pre></td></tr></table></figure><blockquote><p>屏蔽掉引入[gluster]导致的一个升级错误</p></blockquote><p>在<code>playbooks/common/openshift-cluster/upgrades/v3_10/upgrade_control_plane.yml</code>中会去做对<code>glusterfs</code>与<code>glusterfs_registry</code>的比较，3.9之前未必需这些host group所以需要在ansible&#x2F;hosts中需要添加该host group</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#/etc/ansible/host</span><br><span class="line">[glusterfs]</span><br><span class="line">[glusterfs_registry]</span><br></pre></td></tr></table></figure><blockquote><p>在ansible&#x2F;hosts中的nodes列表中添加openshift_node_group_name</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">master openshift_node_group_name=&#x27;node-config-master&#x27;</span><br><span class="line">node openshift_node_group_name=&#x27;node-config-compute&#x27;</span><br><span class="line">infra openshift_node_group_name=&#x27;node-config-infra&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>升级默认的node group configmap</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># ansible-playbook -i &lt;/path/to/inventory/file&gt;  playbooks/openshift-master/openshift_node_group.yml</span><br></pre></td></tr></table></figure><blockquote><p>检测Python OpenSSL版本</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python -c &#x27;import OpenSSL.crypto&#x27;</span><br><span class="line"># 如果报错则需要升级Python OpenSSL</span><br><span class="line">yum install python2-pip</span><br><span class="line">pip install -U pyopenssl -i https://pypi.douban.com/simple</span><br></pre></td></tr></table></figure><blockquote><p>关闭etcd目录的selinux检查<strong>【不建议这么做，建议开启selinux】</strong><br>关闭任务Check selinux label of ‘‘与Make sure the ‘‘ has the proper label</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># roles/etcd/tasks/backup/backup.yml</span><br><span class="line">...</span><br><span class="line">- name: Detecting Atomic Host Operating System</span><br><span class="line">  stat:</span><br><span class="line">    path: /run/ostree-booted</span><br><span class="line">  register: l_ostree_booted</span><br><span class="line"></span><br><span class="line">#- name: Check selinux label of &#x27;&#123;&#123; etcd_data_dir &#125;&#125;&#x27;</span><br><span class="line">#  command: &gt;</span><br><span class="line">#    stat -c &#x27;%C&#x27; &#123;&#123; etcd_data_dir &#125;&#125;</span><br><span class="line">#  register: l_etcd_selinux_labels</span><br><span class="line">#</span><br><span class="line">#- debug:</span><br><span class="line">#    msg: &quot;&#123;&#123; l_etcd_selinux_labels &#125;&#125;&quot;</span><br><span class="line">#</span><br><span class="line">#- name: Make sure the &#x27;&#123;&#123; etcd_data_dir &#125;&#125;&#x27; has the proper label</span><br><span class="line">#  command: &gt;</span><br><span class="line">#    chcon -t svirt_sandbox_file_t  &quot;&#123;&#123; etcd_data_dir &#125;&#125;&quot;</span><br><span class="line">#  when:</span><br><span class="line">#  - l_etcd_selinux_labels.rc == 0</span><br><span class="line">#  - &quot;&#x27;svirt_sandbox_file_t&#x27; not in l_etcd_selinux_labels.stdout&quot;</span><br><span class="line"></span><br><span class="line">- name: Generate etcd backup</span><br><span class="line">  command: &gt;</span><br><span class="line">    &#123;&#123; r_etcd_common_etcdctl_command &#125;&#125; backup --data-dir=&#123;&#123; l_etcd_incontainer_data_dir &#125;&#125;</span><br><span class="line">    --backup-dir=&#123;&#123; l_etcd_incontainer_backup_dir &#125;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>升级集群</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># ansible-playbook -i &lt;/path/to/inventory/file&gt;  playbooks/byo/openshift-cluster/upgrades/v3_10/upgrade.yml</span><br></pre></td></tr></table></figure><hr><h3 id="升级过程中可能遇到的问题"><a href="#升级过程中可能遇到的问题" class="headerlink" title="升级过程中可能遇到的问题"></a>升级过程中可能遇到的问题</h3><blockquote><p>webconsole自定义兼容问题</p></blockquote><p>webconsole自定义格式是通过在openshift-web-console项目中的<code>webconsole-config</code>ConfigMap添加css与js文件路径实现的，3.9版本支持路径不添加引号，而3.10版本必须添加引号。</p><blockquote><p>selinux启动问题</p></blockquote><p>每个节点（包括Master&#x2F;router&#x2F;node）都需要开启selinux。</p><blockquote><p>ceph 无法挂载问题</p></blockquote><p>升级过程中，如果有ceph挂载，则会出现超时，升级完成后，自动修复该问题。</p><blockquote><p>HTPasswdPasswordIdentityProvider方式ansible_hosts文件格式更新问题</p></blockquote><p>3.9版本可以将htpasswd文件路径填写在openshift_master_identity_providers变量中，而3.10版本则需要分开写，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">openshift_master_identity_providers=[&#123;&#x27;name&#x27;: &#x27;htpasswd_auth&#x27;, &#x27;login&#x27;:&#x27;true&#x27;,&#x27;challenge&#x27;: &#x27;true&#x27;, &#x27;kind&#x27;: &#x27;HTPasswdPasswordIdentityProvider&#x27;&#125;]</span><br><span class="line">openshift_master_htpasswd_file=/root/htpasswd</span><br></pre></td></tr></table></figure><blockquote><p>对于router节点添加了独占配置后，ovs服务无法部署问题</p></blockquote><p>版本3.10将组件使用容器的方式部署，如果router节点设置了taints（目的是为了router节点只给route服务，确保应用的性能）那么node,ovs服务将无法在router节点上部署。这时需要给对应deamonset设置tolerations。目前相关的daemonset有：<code>openshift-node/sync</code>、<code>openshift-sdn/sdn</code>、<code>openshift-sdn/ovs</code>。</p><blockquote><p>升级集群时为了尽可能影响线上业务，可以使用分步升级法</p></blockquote><p>所谓分步升级法，就是先升级Master控制节点，再逐个升级计算节点。</p><ol><li>通过执行upgrade_control_plane.yaml 脚本来升级控制平台节点<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cd /usr/share/ansible/openshift-ansible</span><br><span class="line">$ ansible-playbook -i &lt;/path/to/inventory/file&gt; \</span><br><span class="line">    playbooks/byo/openshift-cluster/upgrades/v3_11/upgrade_control_plane.yml</span><br></pre></td></tr></table></figure></li><li>通过执行upgrade_nodes.yaml 脚本来升级计算节点<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd /usr/share/ansible/openshift-ansible</span><br><span class="line">$ ansible-playbook -i &lt;/path/to/inventory/file&gt; \</span><br><span class="line">    playbooks/byo/openshift-cluster/upgrades/v3_11/upgrade_nodes.yml \</span><br><span class="line">    [-e &lt;customized_node_upgrade_variables&gt;] </span><br></pre></td></tr></table></figure>通过-e传入变量的方式来控制升级Node节点的节奏。例如<br><code>-e openshift_upgrade_nodes_serial=&quot;20%&quot;</code> 表示一次只升级20%的节点<br><code>-e openshift_upgrade_nodes_serial=&quot;2&quot;     -e openshift_upgrade_nodes_label=&quot;region=group1&quot;</code>表示一次只升级带label为region&#x3D;group1的节点中的2个。<br><code>-e openshift_upgrade_nodes_drain_timeout=600</code>设置openshift_upgrade_nodes_drain_timeout变量以指定将节点标记为失败之前要等待的时间。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift集群全环境备份</title>
      <link href="/openshift/Openshift%E9%9B%86%E7%BE%A4%E5%85%A8%E7%8E%AF%E5%A2%83%E5%A4%87%E4%BB%BD/"/>
      <url>/openshift/Openshift%E9%9B%86%E7%BE%A4%E5%85%A8%E7%8E%AF%E5%A2%83%E5%A4%87%E4%BB%BD/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-081408b72aaadaa8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="与内容无关"></p><p>创建集群全环境备份非常有必要，特别是在生产过程中。当集群发生异常崩溃，数据丢失时，备份的数据就派上了用场，利用备份数据可以将之前的环境重新构建出来。</p><p>在Openshift平台，我们可以对集群的完整状态备份到外部存储。集群全环境包括：</p><ul><li><p>集群数据文件</p></li><li><p>etcd数据库</p></li><li><p>Openshift对象配置</p></li><li><p>私有镜像仓库存储</p></li><li><p>持久化卷</p></li></ul><p>我们要定期对集群作备份，以防止数据的丢失。</p><p><code>集群全环境备份并不是万能的，应用自己的数据我们应该保证有单独的备份。</code></p><h3 id="创建Master节点备份"><a href="#创建Master节点备份" class="headerlink" title="创建Master节点备份"></a>创建Master节点备份</h3><p>在系统基础架构进行更改，都需要对节点做备份。比如说，系统升级，集群升级或者任何重大更新。通过定期备份数据，当集群出现故障时，我们就能使用备份恢复集群。</p><p>Master主机上运行着非常重要的服务：API、Controllers。&#x2F;etc&#x2F;origin&#x2F;master目录下存放着许多重要的文件。</p><ul><li><p>API、Controllers服务等的配置文件</p></li><li><p>安装生成的证书</p></li><li><p>云提供商提供的配置文件</p></li><li><p>密钥和其它身份认证文件</p></li></ul><p>另外如果有额外自定义的配置，比如更改日志级别，使用代理等。这些配置文件在&#x2F;etc&#x2F;sysconfig&#x2F;目录下。</p><p>Master节点同时也是计算节点，所以备份&#x2F;etc&#x2F;origin整个目录。</p><h4 id="备份过程"><a href="#备份过程" class="headerlink" title="备份过程"></a>备份过程</h4><p>需要在每台Master节点上都运行备份操作</p><ol><li><p>主机配置文件备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/origin <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/sysconfig/ <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig/</span></span><br></pre></td></tr></table></figure><p><code>注意:</code> &#x2F;etc&#x2F;origin&#x2F;master&#x2F;ca.serial.txt文件只在会安装的ansible inventory hosts中的第一台master主机上创建，如果弃用该台主机时，需要将该文件拷贝到其它的Master主机上。</p></li><li><p>备份其它重要的文件</p><table><thead><tr><th>File</th><th>Description</th></tr></thead><tbody><tr><td>&#x2F;etc&#x2F;cni&#x2F;*</td><td>CNI配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;iptables</td><td><code>iptables </code>防火墙配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker-storage-setup</td><td><code>container-storage-setup</code> 命令调用</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker</td><td><code>docker</code> 应用配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker-network</td><td><code>docker</code> 网络配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker-storage</td><td><code>docker</code> 容器存储配置</td></tr><tr><td>&#x2F;etc&#x2F;dnsmasq.conf</td><td><code>dnsmasq</code> 的配置</td></tr><tr><td>&#x2F;etc&#x2F;dnsmasq.d&#x2F;*</td><td><code>dnsmasq</code> 的额外配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;flanneld</td><td><code>flannel</code> 配置文件</td></tr><tr><td>&#x2F;etc&#x2F;pki&#x2F;ca-trust&#x2F;source&#x2F;anchors&#x2F;</td><td>系统信任的证书</td></tr></tbody></table><p>备份以上文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/pki/ca-trust/source/anchors</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/sysconfig/&#123;iptables,docker-*,flanneld&#125; \</span></span><br><span class="line"><span class="language-bash">    <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/dnsmasq* /etc/cni <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/pki/ca-trust/source/anchors/* \</span></span><br><span class="line"><span class="language-bash">    <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/pki/ca-trust/source/anchors/</span></span><br></pre></td></tr></table></figure></li><li><p>如果安装在系统中的应用包被意外删除，也会影响到集群的运行，所以需要备份系统中安装的rpm包列表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -qa | <span class="built_in">sort</span> | sudo <span class="built_in">tee</span> <span class="variable">$MYBACKUPDIR</span>/packages.txt</span></span><br></pre></td></tr></table></figure></li><li><p>执行了上面的操作后，备份目录中会有如下文件列表，可将它们压缩在一个文件中进行保存</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo find <span class="variable">$&#123;MYBACKUPDIR&#125;</span> -mindepth 1 -<span class="built_in">type</span> f -<span class="built_in">printf</span> <span class="string">&#x27;%P\n&#x27;</span></span></span><br><span class="line">etc/sysconfig/flanneld</span><br><span class="line">etc/sysconfig/iptables</span><br><span class="line">etc/sysconfig/docker-network</span><br><span class="line">etc/sysconfig/docker-storage</span><br><span class="line">etc/sysconfig/docker-storage-setup</span><br><span class="line">etc/sysconfig/docker-storage-setup.rpmnew</span><br><span class="line">etc/origin/master/ca.crt</span><br><span class="line">etc/origin/master/ca.key</span><br><span class="line">etc/origin/master/ca.serial.txt</span><br><span class="line">etc/origin/master/ca-bundle.crt</span><br><span class="line">etc/origin/master/master.proxy-client.crt</span><br><span class="line">etc/origin/master/master.proxy-client.key</span><br><span class="line">etc/origin/master/service-signer.crt</span><br><span class="line">etc/origin/master/service-signer.key</span><br><span class="line">etc/origin/master/serviceaccounts.private.key</span><br><span class="line">etc/origin/master/serviceaccounts.public.key</span><br><span class="line">etc/origin/master/openshift-master.crt</span><br><span class="line">etc/origin/master/openshift-master.key</span><br><span class="line">etc/origin/master/openshift-master.kubeconfig</span><br><span class="line">etc/origin/master/master.server.crt</span><br><span class="line">etc/origin/master/master.server.key</span><br><span class="line">etc/origin/master/master.kubelet-client.crt</span><br><span class="line">etc/origin/master/master.kubelet-client.key</span><br><span class="line">etc/origin/master/admin.crt</span><br><span class="line">etc/origin/master/admin.key</span><br><span class="line">etc/origin/master/admin.kubeconfig</span><br><span class="line">etc/origin/master/etcd.server.crt</span><br><span class="line">etc/origin/master/etcd.server.key</span><br><span class="line">etc/origin/master/master.etcd-client.key</span><br><span class="line">etc/origin/master/master.etcd-client.csr</span><br><span class="line">etc/origin/master/master.etcd-client.crt</span><br><span class="line">etc/origin/master/master.etcd-ca.crt</span><br><span class="line">etc/origin/master/policy.json</span><br><span class="line">etc/origin/master/scheduler.json</span><br><span class="line">etc/origin/master/htpasswd</span><br><span class="line">etc/origin/master/session-secrets.yaml</span><br><span class="line">etc/origin/master/openshift-router.crt</span><br><span class="line">etc/origin/master/openshift-router.key</span><br><span class="line">etc/origin/master/registry.crt</span><br><span class="line">etc/origin/master/registry.key</span><br><span class="line">etc/origin/master/master-config.yaml</span><br><span class="line">etc/origin/generated-configs/master-master-1.example.com/master.server.crt</span><br><span class="line">...[OUTPUT OMITTED]...</span><br><span class="line">etc/origin/cloudprovider/openstack.conf</span><br><span class="line">etc/origin/node/system:node:master-0.example.com.crt</span><br><span class="line">etc/origin/node/system:node:master-0.example.com.key</span><br><span class="line">etc/origin/node/ca.crt</span><br><span class="line">etc/origin/node/system:node:master-0.example.com.kubeconfig</span><br><span class="line">etc/origin/node/server.crt</span><br><span class="line">etc/origin/node/server.key</span><br><span class="line">etc/origin/node/node-dnsmasq.conf</span><br><span class="line">etc/origin/node/resolv.conf</span><br><span class="line">etc/origin/node/node-config.yaml</span><br><span class="line">etc/origin/node/flannel.etcd-client.key</span><br><span class="line">etc/origin/node/flannel.etcd-client.csr</span><br><span class="line">etc/origin/node/flannel.etcd-client.crt</span><br><span class="line">etc/origin/node/flannel.etcd-ca.crt</span><br><span class="line">etc/pki/ca-trust/source/anchors/openshift-ca.crt</span><br><span class="line">etc/pki/ca-trust/source/anchors/registry-ca.crt</span><br><span class="line">etc/dnsmasq.conf</span><br><span class="line">etc/dnsmasq.d/origin-dns.conf</span><br><span class="line">etc/dnsmasq.d/origin-upstream-dns.conf</span><br><span class="line">etc/dnsmasq.d/node-dnsmasq.conf</span><br><span class="line">packages.txt</span><br></pre></td></tr></table></figure><p>将备份的文件进行压缩</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo tar -zcvf /backup/$(hostname)-$(<span class="built_in">date</span> +%Y%m%d).tar.gz <span class="variable">$MYBACKUPDIR</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">rm</span> -Rf <span class="variable">$&#123;MYBACKUPDIR&#125;</span></span></span><br></pre></td></tr></table></figure></li></ol><p><em>Openshift 已经在openshift-ansible-contrib这个项目中提供了备份脚本backup_master_node.sh</em></p><p>将该脚本代码存放在master主机上，并执行，将会自动运行上面的步骤，对master主机进行备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> ~/git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ~/git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/openshift/openshift-ansible-contrib.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> openshift-ansible-contrib/reference-architecture/day2ops/scripts</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./backup_master_node.sh -h</span></span><br></pre></td></tr></table></figure><h3 id="创建计算节点备份"><a href="#创建计算节点备份" class="headerlink" title="创建计算节点备份"></a>创建计算节点备份</h3><p>创建计算节点的备份与Master节点的备份不一样，Master节点上有很多非常重要的文件，所以备份Master节点非常有必要。但是计算节点上一般并不保存运行集群的必要数据，即使计算节点出现了故障，其它节点也能代替它的功能，而不受影响。所以一般不需要备份计算节点，如果有一些特殊的配置必须要备份计算节点，则备份计算节点。</p><p>如果计算节点需要备份，那跟Master节点一样，在系统升级，集群升级或者集群有重要变更时都需要对节点做备份，同时也需要定期备份。</p><p>计算节点的主要配置文件存放在&#x2F;etc&#x2F;origin&#x2F;和&#x2F;etc&#x2F;origin&#x2F;node目录中。</p><ul><li><p>计算节点服务的配置</p></li><li><p>安装时生成的证书</p></li><li><p>云提供商提供的配置文件</p></li><li><p>密钥和其它身份认证文件</p></li></ul><p>另外如果有额外自定义的配置，比如更改日志级别，使用代理等。这些配置文件在&#x2F;etc&#x2F;sysconfig&#x2F;目录下。</p><h4 id="备份过程-1"><a href="#备份过程-1" class="headerlink" title="备份过程"></a>备份过程</h4><ol><li>对计算节点服务的配置作备份</li></ol>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/origin <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/sysconfig/origin-node <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig/</span></span><br></pre></td></tr></table></figure><ol start="2"><li><p>备份其它重要的文件</p><table><thead><tr><th>File</th><th>Description</th></tr></thead><tbody><tr><td>&#x2F;etc&#x2F;cni&#x2F;*</td><td>CNI配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;iptables</td><td><code>iptables </code>防火墙配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker-storage-setup</td><td><code>container-storage-setup</code> 命令调用</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker</td><td><code>docker</code> 应用配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker-network</td><td><code>docker</code> 网络配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;docker-storage</td><td><code>docker</code> 容器存储配置</td></tr><tr><td>&#x2F;etc&#x2F;dnsmasq.conf</td><td><code>dnsmasq</code> 的配置</td></tr><tr><td>&#x2F;etc&#x2F;dnsmasq.d&#x2F;*</td><td><code>dnsmasq</code> 的额外配置</td></tr><tr><td>&#x2F;etc&#x2F;sysconfig&#x2F;flanneld</td><td><code>flannel</code> 配置文件</td></tr><tr><td>&#x2F;etc&#x2F;pki&#x2F;ca-trust&#x2F;source&#x2F;anchors&#x2F;</td><td>系统信任的证书</td></tr></tbody></table><p>备份以上文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/pki/ca-trust/source/anchors</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/sysconfig/&#123;iptables,docker-*,flanneld&#125; \</span></span><br><span class="line"><span class="language-bash">    <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/sysconfig/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/dnsmasq* /etc/cni <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -aR /etc/pki/ca-trust/source/anchors/* \</span></span><br><span class="line"><span class="language-bash">    <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/pki/ca-trust/source/anchors/</span></span><br></pre></td></tr></table></figure></li><li><p>如果安装在系统中的应用包被意外删除，也会影响到集群的运行，所以需要备份系统中安装的rpm包列表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p <span class="variable">$&#123;MYBACKUPDIR&#125;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -qa | <span class="built_in">sort</span> | sudo <span class="built_in">tee</span> <span class="variable">$MYBACKUPDIR</span>/packages.txt</span></span><br></pre></td></tr></table></figure></li><li><p>执行了上面的操作后，备份目录中会有如下文件列表，可将它们压缩在一个文件中进行保存</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo find <span class="variable">$&#123;MYBACKUPDIR&#125;</span> -mindepth 1 -<span class="built_in">type</span> f -<span class="built_in">printf</span> <span class="string">&#x27;%P\n&#x27;</span></span></span><br><span class="line">etc/sysconfig/origin-node</span><br><span class="line">etc/sysconfig/flanneld</span><br><span class="line">etc/sysconfig/iptables</span><br><span class="line">etc/sysconfig/docker-network</span><br><span class="line">etc/sysconfig/docker-storage</span><br><span class="line">etc/sysconfig/docker-storage-setup</span><br><span class="line">etc/sysconfig/docker-storage-setup.rpmnew</span><br><span class="line">etc/origin/node/system:node:app-node-0.example.com.crt</span><br><span class="line">etc/origin/node/system:node:app-node-0.example.com.key</span><br><span class="line">etc/origin/node/ca.crt</span><br><span class="line">etc/origin/node/system:node:app-node-0.example.com.kubeconfig</span><br><span class="line">etc/origin/node/server.crt</span><br><span class="line">etc/origin/node/server.key</span><br><span class="line">etc/origin/node/node-dnsmasq.conf</span><br><span class="line">etc/origin/node/resolv.conf</span><br><span class="line">etc/origin/node/node-config.yaml</span><br><span class="line">etc/origin/node/flannel.etcd-client.key</span><br><span class="line">etc/origin/node/flannel.etcd-client.csr</span><br><span class="line">etc/origin/node/flannel.etcd-client.crt</span><br><span class="line">etc/origin/node/flannel.etcd-ca.crt</span><br><span class="line">etc/origin/cloudprovider/openstack.conf</span><br><span class="line">etc/pki/ca-trust/source/anchors/openshift-ca.crt</span><br><span class="line">etc/pki/ca-trust/source/anchors/registry-ca.crt</span><br><span class="line">etc/dnsmasq.conf</span><br><span class="line">etc/dnsmasq.d/origin-dns.conf</span><br><span class="line">etc/dnsmasq.d/origin-upstream-dns.conf</span><br><span class="line">etc/dnsmasq.d/node-dnsmasq.conf</span><br><span class="line">packages.txt</span><br></pre></td></tr></table></figure><p>将备份的文件进行压缩</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo tar -zcvf /backup/$(hostname)-$(<span class="built_in">date</span> +%Y%m%d).tar.gz <span class="variable">$MYBACKUPDIR</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">rm</span> -Rf <span class="variable">$&#123;MYBACKUPDIR&#125;</span></span></span><br></pre></td></tr></table></figure><h6 id="Openshift-已经在openshift-ansible-contrib这个项目中提供了备份脚本backup-master-node-sh"><a href="#Openshift-已经在openshift-ansible-contrib这个项目中提供了备份脚本backup-master-node-sh" class="headerlink" title="Openshift 已经在openshift-ansible-contrib这个项目中提供了备份脚本backup_master_node.sh"></a>Openshift 已经在openshift-ansible-contrib这个项目中提供了备份脚本backup_master_node.sh</h6><p>将该脚本代码存放在master主机上，并执行，将会自动运行上面的步骤，对master主机进行备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> ~/git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ~/git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/openshift/openshift-ansible-contrib.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> openshift-ansible-contrib/reference-architecture/day2ops/scripts</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./backup_master_node.sh -h</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="备份私服镜像仓库证书"><a href="#备份私服镜像仓库证书" class="headerlink" title="备份私服镜像仓库证书"></a>备份私服镜像仓库证书</h3><p>如果使用了外部私有镜像仓库，就必须备份所有的外部镜像仓库的证书。</p><h4 id="备份过程-2"><a href="#备份过程-2" class="headerlink" title="备份过程"></a>备份过程</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /etc/docker/certs.d/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar cf /tmp/docker-registry-certs-$(hostname).tar *</span></span><br></pre></td></tr></table></figure><h3 id="备份相关安装文件"><a href="#备份相关安装文件" class="headerlink" title="备份相关安装文件"></a>备份相关安装文件</h3><p>还原过程集群过程需要完全重新安装，所以需要保存所有相关的文件。包括</p><ul><li>ansible playbooks和inventory hosts完整内容</li><li>yum源文件</li></ul><h3 id="备份应用数据"><a href="#备份应用数据" class="headerlink" title="备份应用数据"></a>备份应用数据</h3><p>大部分情况下，可以使用<code>oc rsync</code> 命令来对应用数据做备份。这个是通用的备份方案。</p><p>不同的存储方案，比如说NFS等，也可以根据存储的不同，使用更方便的备份方案。</p><p>同时备份的目录，也根据应用程序的不同而不同。</p><p>以下是一个备份jenkins应用的例子。</p><h4 id="备份过程-3"><a href="#备份过程-3" class="headerlink" title="备份过程"></a>备份过程</h4><ol><li><p>获得jenkins应用数据挂载目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get dc/jenkins -o jsonpath=<span class="string">&#x27;&#123; .spec.template.spec.containers[?(@.name==&quot;jenkins&quot;)].volumeMounts[?(@.name==&quot;jenkins-data&quot;)].mountPath &#125;&#x27;</span></span></span><br><span class="line">/var/lib/jenkins</span><br></pre></td></tr></table></figure></li><li><p>获取当前运行的应用的pod名字</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pod --selector=deploymentconfig=jenkins -o jsonpath=<span class="string">&#x27;&#123; .metadata.name &#125;&#x27;</span></span></span><br><span class="line">jenkins-1-37nux</span><br></pre></td></tr></table></figure></li><li><p>使用<code>oc rsync</code>对数据进行备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsync jenkins-1-37nux:/var/lib/jenkins /tmp/</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="备份etcd数据库"><a href="#备份etcd数据库" class="headerlink" title="备份etcd数据库"></a>备份etcd数据库</h3><p>备份etcd分布式数据库，需要备份etcd的配置文件及数据。备份时既可以使用etcd v2版本也可以使用etcd v3版本API来备份etcd数据</p><h4 id="备份过程-4"><a href="#备份过程-4" class="headerlink" title="备份过程"></a>备份过程</h4><ul><li>备份etcd配置文件</li></ul><p>etcd的配置文件在&#x2F;etc&#x2F;etcd目录中，其中包括etcd.conf配置文件，及集群通信所需的证书。这些文件都是在用ansible安装时生成的。</p><p>对每个etcd节点备份相关配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ssh master-0</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /backup/etcd-config-$(<span class="built_in">date</span> +%Y%m%d)/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> -R /etc/etcd/ /backup/etcd-config-$(<span class="built_in">date</span> +%Y%m%d)/</span></span><br></pre></td></tr></table></figure><ul><li>备份etcd数据</li></ul><p>openshift容器平台为了方便调用etcdctl不同版本，创建了两个别名，etcdctl2和etcdctl3。但是，etcdctl3别名不会向etcdctl命令提供完整的端点列表，因此您必须指定–endpoints选项并列出所有端点。</p><p>在做etcd数据备份前，需要先做如下处理。</p><ul><li><p>etcdctl可执行文件必须可用，容器化安装时容器etcd必须可用</p></li><li><p>确保openshit容器平台的api服务正常运行</p></li><li><p>确保与etcd集群的2379端口TCP通信正常</p></li><li><p>确保有etcd集群的请求证书</p></li></ul><ol><li><p>检查etcd集群的健康状态，可以使用etcdctl2或者etcdctl3</p><ul><li><p>使用etcd v2 api</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 --cert-file=/etc/etcd/peer.crt \</span></span><br><span class="line"><span class="language-bash">          --key-file=/etc/etcd/peer.key \</span></span><br><span class="line"><span class="language-bash">          --ca-file=/etc/etcd/ca.crt \</span></span><br><span class="line"><span class="language-bash">          --endpoints=<span class="string">&quot;https://master-0.example.com:2379,\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">          https://master-1.example.com:2379,\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">          https://master-2.example.com:2379&quot;</span>\</span></span><br><span class="line"><span class="language-bash">          cluster-health</span></span><br><span class="line">member 5ee217d19001 is healthy: got healthy result from https://192.168.55.12:2379</span><br><span class="line">member 2a529ba1840722c0 is healthy: got healthy result from https://192.168.55.8:2379</span><br><span class="line">member ed4f0efd277d7599 is healthy: got healthy result from https://192.168.55.13:2379</span><br><span class="line">cluster is healthy</span><br></pre></td></tr></table></figure></li><li><p>使用etcd v3 api</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl3 --cert=<span class="string">&quot;/etc/etcd/peer.crt&quot;</span> \</span></span><br><span class="line"><span class="language-bash">          --key=/etc/etcd/peer.key \</span></span><br><span class="line"><span class="language-bash">          --cacert=<span class="string">&quot;/etc/etcd/ca.crt&quot;</span> \</span></span><br><span class="line"><span class="language-bash">          --endpoints=<span class="string">&quot;https://master-0.example.com:2379,\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">            https://master-1.example.com:2379,\</span></span></span><br><span class="line"><span class="string"><span class="language-bash">            https://master-2.example.com:2379&quot;</span></span></span><br><span class="line">            endpoint health</span><br><span class="line">https://master-0.example.com:2379 is healthy: successfully committed proposal: took = 5.011358ms</span><br><span class="line">https://master-1.example.com:2379 is healthy: successfully committed proposal: took = 1.305173ms</span><br><span class="line">https://master-2.example.com:2379 is healthy: successfully committed proposal: took = 1.388772ms</span><br></pre></td></tr></table></figure></li></ul></li><li><p>查看member列表</p><ul><li><p>使用etcd v2 api</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl2 member list</span></span><br><span class="line">2a371dd20f21ca8d: name=master-1.example.com peerURLs=https://192.168.55.12:2380 clientURLs=https://192.168.55.12:2379 isLeader=false</span><br><span class="line">40bef1f6c79b3163: name=master-0.example.com peerURLs=https://192.168.55.8:2380 clientURLs=https://192.168.55.8:2379 isLeader=false</span><br><span class="line">95dc17ffcce8ee29: name=master-2.example.com peerURLs=https://192.168.55.13:2380 clientURLs=https://192.168.55.13:2379 isLeader=true</span><br></pre></td></tr></table></figure></li><li><p>使用etcd v3 api</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl3 member list</span></span><br><span class="line">2a371dd20f21ca8d, started, master-1.example.com, https://192.168.55.12:2380, https://192.168.55.12:2379</span><br><span class="line">40bef1f6c79b3163, started, master-0.example.com, https://192.168.55.8:2380, https://192.168.55.8:2379</span><br><span class="line">95dc17ffcce8ee29, started, master-2.example.com, https://192.168.55.13:2380, https://192.168.55.13:2379</span><br></pre></td></tr></table></figure></li></ul></li><li><p>开始备份etcd数据</p><p>  v2版本有<code>etcdctl backup</code>命令，用这个命令可以对etcd集群数据做备份。但是etcdctl v3没有这个命令，但是v3版本有<code>etcdctl snapshot save</code>命令或者直接复制member&#x2F;snap&#x2F;db文件。</p><p>  <code>etcdctl backup</code>命令会重写备份中包含的一些元数据，特别是节点ID和集群ID，这意味着在备份中，节点将丢失其以前的标识。 要从备份重新创建群集，需要创建新的单节点群集，然后将其余节点添加到群集。 重写元数据以防止新节点加入现有集群。</p><ul><li><p>如果etcd部署在独立的主机上，使用etcd v2 api备份</p><ol><li><p>通过删除etcd pod yaml文件，停止etcd服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br></pre></td></tr></table></figure></li><li><p>创建etcd数据备份文件夹，复制etcd db文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /backup/etcd-$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 backup \</span></span><br><span class="line"><span class="language-bash">    --data-dir /var/lib/etcd \</span></span><br><span class="line"><span class="language-bash">    --backup-dir /backup/etcd-$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /var/lib/etcd/member/snap/db /backup/etcd-$(<span class="built_in">date</span> +%Y%m%d)</span></span><br></pre></td></tr></table></figure></li><li><p>重启主机</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">reboot</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>如果etcd部署在独立的主机上，使用etcd v3 api</p><ol><li><p>在etcd节点上创建快照snapshot</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl show etcd --property=ActiveState,SubState</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /backup/etcd-$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl3 snapshot save /backup/etcd-$(<span class="built_in">date</span> +%Y%m%d)/db</span></span><br></pre></td></tr></table></figure></li><li><p>通过删除etcd pod yaml文件，停止etcd服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br></pre></td></tr></table></figure></li><li><p>创建etcd数据备份文件夹，复制etcd db文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 backup \</span></span><br><span class="line"><span class="language-bash">    --data-dir /var/lib/etcd \</span></span><br><span class="line"><span class="language-bash">    --backup-dir /backup/etcd-$(<span class="built_in">date</span> +%Y%m%d)</span></span><br></pre></td></tr></table></figure></li><li><p>重启主机</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">reboot</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>如果部署etcd使用的是容器安装，使用etcd v3 api</p><ol><li><p>从etcd pod的配置文件中获取etcd endpoint IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ETCD_POD_MANIFEST=<span class="string">&quot;/etc/origin/node/pods/etcd.yaml&quot;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ETCD_EP=$(grep https <span class="variable">$&#123;ETCD_POD_MANIFEST&#125;</span> | <span class="built_in">cut</span> -d <span class="string">&#x27;/&#x27;</span> -f3)</span></span><br></pre></td></tr></table></figure></li><li><p>获得etcd pod名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc login -u system:admin</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ETCD_POD=$(oc get pods -n kube-system | grep -o -m 1 <span class="string">&#x27;\S*etcd\S*&#x27;</span>)</span></span><br></pre></td></tr></table></figure></li><li><p>创建快照snapshot，并将它保存到本地</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc project kube-system</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">exec</span> <span class="variable">$&#123;ETCD_POD&#125;</span> -c etcd -- /bin/bash -c <span class="string">&quot;ETCDCTL_API=3 etcdctl \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">    --cert /etc/etcd/peer.crt \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">    --key /etc/etcd/peer.key \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">    --cacert /etc/etcd/ca.crt \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">    --endpoints &lt;ETCD_EP&gt; \ </span></span></span><br><span class="line">    snapshot save /var/lib/etcd/snapshot.db&quot;</span><br></pre></td></tr></table></figure></li></ol></li></ul></li></ol><h3 id="备份项目project"><a href="#备份项目project" class="headerlink" title="备份项目project"></a>备份项目project</h3><p>项目的备份，涉及导出所有相关的对象，最终使用备份的文件恢复到新的项目中。</p><h4 id="备份过程-5"><a href="#备份过程-5" class="headerlink" title="备份过程"></a>备份过程</h4><ol><li><p>列出需要备份的所有对象</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get all</span></span><br><span class="line">NAME         TYPE      FROM      LATEST</span><br><span class="line">bc/ruby-ex   Source    Git       1</span><br><span class="line"></span><br><span class="line">NAME               TYPE      FROM          STATUS     STARTED         DURATION</span><br><span class="line">builds/ruby-ex-1   Source    Git@c457001   Complete   2 minutes ago   35s</span><br><span class="line"></span><br><span class="line">NAME                 DOCKER REPO                                     TAGS      UPDATED</span><br><span class="line">is/guestbook         10.111.255.221:5000/myproject/guestbook         latest    2 minutes ago</span><br><span class="line">is/hello-openshift   10.111.255.221:5000/myproject/hello-openshift   latest    2 minutes ago</span><br><span class="line">is/ruby-22-centos7   10.111.255.221:5000/myproject/ruby-22-centos7   latest    2 minutes ago</span><br><span class="line">is/ruby-ex           10.111.255.221:5000/myproject/ruby-ex           latest    2 minutes ago</span><br><span class="line"></span><br><span class="line">NAME                 REVISION   DESIRED   CURRENT   TRIGGERED BY</span><br><span class="line">dc/guestbook         1          1         1         config,image(guestbook:latest)</span><br><span class="line">dc/hello-openshift   1          1         1         config,image(hello-openshift:latest)</span><br><span class="line">dc/ruby-ex           1          1         1         config,image(ruby-ex:latest)</span><br><span class="line"></span><br><span class="line">NAME                   DESIRED   CURRENT   READY     AGE</span><br><span class="line">rc/guestbook-1         1         1         1         2m</span><br><span class="line">rc/hello-openshift-1   1         1         1         2m</span><br><span class="line">rc/ruby-ex-1           1         1         1         2m</span><br><span class="line"></span><br><span class="line">NAME                  CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">svc/guestbook         10.111.105.84    &lt;none&gt;        3000/TCP            2m</span><br><span class="line">svc/hello-openshift   10.111.230.24    &lt;none&gt;        8080/TCP,8888/TCP   2m</span><br><span class="line">svc/ruby-ex           10.111.232.117   &lt;none&gt;        8080/TCP            2m</span><br><span class="line"></span><br><span class="line">NAME                         READY     STATUS      RESTARTS   AGE</span><br><span class="line">po/guestbook-1-c010g         1/1       Running     0          2m</span><br><span class="line">po/hello-openshift-1-4zw2q   1/1       Running     0          2m</span><br><span class="line">po/ruby-ex-1-build           0/1       Completed   0          2m</span><br><span class="line">po/ruby-ex-1-rxc74           1/1       Running     0          2m</span><br></pre></td></tr></table></figure></li><li><p>将对象配置导出为yaml文件或者json文件</p><ul><li><p>导出为yaml文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get -o yaml --<span class="built_in">export</span> all &gt; project.yaml</span></span><br></pre></td></tr></table></figure></li><li><p>导出为json文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get -o json --<span class="built_in">export</span> all &gt; project.json</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>将 <code>role bindings</code>, <code>secrets</code>, <code>service accounts</code>和 <code>persistent volume claims</code>等导出</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="keyword">for</span> object <span class="keyword">in</span> rolebindings serviceaccounts secrets imagestreamtags podpreset cms egressnetworkpolicies rolebindingrestrictions limitranges resourcequotas pvcs templates cronjobs statefulsets hpas deployments replicasets poddisruptionbudget endpoints</span></span><br><span class="line">do</span><br><span class="line">  oc get -o yaml --export $object &gt; $object.yaml</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li></ol><p><code>说明</code></p><ul><li><p>列出所有的对象种类</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc api-resources --namespaced=<span class="literal">true</span> -o name</span></span><br></pre></td></tr></table></figure></li><li><p>有些对象的参数中依赖于元数据，或者带有唯一的认证标识。这些对象在恢复时将会受到影响。比如说deploymentconfig中的image指向imagestream时，image将会指向镜像的一个sha256值，在恢复时将无法找到镜像，而导致恢复失败。</p></li></ul><h3 id="备份持久化卷"><a href="#备份持久化卷" class="headerlink" title="备份持久化卷"></a>备份持久化卷</h3><p>将持久化卷挂载到pod上，再使用<code>oc rsync</code>命令将数据备份到服务器</p><h4 id="备份过程-6"><a href="#备份过程-6" class="headerlink" title="备份过程"></a>备份过程</h4><ol><li><p>查看pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc get pods</span></span><br><span class="line">NAME           READY     STATUS      RESTARTS   AGE</span><br><span class="line">demo-1-build   0/1       Completed   0          2h</span><br><span class="line">demo-2-fxx6d   1/1       Running     0          1h</span><br></pre></td></tr></table></figure></li><li><p>查看pod将pvc挂载到的目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc describe pod demo-2-fxx6d</span></span><br><span class="line">Name:demo-2-fxx6d</span><br><span class="line">Namespace:test</span><br><span class="line">Security Policy:restricted</span><br><span class="line">Node:ip-10-20-6-20.ec2.internal/10.20.6.20</span><br><span class="line">Start Time:Tue, 05 Dec 2017 12:54:34 -0500</span><br><span class="line">Labels:app=demo</span><br><span class="line">deployment=demo-2</span><br><span class="line">deploymentconfig=demo</span><br><span class="line">Status:Running</span><br><span class="line">IP:172.16.12.5</span><br><span class="line">Controllers:ReplicationController/demo-2</span><br><span class="line">Containers:</span><br><span class="line">  demo:</span><br><span class="line">    Container ID:docker://201f3e55b373641eb36945d723e1e212ecab847311109b5cee1fd0109424217a</span><br><span class="line">    Image:docker-registry.default.svc:5000/test/demo@sha256:0a9f2487a0d95d51511e49d20dc9ff6f350436f935968b0c83fcb98a7a8c381a</span><br><span class="line">    Image ID:docker-pullable://docker-registry.default.svc:5000/test/demo@sha256:0a9f2487a0d95d51511e49d20dc9ff6f350436f935968b0c83fcb98a7a8c381a</span><br><span class="line">    Port:8080/TCP</span><br><span class="line">    State:Running</span><br><span class="line">      Started:Tue, 05 Dec 2017 12:54:52 -0500</span><br><span class="line">    Ready:True</span><br><span class="line">    Restart Count:0</span><br><span class="line">    Volume Mounts:</span><br><span class="line">      */opt/app-root/src/uploaded from persistent-volume (rw)*</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8mmrk (ro)</span><br><span class="line">    Environment Variables:&lt;none&gt;</span><br><span class="line">...omitted...</span><br></pre></td></tr></table></figure><p>可以看到将pvc对应在pod中的目录为<code>/opt/app-root/src/uploaded from persistent-volume</code></p></li><li><p><code>oc rsync</code>备份数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsync demo-2-fxx6d:/opt/app-root/src/uploaded ./demo-app</span></span><br><span class="line">receiving incremental file list</span><br><span class="line">uploaded/</span><br><span class="line">uploaded/ocp_sop.txt</span><br><span class="line">uploaded/lost+found/</span><br><span class="line"></span><br><span class="line">sent 38 bytes  received 190 bytes  152.00 bytes/sec</span><br><span class="line">total size is 32  speedup is 0.14</span><br></pre></td></tr></table></figure></li></ol><h2 id="一键备份etcd数据脚本"><a href="#一键备份etcd数据脚本" class="headerlink" title="一键备份etcd数据脚本"></a>一键备份etcd数据脚本</h2><p>一键备份etcd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat backup_etcd.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">export ETCD_POD_MANIFEST=&quot;/etc/origin/node/pods/etcd.yaml&quot;</span><br><span class="line">export ETCD_EP=$(grep https $&#123;ETCD_POD_MANIFEST&#125; | cut -d &#x27;/&#x27; -f3)</span><br><span class="line">oc login -u system:admin</span><br><span class="line">export ETCD_POD=$(oc get pods -n kube-system | grep -o -m 1 &#x27;\S*etcd\S*&#x27;)</span><br><span class="line">oc project kube-system</span><br><span class="line">oc exec $&#123;ETCD_POD&#125; -c etcd -- /bin/sh -c &quot;ETCDCTL_API=3 etcdctl --cert /etc/etcd/peer.crt --key /etc/etcd/peer.key --cacert /etc/etcd/ca.crt --endpoints $ETCD_EP snapshot save /var/lib/etcd/snapshot.db&quot;</span><br><span class="line"></span><br><span class="line">today_date=$(date +%Y%m%d)</span><br><span class="line">mkdir -p /backup/$&#123;today_date&#125;/etcd</span><br><span class="line">mv /var/lib/etcd/snapshot.db /backup/$&#123;today_date&#125;/etcd/snapshot.db</span><br><span class="line"></span><br><span class="line">ls /backup/$&#123;today_date&#125;/etcd/</span><br><span class="line">echo &quot;success backup etcd&quot;</span><br></pre></td></tr></table></figure><p>参考文章<br><a href="https://docs.openshift.com/container-platform/3.11/day_two_guide/environment_backup.html#day_two_environment_backup">Openshift官方文档之集群备份</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift集群全环境恢复</title>
      <link href="/openshift/Openshift%E9%9B%86%E7%BE%A4%E5%85%A8%E7%8E%AF%E5%A2%83%E6%81%A2%E5%A4%8D/"/>
      <url>/openshift/Openshift%E9%9B%86%E7%BE%A4%E5%85%A8%E7%8E%AF%E5%A2%83%E6%81%A2%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-9803db94b4c351e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="敏捷自动化"></p><h2 id="阅读前说明"><a href="#阅读前说明" class="headerlink" title="阅读前说明"></a>阅读前说明</h2><ul><li>按照官网提供的文档操作能够恢复etcd数据，但是由于证书的问题，恢复的集群并不能正常使用，需要单独对集群的token进行清理。</li><li>官方文档中没有明确恢复etcd集群的部署，经过多次验证，确认了恢复etcd集群需要以下三步：1. 部署1台节点的etcd；2. 在当前1台etcd节点上恢复数据；3. 使用ansible扩容的方式，将etcd节点扩展到3台。</li><li>可以更新&#x2F;etc&#x2F;etcd&#x2F;etcd.conf文件更改etcd name，进而解决etcd客户端访问服务器端证书不匹配的问题。</li><li>文章最后附上了经过测试认证的根据备份一键恢复etcd集群的脚本。</li></ul><p>Openshift集群平台能够使用备份完整恢复集群。<a href="https://www.jianshu.com/p/dc7b3ec6abd6">Openshift集群全环境备份</a></p><p>在恢复集群之前，请确保对集群做过完成的备份，并重新安装Openshift集群。</p><h3 id="恢复Master节点"><a href="#恢复Master节点" class="headerlink" title="恢复Master节点"></a>恢复Master节点</h3><p>创建Master主机文件的备份后，如果它们被损坏或意外删除，就可以通过这些文件复制回Master主机来恢复文件，然后重新启动受影响的服务。</p><h4 id="恢复过程"><a href="#恢复过程" class="headerlink" title="恢复过程"></a>恢复过程</h4><ol><li><p>恢复<code>/etc/origin/master/master-config.yaml</code>文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=*/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)*</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /etc/origin/master/master-config.yaml /etc/origin/master/master-config.yaml.old</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)/origin/master/master-config.yaml /etc/origin/master/master-config.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-restart api</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-restart controllers</span></span><br></pre></td></tr></table></figure><p>重启master服务可能会导致停机，此时可以将该主机从负载均衡池中删除，再恢复主机，待恢复完成后，Master服务也起来了，再将它添加到负载均衡池中。</p></li><li><p>如果因为缺少一些二进制包，而导致无法启动Master服务，那么重新安装缺少的包</p><ul><li><p>获得当前已有的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -qa | <span class="built_in">sort</span> &gt; /tmp/current_packages.txt</span></span><br></pre></td></tr></table></figure></li><li><p>与之前备份的包列表作比较，得到缺少的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">diff /tmp/current_packages.txt <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/packages.txt</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ansible-2.4.0.0-5.el7.noarch</span></span><br></pre></td></tr></table></figure></li><li><p>安装缺少的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum reinstall -y &lt;packages&gt;</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>恢复系统信任的证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=*/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)*</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/external_certificates/my_company.crt /etc/pki/ca-trust/source/anchors/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo update-ca-trust</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="恢复计算节点"><a href="#恢复计算节点" class="headerlink" title="恢复计算节点"></a>恢复计算节点</h3><p>一般计算节点不需要做恢复，但是如果有特殊的重要节点需要恢复的话，与Master节点恢复过程类似。</p><h4 id="恢复过程-1"><a href="#恢复过程-1" class="headerlink" title="恢复过程"></a>恢复过程</h4><ol><li><p>恢复<code>/etc/origin/node/node-config.yaml</code>文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /etc/origin/node/node-config.yaml /etc/origin/node/node-config.yaml.old</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)/etc/origin/node/node-config.yaml /etc/origin/node/node-config.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">reboot</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>如果因为缺少一些二进制包，而导致无法启动Master服务，那么重新安装缺少的包</p><ul><li><p>获得当前已有的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -qa | <span class="built_in">sort</span> &gt; /tmp/current_packages.txt</span></span><br></pre></td></tr></table></figure></li><li><p>与之前备份的包列表作比较，得到缺少的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">diff /tmp/current_packages.txt <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/packages.txt</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ansible-2.4.0.0-5.el7.noarch</span></span><br></pre></td></tr></table></figure></li><li><p>安装缺少的包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum reinstall -y &lt;packages&gt;</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>恢复系统信任的证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">MYBACKUPDIR=*/backup/$(hostname)/$(<span class="built_in">date</span> +%Y%m%d)*</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/external_certificates/my_company.crt /etc/pki/ca-trust/source/anchors/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo update-ca-trust</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="恢复etcd数据"><a href="#恢复etcd数据" class="headerlink" title="恢复etcd数据"></a>恢复etcd数据</h3><h4 id="恢复过程-2"><a href="#恢复过程-2" class="headerlink" title="恢复过程"></a>恢复过程</h4><ul><li><p>恢复etcd配置文件</p><p>用备份中的etcd配置文件替换掉当前集群的配置文件，然后重启服务或者静态Pod。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> ssh master-0</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /backup/yesterday/master-0-files/etcd.conf /etc/etcd/etcd.conf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restorecon -Rv /etc/etcd/etcd.conf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl restart etcd.service</span></span><br></pre></td></tr></table></figure></li><li><p>恢复etcd数据</p><ul><li><p>根据etcd v2 和 v3数据恢复</p><p>该恢复过程必须，在单独的一台主机上恢复数据，再通过扩容的方式加入剩下的主机</p><ol><li><p>通过将pod的yaml文件移出来暂停etcd pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">reboot</span></span><br></pre></td></tr></table></figure></li><li><p>清除之前的数据</p><ul><li><p>对当前数据做备份</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /var/lib/etcd /var/lib/etcd.old</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /var/lib/etcd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restorecon -Rv /var/lib/etcd/</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>直接清除当前数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul></li><li><p>在所有的etcd节点做如下操作，恢复数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> -R /backup/etcd-xxx/* /var/lib/etcd/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /var/lib/etcd/db /var/lib/etcd/member/snap/db</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chcon</span> -R --reference /backup/etcd-xxx/* /var/lib/etcd/</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>在每台etcd主机上执行以下操作，强制创建一个新的etcd集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/systemd/system/etcd.service.d/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;[Service]&quot;</span> &gt; /etc/systemd/system/etcd.service.d/temp.conf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;ExecStart=&quot;</span> &gt;&gt; /etc/systemd/system/etcd.service.d/temp.conf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -n <span class="string">&#x27;/ExecStart/s/&quot;$/ --force-new-cluster&quot;/p&#x27;</span> \</span></span><br><span class="line"><span class="language-bash">    /usr/lib/systemd/system/etcd.service \</span></span><br><span class="line"><span class="language-bash">    &gt;&gt; /etc/systemd/system/etcd.service.d/temp.conf</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-restart etcd</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>检查错误日志</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-logs etcd etcd</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>检查etcd集群的状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl2 cluster-health</span></span><br><span class="line">member 5ee217d17301 is healthy: got healthy result from https://192.168.55.8:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>集群默认配置下启动etcd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -f /etc/systemd/system/etcd.service.d/temp.conf</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-restart etcd</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>检查etcd状态，查看member list</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 cluster-health</span></span><br><span class="line">member 5ee217d17301 is healthy: got healthy result from https://192.168.55.8:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 member list</span></span><br><span class="line">5ee217d17301: name=master-0.example.com peerURLs=http://localhost:2380 clientURLs=https://192.168.55.8:2379 isLeader=true</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>第一个实例运行后，就可以还原其余的etcd服务器</p></li></ol><p><strong>修复PEERURL参数问题</strong></p><p>在恢复数据后，新的etcd集群参数peerurl为localhost而不是ip地址，我们需要将它修改为ip地址</p><ol><li><p>执行<strong>etcdctl member list</strong>获得member ID</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl member list</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>获得etcd通信的IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ss -l4n | grep 2380</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>更新对应member的peer地址</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 member update 5ee217d17301 https://192.168.55.8:2380</span></span><br><span class="line">Updated member with ID 5ee217d17301 in cluster</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>查看新的peer地址进行校验</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl2 member list</span></span><br><span class="line">5ee217d17301: name=master-0.example.com peerURLs=https://*192.168.55.8*:2380 clientURLs=https://192.168.55.8:2379 isLeader=true</span><br></pre></td></tr></table></figure></li></ol></li><li><p>根据v3的快照snapshot恢复</p><p>如果是使用<strong>etcdctl snapshot save</strong>的方式备份的snapshot，<strong>etcdctl snapshot restore</strong>恢复数据时会去校验数据的hash，但是如果直接从数据目录中拷贝出来的就无法校验hash，这时恢复数据时需要加上**–skip-hash-check**</p><p>该恢复过程必须，在单独的一台主机上恢复数据，再通过扩容的方式加入剩下的主机</p><ol><li><p>通过将pod的yaml文件移出来暂停etcd pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /etc/origin/node/pods-stopped</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/* /etc/origin/node/pods-stopped/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">reboot</span></span><br></pre></td></tr></table></figure></li><li><p>清除之前的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd</span></span><br></pre></td></tr></table></figure></li><li><p>使用<strong>snapshot restore</strong>命令来恢复数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etcdctl3 snapshot restore /backup/etcd-xxxxxx/backup.db \</span></span><br><span class="line"><span class="language-bash">  --data-dir /var/lib/etcd \</span></span><br><span class="line"><span class="language-bash">  --name master-0.example.com \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster <span class="string">&quot;master-0.example.com=https://192.168.55.8:2380&quot;</span> \</span></span><br><span class="line"><span class="language-bash">  --initial-cluster-token <span class="string">&quot;etcd-cluster-1&quot;</span> \</span></span><br><span class="line"><span class="language-bash">  --initial-advertise-peer-urls https://192.168.55.8:2380 \</span></span><br><span class="line"><span class="language-bash">  --skip-hash-check=<span class="literal">true</span></span></span><br><span class="line"></span><br><span class="line">2017-10-03 08:55:32.440779 I | mvcc: restore compact to 1041269</span><br><span class="line">2017-10-03 08:55:32.468244 I | etcdserver/membership: added member 40bef1f6c79b3163 [https://192.168.55.8:2380] to cluster 26841ebcf610583c</span><br></pre></td></tr></table></figure><p>相关配置从&#x2F;etc&#x2F;etcd&#x2F;etcd.conf获取</p></li><li><p>给相关文件及目录设置相关的selinux权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restorecon -Rv /var/lib/etcd/</span></span><br></pre></td></tr></table></figure></li><li><p>启动etcd服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start etcd</span></span><br></pre></td></tr></table></figure></li><li><p>检查错误日志</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-logs etcd etcd</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>在静态etcd pod恢复etcd</p><ol><li><p>通过将pod的yaml文件移出来暂停etcd pod</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> /etc/origin/node/pods/etcd.yaml .</span></span><br></pre></td></tr></table></figure></li><li><p>清除之前的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> -rf /var/lib/etcd</span></span><br></pre></td></tr></table></figure></li><li><p>使用snapshot恢复集群数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">export</span> ETCDCTL_API=3</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">etcdctl snapshot restore /etc/etcd/backup/etcd/snapshot.db</span></span><br><span class="line"> --data-dir /var/lib/etcd/</span><br><span class="line"> --name ip-172-18-3-48.ec2.internal</span><br><span class="line"> --initial-cluster &quot;ip-172-18-3-48.ec2.internal=https://172.18.3.48:2380&quot;</span><br><span class="line"> --initial-cluster-token &quot;etcd-cluster-1&quot;</span><br><span class="line"> --initial-advertise-peer-urls https://172.18.3.48:2380</span><br><span class="line"> --skip-hash-check=true</span><br></pre></td></tr></table></figure><p>从**$&#x2F;backup_files&#x2F;etcd.conf** 文件中获得相关的参数</p></li><li><p>给相关文件及目录设置相关的selinux权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">restorecon -Rv /var/lib/etcd/</span></span><br></pre></td></tr></table></figure></li><li><p>通过将etcd pod的yaml文件恢复到静态pod目录下来重启etcd数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> etcd.yaml /etc/origin/node/pods/.</span></span><br></pre></td></tr></table></figure></li></ol></li></ul></li></ul><h3 id="使用Ansible添加etcd节点"><a href="#使用Ansible添加etcd节点" class="headerlink" title="使用Ansible添加etcd节点"></a>使用Ansible添加etcd节点</h3><p>还原etcd数据后，可以使用ansible或者手动的方式对etcd进行扩容。</p><h4 id="添加过程"><a href="#添加过程" class="headerlink" title="添加过程"></a>添加过程</h4><ol><li><p>在inventory的hosts中添加[new_etcd]服务器组</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">etcd</span><br><span class="line">new<span class="built_in">_</span>etcd </span><br><span class="line"></span><br><span class="line">... [OUTPUT ABBREVIATED] ...</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master-0.example.com</span><br><span class="line">master-1.example.com</span><br><span class="line">master-2.example.com</span><br><span class="line"></span><br><span class="line">[new<span class="built_in">_</span>etcd] </span><br><span class="line">etcd0.example.com </span><br></pre></td></tr></table></figure></li><li><p>执行ansible扩容ansible脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /usr/share/ansible/openshift-ansible</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ansible-playbook  playbooks/openshift-etcd/scaleup.yml</span></span><br></pre></td></tr></table></figure></li><li><p>将[new_etcd]服务器组的主机移到[etcd]组</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">etcd</span><br><span class="line">new<span class="built_in">_</span>etcd</span><br><span class="line"></span><br><span class="line">... [OUTPUT ABBREVIATED] ...</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master-0.example.com</span><br><span class="line">master-1.example.com</span><br><span class="line">master-2.example.com</span><br><span class="line">etcd0.example.com</span><br></pre></td></tr></table></figure></li></ol><h3 id="恢复Openshift集群节点上的服务"><a href="#恢复Openshift集群节点上的服务" class="headerlink" title="恢复Openshift集群节点上的服务"></a>恢复Openshift集群节点上的服务</h3><h4 id="恢复过程-3"><a href="#恢复过程-3" class="headerlink" title="恢复过程"></a>恢复过程</h4><ol><li><p>在每一个Master节点恢复配置文件及重启相关服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/origin/node/pods/* /etc/origin/node/pods/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/origin/master/master.env /etc/origin/master/master.env</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/origin/master/master-config.yaml.&lt;timestamp&gt; /etc/origin/master/master-config.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/origin/node/node-config.yaml.&lt;timestamp&gt; /etc/origin/node/node-config.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> <span class="variable">$&#123;MYBACKUPDIR&#125;</span>/etc/origin/master/scheduler.json.&lt;timestamp&gt; /etc/origin/master/scheduler.json</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-restart api</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">master-restart controllers</span></span><br></pre></td></tr></table></figure></li><li><p>在每一个Node节点，恢复配置文件，并重启origin-node服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cp</span> /etc/origin/node/node-config.yaml.&lt;timestamp&gt; /etc/origin/node/node-config.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl <span class="built_in">enable</span> atomic-openshift-node</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start atomic-openshift-node</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="恢复项目Project"><a href="#恢复项目Project" class="headerlink" title="恢复项目Project"></a>恢复项目Project</h3><p>恢复项目前，先创建项目，再通过<code>oc create -f</code>命令将项目中的对象恢复。恢复项目时要注意对象的依赖关系，比如说pod依赖configmap资源，就需要先创建configmap。</p><h4 id="恢复过程-4"><a href="#恢复过程-4" class="headerlink" title="恢复过程"></a>恢复过程</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project &lt;projectname&gt;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f project.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f secret.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f serviceaccount.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f pvc.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f rolebindings.yaml</span></span><br></pre></td></tr></table></figure><h3 id="恢复应用数据"><a href="#恢复应用数据" class="headerlink" title="恢复应用数据"></a>恢复应用数据</h3><p>与备份应用数据类似，可以使用<code>oc rsync</code>命令来恢复应用数据。</p><p>以下是一个利用jenkins应用的备份数据恢复应用的例子。</p><h4 id="恢复过程-5"><a href="#恢复过程-5" class="headerlink" title="恢复过程"></a>恢复过程</h4><ol><li><p>检查备份数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -la /tmp/jenkins-backup/</span></span><br><span class="line">total 8</span><br><span class="line">drwxrwxr-x.  3 user     user   20 Sep  6 11:14 .</span><br><span class="line">drwxrwxrwt. 17 root     root 4096 Sep  6 11:16 ..</span><br><span class="line">drwxrwsrwx. 12 user     user 4096 Sep  6 11:14 jenkins</span><br></pre></td></tr></table></figure></li><li><p>使用<code>oc rsync</code>恢复应用数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsync /tmp/jenkins-backup/jenkins jenkins-1-37nux:/var/lib</span></span><br></pre></td></tr></table></figure></li><li><p>重启应用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc delete pod jenkins-1-37nux</span></span><br></pre></td></tr></table></figure><p>或者使用<code>oc scale</code>命令将pod数调整为0，再调整为1，实现应用的重启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc scale --replicas=0 dc/jenkins</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc scale --replicas=1 dc/jenkins</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="恢复持久化卷数据"><a href="#恢复持久化卷数据" class="headerlink" title="恢复持久化卷数据"></a>恢复持久化卷数据</h3><p>如果应用已挂载了新的PV，那就将该PV原来的数据删除，之后将备份的数据拷贝到对应的目录；如果应用没有挂载PV，那就先挂载一个PV，再恢复数据。</p><h4 id="恢复过程-6"><a href="#恢复过程-6" class="headerlink" title="恢复过程"></a>恢复过程</h4><ol><li><p>如果没有挂载PV执行创建新的挂载</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc <span class="built_in">set</span> volume dc/demo --add --name=persistent-volume \</span></span><br><span class="line"><span class="language-bash">--<span class="built_in">type</span>=persistentVolumeClaim --claim-name=filestore \ --mount-path=/opt/app-root/src/uploaded --overwrite</span></span><br></pre></td></tr></table></figure></li><li><p>删除当前PV挂载目录下的数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsh demo-2-fxx6d</span></span><br><span class="line">sh-4.2$ ls */opt/app-root/src/uploaded/*</span><br><span class="line">lost+found  ocp_sop.txt</span><br><span class="line">sh-4.2$ *rm -rf /opt/app-root/src/uploaded/ocp_sop.txt*</span><br><span class="line">sh-4.2$ *ls /opt/app-root/src/uploaded/*</span><br><span class="line">lost+found</span><br></pre></td></tr></table></figure></li><li><p>将之前备份的数据拷贝到对应的目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsync uploaded demo-2-fxx6d:/opt/app-root/src/</span></span><br></pre></td></tr></table></figure></li><li><p>验证应用数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc rsh demo-2-fxx6d</span></span><br><span class="line">sh-4.2$ *ls /opt/app-root/src/uploaded/*</span><br><span class="line">lost+found  ocp_sop.txt</span><br></pre></td></tr></table></figure></li></ol><h2 id="实战演练步骤"><a href="#实战演练步骤" class="headerlink" title="实战演练步骤"></a>实战演练步骤</h2><ol><li>部署安装3Master 1etcd及2个Node节点的Openshift集群</li><li>使用<code>恢复etcd数据</code>中的<code>根据v3的快照snapshot恢复</code>恢复etcd数据<br>如果此时pod无法正常启动，可以执行以下命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ echo &quot;ETCD_FORCE_NEW_CLUSTER=true&quot; &gt;&gt; /etc/etcd/etcd.conf</span><br></pre></td></tr></table></figure>再重启Pod，待etcd正常运行后，将刚才添加的<code>ETCD_FORCE_NEW_CLUSTER=true</code>从&#x2F;etc&#x2F;etcd&#x2F;etcd.conf文件中删除。</li><li>按照<code>使用Ansible添加etcd节点</code>中的步骤将1个etcd节点扩容为3个etcd节点</li><li>清理恢复中的Openshift集群中的token，并重启相关pod，实现Openshift集群的完整恢复。</li></ol><h2 id="一键恢复与解决证书问题的脚本"><a href="#一键恢复与解决证书问题的脚本" class="headerlink" title="一键恢复与解决证书问题的脚本"></a>一键恢复与解决证书问题的脚本</h2><p>一键恢复etcd</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat restore_etcd.sh </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">snapshot_file_dir=$1</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;Please input snapshot file path&quot;</span><br><span class="line">    exit 2</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">export ETCD_POD_MANIFEST=&quot;/etc/origin/node/pods/etcd.yaml&quot;</span><br><span class="line">mv $&#123;ETCD_POD_MANIFEST&#125; .</span><br><span class="line">rm -rf /var/lib/etcd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 获取etcd相关初始化配置项</span></span></span><br><span class="line">ETCD_CONFIG_FILE=&quot;/etc/etcd/etcd.conf&quot;</span><br><span class="line">etcd_data_dir=$(grep ^ETCD_DATA_DIR= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line">etcd_name=$(grep ^ETCD_NAME= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line">etcd_initial_cluster=$(grep ^ETCD_INITIAL_CLUSTER= $ETCD_CONFIG_FILE|awk -F&#x27;ETCD_INITIAL_CLUSTER=&#x27; &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">etcd_initial_cluster_token=$(grep ^ETCD_INITIAL_CLUSTER_TOKEN= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line">etcd_initial_advertise_peer_urls=$(grep ^ETCD_INITIAL_ADVERTISE_PEER_URLS= $ETCD_CONFIG_FILE|cut -d= -f2)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># 恢复etcd数据</span></span></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl snapshot restore $snapshot_file_dir --data-dir $etcd_data_dir --name $etcd_name --initial-cluster &quot;$etcd_initial_cluster&quot; --initial-cluster-token &quot;$etcd_initial_cluster_token&quot; --initial-advertise-peer-urls $etcd_initial_advertise_peer_urls --skip-hash-check=true</span><br><span class="line"></span><br><span class="line">restorecon -Rv /var/lib/etcd</span><br><span class="line"></span><br><span class="line">mv etcd.yaml $ETCD_POD_MANIFEST</span><br></pre></td></tr></table></figure><p>一键整理etcd数据，解决证书问题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat reset.sh </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">oc login -u system:admin</span><br><span class="line"></span><br><span class="line">projects=$(oc get projects | awk &#x27;&#123;print $1&#125;&#x27; | grep -v kube-system|grep -v NAME)</span><br><span class="line"></span><br><span class="line">for project in $(echo $projects)</span><br><span class="line">do</span><br><span class="line">  oc delete secret $(oc get secret -n $project | grep token | awk &#x27;&#123;print $1&#125;&#x27;) -n $project</span><br><span class="line">  oc delete pod $(oc get pod -n $project | grep -v NAME | awk &#x27;&#123;print $1&#125;&#x27;) -n $project --force --grace-period=0</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://docs.openshift.com/container-platform/3.11/admin_guide/assembly_restoring-cluster.html">Openshift官方文档之恢复集群</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshift集群升级3-6至3-7</title>
      <link href="/openshift/Openshift%E9%9B%86%E7%BE%A4%E5%8D%87%E7%BA%A73-6%E8%87%B33-7/"/>
      <url>/openshift/Openshift%E9%9B%86%E7%BE%A4%E5%8D%87%E7%BA%A73-6%E8%87%B33-7/</url>
      
        <content type="html"><![CDATA[<p>更新方法与策略：自动升级方法</p><blockquote><p>更新openshift-ansible的脚本代码<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git pull </span><br><span class="line">git checkout -b release-3.7</span><br></pre></td></tr></table></figure><br>安装需要的包</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m yum -a &#x27;name=pyOpenSSL state=present&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>关闭Service Catalog和Template Service Broker。<br>3.7 以上版本默认会启用 Service Catalog 和 Template Service Broker</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># /etc/ansible/hosts</span><br><span class="line">...</span><br><span class="line">openshift_enable_service_catalog=false</span><br><span class="line">template_service_broker_install=false</span><br><span class="line">ansible_service_broker_install=false</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>关闭etcd目录的selinux检查<br>关闭任务Check selinux label of ‘‘与Make sure the ‘‘ has the proper label</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># roles/etcd/tasks/backup/backup.yml</span><br><span class="line">...</span><br><span class="line">- name: Detecting Atomic Host Operating System</span><br><span class="line">  stat:</span><br><span class="line">    path: /run/ostree-booted</span><br><span class="line">  register: l_ostree_booted</span><br><span class="line"></span><br><span class="line">#- name: Check selinux label of &#x27;&#123;&#123; etcd_data_dir &#125;&#125;&#x27;</span><br><span class="line">#  command: &gt;</span><br><span class="line">#    stat -c &#x27;%C&#x27; &#123;&#123; etcd_data_dir &#125;&#125;</span><br><span class="line">#  register: l_etcd_selinux_labels</span><br><span class="line">#</span><br><span class="line">#- debug:</span><br><span class="line">#    msg: &quot;&#123;&#123; l_etcd_selinux_labels &#125;&#125;&quot;</span><br><span class="line">#</span><br><span class="line">#- name: Make sure the &#x27;&#123;&#123; etcd_data_dir &#125;&#125;&#x27; has the proper label</span><br><span class="line">#  command: &gt;</span><br><span class="line">#    chcon -t svirt_sandbox_file_t  &quot;&#123;&#123; etcd_data_dir &#125;&#125;&quot;</span><br><span class="line">#  when:</span><br><span class="line">#  - l_etcd_selinux_labels.rc == 0</span><br><span class="line">#  - &quot;&#x27;svirt_sandbox_file_t&#x27; not in l_etcd_selinux_labels.stdout&quot;</span><br><span class="line"></span><br><span class="line">- name: Generate etcd backup</span><br><span class="line">  command: &gt;</span><br><span class="line">    &#123;&#123; r_etcd_common_etcdctl_command &#125;&#125; backup --data-dir=&#123;&#123; l_etcd_incontainer_data_dir &#125;&#125;</span><br><span class="line">    --backup-dir=&#123;&#123; l_etcd_incontainer_backup_dir &#125;&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>执行更新</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -i inventory-hosts playbooks/byo/openshift-cluster/upgrades/v3_7/upgrade.yml</span><br></pre></td></tr></table></figure><blockquote><p>查看当前oc版本及各node版本</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oc version</span><br><span class="line">oc get node</span><br></pre></td></tr></table></figure><h2 id="升级后发现的问题"><a href="#升级后发现的问题" class="headerlink" title="升级后发现的问题"></a>升级后发现的问题</h2><blockquote><p>RBD的storageclass异常</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 解决方法，storageclass.parameters中添加 imageFormat: &quot;1&quot;</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">   name: ceph-rbd-sc</span><br><span class="line">Parameters:</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretName: ceph-secret</span><br><span class="line">  adminSecretNamespace: kube-system</span><br><span class="line">  fsType: ext4</span><br><span class="line">  imageFormat: &quot;1&quot;</span><br><span class="line">  monitors: 192.168.1.3:6789</span><br><span class="line">  pool: rbd</span><br><span class="line">  userId: admin</span><br><span class="line">  userSecretName: ceph-secret</span><br><span class="line">Provisioner: kubernetes.io/rbd</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshif对集群的扩容与缩容</title>
      <link href="/openshift/Openshif%E5%AF%B9%E9%9B%86%E7%BE%A4%E7%9A%84%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9/"/>
      <url>/openshift/Openshif%E5%AF%B9%E9%9B%86%E7%BE%A4%E7%9A%84%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9/</url>
      
        <content type="html"><![CDATA[<ul><li>Openshift是一个云平台，它是以集群的方式提供服务。前面已经介绍了，业务都跑在Openshift的Node节点上。随着业务的不断变化，扩展或者消亡，我们的Node提供的服务需求也会不断变化。这时就需要对Node节点进行增删管理。</li><li>本篇只介绍CentOS7下管理Node节点。</li><li>Openshift使用Ansible playbook来实现扩容与缩容</li></ul><h3 id="1-oc命令查看当前Node节点的状态"><a href="#1-oc命令查看当前Node节点的状态" class="headerlink" title="1. oc命令查看当前Node节点的状态"></a>1. oc命令查看当前Node节点的状态</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc get node --show-labels</span><br></pre></td></tr></table></figure><h3 id="2-添加Node节点到已存在的集群"><a href="#2-添加Node节点到已存在的集群" class="headerlink" title="2. 添加Node节点到已存在的集群"></a>2. 添加Node节点到已存在的集群</h3><blockquote><p>准备好需要添加的主机</p></blockquote><table><thead><tr><th>节点类型</th><th>说明</th></tr></thead><tbody><tr><td>Nodes</td><td><br>物理主机或者虚拟机<br> 系统：Fedora 21, CentOS 7.3, 7.4或者7.5<br> NetworkManager版本1.0以上<br>最少1vCPU<br>最少8GB内存<br>&#x2F;var&#x2F;最少15GB空间 <br>&#x2F;usr&#x2F;local&#x2F;bin最少1GB空间<br>容器临时目录最少1GB空间<br> &amp;nbsp;</td></tr></tbody></table><blockquote><p>设置主机的hostname</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl --static set-hostname infra1.example.com</span><br></pre></td></tr></table></figure><blockquote><p>集群中的DNS中添加新加主机的域名与ip的解析</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#/etc/dnsmasq.d/more.conf</span><br><span class="line">address=/infra1.example.com/192.168.0.8</span><br><span class="line"></span><br><span class="line">systemctl restart dnsmasq</span><br></pre></td></tr></table></figure><blockquote><p>设置新增加主机的默认DNS</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/resolv.conf</span><br><span class="line">nameserver 192.168.0.2</span><br></pre></td></tr></table></figure><p><code>补充</code>，如果是使用&#x2F;etc&#x2F;hosts的方式来设置域名与IP的，需要为每台主机添加hosts条目，同时重启dnsmasq。</p><blockquote><p>配置ansible Hosts文件，添加新增的主机</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#/etc/ansible/hosts</span><br><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">new_nodes</span><br><span class="line">...</span><br><span class="line">[new_nodes]</span><br><span class="line">infra1.example.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;primary&#x27;, &#x27;zone&#x27;: &#x27;default&#x27;, &#x27;node-role.kubernetes.io/infra&#x27;: &#x27;true&#x27;&#125;&quot;</span><br></pre></td></tr></table></figure><blockquote><p>执行扩容脚本</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook playbooks/openshift-node/scaleup.yml</span><br></pre></td></tr></table></figure><blockquote><p>将new_nodes中的主机移到nodes组中移除</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#/etc/ansible/hosts</span><br><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">new_nodes</span><br><span class="line">...</span><br><span class="line">[nodes]</span><br><span class="line">infra1.example.com openshift_node_labels=&quot;&#123;&#x27;region&#x27;: &#x27;primary&#x27;, &#x27;zone&#x27;: &#x27;default&#x27;, &#x27;node-role.kubernetes.io/infra&#x27;: &#x27;true&#x27;&#125;&quot;</span><br><span class="line">[new_nodes]</span><br></pre></td></tr></table></figure><blockquote><p>给新增的节点配置&#x2F;etc&#x2F;origin&#x2F;node&#x2F;node-config.yaml</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeletArguments:</span><br><span class="line">  system-reserved:</span><br><span class="line">  - cpu=200m</span><br><span class="line">  - memory=1G</span><br><span class="line">  kube-reserved:</span><br><span class="line">  - cpu=200m</span><br><span class="line">  - memory=1G</span><br></pre></td></tr></table></figure><blockquote><p>重启origin-node服务</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart origin-node</span><br></pre></td></tr></table></figure><blockquote><p>查看集群中的主机情况进行确认</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc get node --show-labels</span><br></pre></td></tr></table></figure><h3 id="3-从集群中移除Node节点"><a href="#3-从集群中移除Node节点" class="headerlink" title="3.从集群中移除Node节点"></a>3.从集群中移除Node节点</h3><blockquote><p>设置需要移除的Node为不可调度</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oadm manage-node &lt;node1&gt; --schedulable=false</span><br></pre></td></tr></table></figure><blockquote><p>迁移node上已有的容器</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oadm manage-node &lt;node1&gt; --evacuate</span><br></pre></td></tr></table></figure><blockquote><p>在集群中删除指定的node节点</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc delete node infra1.example.com</span><br></pre></td></tr></table></figure><blockquote><p>删除在Ansible hosts文件中的主机配置</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">[nodes]</span><br></pre></td></tr></table></figure><blockquote><p>查看集群中的主机情况进行确认</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc get node --show-labels</span><br></pre></td></tr></table></figure><blockquote><p>**[<em>可选</em>]**新建一个hosts文件，作为ansible-playbook的inventory，只需要写需要删除的node节点</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[OSEv3:children]</span><br><span class="line">nodes</span><br><span class="line"> </span><br><span class="line">[OSEv3:vars]</span><br><span class="line">ansible_ssh_user=root</span><br><span class="line">openshift_deployment_type=origin</span><br><span class="line"> </span><br><span class="line">[nodes]</span><br><span class="line">infra1.example.com</span><br></pre></td></tr></table></figure><blockquote><p>**[<em>可选</em>]**执行清理脚本uninstall.yml</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -i hosts openshift-ansible/playbooks/adhoc/uninstall.yml</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rancher大屏</title>
      <link href="/openshift/Rancher%E5%A4%A7%E5%B1%8F/"/>
      <url>/openshift/Rancher%E5%A4%A7%E5%B1%8F/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-0f75246f94417838.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-b0593a56fa764dcd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-6727cc4b88b992ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openshit-新的存储类型LocalVolume该如何使用</title>
      <link href="/openshift/Openshit-%E6%96%B0%E7%9A%84%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8BLocalVolume%E8%AF%A5%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/"/>
      <url>/openshift/Openshit-%E6%96%B0%E7%9A%84%E5%AD%98%E5%82%A8%E7%B1%BB%E5%9E%8BLocalVolume%E8%AF%A5%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-e12accac99fb1a47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Local Volume Openshift"></p><ul><li>使用本地盘的方式的有三种：emptyDir、HostPath与Local Volume</li><li>Openshift针对Local Volume提供了一个local volume provisioner方便PV的自动创建，但目前它需要创建的PV对应的目录必须是挂载点。否则无法创建PV。</li><li>除了自动创建PV的过程外，部分与正常使用Local Volume一样。</li></ul><h1 id="手动挂载目录使用Local-Volume"><a href="#手动挂载目录使用Local-Volume" class="headerlink" title="手动挂载目录使用Local Volume"></a>手动挂载目录使用Local Volume</h1><p>我们先来看下通过手动的方式创建PV使用Local Volume是如何操作的。</p><h2 id="1-创建StorageClass"><a href="#1-创建StorageClass" class="headerlink" title="1. 创建StorageClass"></a>1. 创建StorageClass</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: local-hdd</span><br><span class="line">provisioner: kubernetes.io/no-provisioner</span><br><span class="line">volumeBindingMode: WaitForFirstConsumer</span><br></pre></td></tr></table></figure><h2 id="2-创建PV"><a href="#2-创建PV" class="headerlink" title="2. 创建PV"></a>2. 创建PV</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line"> kind: PersistentVolume</span><br><span class="line"> metadata:</span><br><span class="line">   name: local-volume-1</span><br><span class="line"> spec:</span><br><span class="line">   accessModes:</span><br><span class="line">   - ReadWriteOnce</span><br><span class="line">   capacity:</span><br><span class="line">     storage: 1Gi</span><br><span class="line">   local:</span><br><span class="line">     path: /root/hdd/vol1</span><br><span class="line">   nodeAffinity:</span><br><span class="line">     required:</span><br><span class="line">       nodeSelectorTerms:</span><br><span class="line">       - matchExpressions:</span><br><span class="line">         - key: kubernetes.io/hostname</span><br><span class="line">           operator: In</span><br><span class="line">           values:</span><br><span class="line">           - node01.example.com</span><br><span class="line">   storageClassName: local-hdd</span><br></pre></td></tr></table></figure><h2 id="3-创建PVC使用PV"><a href="#3-创建PVC使用PV" class="headerlink" title="3. 创建PVC使用PV"></a>3. 创建PVC使用PV</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line"> kind: PersistentVolumeClaim</span><br><span class="line"> metadata:</span><br><span class="line">   name: local-pvc</span><br><span class="line"> spec:</span><br><span class="line">   accessModes:</span><br><span class="line">   - ReadWriteOnce</span><br><span class="line">   resources:</span><br><span class="line">     requests:</span><br><span class="line">       storage: 1Gi</span><br><span class="line">   storageClassName: local-hdd</span><br><span class="line">   volumeName: local-volume-1</span><br></pre></td></tr></table></figure><h2 id="4-对于StatefulSet创建volumeClaimTemplates"><a href="#4-对于StatefulSet创建volumeClaimTemplates" class="headerlink" title="4. 对于StatefulSet创建volumeClaimTemplates"></a>4. 对于StatefulSet创建volumeClaimTemplates</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">volumeClaimTemplates:</span><br><span class="line">  - metadata:</span><br><span class="line">      name: local-pvc</span><br><span class="line">    spec:</span><br><span class="line">      accessModes: [ &quot;ReadWriteOnce&quot; ]</span><br><span class="line">      storageClassName: local-hdd</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: 1Gi</span><br></pre></td></tr></table></figure><h1 id="使用Local-Volume-Provisioner方式自动挂载目录使用Local-Volume"><a href="#使用Local-Volume-Provisioner方式自动挂载目录使用Local-Volume" class="headerlink" title="使用Local Volume Provisioner方式自动挂载目录使用Local Volume"></a>使用Local Volume Provisioner方式自动挂载目录使用Local Volume</h1><p><code>再次说明</code>：目前它需要创建的PV对应的目录必须是挂载点。</p><h2 id="1-准备磁盘-x2F-分区，并将它挂载到指定目录下，每个Node节点都做一样的挂载点。如-etc-fstab配置如下"><a href="#1-准备磁盘-x2F-分区，并将它挂载到指定目录下，每个Node节点都做一样的挂载点。如-etc-fstab配置如下" class="headerlink" title="1. 准备磁盘&#x2F;分区，并将它挂载到指定目录下，每个Node节点都做一样的挂载点。如/etc/fstab配置如下"></a>1. 准备磁盘&#x2F;分区，并将它挂载到指定目录下，每个Node节点都做一样的挂载点。如<code>/etc/fstab</code>配置如下</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/dev/sdb1       /mnt/local-storage/hdd/disk1 ext4     defaults 1 2</span><br></pre></td></tr></table></figure><h2 id="2-对挂载点目录设置权限，允许容器进行访问读写"><a href="#2-对挂载点目录设置权限，允许容器进行访问读写" class="headerlink" title="2. 对挂载点目录设置权限，允许容器进行访问读写"></a>2. 对挂载点目录设置权限，允许容器进行访问读写</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chcon</span> -R unconfined_u:object_r:svirt_sandbox_file_t:s0 /mnt/local-storage/</span></span><br></pre></td></tr></table></figure><h2 id="3-创建一个新的Project，为部署Local-Volume-Provisioner准备"><a href="#3-创建一个新的Project，为部署Local-Volume-Provisioner准备" class="headerlink" title="3. 创建一个新的Project，为部署Local Volume Provisioner准备"></a>3. 创建一个新的Project，为部署Local Volume Provisioner准备</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project local-storage.</span></span><br></pre></td></tr></table></figure><h2 id="4-导入主机local-volume的目录配置，即创建对应的configmap"><a href="#4-导入主机local-volume的目录配置，即创建对应的configmap" class="headerlink" title="4. 导入主机local volume的目录配置，即创建对应的configmap"></a>4. 导入主机local volume的目录配置，即创建对应的configmap</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span>  &lt;&lt; <span class="string">EOF | create -f</span></span> </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: local-volume-config</span><br><span class="line">data:</span><br><span class="line">    storageClassMap: |</span><br><span class="line">        local-hdd:</span><br><span class="line">            hostDir: /mnt/local-storage/hdd</span><br><span class="line">            mountDir: /mnt/local-storage/hdd</span><br></pre></td></tr></table></figure><p><code>local-hdd</code>将为创建的StorageClass的名字<br><code>hostDir</code>为主机挂载点的父目录，如果该目录下有新的挂载点，将会自动创建新的PV<br><code>mountDir</code>为Provisioner Pod的挂载点，最好与<code>hostDir</code>一致</p><h2 id="5-准备serviceaccount等权限配置"><a href="#5-准备serviceaccount等权限配置" class="headerlink" title="5. 准备serviceaccount等权限配置"></a>5. 准备serviceaccount等权限配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create serviceaccount local-storage-admin</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm policy add-scc-to-user privileged -z local-storage-admin</span></span><br></pre></td></tr></table></figure><h2 id="6-安装Local-Volume-Provisioner"><a href="#6-安装Local-Volume-Provisioner" class="headerlink" title="6. 安装Local Volume Provisioner"></a>6. 安装Local Volume Provisioner</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc create -f https://raw.githubusercontent.com/openshift/origin/release-3.11/examples/storage-examples/local-examples/local-storage-provisioner-template.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> oc new-app -p CONFIGMAP=local-volume-config \</span></span><br><span class="line"><span class="language-bash">  -p SERVICE_ACCOUNT=local-storage-admin \</span></span><br><span class="line"><span class="language-bash">  -p NAMESPACE=local-storage \</span></span><br><span class="line"><span class="language-bash">  -p PROVISIONER_IMAGE=docker.io/xhuaustc/openshift3-local-storage-provisioner:v3.11 \ </span></span><br><span class="line">  local-storage-provisioner</span><br></pre></td></tr></table></figure><h2 id="7-创建对应的storageclass"><a href="#7-创建对应的storageclass" class="headerlink" title="7. 创建对应的storageclass"></a>7. 创建对应的storageclass</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF | oc create -f -</span></span></span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line"> name: local-hdd</span><br><span class="line">provisioner: kubernetes.io/no-provisioner</span><br><span class="line">volumeBindingMode: WaitForFirstConsumer</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>至此，部署完成。使用方式与手动创建PV一样。新加一块存储也非常容易，只需要在各个Node节点的hostDir目录下创建新挂载点，并更新好权限，Local Volume Provisioner将会自动创建PV以供使用。<br>需要注意的是，<strong>PVC的配置yaml中，storageClassName必须写在spec的配置中</strong>。而openshift console默认是将storageclass写在metadata-&gt;annotations-&gt;volume.beta.kubernetes.io&#x2F;storage-class: local-hdd，所以通过openshift console创建的pvc是无法使用Local Volume创建的pv的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Service-iptables实现原理</title>
      <link href="/openshift/Service-iptables%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
      <url>/openshift/Service-iptables%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-edfe5d05e598072b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="iptables实现Service"></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>oc的常用命令整理</title>
      <link href="/openshift/oc%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/"/>
      <url>/openshift/oc%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<blockquote><p>oc process</p></blockquote><blockquote><p>oc new-app</p></blockquote><blockquote><p>oc new-build</p></blockquote><blockquote><p>oc create imagestream</p></blockquote><blockquote><p>oc run</p></blockquote><blockquote><p>oc create -f </p></blockquote><blockquote><p>oc policy add-role-to-user edit system:serviceaccount:jenkins:jenkins -n dev</p></blockquote><blockquote><p>oc adm policy add-scc-to-user anyuid -z gitlab -n gitlab</p></blockquote><blockquote><p>oc new-project</p></blockquote><blockquote><p>oc set volumes</p></blockquote><blockquote><p>oc expose</p></blockquote><blockquote><p>oc start-build</p></blockquote><blockquote><p>oc rollback</p></blockquote><blockquote><p>oc rollout</p></blockquote><blockquote><p>oc rsync</p></blockquote><blockquote><p>oc rsh</p></blockquote><blockquote><p>oc set triggers dc&#x2F;flask-app-s2i –remove-all &amp;&amp; oc set triggers dc&#x2F;flask-app-s2i –from-image&#x3D;flask-app-s2i:v1 -c flask-app-s2i &amp;&amp; oc set triggers dc&#x2F;flask-app-s2i –from-config</p></blockquote><blockquote><p>oc patch NginxLB example-nginxlb -p ‘{“spec”: {“size”: “1”}}’ –type&#x3D;merge</p></blockquote><blockquote><p>oc serviceaccounts create-kubeconfig <serviceaccount-name> -n <namespace></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Prometheus监控实战》读书笔记</title>
      <link href="/openshift/%E3%80%8APrometheus%E7%9B%91%E6%8E%A7%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/openshift/%E3%80%8APrometheus%E7%9B%91%E6%8E%A7%E5%AE%9E%E6%88%98%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8a25a774e85f4cee5a52f1b5a1866767ea695e09b6e57370d72b1a7bd0bc7e5f.png" alt="《Prometheus监控实战》">  </p><p>Prometheus是一个开源的监控系统。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/1f8a3c449d01077883005884a31996646634a14c3d8dc713bf627d7e90f893a1.png" alt="Prometheus架构">  </p><h1 id="一、监控简介"><a href="#一、监控简介" class="headerlink" title="一、监控简介"></a>一、监控简介</h1><p>监控不仅仅只是系统的技术指标，还可以是业务指标。确保为客户提供可靠恰当的产品。<br>在生产系统中，监控是必须的，它应该和应用程序一起构建和部署。帮助我们了解系统的环境、进行诊断故障、制定容量计划，为组织提供系统的性能、成本和状态等信息。</p><h2 id="监控模式"><a href="#监控模式" class="headerlink" title="监控模式"></a>监控模式</h2><ol><li>务必在项目最开始阶段就把监控考虑进去，它和安全性一样，都是应用的核心功能。</li><li>根据服务价值设计自上而下的监控系统是一个很好的方式。先是业务逻辑，再是应用程序，最后才是基础设施操作系统。</li><li>需要找准监控项，及时发现错误</li><li>通过多样化的数据，如查看数据窗口等更智能的技术分析指标与阀值</li><li>增加监控的频率</li><li>尽可能实现监控系统部署实施自动化</li></ol><h2 id="监控机制"><a href="#监控机制" class="headerlink" title="监控机制"></a>监控机制</h2><ol><li>探针与内省：监控应用程序的两种方法。<br>探针：在应用程序的外部，查询应用程序的外部特征。如Nagios。<br>内省：查看应用程序的内部内容，经过检测，返回其状态、内部组件等的度量。可用作健康检查接口，由监控工具收集。</li><li>拉取与推送：执行监控检查的两种方式。<br>拉取：提取或检查远程应用程序。如Prometheus。<br>推送：应用程序发送事件给监控系统接收。</li></ol><h2 id="监控数据类型"><a href="#监控数据类型" class="headerlink" title="监控数据类型"></a>监控数据类型</h2><ol><li>指标：软件和硬件组件属性的度量。<br>指标类型：测量型 <code>Gauge</code>、计数型 <code>Counter</code>、直方图 <code>Histogram</code></li><li>日志：应用程序发出的事件（通常是文本类型）。</li></ol><h2 id="监控方法论"><a href="#监控方法论" class="headerlink" title="监控方法论"></a>监控方法论</h2><ol><li>Brendan Gregg的USE方法 <code>主机级监控</code><br>USE：使用率、饱和度、错误。针对每个资源（如CPU），检查使用率（如CPU使用百分比）、饱和度（如等待CPU的进程数）和错误（如错误事件的计数）。</li><li>Google四个黄金指标 <code>应用程序级监控</code><br>延迟（如服务请求时间）、流量（如每秒HTTP请求数）、错误（如响应时间走过30ms的请求视为错误）、饱和度（如内存IO）。</li><li>RED方法<br>Rate（你的服务所服务的每秒的请求数）、Errors（每秒失败的请求数）、Duration（每个请求所花费的时间，用时间间隔表示）</li></ol><h2 id="通知系统"><a href="#通知系统" class="headerlink" title="通知系统"></a>通知系统</h2><p>通知系统需要关注以下几点：</p><ol><li>通知清晰、准确、可操作。人易读。</li><li>通知添加上下文，通知应包含组件的其他相关信息。</li><li>仅发送有意义的通知。</li></ol><h1 id="二、Prometheus是什么？"><a href="#二、Prometheus是什么？" class="headerlink" title="二、Prometheus是什么？"></a>二、Prometheus是什么？</h1><p>Prometheus灵感来自于谷歌的Borgmon。这由前谷歌SRE Matt T. Proud开发。Proud加入SoundCloud后，两天Julius Volz合作开发了Prometheus。于2015年1月发布。<br>Prometheus主要用于提供近实时的、基于动态云环境和容器的微服务、服务和应用的内省监控。Prometheus专注于当前的事件，大多数监控查询和警报都是从最近（通常为一天内）的数据中生成。<br>Prometheus通过拉取应用程序中暴露的时间序列数据来工作。时间序列数据通常由应用程序本身通过客户端库或exporter的代理来作为HTTP端点暴露。</p><h2 id="Prometheus架构"><a href="#Prometheus架构" class="headerlink" title="Prometheus架构"></a>Prometheus架构</h2><p>Prometheus有一个推送网关，可用于接收少量数据。<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7311a0c938a022433533fcbd789eb208c964029b829002fad40759079fdc7cff.png" alt="Prometheus架构">  </p><h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><p>endpoint：端点，Prometheus抓取的指标来源<br>target：目标，定义执行抓取所需的信息，如链接，身份验证，抓取方式<br>job：一组目标，具有相同角色的目标组</p><h3 id="监控资源服务发现"><a href="#监控资源服务发现" class="headerlink" title="监控资源服务发现"></a>监控资源服务发现</h3><ol><li>用户提供静态资源列表。</li><li>基于文件的发现。例如使用配置管理工具生成在Prometheus中可以自动更新的资源列表。</li><li>自动发现。例如，查询consule等数据存储。</li></ol><h3 id="聚合和警报"><a href="#聚合和警报" class="headerlink" title="聚合和警报"></a>聚合和警报</h3><p>Prometheus服务器可以查询和聚合时间序列数据，创建规则来记录常用的查询和聚合。<br>Prometheus可以定义警报规则。为系统配置的在满足条件时触发警报的标准。将警报从Prometheus推送到警报管理器（Alertmanager）的单独服务器。<br>AlertManager可以管理、整合、分发各种警报到不同的目的地。</p><h3 id="查询、可视化"><a href="#查询、可视化" class="headerlink" title="查询、可视化"></a>查询、可视化</h3><p>Prometheus提供了一套内置查询语言PromQL、一个表达式浏览器及浏览数据的图形界面。<br>Prometheus可以与开源DashBoard Grafana集成，同时也支持其他的DashBoard。<br><code>为了速度与可靠性，Prometheus服务器充分使用内存和SSD磁盘</code></p><h3 id="冗余和高可用性"><a href="#冗余和高可用性" class="headerlink" title="冗余和高可用性"></a>冗余和高可用性</h3><p>部署Prometheus的高可用模式，可以使用两个以上配置相同的Prometheus服务器来收集时间序列数据，并且生成的警报由Alertmanager集群来处理。</p><h3 id="Prometheus数据模型"><a href="#Prometheus数据模型" class="headerlink" title="Prometheus数据模型"></a>Prometheus数据模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_website_visits&#123;site=&quot;MegaApp&quot;, location=&quot;NJ&quot;, instance=&quot;webserver:9090&quot;, job=&quot;web&quot;&#125;</span><br></pre></td></tr></table></figure><ul><li>指标名称：total_website</li><li>标签：site&#x3D;”MegaApp”等，通常都有一个instance标签和job标签<br>标签分为两类：1，插桩标签；2，目标标签<br>插桩标签：来自被监控的资源<br>目标标签：通常与架构相关，由Prometheus在抓取期间和之后添加。</li><li>时间序列由名称和标签标识，如果在时间序列中添加或更改标签，Prometheus会将其视为新的时间序列。</li></ul><h1 id="三、安装部署Prometheus"><a href="#三、安装部署Prometheus" class="headerlink" title="三、安装部署Prometheus"></a>三、安装部署Prometheus</h1><h2 id="安装Prometheus"><a href="#安装Prometheus" class="headerlink" title="安装Prometheus"></a>安装Prometheus</h2><h3 id="Linux上安装Prometheus"><a href="#Linux上安装Prometheus" class="headerlink" title="Linux上安装Prometheus"></a>Linux上安装Prometheus</h3><ol><li>下载Prometheus的二进制文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/prometheus/prometheus/releases/download/v2.14.0/prometheus-2.14.0.linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure></li><li>解压文件到相关目录，安装promtool<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xzf prometheus-2.14.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> prometheus-2.14.0.linux-amd64/prometheus /usr/local/bin/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> prometheus-2.14.0.linux-amd64/promtool /usr/local/bin/</span></span><br></pre></td></tr></table></figure></li><li>执行prometheus –version查看版本验证安装。</li></ol><h3 id="Ansible安装Promethues"><a href="#Ansible安装Promethues" class="headerlink" title="Ansible安装Promethues"></a>Ansible安装Promethues</h3><p>相关的role路径为：<a href="https://github.com/cloudalchemy/ansible-prometheus">https://github.com/cloudalchemy/ansible-prometheus</a>。</p><h3 id="OpenShift上安装Prometheus"><a href="#OpenShift上安装Prometheus" class="headerlink" title="OpenShift上安装Prometheus"></a>OpenShift上安装Prometheus</h3><p>OpenShift官方部署脚本支持Prometheus的安装。在OpenShift 3.11部署的时候，prometheus默认是安装的，如果要禁止安装则需将inventory中的配置<code>openshift_cluster_monitoring_operator_install</code>设置为<code>false</code>。<br>相关的开源软件地址为：<a href="https://github.com/openshift/cluster-monitoring-operator">https://github.com/openshift/cluster-monitoring-operator</a></p><h2 id="配置Prometheus"><a href="#配置Prometheus" class="headerlink" title="配置Prometheus"></a>配置Prometheus</h2><p>Prometheus通过YAML文件来配置。Prometheus的解压的目录中自带有配置文件prometheus.yml。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval:     15s # 应用程序或服务抓取数据的时间间隔，默认为1min</span><br><span class="line">  evaluation_interval: 15s # Prometheus评估规则（记录规则、警报规则）的频率，默认为1min</span><br><span class="line">  # scrape_timeout is set to the global default (10s).</span><br><span class="line"></span><br><span class="line"># Alertmanager configuration</span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      # - alertmanager:9093</span><br><span class="line"></span><br><span class="line"># 一次性加载规则，并且每隔evaluation_interval时间对规则进行评估&#x27;evaluation_interval&#x27;.</span><br><span class="line">rule_files:</span><br><span class="line">  # - &quot;first_rules.yml&quot;</span><br><span class="line">  # - &quot;second_rules.yml&quot;</span><br><span class="line"></span><br><span class="line"># 指定Prometheus抓取的所有目标</span><br><span class="line"># 下面是监控Prometheus本身</span><br><span class="line">scrape_configs:</span><br><span class="line">  # job名字将会被加到监控的指标中`job=&lt;job_name&gt;` </span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line"></span><br><span class="line">    # metrics_path 默认为 &#x27;/metrics&#x27;</span><br><span class="line">    # scheme 默认为 &#x27;http&#x27;.</span><br><span class="line"></span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;localhost:9090&#x27;]</span><br></pre></td></tr></table></figure><p>global：全局配置<br>alerting：设置Prometheus的警报。Prometheus支持Alertmanager服务发现功能。<br>rule_files：指定包含记录规则或警报规则的文件列表。<br>scrape_configs：指定Prometheus抓取的所有目标。</p><h2 id="运行Prometheus"><a href="#运行Prometheus" class="headerlink" title="运行Prometheus"></a>运行Prometheus</h2><ol><li>将配置文件prometheus.yml移到合适的位置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p /etc/prometheus</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> prometheus.yml /etc/prometheus/</span></span><br></pre></td></tr></table></figure></li><li>运行prometheus应用<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">prometheus --config.file <span class="string">&quot;/etc/prometheus/prometheus.yml&quot;</span></span></span><br></pre></td></tr></table></figure></li><li>如果发生异常，可以使用promtool来验证配置文件<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">promtool check config prometheus.yml</span></span><br><span class="line">Checking prometheus.yml</span><br><span class="line">    SUCCESS: 0 rule files found</span><br></pre></td></tr></table></figure></li></ol><h2 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h2><ol><li>查看指定指标值<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go_gc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125;  1.6166e-05</span><br></pre></td></tr></table></figure></li><li>过滤一些匹配标签<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go_gc_duration_seconds&#123;quantile!=&quot;0.5&quot;&#125;  </span><br></pre></td></tr></table></figure></li><li>聚合数据求和<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(promhttp_metric_handler_requests_total) # 求和</span><br></pre></td></tr></table></figure></li><li>PromQL通过子名by，按特定维度聚合<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(promhttp_metric_handler_requests_total) by (job)</span><br></pre></td></tr></table></figure></li><li>转换成速率<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(rate(promhttp_metric_handler_requests_total[5m])) by (job)</span><br></pre></td></tr></table></figure>rate()函数计算一定范围内时间序列的每秒平均增长率，适合缓慢变化的计数器（counter）。<br>irate()函数计算指定时间范围内的最近两个数据点来算速率，适合快速变化的计数器（counter）。<br>rate()与irate()函数都必须与计数器一起使用。</li><li>增加数量<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">increase(promhttp_metric_handler_requests_total[1h])</span><br></pre></td></tr></table></figure>指标1小时内增长的值。</li></ol><h2 id="容量规划"><a href="#容量规划" class="headerlink" title="容量规划"></a>容量规划</h2><ol><li>内存</li></ol><p>通过以下查询语句查看样本的收集率。显示最后一分钟添加到数据库的每秒样本率。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rate(prometheus_tsdb_head_samples_appended_total[1m])</span><br></pre></td></tr></table></figure><p>查询收集的指标数量，通过以下语句</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(count by (__name__)(&#123;__name__-\~&quot;\.\+&quot;&#125;))</span><br></pre></td></tr></table></figure><p>每个样本大小通常为1到2字节，假设在12小时内每秒收集100000个样本，那么内存使用情况为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">100000 * 2 bytes * 43200秒 约为 8.64GB内存</span><br></pre></td></tr></table></figure><p>约为 8.64GB内存，还需要考虑查询与记录规则方面内存的使用情况。<br>可以通过查看process_resident_memory_bytes指标查看Prometheus进程的内存使用情况。<br>2. 磁盘</p><p>默认情况下，指标会在本地数据库中存储15天。具体时间由命令行选项控制。<br>–storage.tsdb.path： 设置数据存储目录，默认为Prometheus的目录中。<br>–storage.tsdb.retention： 设置时间序列保留期，默认为15天。<br><code>建议采用SSD作为时间序列数据库的磁盘</code><br>每秒10万个样本的示例，每个样本磁盘上占用约1~2字节，保留15天数据算，大约需要259GB磁盘。</p><h1 id="四、监控主机和容器"><a href="#四、监控主机和容器" class="headerlink" title="四、监控主机和容器"></a>四、监控主机和容器</h1><p>Prometheus通过使用exporter工具来暴露主机和应用程序的指标。常用的exporter列表可在以下网站上查看。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://prometheus.io/docs/instrumenting/exporters/</span><br></pre></td></tr></table></figure><h2 id="监控主机"><a href="#监控主机" class="headerlink" title="监控主机"></a>监控主机</h2><p>Node Exporter 是用GO语言编写的，收集各种主机指标数据（CPU&#x2F;内存&#x2F;磁盘等）。同时还有一个textfile收集器，允许导出静态指标。</p><ol><li>安装Node Exporter<br>Node Exporter的下载地址如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/prometheus/node_exporter</span><br></pre></td></tr></table></figure>下载并解压安装<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xzf node_exporter-*</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> node_exporter-*/node_exporter /user/local/bin/</span></span><br></pre></td></tr></table></figure></li><li>配置Node Exporter<br>node_exporter是通过执行命令时传入参数来配置。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">node_exporter --<span class="built_in">help</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>默认情况下node_exporter在端口9100上运行，路径为&#x2F;metrics。可通过–web.listen-address和–web.telemetry-path来设置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">node_exporter --web.listen-address=<span class="string">&quot;:9600&quot;</span> --web.telemetry-path=<span class="string">&quot;/node_metrics&quot;</span></span></span><br></pre></td></tr></table></figure>同时可以通过参数控制启动的收集器，默认的收集器可在以下地址中查看<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/prometheus/node_exporter#enabled-by-default</span><br></pre></td></tr></table></figure>例如，想要禁用&#x2F;proc&#x2F;net&#x2F;arp统计信息，只需要启动node_exporter时添加<code>--no-collector.arp</code>配置项。</li><li>配置textfile收集器<br>textfile收集器可以帮助我们暴露自定义指标。node_exporter通过参数<code>--collector.textfile.directory</code>参数指定textfile的目录，它会扫描该目录下的所有文件，提取所有格式为Prometheus指标的字符串，然后暴露它们。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p /var/lib/node_exporter/textfile_collector</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&#x27;metadata&#123;role=&quot;docker_server&quot;, datacenter=&quot;NJ&quot;&#125; 1&#x27;</span> | sudo <span class="built_in">tee</span> /var/lib/node_exporter/textfile_collector/metadata.prom</span></span><br></pre></td></tr></table></figure></li><li>启用systemd收集器<br>systemd收集器记录systemd中的服务和系统状态。首先需要通过参数<code>--collector.systemd</code>启用该收集器，同时如果不希望收集所有的服务，只收集部分关键服务。node_exporter在启动时可以使用<code>--collector.systemd.unit-whitelist</code>参数配置。</li><li>运行Node Exporter<br>启动node_exporter的实例<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">node_exporter --collector.textfile.director /var/lib/node_exporter/textfile_collector --collector.systemd --collector.systemd.unit-whitelist-&#123;(docker|ssh|rsyslog).service<span class="string">&quot;</span></span></span><br></pre></td></tr></table></figure></li><li>抓取Node Exporter<br>配置新作业来抓取Node Exporter导出的数据。prometheus.yml文件中的scrape_configs部分添加job<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">  - job_name: &#x27;node&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;192.168.0.3:9100&#x27;, &#x27;192.168.0.4:9100&#x27;, &#x27;192.168.0.5:9100&#x27;]</span><br></pre></td></tr></table></figure>添加了新的job ‘node’，添加了三台主机的node_exporter监控，默认路径为&#x2F;metrics。<br>重启Prometheus服务，将会加载最新的配置，新监控项将会被收集到prometheus数据中。</li><li>过滤收集器<br>Prometheus提供了限制抓取过来的数据指标的机制。使用params块中的collect[]来指定收集的指标。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;node&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;192.168.0.3:9100&#x27;, &#x27;192.168.0.4:9100&#x27;, &#x27;192.168.0.5:9100&#x27;]</span><br><span class="line">    params:</span><br><span class="line">      collect[]:</span><br><span class="line">        - cpu</span><br><span class="line">        - meminfo</span><br><span class="line">        - diskstats</span><br><span class="line">        - netdev</span><br><span class="line">        - netstat</span><br><span class="line">        - filefd</span><br><span class="line">        - filesystem</span><br><span class="line">        - xfs</span><br><span class="line">        - systemd</span><br></pre></td></tr></table></figure>使用以下命令来模拟测试<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -g -X GET http://192.168.0.3:9100/metrics?collect[]=cpu</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="监控Docker容器"><a href="#监控Docker容器" class="headerlink" title="监控Docker容器"></a>监控Docker容器</h2><p>推荐使用Google的cAdvisor工具来监控Docker。cAdvisor作为Docker容器运行，单个cAdvisor容器返回针对Docker守护进程和所有正在运行的容器的指标。</p><ol><li>运行cAdvisor<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker run \</span></span><br><span class="line"><span class="language-bash">-v /:/rootfs:ro \</span></span><br><span class="line"><span class="language-bash">-v /var/run:/var/run:rw \</span></span><br><span class="line"><span class="language-bash">-v /sys:/sys:ro \</span></span><br><span class="line"><span class="language-bash">-v /var/lib/docker/:/var/lib/docker:ro \</span></span><br><span class="line"><span class="language-bash">-v /dev/disk/:/dev/disk:ro \</span></span><br><span class="line"><span class="language-bash">-p 8080:8080 \</span></span><br><span class="line"><span class="language-bash">-d --name=cadvisor \</span></span><br><span class="line"><span class="language-bash">google/cadvisor:latest</span></span><br></pre></td></tr></table></figure>通过浏览器访问<a href="http://192.168.0.3:8080/containers/%E5%8F%AF%E6%9F%A5%E7%9C%8B">http://192.168.0.3:8080/containers/可查看</a><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/e00420385b6a381e48b2720f6f06a80923a48dca9c1090627348c8cf26eeabb4.png" alt="cAdvisor"></li></ol><p>通过浏览器访问<a href="http://192.168.0.3:8080/metrics%E6%9F%A5%E7%9C%8B%E6%9A%B4%E9%9C%B2%E7%9A%84%E5%86%85%E7%BD%AEPrometheus%E6%8C%87%E6%A0%87">http://192.168.0.3:8080/metrics查看暴露的内置Prometheus指标</a><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/bf56e152574f3826c60b507be21085d05115bb0e27748ca0dee37258e8f918cf.png" alt="cAdvisor指标">  </p><ol start="2"><li>抓取cAdvisor<br>配置新作业来抓取cAdvisor导出的数据。prometheus.yml文件中的scrape_configs部分添加job<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">  - job_name: &#x27;node&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;192.168.0.3:9100&#x27;, &#x27;192.168.0.4:9100&#x27;, &#x27;192.168.0.5:9100&#x27;]</span><br><span class="line">  - job_name: &#x27;docker&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;192.168.0.3:8080&#x27;, &#x27;192.168.0.4:8080&#x27;, &#x27;192.168.0.5:8080&#x27;]</span><br></pre></td></tr></table></figure>添加了新的job ‘docker’，添加了三台主机的node_exporter监控，默认路径为&#x2F;metrics。</li></ol><h2 id="Prometheus抓取数据的生命周期"><a href="#Prometheus抓取数据的生命周期" class="headerlink" title="Prometheus抓取数据的生命周期"></a>Prometheus抓取数据的生命周期</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/09de44fe6e1aa13aaaed501e8fbd1b6b8ebeac3059fc73c65a46c5a1218ea602.png" alt="Prometheus抓取数据的生命周期简化版">  </p><p>可以看到在Prometheus抓取数据的生命周期中，有两处重新标记指标的部分，一个在抓取前，一个是在抓取后。</p><h2 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h2><p>标签提供了时间序列的维度，可以定义目标，并为时间序列提供上下文。最重要的是，结合指标名称，它们构成了时间序列的标识。<br>更改或者添加标签会创建新的时间序列</p><ol><li><p>标签分类：拓扑标签、模式标签<br>拓扑标签：通过其物理或者逻辑组成来切割服务组件。每个指标都天然带着job和instance两个拓扑标签。instance标签可以标识目标，通常是目标的IP地址和端口，并且来自__address__标签。<br>模式标签：url、error_code或者user之类，允许将拓扑中同一级别的时间序列匹配在一起。<br>如果需要添加额外的标签，可以考虑以下的层次结构<br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/fcbef27c720f8c1f18917b04ea0fe1f426d8ddca1b2ffae9be3ecd3292d78acc.png" alt="标签层次结构参考">  </p></li><li><p>重新标记<br>控制标签。有两个阶段可以重新标记标签。抓取前的relabel_configs和抓取后的metric_relabel_configs模式。</p></li></ol><ul><li>删除不必要的指标</li><li>从指标中删除敏感或不需要的标签</li><li>添加、编辑、修改指标的标签值或标签格式</li></ul><blockquote><p>在拉取了cAdvisor的指标数据后，删除<code>container_tasks_state</code>与<code>container_memory_failures_total</code>指标数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;docker&#x27;</span><br><span class="line">   static_configs:</span><br><span class="line">     - targets: [&#x27;192.168.0.3:8080&#x27;, &#x27;192.168.0.4:8080&#x27;, &#x27;192.168.0.5:8080&#x27;]</span><br><span class="line">   metric_relabel_configs:</span><br><span class="line">     - source_labels: [__name__]</span><br><span class="line">       separator: &#x27;;&#x27;</span><br><span class="line">       regex: &#x27;(container_tasks_state|container_memory_failures_total)&#x27;</span><br><span class="line">       action: drop</span><br></pre></td></tr></table></figure><p>separator默认值为’;’，多个标签通过separator连接在一起。<br>如果指定多个源标签，可以使用；隔开每个正则表达式。<br>action: drop将会在数据存储之前删除指标，keep则会保留与正则匹配的指标，删除所有其他指标。</p><blockquote><p>正则配置id指标中的数据，并将匹配的值放入新的标签container_id中。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;docker&#x27;</span><br><span class="line">   static_configs:</span><br><span class="line">     - targets: [&#x27;192.168.0.3:8080&#x27;, &#x27;192.168.0.4:8080&#x27;, &#x27;192.168.0.5:8080&#x27;]</span><br><span class="line">   metric_relabel_configs:</span><br><span class="line">     - source_labels: [id]</span><br><span class="line">       regex: &#x27;/docker/([a-z0-9]+);&#x27;</span><br><span class="line">       replacement: &#x27;$1&#x27;</span><br><span class="line">       target_label: container_id</span><br></pre></td></tr></table></figure><p>没有指定action操作，因为metric_relabel_configs的action默认操作为replace。<br>honor_labels默认值为false，如果target_label的标签已经存在，则会在其前面添加exported_前缀来做区分。</p><blockquote><p>删除标签kernelVersion</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;docker&#x27;</span><br><span class="line">   static_configs:</span><br><span class="line">     - targets: [&#x27;192.168.0.3:8080&#x27;, &#x27;192.168.0.4:8080&#x27;, &#x27;192.168.0.5:8080&#x27;]</span><br><span class="line">   metric_relabel_configs:</span><br><span class="line">     - regex: &#x27;kernelVersion&#x27;</span><br><span class="line">       action: labeldrop</span><br></pre></td></tr></table></figure><p>action: labeldrop，删除匹配的标签<br>action: labelkeep，保留匹配的标签，删除所有其他标签</p><h2 id="Node-Exporter和cAdvisor指标"><a href="#Node-Exporter和cAdvisor指标" class="headerlink" title="Node Exporter和cAdvisor指标"></a>Node Exporter和cAdvisor指标</h2><ol><li>CPU使用率<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">100 - avg(irate(node_cpu_seconds_total&#123;job=&quot;node&quot;, mode=&quot;idle&quot;&#125;[5m])) by (instance) * 100</span><br></pre></td></tr></table></figure></li><li>CPU饱和度<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node_load1 &gt; on (instance) 2 * count by (instance)(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;)</span><br></pre></td></tr></table></figure></li><li>内存使用率<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(node_memory_MemTotal_bytes - (node_memory_MemFree_bytes + node_memory_Cached_bytes + node_memory_Buffers_bytes)) / node_memory_MemTotal_bytes * 100</span><br></pre></td></tr></table></figure></li><li>内存饱和度<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1024 * sum by (instance) ((rate(node_vmstat_pgpgin[1m]) + rate(node_vmstat_pgpgout[1m])))</span><br></pre></td></tr></table></figure></li><li>磁盘使用率<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(node_fileystem_size_bytes&#123;mountpoint=~&quot;/|/run&quot;&#125; - node_filesystem_free_bytes&#123;mountpoint=~&quot;/|/run&quot;&#125;) / node_filesystem_size_bytes&#123;mountpoint=~&quot;/|/run&quot;&#125; * 100</span><br></pre></td></tr></table></figure>Prometheus支持预测<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">predict_linear(node_fileystem_size_bytes&#123;job=&quot;node&quot;&#125;[1h], 4*3600) &lt; 0</span><br></pre></td></tr></table></figure>使用1个小时窗口数据，预测所有磁盘4个小时后的磁盘会不会用完。</li><li>服务状态<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node_systemd_unit_state&#123;name=&quot;docker.service&quot;, state=&quot;active&quot;&#125;</span><br></pre></td></tr></table></figure></li><li>exporter的可用性和up指标<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">up &#123;job=&quot;node&quot;, instance=&quot;192.168.0.3:9100&quot;&#125;</span><br></pre></td></tr></table></figure></li><li>textfile收集器metadata指标<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metadata&#123;datacenter != &quot;NJ&quot;&#125;</span><br><span class="line">node_systemd_unit_state&#123;name=&quot;docker.service&quot;&#125; == 1 and on (instance, job) metadata&#123;datacenter = &quot;SF&quot;&#125;</span><br></pre></td></tr></table></figure>on：一对一匹配<br>group_left：多对一<br>group_right：一对多<br>详情：<a href="https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching">https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching</a></li></ol><h2 id="查询持久化"><a href="#查询持久化" class="headerlink" title="查询持久化"></a>查询持久化</h2><p>三种方式使查询持久化</p><ul><li>记录规则：根据查询创建新指标</li><li>警报规则：从查询生成警报</li><li>可视化：使用Grafana等仪表板可视化查询</li></ul><p>记录规则<br>prometheus.yml中的配置项<code>evaluation_interval</code>设置为自动计算记录的规则。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval: 15s</span><br><span class="line">  evaluation_interval: 15s</span><br></pre></td></tr></table></figure><p>在prometheus.yml文件的同一文件夹下，创建名为rules的子文件夹，用于保存记录规则。同时在prometheus.yml配置文件中的rule_files块中添加文件<code>rules/node_rules.yml</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p rules &amp;&amp; <span class="built_in">cd</span> rules</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; node_rules.yml &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">groups:</span><br><span class="line">- name: node_rules</span><br><span class="line">  interval: 10s</span><br><span class="line">  rules:</span><br><span class="line">  - record: instance:node_cpu:avg_rate5m</span><br><span class="line">    expr: 100 - avg(irate(node_cpu_seconds_total&#123;job=&quot;node&quot;, mode=&quot;idle&quot;&#125;[5m])) by (instance) * 100</span><br><span class="line">    labels:</span><br><span class="line">      metric_type: aggregation</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>创建了名为”node_rules”的规则组，顺序执行规则，后面的规则可以重用前面的规则。规则组间是并行运行的，因此不建议跨组使用规则。<br>interval：10s 可以设置interval覆盖默认的evaluation_interval值。<br>record：<strong>应该仔细为新的时间序列取名，以便快速识别它的含义，一般推荐的格式是：</strong> <code>level:metric:operations</code><br>expr：保存生成新时间序列的查询<br>labels：向新序列添加新的标签</p><h2 id="可视化-Grafana"><a href="#可视化-Grafana" class="headerlink" title="可视化 Grafana"></a>可视化 Grafana</h2><ol><li>安装Grafana<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://dl.grafana.com/oss/release/grafana-6.5.1-1.x86_64.rpm</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum localinstall grafana-6.5.1-1.x86_64.rpm</span></span><br></pre></td></tr></table></figure>使用ansible role安装：<a href="https://galaxy.ansible.com/list#roles/3563">https://galaxy.ansible.com/list#roles/3563</a><br>使用Docker镜像安装：<a href="https://hub.docker.com/search/?q=grafana">https://hub.docker.com/search/?q=grafana</a></li><li>启动与配置Grafana<br>配置文件位于<code>/etc/grafana/grafana.ini</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start grafana-server</span></span><br></pre></td></tr></table></figure></li><li>浏览器访问<a href="http://localhost:3000，默认用户名和密码为admin和admin。">http://localhost:3000，默认用户名和密码为admin和admin。</a><br>Grafana仪表盘实例查看地址：<a href="https://grafana.com/grafana/dashboards">https://grafana.com/grafana/dashboards</a><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2076ee0e76cebf306876738067177ef0c906b2b4c259a19a1eab6509008e7607.png" alt="Grafana"></li></ol><h1 id="五、Prometheus服务发现"><a href="#五、Prometheus服务发现" class="headerlink" title="五、Prometheus服务发现"></a>五、Prometheus服务发现</h1><p>对于主机数少的情况下，Prometheus可以使用静态配置目标。当规模较大的集群时，就不适用了。服务发现可以通过以下三种机制实现：</p><ul><li>配置管理工具生成的文件中接收目标列表</li><li>查询API以获取目标列表</li><li>使用DNS记录以返回目标列表</li></ul><h2 id="基于文件的服务发现"><a href="#基于文件的服务发现" class="headerlink" title="基于文件的服务发现"></a>基于文件的服务发现</h2><p>适合配置管理工具。Prometheus会按指定时间计划从这些文件重新加载目标，文件格式支持yaml、Json格式，它们包含了目标列表。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- job_name: node</span><br><span class="line">  file_sd_configs:</span><br><span class="line">    - files:</span><br><span class="line">      - targets/nodes/*.json</span><br><span class="line">        refresh_interval: 5m</span><br><span class="line">- job_name: docker</span><br><span class="line">  file_sd_configs:</span><br><span class="line">    - files:</span><br><span class="line">      - targets/docker/*.yml</span><br><span class="line">        refresh_interval: 5m</span><br></pre></td></tr></table></figure><p>新建nodes与docker目录，并添加对应的配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /etc/prometheus</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p targets/&#123;nodes,docker&#125;</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; targets/nodes/nodes.json &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">[&#123;</span><br><span class="line">  &quot;targets&quot;: [</span><br><span class="line">    &#x27;192.168.0.3:9100&#x27;, </span><br><span class="line">    &#x27;192.168.0.4:9100&#x27;, </span><br><span class="line">    &#x27;192.168.0.5:9100&#x27;</span><br><span class="line">  ]</span><br><span class="line">&#125;]</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">cat &gt; targets/docker/daemons.yml &lt;&lt;EOF</span></span></span><br><span class="line">- targets:</span><br><span class="line">  - &#x27;192.168.0.3:8080&#x27;</span><br><span class="line">  - &#x27;192.168.0.4:8080&#x27;</span><br><span class="line">  - &#x27;192.168.0.5:8080&#x27;</span><br><span class="line">  labels:</span><br><span class="line">    datacenter: NJ</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="基于API的服务发现"><a href="#基于API的服务发现" class="headerlink" title="基于API的服务发现"></a>基于API的服务发现</h2><p>当前API的服务发现支持以下平台：</p><ul><li>AWS EC2</li><li>Azure</li><li>Consul</li><li>Google Compute Cloud</li><li><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config">Kubernetes</a></li></ul><h2 id="基于DNS的服务发现"><a href="#基于DNS的服务发现" class="headerlink" title="基于DNS的服务发现"></a>基于DNS的服务发现</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- job_name: webapp</span><br><span class="line">  dns_sd_configs:</span><br><span class="line">    - names: [&#x27;_prometheus._tcp.example.com&#x27;]</span><br></pre></td></tr></table></figure><p>Prometheus在查询目标时，通过DNS服务器查找example.com域，然后在该域下搜索名为_prometheus._tcp.example.com的SRV记录，返回该条目中的服务记录。<br>还可以使用DNS服务发现来查询单个A或AAAA记录。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- job_name: webapp</span><br><span class="line">  dns_sd_configs:</span><br><span class="line">    - names: [&#x27;example.com&#x27;]</span><br><span class="line">      type: A</span><br><span class="line">      port: 9100</span><br></pre></td></tr></table></figure><p>返回example.com域根目录下的所有A记录。</p><h1 id="六、Alert-Manager报警管理"><a href="#六、Alert-Manager报警管理" class="headerlink" title="六、Alert Manager报警管理"></a>六、Alert Manager报警管理</h1><p>监控是为了了解系统的状态，以便于及时发现问题。当指标出现异常时，我们应该第一时间知道，便及时处理，但是我们又无法实时关注在每个监控指标，这时我们就需要告警机制。没有告警机制的监控，像是摆在家里的花瓶，它很美但用处不大。<br><strong>一个好的警报应该是，在正确的时间、发给正确的人、恰当的量、包含准确（不多也不少）的信息。</strong></p><ul><li>适当数量的警报</li><li>设置正确的警报优先级</li><li>警报应包括适当的上下文</li></ul><h2 id="Alertmanager如何工作"><a href="#Alertmanager如何工作" class="headerlink" title="Alertmanager如何工作"></a>Alertmanager如何工作</h2><p>Prometheus服务器向Alertmanager发送警报，当然Alertmanager也可以接收其他工具的警报。Alertmanager对警报进行去重、分组，然后路由到不同的接收器：email，sms等。</p><ul><li>在Prometheus服务上编写警报规则</li><li>当指标达到阈值时，会生成警报推送到Alertmanager。</li><li>一个或多个Prometheus服务器可以将警报定向到单个Alertmanager下</li><li>Alertmanager处理警报，并根据其标签进行路由。</li></ul><h2 id="Alertmanager安装、配置、运行"><a href="#Alertmanager安装、配置、运行" class="headerlink" title="Alertmanager安装、配置、运行"></a>Alertmanager安装、配置、运行</h2><ol><li>Alertmanager安装<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/prometheus/alertmanager/releases/download/v0.20.0-rc.0/alertmanager-0.20.0-rc.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xzf alertmanager-0.20.0-rc.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> alertmanager-0.20.0-rc.0.linux-amd64/alertmanager /usr/local/bin/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> alertmanager-0.20.0-rc.0.linux-amd64/amtool /usr/local/bin/</span></span><br></pre></td></tr></table></figure></li><li>配置Alertmanager<br><a href="https://prometheus.io/docs/alerting/configuration/">https://prometheus.io/docs/alerting/configuration/</a><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p /etc/alertmanager</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cat</span> &gt; /etc/alertmanager/alertmanager.yml &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">global:</span><br><span class="line">  smtp_smarthost: &#x27;localhost:25&#x27;</span><br><span class="line">  smtp_from: &#x27;alertmanager@example.com&#x27;</span><br><span class="line">  smtp_require_tls: false</span><br><span class="line"></span><br><span class="line">templates:</span><br><span class="line">- &#x27;/etc/alertmanager/template/*.tmpl&#x27;</span><br><span class="line"></span><br><span class="line">route:</span><br><span class="line">  receiver: email</span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">- name: &#x27;email&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;alerts@example.com&#x27;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>global：全局设置，为其他模块的默认值<br>template：保存警报模板<br>route：警报根据规则进行匹配，采取相应的操作<br>receivers：接收器列表，每个接收器有唯一的名字及配置。<a href="https://prometheus.io/docs/alerting/configuration/#email_config">email_configs</a>来指定电子邮件选项，<a href="https://prometheus.io/docs/alerting/configuration/#webhook_config">webhook_configs</a>可以扩展Alertmanager的接收器。</li><li>运行Alertmanager<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">alertmanager --config.file alertmanager.yml</span></span><br></pre></td></tr></table></figure>通过浏览器访问alertmanager，<a href="http://localhost:9093/">http://localhost:9093</a></li></ol><h2 id="Prometheus配置Alertmanager"><a href="#Prometheus配置Alertmanager" class="headerlink" title="Prometheus配置Alertmanager"></a>Prometheus配置Alertmanager</h2><ol><li>在prometheus.yml配置中设置alerting模块。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    -targets:</span><br><span class="line">      - alertmanager:9093</span><br></pre></td></tr></table></figure></li><li>监控Alertmanager<br>Alertmanager服务暴露了自身的相关指标，创建一个Prometheus Job就可以监控Alertmanager<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;alertmanager&#x27;</span><br><span class="line">  static_configs:</span><br><span class="line">    - targets: [&#x27;localhost:9093&#x27;]</span><br></pre></td></tr></table></figure></li><li>添加警报规则<br>与记录规则一样，警报规则在Prometheus服务器配置中加载的规则文件内也使用Yaml语句定义。<br>在prometheus.yml配置文件中的rule_files块中添加文件rules&#x2F;node_alerts.yml<br>在rules目录下创建文件node_alerts.yml来保存节点报警规则。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; rules/node_alerts.yml &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">groups:</span><br><span class="line">- name: node_alerts</span><br><span class="line">  rules:</span><br><span class="line">  - alert: HighNodeCPU</span><br><span class="line">    expr: instance:node_cpu:avg_rate5m &gt; 80</span><br><span class="line">    for: 60m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      summary: High Node CPU for 1 hour</span><br><span class="line">      console: You might want to check the Node Dashboard at http://grafana.example.com/dashboard/db/node-dashboard</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>alert：规则名<br>expr：触发规则<br>for：控制在触发警报之前测试表达式必须为true的时长<br>labels与annotations：装饰警报</li></ol><p>警报有三种状态：<br>Inactive：警报未激活<br>Pending：警报已满足测试表达式条件，但仍在等待for子句中指定的持续时长<br>Firing：警报（如果没有设置for，则一旦触发条件，立刻Firing）</p><p>Pending、Firing状态下的警报可以在Prometheus的指标中查看到ALERTS。<br>新的警报与模板示例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: node_alerts</span><br><span class="line">  rules:</span><br><span class="line">  - alert: DiskWillFillIn4Hours</span><br><span class="line">    expr: predict_linear(node_fileystem_size_bytes&#123;mountpoing=&quot;/&quot;&#125;[1h], 4*3600) &lt; 0</span><br><span class="line">    for: 5m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Disk on &#123;&#123; $labels.instance &#125;&#125; will fill in approximately 4 hours.</span><br><span class="line">  - alert: InstanceDown</span><br><span class="line">    expr: up&#123;job=&quot;node&quot;&#125; == 0</span><br><span class="line">    for: 10m</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Host &#123;&#123; $labels.instance &#125;&#125; of &#123;&#123; $labels.job &#125;&#125; is down!</span><br><span class="line">  - alert: NodeServiceDown</span><br><span class="line">    expr: node_systemd_unit_state&#123;state=&quot;active&quot;&#125; != 1</span><br><span class="line">    for: 60s</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Service &#123;&#123;$labels.name&#125;&#125; on &#123;&#123; $labels.instance &#125;&#125; is no longer active!</span><br><span class="line">      description: Service Down</span><br><span class="line">  - alert: InstanceGone</span><br><span class="line">    expr: absent(up&#123;job=&quot;node&quot;&#125;)</span><br><span class="line">    for: 10s</span><br><span class="line">    labels:</span><br><span class="line">      severity: critical</span><br><span class="line">    annotations:</span><br><span class="line">      summary: Host &#123;&#123; $labels.instance &#125;&#125; is no logger reporting!</span><br><span class="line">      description: &#x27;OMG Where are my instances&#x27;</span><br><span class="line">- name: prometheus_alerts</span><br><span class="line">  rules:</span><br><span class="line">  - alert: PrometheusConfigReloadFailed</span><br><span class="line">    expr: prometheus_config_last_reload_successful == 0</span><br><span class="line">    for: 10m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      description: Reloading Prometheus configuration has failed on &#123;&#123; $lables.instance &#125;&#125;.</span><br><span class="line">  - alert: PrometheusNotConnectedToAlertmanagers</span><br><span class="line">    expr: prometheus_notifications_alertmanagers_discovered &lt; 1</span><br><span class="line">    for: 10m</span><br><span class="line">    labels:</span><br><span class="line">      severity: warning</span><br><span class="line">    annotations:</span><br><span class="line">      description: Prometheus &#123;&#123; $labels.instance &#125;&#125; is not connected to any Alertmanagers.</span><br></pre></td></tr></table></figure><h2 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h2><p>Alertmanager的配置文件alertmanager.yml中添加一些路由配置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">route:</span><br><span class="line">  group_by: [&#x27;instance&#x27;]</span><br><span class="line">  group_wait: 30s</span><br><span class="line">  group_interval: 5m</span><br><span class="line">  repeat_interval: 3h</span><br><span class="line">  receiver: email</span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      severity: critical</span><br><span class="line">    receiver: pager</span><br><span class="line">  - match_re:</span><br><span class="line">      severity: ^(warning|critical)$</span><br><span class="line">    receiver: support_team</span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">- name: &#x27;email&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;alert@example.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#x27;support_team&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;support@example.com&#x27;</span><br><span class="line">- name: &#x27;pager&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;alert-pager@example.com&#x27;</span><br><span class="line">  pagerduty_configs:</span><br><span class="line">  - service_key: TEAFDSFEWS</span><br></pre></td></tr></table></figure><p>group_by：对Alertmanager警报指定分组方式，如按照instance来分组<br>group_wait：如果进行分组，Alertmanager会等待group_wait指定的时间，以便在触发报警前查看是否收到该组中的其他报警<br>group_interval：如果发出警报后，Alertmanager收到该分组的下一次评估的新警报后，会等待group_interval时间后再发送新警报，以免警报泛滥<br>repeat_interval：适用于单个警报，等待重新发送相同警报的时间段<br>receiver：默认接收器<br>send_resolved: 恢复后发送通知<br>routes：路由规则。如果需要routers还可以分支。如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">routes:</span><br><span class="line">- match:</span><br><span class="line">    severity: critical</span><br><span class="line">  receiver: pager</span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      service: application1</span><br><span class="line">    receiver: support_team</span><br></pre></td></tr></table></figure><h2 id="通知模板"><a href="#通知模板" class="headerlink" title="通知模板"></a>通知模板</h2><p>模板目录：&#x2F;etc&#x2F;alertmanager&#x2F;templates</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /etc/alertmanager/templates/slack.tmpl &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">&#123;&#123; define &quot;annotation.summary.text&quot; &#125;&#125;&#123;&#123; .CommonAnnotations.summary&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>对应的slack_configs receiver配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  slack_configs:</span><br><span class="line">  - api_url: https://hooks.slack.com/services/ABC123/fsdaf、</span><br><span class="line">EXAMPLE</span><br><span class="line">  channel: #monitoring</span><br><span class="line">  text: &#x27;&#123;&#123;template &quot;annotation.summary.text&quot; .&#125;&#125;</span><br></pre></td></tr></table></figure><p>使用模板通知来填充text字段，使用上下文通知。</p><h2 id="silence和维护"><a href="#silence和维护" class="headerlink" title="silence和维护"></a>silence和维护</h2><p>报警静默设置。当服务进行维护时，不需要发出告警，使用silence进行控制。两种方法进行设置：</p><ul><li>通过Alertmanger Web控制台</li><li>通过amtool命令工具</li></ul><ol><li>使用amtool添加silence。默认为1h过期时间，可以指定–expires和–expire-on参数指定更长的时间与窗口<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">amtool --alertmanager.url=http://localhost:9093 silence add alertname=InstancesGone service=application1</span></span><br></pre></td></tr></table></figure></li><li>使用query命令查询silence列表<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">amtool  --alertmanager.url=http://localhost:9093 silence query</span></span><br></pre></td></tr></table></figure></li><li>指定silence过期<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">amtool  --alertmanager.url=http://localhost:9093 silence expire <span class="variable">$SILENCE_ID</span></span></span><br></pre></td></tr></table></figure></li><li>使用正则创建silence<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">amtool  --alertmanager.url=http://localhost:9093 silence add --comment <span class="string">&quot;App1 maintenance&quot;</span> alertname=~<span class="string">&#x27;Instance.*&#x27;</span> service=application1</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="七、Prometheus高可用性"><a href="#七、Prometheus高可用性" class="headerlink" title="七、Prometheus高可用性"></a>七、Prometheus高可用性</h1><p>Prometheus通过运行两个配置相同的Prometheus服务器，并且它们同时处于活动状态来实现容错。该配置生成的重复警报交由上游Alertmanager使用其分组功能进行处理。所以一个推荐的做法是关注Alertmanager的高可用，而不是Prometheus服务。<br>通过创建一个Alertmanager集群来实现高可用，所有Prometheus服务器将告警发送到Alertmamanager集群，而Alertmanager负责去除重复数据。</p><h2 id="设置Alertmanager集群"><a href="#设置Alertmanager集群" class="headerlink" title="设置Alertmanager集群"></a>设置Alertmanager集群</h2><p>Alertmanager包含由HashiCorp Memberlist库提供的集群功能。</p><ol><li>在多台主机上安装Alertmanager</li><li>启动Alertmanager，传入参数–cluster.listen-address<br>第一台主机启动Alertmanager命令如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">alertmanager --config.file alertmanager.yml --cluster.listen-address 192.168.0.3:8001</span></span><br></pre></td></tr></table></figure>剩下的主机启动Alertmanager命令如下：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">alertmanager --config.file alertmanager.yml --cluster.listen-address 192.168.0.4:8001 --cluster.peer 192.168.0.3:8001</span></span><br></pre></td></tr></table></figure></li><li>在Alertmanager的控制台状态页面&#x2F;status上查看集群状态</li><li>为Prometheus配置Alertmanager集群<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">    - static_configs:</span><br><span class="line">      - targets:</span><br><span class="line">        - 192.168.0.3:9093</span><br><span class="line">        - 192.168.0.4:9093</span><br><span class="line">        - 192.168.0.5:9093</span><br></pre></td></tr></table></figure>三个Alertmanager服务都会收到告警信息，保证告警可达。</li></ol><h2 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h2><p><a href="https://prometheus.io/docs/prometheus/latest/federation/">Prometheus federation API</a>抓取每个工作节点的聚合指标<br>一个很好的例子是：基于区域的主节点和工作节点，基于区域的主节点视为全局的工作节点，然后向全局的主节点进行报告。<br>因为是金字塔级结构，主节点可能会有延时，所以尽量通过工作节点向Alertmanager发送告警。<br><strong>水平分片通常是最后的选择。每个目标都有数万个指标或者大量时间序列。</strong></p><p>Prometheus work0配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  external_labels:</span><br><span class="line">    worker: 0</span><br><span class="line">rule_files:</span><br><span class="line">  - &quot;rules/node_rules.yml&quot;</span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;node&#x27;</span><br><span class="line">    file_sd_configs:</span><br><span class="line">    - files:</span><br><span class="line">      - targets/nodes/*.json</span><br><span class="line">        refresh_interval: 5m</span><br><span class="line">    relabel_configs:</span><br><span class="line">    - source_labels: [__address__]</span><br><span class="line">      modulus: 3</span><br><span class="line">      target_label: __tmp_hash</span><br><span class="line">      action: hashmod</span><br><span class="line">    - source_labels: [__tmp_hash]</span><br><span class="line">      regex: ^0$</span><br><span class="line">      action: keep</span><br></pre></td></tr></table></figure><p>该过程是使用hashmod模块对<code>__address__</code>标签的值对3取Mod，如果余数为0，则保留。<br>同样的方法配置好work1与work2节点。</p><p>Prometheus 主节点配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scrap_configs:</span><br><span class="line">- job_name: &#x27;node_workers&#x27;</span><br><span class="line">  file_sd_configs:</span><br><span class="line">    - files:</span><br><span class="line">      - &#x27;targets/workers.json&#x27;</span><br><span class="line">      refresh_interval: 5m</span><br><span class="line">  honor_labels: true</span><br><span class="line">  metrics_path: /federate</span><br><span class="line">  params:</span><br><span class="line">    &#x27;match[]&#x27;:</span><br><span class="line">      - &#x27;&#123;__name__=&quot;^instance:.*&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure><p>其中targets&#x2F;workers.json内容为</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  &quot;targets&quot;: [</span><br><span class="line">    &quot;worker0:9090&quot;,</span><br><span class="line">    &quot;worker1:9090&quot;,</span><br><span class="line">    &quot;worker2:9090&quot;,</span><br><span class="line">  ]</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><p>Prometheus支持使用&#x2F;federate API根据指定的匹配参数来查询服务器指标。</p><h1 id="八、日志监控"><a href="#八、日志监控" class="headerlink" title="八、日志监控"></a>八、日志监控</h1><p>使用<a href="https://github.com/google/mtail">mtail</a>作为日志处理工具，它是Google开发的，非常轻巧。它专门用于从应用程序日志中提取要导出到时间序列数据库中的指标。</p><ol><li>安装mtail<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/google/mtail/releases/download/v3.0.0-rc33/mtail_v3.0.0-rc33_linux_amd64 -O mtail</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> 0755 mtail</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> mtail /usr/local/bin/</span></span><br></pre></td></tr></table></figure></li><li>使用mtail<br>mtail通过命令进行配置，指定日志文件列表，以及运行的程序目录。每个mtail程序都以.mtail为后缀名。<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> /etc/mtail</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /etc/mtail/line_count.mtail &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">counter line_count</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">/$</span><span class="language-bash"><span class="string">/ &#123;</span></span></span><br><span class="line">  line_count++</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>程序定义了一个名为line_count的计数器（计数器 counter，测量型 gauge）。这些计数与测量通过mtail导出到定义的任何目的地。</li><li>运行mtail<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo mtail --progs /etc/mtail --logs <span class="string">&#x27;/var/log/*.log&#x27;</span></span> </span><br></pre></td></tr></table></figure>–progs：指定mtail程序所在目录<br>–logs：指定日志文件<br>执行后，mtail将在3903端口上启动Web服务（使用–address和–port参数设置IP与端口）。<a href="http://localhost:3903/metrics%E8%B7%AF%E5%BE%84%E5%8F%AF%E4%BB%A5%E8%A2%ABPrometheus%E8%8E%B7%E5%8F%96%E7%9B%B8%E5%85%B3%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE%E3%80%82">http://localhost:3903/metrics路径可以被Prometheus获取相关监控数据。</a></li></ol><h2 id="处理Web服务器访问日志"><a href="#处理Web服务器访问日志" class="headerlink" title="处理Web服务器访问日志"></a>处理Web服务器访问日志</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">LogFormat <span class="string">&quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer|i\&quot; \&quot;%&#125;User-agent|i\&quot;</span></span></span><br><span class="line">counter apache_http_requests_total by request_method, http_version, request_status</span><br><span class="line">counter apache_http_bytes_total by request_method, http_version, request_status</span><br><span class="line"></span><br><span class="line">/^/ +</span><br><span class="line">/(?P&lt;hostname&gt;[0-9A-Za=z\.-]+) / + # %h</span><br><span class="line">/(?P&lt;remote_logname&gt;[0-9A-Za=z\.-]+) / + # %l</span><br><span class="line">/(?P&lt;remote_username&gt;[0-9A-Za=z\.-]+) / + # %u</span><br><span class="line">/(?P&lt;timestamp&gt;\[\d&#123;2&#125;\/\w&#123;3&#125;\/\d&#123;4&#125;:\d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125; (\+|-)\d&#123;4&#125;\]) / + # %u</span><br><span class="line">/&quot;(?P&lt;request_method&gt;[A-Z]+) (?P&lt;URI&gt;\S+) (?P&lt;http_version&gt;HTTP\/[0-9\.]+)&quot; / + # \&quot;%r\&quot;</span><br><span class="line">/(?P&lt;request_status&gt;\d&#123;3&#125;) / + # %&gt;s</span><br><span class="line">/(?P&lt;response_size&gt;\d+) / + # %b</span><br><span class="line">/&quot;(?P&lt;referer&gt;\S+)&quot; / + # \&quot;%&#123;Referer&#125;i\&quot;</span><br><span class="line">/&quot;(?P&lt;user_agent&gt;[[:print:]]+)&quot;/ + # \&quot;%&#123;User-agent&#125;i\&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">/$</span><span class="language-bash"><span class="string">/ &#123;</span></span></span><br><span class="line"><span class="meta prompt_">  apache_http_requests_total[$</span><span class="language-bash"><span class="string">request_method][<span class="variable">$http_version</span>][<span class="variable">$request_status</span>]++</span></span></span><br><span class="line"><span class="meta prompt_">  apache_http_bytes_total[$</span><span class="language-bash"><span class="string">request_method][<span class="variable">$http_version</span>][<span class="variable">$request_status</span>] += <span class="variable">$response_size</span></span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>by：指定要添加到指标的其他维度，它们将会添加到指标的标签中。<br>每个维度包含在[ ]中。<br>运行mtail程序</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo mtail --progs /etc/mtail --logs <span class="string">&#x27;/var/log/apache/*.access&#x27;</span></span></span><br></pre></td></tr></table></figure><h2 id="解析Rail日志到直方图"><a href="#解析Rail日志到直方图" class="headerlink" title="解析Rail日志到直方图"></a>解析Rail日志到直方图</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">counter rails_requests_started_total</span><br><span class="line">counter rails_requests_started by verb</span><br><span class="line">counter rails_requests_completed_total</span><br><span class="line">counter rails_requests_completed by status</span><br><span class="line">counter rails_requests_completed_milliseconds_sum by status</span><br><span class="line">counter rails_requests_completed_milliseconds_count by status</span><br><span class="line">counter rails_requests_completed_milliseconds_bucket by le,status</span><br><span class="line"></span><br><span class="line">/^Started (?P&lt;verb&gt;[A-Z]+) ./*/ &#123;</span><br><span class="line">  rails_requests_started_total++</span><br><span class="line"><span class="meta prompt_">  rails_requests_started[$</span><span class="language-bash">verb]++</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/^Completed (?P&lt;status&gt;\d&#123;3&#125;) .+ in (?P&lt;request_milliseconds&gt;\d+)ms .*$/ &#123;</span><br><span class="line">rails_requests_completed_total++</span><br><span class="line"><span class="meta prompt_">rails_requests_completed[$</span><span class="language-bash">status]++</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">rails_requests_completed_milliseconds_sum[$</span><span class="language-bash">status] += <span class="variable">$request_milliseconds</span></span></span><br><span class="line"><span class="meta prompt_">rails_requests_completed_milliseconds_count[$</span><span class="language-bash">status] ++</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">request_milliseconds &lt;= 10&#123;</span></span><br><span class="line">    rails_requests_completed_milliseconds_bucket[&quot;10&quot;][$status] ++</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">request_milliseconds &lt;= 50&#123;</span></span><br><span class="line">  rails_requests_completed_milliseconds_bucket[&quot;50&quot;][$status] ++</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>尽量为每个应用单独部署日志监控，对于K8S上的应用，可以使用sidecar的方式运行mtail来实现日志监控。<br>例子代码：<a href="https://github.com/google/mtail/tree/master/examples">https://github.com/google/mtail/tree/master/examples</a></p><h1 id="九、探针监控"><a href="#九、探针监控" class="headerlink" title="九、探针监控"></a>九、探针监控</h1><p>使用<a href="https://github.com/prometheus/blackbox_exporter">Blackbox exporter</a>来对外部服务探测监控。</p><ol><li>安装Blackbox exporter<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.16.0/blackbox_exporter-0.16.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xzf blackbox_exporter-0.16.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> blackbox_exporter-0.16.0.linux-amd64/blackbox_exporter /usr/local/bin/</span></span><br></pre></td></tr></table></figure></li><li>配置Blackbox exporter<br>使用&#x2F;etc&#x2F;prober&#x2F;prober.yml文件配置exporter<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> -p /etc/prober</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">touch</span> /etc/prober/prober.yml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &gt; /etc/prober/prober.yml &lt;&lt;<span class="string">EOF</span></span></span><br><span class="line">modules:</span><br><span class="line">  http_2xx_check:</span><br><span class="line">    prober: http</span><br><span class="line">    timeout: 5s</span><br><span class="line">    http:</span><br><span class="line">      valid_status_codes: []</span><br><span class="line">      method: GET</span><br><span class="line">  icmp_check:</span><br><span class="line">    prober: icmp</span><br><span class="line">    timeout: 5s</span><br><span class="line">    icmp:</span><br><span class="line">      preferred_ip_protocol: &quot;ip4&quot;</span><br><span class="line">  dns_examplecom_check:</span><br><span class="line">    prober: dns</span><br><span class="line">    dns:</span><br><span class="line">      preferred_ip_protocol: &quot;ip4&quot;</span><br><span class="line">      query_name: &quot;www.example.com&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li>启动exporter<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo blackbox_exporter --config.file=<span class="string">&quot;/etc/prober/prober.yml&quot;</span></span></span><br></pre></td></tr></table></figure>默认在端口9115下运行服务：<a href="http://localhost:9115/metrics">http://localhost:9115/metrics</a></li><li>Prometheus创建作业，调用Blackbox Exporter服务<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;blackbox&#x27;</span><br><span class="line">    metrics_path: /probe</span><br><span class="line">    params:</span><br><span class="line">      module: [http_2xx_check]  # Look for a HTTP 200 response.</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets:</span><br><span class="line">        - http://prometheus.io    # Target to probe with http.</span><br><span class="line">        - https://prometheus.io   # Target to probe with https.</span><br><span class="line">        - http://example.com:8080 # Target to probe with http on port 8080.</span><br><span class="line">    relabel_configs:</span><br><span class="line">      - source_labels: [__address__]</span><br><span class="line">        target_label: __param_target</span><br><span class="line">      - source_labels: [__param_target]</span><br><span class="line">        target_label: instance</span><br><span class="line">      - target_label: __address__</span><br><span class="line">        replacement: 127.0.0.1:9115 </span><br></pre></td></tr></table></figure>Blackbox Exporter的配置Job方式与其他作业不同，这的targets是作为Blackbox Exporter检测的目标地址。而Blackbox Exporter的服务地址，通过relabel_configs替换掉__address__标签的方式设置。</li></ol><h1 id="十、Pushgateway方式推送监控数据"><a href="#十、Pushgateway方式推送监控数据" class="headerlink" title="十、Pushgateway方式推送监控数据"></a>十、Pushgateway方式推送监控数据</h1><p>Prometheus主要是基于拉取的架构来运行作业，同时也提供了Pushgateway服务来支持Push方式。<br>Pushgateway位于发送指标的应用程序与Prometheus服务器之间，接收指标，同时作为目标被抓取。<br>Pushgateway只能用作有限的解决方案使用，特别是监控其他无法访问的资源。</p><ol><li>安装Pushgateway<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://github.com/prometheus/pushgateway/releases/download/v1.0.0/pushgateway-1.0.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xzf pushgateway-1.0.0.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> pushgateway-1.0.0.linux-amd64/pushgateway /usr/local/bin</span></span><br></pre></td></tr></table></figure></li><li>配置和运行Pushgateway<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pushgateway --web.listen-address=<span class="string">&quot;0.0.0.0:9091&quot;</span> --persistence.file=<span class="string">&quot;/tmp/pushgateway_persist&quot;</span> --persistence.interval=5m</span></span><br></pre></td></tr></table></figure>–web.listen-address：指定服务端口。pushgateway默认端口是9091.<br> –persistence.file：指标持久化到路径。默认情况下，pushgateway所有指标存储在内存中，如果pushgateway停止服务或者重新启动，所有数据将会丢失。<br>–persistence.interval：指标持久化写入周期。默认5m</li><li>向pushgateway服务发送指标<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;batchjob1_user_counter 2&quot;</span> | curl --data-binary @- http://localhost:9091/metrics/job/batchjob1/instance/sidekiq_server</span></span><br></pre></td></tr></table></figure>将为作业batchjob1添加一个新的指标<br><code>batchjob1_user_counter&#123;instance=&quot;sidekiq_server&quot;&#125; 2</code><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | curl --data-binary @- http://localhost:9091/metrics/job/batchjob1/instance/sidekiq_server</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">TYPE batchjob1_user_counter counter</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">HELP batchjob1_user_counter A metric from BatchJob1.</span></span></span><br><span class="line">batchjob1_user_counter&#123;job_id=&quot;123ABC&quot;&#125; 2</span><br></pre></td></tr></table></figure>也可以同时发送多个指标。</li><li>在pushgateway上查看指标<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://localhost:9091/metrics</span></span><br></pre></td></tr></table></figure></li><li>删除pushgateway上的指标<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -x DELETE localhost:9091/metrics/job/batchjob1 <span class="comment">#删除job batchjob1下的所有指标</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -x DELETE localhost:9091/metrics/job/batchjob1/instance/sidekiq_server <span class="comment"># 删除job batchjob1下标签满足instance=sidekiq_server的指标</span></span></span><br></pre></td></tr></table></figure></li><li>Promethes上添加Pushgateway Job<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;pushgateway&#x27;</span><br><span class="line">    honor_labels: true</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;localhost:9091&#x27;]</span><br></pre></td></tr></table></figure>honor_labels设置为true，Prometheus使用Pushgateway上的job和instance标签，否则会在前面加上exported_前缀。</li></ol><h1 id="十一、监控OpenShift"><a href="#十一、监控OpenShift" class="headerlink" title="十一、监控OpenShift"></a>十一、监控OpenShift</h1><p>OpenShift平台的监控方案默认为Prometheus开源监控方案，它不仅带有一整套完成的监控，而且还预配置了一组告警，以及一组丰富的Grafana仪表盘。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/d07beb395f99d464221c04f52627d4c344ba13170d852b22bef3dda3810c3aaa.png" alt="OpenShift Prometheus架构">  </p><p>可以通过Prometheus Operator方便地创建、配置和管理Prometheus及Alertmanager。<br>从上图可以看到，除了Prometheus与Alertmanager服务，OpenShift的监控方案中还装了node exporter与kube-state-metrics获取集群的状态指标。<br>OpenShift使用ansible安装时，默认会安装的cluster monitoring operator。除非在inventory中指定openshift_cluster_monitoring_operator_install为false。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/dce9c9a3b49f8064c9296b824a6ff9e393010a8ee99523593753ba8d91cbfc8f.png" alt="OpenShift中Prometheus默认监控目标Targets">  </p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4ddcd027c0784c7805ea907691df298ce62cfb4279fb38797add0b9162f43a72.png" alt="OpenShift中Prometheus默认添加的告警规则">  </p><h1 id="扩展资料"><a href="#扩展资料" class="headerlink" title="扩展资料"></a>扩展资料</h1><p><a href="https://awesome-prometheus-alerts.grep.to/">Awesome Prometheus alerts</a><br><a href="https://github.com/prometheus-community/helm-charts">Rich Exporter</a><br><a href="https://github.com/3scale-ops/prometheus-exporter-operator">Exporter Operator</a></p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
          <category> openshift </category>
          
      </categories>
      
      
        <tags>
            
            <tag> openshift </tag>
            
            <tag> 读书笔记 </tag>
            
            <tag> monitor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一条命令解决Kubernetes更改默认的namespace</title>
      <link href="/openshift/%E4%B8%80%E6%9D%A1%E5%91%BD%E4%BB%A4%E8%A7%A3%E5%86%B3Kubernetes%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84namespace/"/>
      <url>/openshift/%E4%B8%80%E6%9D%A1%E5%91%BD%E4%BB%A4%E8%A7%A3%E5%86%B3Kubernetes%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84namespace/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-925d24237df29076.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Kubernetes"></p><p>K8S默认是在default的namespace下，但是很多时候我们是在一个新的namespace下部署应用，每个操作都需要指定namespace，非常不方便。那么有没有办法切换namespce呢？如果可以切换的话，那有没有更简单的办法。</p><h2 id="最简单的方式切换namespace，赠送一个方便的脚本"><a href="#最简单的方式切换namespace，赠送一个方便的脚本" class="headerlink" title="最简单的方式切换namespace，赠送一个方便的脚本"></a>最简单的方式切换namespace，赠送一个方便的脚本</h2><p>可以将它alias到一个新的命令”kubectl ns”</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"> <span class="built_in">alias</span> kubectl=<span class="string">&#x27;_kubectl_custom()&#123; if [[ &quot;$1&quot; == &quot;project&quot; &amp;&amp; &quot;$2&quot; != &quot;&quot; ]]; then ccontext=`kubectl config current-context`; kubectl config set-context $ccontext --namespace=$2; elif [[ &quot;$1&quot; == &quot;projects&quot; &amp;&amp; &quot;$2&quot; == &quot;&quot; ]]; then kubectl get ns; elif [[ &quot;$1&quot; == &quot;project&quot; &amp;&amp; &quot;$2&quot; == &quot;&quot; ]]; then project=$(kubectl config get-contexts | sed -n &quot;2p&quot; | awk &quot;&#123;print \$5&#125;&quot;); if [[ &quot;$project&quot; == &quot;&quot; ]]; then echo default; else echo $project; fi; else kubectl $*; fi;&#125;; _kubectl_custom&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">alias</span> oc=<span class="string">&#x27;kubectl&#x27;</span></span></span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost k8s]# kubectl project test</span><br><span class="line">Context &quot;kubernetes-admin@kubernetes&quot; modified.</span><br><span class="line">[root@localhost k8s]# kubectl get pod</span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">test-46mfd                           1/1     Running   0          16h</span><br></pre></td></tr></table></figure><p>成功切换了namespace，同时对之前的命令没有任何影响。</p><h2 id="相关配置具体操作"><a href="#相关配置具体操作" class="headerlink" title="相关配置具体操作"></a>相关配置具体操作</h2><p>kubernetes的运行时是通过~&#x2F;.kube&#x2F;config文件的配置来设置的</p><ol><li>查看当前cluster config配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl config view</span></span><br></pre></td></tr></table></figure></li><li>如果没有的话，可以添加cluster配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl config set-cluster kubernetes-cluster --server=https://192.168.1.128:6443</span></span><br></pre></td></tr></table></figure></li><li>新建context运行时<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl config set-context &#123;&#123; namespace &#125;&#125; --namespace=&#123;&#123; namespace &#125;&#125; --cluster=kubernetes-cluster --userkubernetes-admin</span></span><br></pre></td></tr></table></figure></li><li>设置当前运行环境<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl config use-context &#123;&#123; namespace &#125;&#125;</span></span><br></pre></td></tr></table></figure>这时所有操作默认都会在下操作。</li></ol><h2 id="直接更改当前context的namespace"><a href="#直接更改当前context的namespace" class="headerlink" title="直接更改当前context的namespace"></a>直接更改当前context的namespace</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl config set-context --current --namespace=&#123;&#123; namespace &#125;&#125;</span></span><br></pre></td></tr></table></figure><h2 id="补充Openshift"><a href="#补充Openshift" class="headerlink" title="补充Openshift"></a>补充Openshift</h2><p>openshift就非常方便了，把这些操作都进行了封装，在创建project时也会自动把context加入到kubeconfig的配置中，如果需要切换运行环境，只要执行<code>oc project &#123;&#123; projectname &#125;&#125;</code>就好了。</p><p>kubernetes也可以使用Ansible进行安装生产集群： <a href="https://github.com/kubernetes-sigs/kubespray">kubespray</a> </p><p>Kubernetes添加节点前Token忘了怎么办？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;</span><br><span class="line">cda2299d203e26b6499e8283937ffbb6489421ff761569fdf8172d03d9a889d6</span><br><span class="line"></span><br><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# kubeadm token list</span><br><span class="line">TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS</span><br><span class="line">qyg3si.njhyhixcqd18by2g   23h       2019-07-27T15:13:15+08:00   authentication,signing   The default bootstrap token generated by &#x27;kubeadm init&#x27;.   system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"></span><br><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# kubeadm join 172.17.3.226:6443 --token qyg3si.njhyhixcqd18by2g --discovery-token-ca-cert-hash sha256:cda2299d203e26b6499e8283937ffbb6489421ff761569fdf8172d03d9a889d6</span><br></pre></td></tr></table></figure><p>或者创建新的token</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@iZ2ze436suxv73x9jtiy2vZ helm-demo-master]# kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>下载国外资源加速器</title>
      <link href="/openshift/%E4%B8%8B%E8%BD%BD%E5%9B%BD%E5%A4%96%E8%B5%84%E6%BA%90%E5%8A%A0%E9%80%9F%E5%99%A8/"/>
      <url>/openshift/%E4%B8%8B%E8%BD%BD%E5%9B%BD%E5%A4%96%E8%B5%84%E6%BA%90%E5%8A%A0%E9%80%9F%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>axel</p><p><a href="https://github.com/axel-download-accelerator/axel">https://github.com/axel-download-accelerator/axel</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>云原生简介</title>
      <link href="/openshift/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%AE%80%E4%BB%8B/"/>
      <url>/openshift/%E4%BA%91%E5%8E%9F%E7%94%9F%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是云原生"><a href="#什么是云原生" class="headerlink" title="什么是云原生"></a>什么是云原生</h1><p>云原生（Cloud Native）的概念由Pivotal的Matt Stine于2013年首次提出。它是Matt Stine根据多年的架构和咨询经验总结出来的一个思想集合，并得到社区的不断完善和补充，包括DevOps、持续交付、微服务、敏捷基础设施和12要素等几大主题。包括根据业务能力对公司进行文化、组织架构的重组与建设、方法论与原则、还有具体的操作工具。将云计算从传统的以资源为中心，改变为以应用为中心，聚焦于业务，从而满足应用快速迭代的要求。</p><p><strong>CNCF（Cloud Native Computing Foundation）云原生计算基金会</strong><br>2015年把云原生定义为三个方面</p><ul><li>应用容器化</li><li>面向微服务架构</li><li>应用支持容器的编排调度</li></ul><p>随着CNCF中的项目越来越多，原先的定义已经限制了云原生生态的发展，于是更新了定义</p><ul><li>云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API。</li><li>这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。</li><li>云原生计算基金会（CNCF）致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。我们通过将最前沿的模式民主化，让这些创新为大众所用。</li></ul><p>#云原生的起因</p><h1 id="云原生的意义"><a href="#云原生的意义" class="headerlink" title="云原生的意义"></a>云原生的意义</h1><p>让产品能够支持快速验证业务模式<br>简化复杂的开发流程、提升研发效率<br>保障产品的高可用性<br>实现大规模弹性伸缩，轻松应对业务爆发</p><p>架构技术的升级</p><ul><li>可用性</li><li>可扩展性，弹性</li><li>可管理性<br>开发模式的升级</li><li>DevOps模式<br>架构设计的升级</li><li>更快的迭代速度</li><li>持续可用的服务</li><li>弹性伸缩</li><li>非功能要求</li></ul><h1 id="如何实施云原生"><a href="#如何实施云原生" class="headerlink" title="如何实施云原生"></a>如何实施云原生</h1><ol><li>基础设施建设（云容器平台）</li><li>约束技术栈，微服务化建设</li><li>标准化技术栈构建及构建流程标准化</li><li>应用架构必须遵循规范要求</li></ol><h1 id="云原生的未来"><a href="#云原生的未来" class="headerlink" title="云原生的未来"></a>云原生的未来</h1>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业生产系统迁移至容器云平台的众多难题</title>
      <link href="/openshift/%E4%BC%81%E4%B8%9A%E7%94%9F%E4%BA%A7%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB%E8%87%B3%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E7%9A%84%E4%BC%97%E5%A4%9A%E9%9A%BE%E9%A2%98/"/>
      <url>/openshift/%E4%BC%81%E4%B8%9A%E7%94%9F%E4%BA%A7%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB%E8%87%B3%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E7%9A%84%E4%BC%97%E5%A4%9A%E9%9A%BE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-c3bfd7dddf354123.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="云原生"></p><p>该篇是twt论坛交流活动《企业生产系统迁移至容器云平台的网络及安全方案探讨—暨红帽容器化混合云解决方案在线发布活动》的总结。<br>原文：<a href="http://www.talkwithtrend.com/Article/245665">http://www.talkwithtrend.com/Article/245665</a><br>活动地址：<a href="http://www.talkwithtrend.com/activity/?id=1459">http://www.talkwithtrend.com/activity/?id=1459</a></p><p>自从2013年Docker应用开源以来，容器技术飞速发展，它彻底改变了PaaS原先的发展轨迹。2014年Google发布的容器编排应用Kubernetes，经过5年的发展，更是已经成为了现代容器平台的事实标准，容器平台应用于生产环境也已经现实可落地。</p><p>与之前的虚拟技术相比，容器技术具有更快、更轻、更强的优势。</p><p>更快，体现在容器可以实现秒级启动。</p><p>更轻，体现在容器更加轻量，往往一个容器镜像只有几十兆，可以快速在主机之间迁移，而虚拟机镜像往往是几个G。</p><p>更强，体现在容器的性能更好。容器是直接调用硬件资源，不存在虚拟化层，所以它的性能接近于原生应用。</p><p>容器以应用为中心，能够快速地在各个平台下部署运行，可以很好地满足应用的快速部署。</p><p>但是容器运行时使用的是宿主机的内核，在同一台宿主机上的容器也会共享系统的资源，如果没有做好资源的规划及权限的控制，不仅容器之间会互相影响，甚至会让整个系统的受到威胁。那么怎样能够避免这些问题呢？这是在容器平台上生产前必须考虑的问题。</p><p>另外，容器的网络也是在容器平台规划时需要考虑的一个重点，我们很多网络安全策略都是基于IP做的规则，但是一般而言同一个镜像运行的不同容器的IP是不一样的，一旦容器被重新调度，之前的安全策略便失效了，而新的容器并没有受到安全策略管理。另外生产中的主机一般会配置多个网络，有业务网，管理网等，那么容器化后是否有办法支持多网络平面呢？</p><p>当然容器平台上生产需要考虑的问题不止这一些，比如说容器的调度，存储的规划等等。</p><p>但随着容器技术的不断演进，以及企业应用的不断加深，容器平台上生产中遇到的问题也得到了很大程度的突破。此外，容器生态圈中的重要力量——容器平台厂家为更能满足企业客户生产的要求，实现容器平台上生产，也在不断优化各自的产品，推出新的解决方案。</p><p>其中，2019年5月红帽推出了RHEL8和第四代OpenShift容器平台，该版本融合了OpenShift与CoreOS两家容器平台大玩家的技术。相对于第三代OpenShift，新一代OpenShift拥有很多新的特性，比如说Operator管理组件的生命周期，添加了多集群管理等。同时网络及安全方面也是OpenShift4.1版本升级的一个重要部分。</p><p>为解决容器平台上生产中的诸多问题，本次<a href="http://www.talkwithtrend.com/Activity/?id=1459" title="活动">活动</a>不仅邀请到招银云创专家和某股份制银行专家一起，基于企业生产系统迁移至容器云平台的网络及安全方案进行探讨；并同时邀请红帽专家，围绕OpenShift4的特性，如何帮助企业基于OpenShift实现企业容器化混合云的价值进行答疑。</p><p>答疑结束后，对活动中提出的问题进行了分类总结，供大家参考。</p><h2 id="容器平台价值"><a href="#容器平台价值" class="headerlink" title="容器平台价值"></a>容器平台价值</h2><p><strong>容器云和传统的虚拟机比有什么优势呢？</strong></p><p>解答1：</p><p>优势：</p><p>a. 更快，可以实现秒级启动。</p><p>b. 更轻，更加轻量，往往一个容器镜像只有几十兆，可以快速在主机之间迁移，而虚拟机镜像往往是几个G。</p><p>c. 更强，性能更好。</p><p>并且有了Kubernetes容器编排引擎后，应用的水平扩展、服务发现、滚动升级、应用高可用等等特性变得非常容易实现。</p><p>基于此容器可以大大降低于低企业成本，资源成本及运维管理成本。当然容器也有较虚拟机不足的地方。</p><p>劣势：</p><p>a. 容器共用内核，隔离性低于虚拟机，也不够虚拟机安全。</p><p>b. 跨平台性低于虚拟机，容器只能运行在linux系统，而虚机可运行在windows&#x2F;Linux&#x2F;Unix系统。</p><p>解答2：</p><p>拿容器和虚拟机比较更准确，不是容器云</p><p>容器优势明显，缺点也很明显</p><p>容器轻量，可快速弹性伸缩，适合部署轻量的分布式应用或服务，但带来管理的复杂性，需要借助容器管理调度工具或者实现的容器云平台</p><p>标准化，容器引擎使基础设施标准化，容器镜像使应用交付标准化，容器使运维调度管理标准化，容器镜像仓库使分发部署标准化</p><p>一致性，容器的标准化使开发、测试、生产环境具备一致性，可以快速构建一致性的环境</p><p>维护简单，一个容器通常部署一个服务或实例，而虚拟机通常很多服务和应用，所以其准备、启动、维护都相对简单很多</p><p>另外需要强调一点的是，容器并不节省资源，在容器规模达到一定程度，能实现资源分时共享时才能节省资源</p><p>解答3：</p><p>轻量级，资源利用率高扩展容易，最重要的是和微服务结合的好，当然用了PAAS以后你的蓝绿发布，应用构建，灰度发布都更简单</p><p><strong>传统应用是否应该迁移到容器环境，有没有意义，有什么值得参考的迁移方法论？</strong></p><p>解答1：</p><p>不同应用有不同的要求，比如稳定性、可靠性、可扩展性等，在迁移之前需要明确容器是否满足应用的要求。应用迁云或迁容器云需要遵循相应的原则和方法，难以一概论之，具体的应用需要根据实际确定具体的方案</p><p>解答2：</p><p>如果是传统应用做容器话的迁移，那没啥方法轮，如果是为服务改造有很多方法论，比如 绞杀模式 （Strangler） 以及 修缮者模式</p><h2 id="容器平台架构方案"><a href="#容器平台架构方案" class="headerlink" title="容器平台架构方案"></a>容器平台架构方案</h2><p><strong>传统架构模式和云与docker模式结合后如何解决网络和SDN的问题？</strong></p><p>解答1：</p><p>我们采用的方案是，容器建设在虚拟机或者物理机上，集群中的容器使用SDN网络方案，互相间通讯，同时也可以与宿主机同一网络的主机通信。但是集群外部机器要访问集群内部的服务，只能通过route&#x2F;ingress&#x2F;NodePort。</p><p>pod与pod之间网络通过networkpolicy做网络隔离，主机与主机之间的使用传统的防火墙来做隔离。</p><p>另外macvlan网络方案，可以让pod与宿主机在同一个网络，这种方式下容器间的网络隔离与传统方式一样，每个容器可以当作一个单独的主机。但这种方案生产应用并不常见。</p><p>解答2：</p><p>目前来看没有什么问题啊，传统网络和SDN的问题本身就可以通过网络厂家的设备来解决，如果你说的是PAAS自身的SDN如何同集群外的服务互联互通，那就是通过router来实现（或者是ingress和egress）。安全域的问题更多的是通过多集群和设计的问题来规避。</p><p><strong>在私有云，在容器环境下安全区域怎么划分，是否设置DMZ区域？</strong></p><p>解答1：</p><p>可以考虑部署多个容器集群来设置不同区域。测试环境、生产环境完全隔离的情况下，可考虑建设DMZ区以实现可能需要的镜像流转等场景。</p><p>解答2：</p><p>安全组网在容器环境下并不需要改变，按照安全规范实施即可，确保安全优先</p><p>解答3：</p><p>为了安全，可以部署多个容器集群来设置不同区域。一个集群作为DMZ区，另一个集群作为核心区，还可以有一个互联区的集群。</p><p>解答4：</p><p>在多个网络区域布署不同的容器集群，DMZ，业务区可以分别多套集群，做为多可用区，提高可用性</p><p><strong>容器云是否有和SDN集成的方案？</strong></p><p>解答1：</p><p>有很多，但是界面或者说管理能力展示的集成需要自己做，也就是openshift 并不会有第三方SDN的管理功能，通常来说只要这个SDN厂家有CNI的呃插件，那么OCP4 就可以和他集成，当然如果需要提供售后支持的话，还需要该SDN厂家和红帽做认证。</p><p>解答2：</p><p>有啊 比如和neutron集成 你可以根据需要自己开发cni的插件，开源实现里面也有kury（python实现）</p><p><strong>虚拟机与容器并行承载同一套应用系统是否可行？</strong></p><p>解答1：</p><p>负载均衡实现虚拟机应用与容器应用共同支撑业务系统, 这个业务场景没有先例</p><p>既然上容器就需要服务治理等一系列微服务框架运维,</p><p>vm技术和容器技术对应用来说如果不进行微服务化改造, 是没有任何区分的,</p><p>所以你这个场景 是可以实现但 vm 会比 容器快很多, 容器需要多层网络转换</p><p>解答2：</p><p>我们公司的业务生产环境便是虚拟机与容器并行，容器中运行的是无状态的app及前端静态界面，而中间件及数据库等仍然运行在虚拟机中。</p><p>解答3：</p><p>完全没有问题，简单的你可以看做两个虚拟数据中心，分别部署一套应用系统，前端负载均衡器实现负载分发。所以部署在容器或者虚拟机对前端是不可见的，只要可访问就行</p><p><strong>如何按照网络隔离区域对容器集群规划？</strong></p><p>解答：</p><p>这个主要看公司对网络安全的要求和成本的平衡。</p><p>a 方案每个区都部署一套集群的话，安全性高，但成本高，包括资源成本及维护成本等。</p><p>b 方案成本低，也能满足一定的隔离要求</p><p>开发测试环境一般更偏向于使用b方案，k8s&#x2F;openshift网络支持多租户，能实现软隔离，及通过给节点作标记Label，定向调度的方式就能够满足隔离的要求。</p><p>但是生产环境是需要单独构建集群与开发测试环境隔离的。</p><p><strong>如何保障容器镜像的安全防护？</strong></p><p>解答1：</p><p>我们使用的是集成在harbor中的clair容器镜像静态扫描工具。它会定期同步公共源镜像漏洞数据，并对harbor镜像仓库中的镜像做扫描。如果发现有问题会发出通知，且也支持webhook的方式对接公司统一的告警平台。</p><p>解答2：</p><p>红帽又一款产品叫QUAY可以做到你提到的所有功能，更详细的信息还请看红帽工程师的博客： <a href="http://www.10tiao.com/html/360/201806/2663487906/1.html">http://www.10tiao.com/html/360/201806/2663487906/1.html</a></p><h2 id="容器平台应用"><a href="#容器平台应用" class="headerlink" title="容器平台应用"></a>容器平台应用</h2><p><strong>容器平台、微服务平台、devops平台在规划建设的时候如何能有序整合起来？</strong></p><p>解答1：</p><p>容器平台是DevOps中的一部分， 不需要微服务平台，微服务部署于容器平台，在容器平台实现微服务管理和治理能力</p><p>解答2：</p><ol><li>容器平台与服务治理在以下维度相同，需要从统一化进行管理：1、应用管理；2、服务管理；3、实例管理；4、聚合管理；采用统一权限中心管理，数据权限与操作权限灵活设置，以用户+权限定义产品形态和管理范畴。平台管理（重点在于资源管理），租户管理（重点在于应用管理和服务治理能力）。</li><li>在建设DevOps的过程中，需要结合企业自身开发运维的流程，与容器云与微服务治理平台的结合的过程中，更多的考虑整体DevOps过程中需要实现的场景，而不是仅仅考虑CICD。</li></ol><p>解答3：</p><p>容器平台更多的是规范运维操作以及故障处理，微服务跟多的是做开发规范，DevOps工作的是工作流工具链的梳理，三个各有侧重点。</p><p>解答4：</p><p>从不同的角度看才有了容器平台、微服务平台、devops平台。它们之间并不是独立的平台。</p><p>首先，容器平台是基础设施，微服务平台和devops平台部署在上面。</p><p>其次，devops平台建设过程中，需要考虑微服务架构，采用不同的方案在构建devops流水线时也会有所不同。</p><p>最后，如果要做持续部署的话，需要考虑公司的安全规范与流程规范。</p><p>以下是我们的实践：</p><ol><li>分别部署了开发测试容器集群与生产容器集群。</li><li>devops工具链与流水线构建只在开发测试环境上，构建与测试完成后，通过人工审核后才允许将镜像同步到生产集群，再单独走部署流水线。</li><li>统一微服务架构，及规范。我们互联网应用都采用spring cloud微服务架构，技术统一后devops流水线也方便统一及优化、维护。</li></ol><p><strong>容器平台上生产的可靠性及容器平台与devops能否对接？</strong></p><p>解答1：</p><p>技术上是完全可行的，还需要考虑一些非技术的因素。</p><p>由于生产环境的特殊性，公司会有很多复杂的安全规范及流程规范，它们限制devops直接对接生产环境。这个其实与是否在容器平台无关。</p><p>安全规范、流程规范，很多公司是一条红线，特别是金融行业，因为多年来正是遵循它们才保证了业务的安全可靠，还有各种认证、审计的需要。</p><p>当然技术和规范也都是与时俱进，不断发展的。现在有些公司把流程规范开始融入到持续部署的流程中了，包括临时授权等，也都可以作为流水线中的一个环节。</p><p>解答2：</p><p>容器平台是devops的一部分，devops不是一个平台</p><p>需求提议、项目管理、开发测试、部署交付、运维运营、监控反馈、持续改进，容器平台的定位和价值在这些闭环过程中。</p><p><strong>如何更好地实现现有系统的容器化迁移？</strong></p><p>解答：</p><p>这个真没有，你不能指望平台解决应用的问题</p><p><strong>部署流计算框架和机器学习平台在红帽容器平台上有什么要注意的？</strong></p><p>解答：</p><p>主要是用到GPU的话，务必做好PAAS集群和GPU的配置，其他没有太多需要注意的，很多框架已经在k8s上部署运行了很长时间了。OCP没有额外的要求</p><h2 id="Openshift4特性"><a href="#Openshift4特性" class="headerlink" title="Openshift4特性"></a>Openshift4特性</h2><p><strong>Openshift 4推荐的直接部署物理机还是虚拟机？为物理机部署提供了什么便利？</strong></p><p>解答：</p><p>Openshift4 部署在物理机和虚拟机都行，但是红帽推荐部署在虚拟化平台上，因为OCP4以后增加了很多基础架构的管理功能，其中就包括针对openshift 节点的自动扩容和缩容。很有用</p><p><strong>OpenShift 4对单集群多租户的支持怎么样？</strong></p><p>解答：</p><p>OpenShift中不仅有用户,还有用户组。OpenShift的账号管理最简单是使用HtPasswd方式，同时OpenShift可以与多种系统账号对接，如OpenLdap，KeyStore，GitLab，GitHub，OpenID等。</p><p><strong>OpenShift 4对Serverless的支持情况？</strong></p><p>解答：</p><p>红帽ocp4 支持knative 啊，不过目前应该是beta版。具体请看 <a href="https://github.com/openshift-knative/docs/">https://github.com/openshift-knative/docs/</a></p><p><strong>正在生产运行的OpenShift3是否可以原地升级到OpenShift4？如果不行，该如何升级？</strong></p><p>解答：</p><p>不行，未来从OCP3系列到OCP4系列都是迁移，当然红帽会有官方的迁移工具来帮助客户做这个事情，但是也需要准备停机窗口，并且两套集群一个是老得ocp3 集群一个是ocp4集群。</p><p><strong>金融行业对安全非常重视，OpenShift4和RHEL8在安全方面改进的体现有哪些？</strong></p><p>解答：</p><p>openshift一直关注安全 我们的10层安全体系从基础设施层到标准化基础中间件镜像都在层层为客户企业安全进行保障。ocp4的比以前多了coreos作为操作系统选项：CoreOS裁减了传统linux中无用的软件，减少了依赖冲突和attack surface，系统更小、更紧凑、更安全。另外 用来取代传统docker容器的另一种选择其中podman是最重要的组件之一。其主要优势是无需docker守护进程，以普通用户形式启动，是一种更安全的容器管理器。</p><h2 id="OpenShift与其它容器平台比较"><a href="#OpenShift与其它容器平台比较" class="headerlink" title="OpenShift与其它容器平台比较"></a>OpenShift与其它容器平台比较</h2><p><strong>Openshift与Rancher如何选择，是否有可比较性？</strong></p><p>解答：</p><p>OpenShift有开源版本，是免费的。</p><p>它们俩各有各的特点。</p><p>OpenShift:</p><ol><li>设计了ImageStream，BuildConfig与DeploymentConfig等资源对象，及s2i构建方法，方便了开发者实施Devops。</li><li>添加了一个内部镜像仓库。</li><li>使用Route资源，为应用提供了一个公共统一的访问入口。类似于Ingress，使用起来比Ingress方便。</li><li>提供了一个友好的可视化界面。</li><li>对容器有更多的安全策略，更安全</li><li>有更高的可靠性。 作为RedHat的企业级容器平台，红帽会对集群做详细的测试，修复bug。</li><li>一般版本会落后K8S一个大版本</li><li>一般为只管理单个OpenShift集群</li></ol><p>Rancher:</p><ol><li>具有良好的界面</li><li>方便管理多个K8S集群</li><li>对网络插件的选择会比OpenShift更加灵活</li><li>与K8S版本同步，及时拥有K8S最新的特性</li></ol><p>个人认为，单集群管理使用OpenShift，更稳定，更简单，也更安全，而如果是要管理多集群，选择Rancher。不过OpenShift 4起红帽也支持多集群管理，但还不能私有化部署。</p><p>两种方案都有不少的企业客户选择，因为都是基于K8S， 功能上都差不多 。不管是构建DevOps流水线，还是生产部署原生应用上。</p><p><strong>openshift 与其他容器云厂商产品的异同点有哪些？</strong></p><p>解答：</p><p>上一个问题中介绍了Openshift与Rancher的差异，可以作为参考。</p><p>还有需要补充一点的是，红帽是继google和社区之后k8s最大的贡献者，不少K8S中的特性是来自于OpenShift，比如说RBAC。同时目前很热的operator是coreos的产品，而coreos现在也是红帽的了。</p><p><strong>红帽容器化混合云跟其他友商的方案在稳定性、安全性上有哪些不同，是否有更好的表现？</strong></p><p>解答：</p><p>容器就是linux，红帽的RHEL是最安全的，因此红帽的PAAS平台必然也是最安全的，当然红帽的研发策略一直是做减法，把最重要和最稳定的特性和代码放到自己的企业版，因此在你说的稳定性和安全性上，红帽一定是全球第一，但是特性上不一定，国内创业公司都在做加法，所以特性上都会比红帽PAAS多那么一点</p><h2 id="Redhat"><a href="#Redhat" class="headerlink" title="Redhat"></a>Redhat</h2><p><strong>RHEL8否对6上的命令还能继续兼容，比如服务命令，6迁移到8有什么注意点？</strong></p><p>解答1：</p><p>rhel8.x 在上线前 一般会等到8.3 第三个维护版本进行上线系统更新</p><p>目前在8.0和8.1还有8.2不建议使用</p><p>而且从6版本直接升级到8版本,跨度过大业务系统是否支持,都要考虑</p><p>只是命令变化不会有太多技术问题,修改下运维脚本没问难度</p><p>解答2：</p><p>命令会有所改变，关键是8 比6 新太多了，迁移前务必做应用测试，然后再迁移</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从0开始构建CI-CD持续集成流水线[Openshift]</title>
      <link href="/openshift/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E6%9E%84%E5%BB%BACI-CD%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%B5%81%E6%B0%B4%E7%BA%BF%5BOpenshift%5D/"/>
      <url>/openshift/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E6%9E%84%E5%BB%BACI-CD%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%B5%81%E6%B0%B4%E7%BA%BF%5BOpenshift%5D/</url>
      
        <content type="html"><![CDATA[<h2 id="开始前的话"><a href="#开始前的话" class="headerlink" title="开始前的话"></a>开始前的话</h2><ul><li>完成一只大象装进冰箱需要几步？<br>三步： 1. 有一个冰箱；2. 有一只大象；3. 把大象装进冰箱</li><li>构建CI&#x2F;CD流水线[Openshift]需要几步？<br>三步： 1. 有Openshift平台；2. 部署CI&#x2F;CD流水线应用；3. 启动流水线</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业级容器云平台建设之功能汇总</title>
      <link href="/openshift/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%B1%87%E6%80%BB/"/>
      <url>/openshift/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E4%B9%8B%E5%8A%9F%E8%83%BD%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-c070a16c92fc5e2d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="企业级容器云建设"></p><ol><li>多集群管理与运维</li><li>多区建设（DMZ&#x2F;业务区&#x2F;核心区）</li><li>应用商店（模板管理、Operator管理等）</li><li>集群监控、告警、日志管理</li><li>权限管理，多租户管理&#x2F;账号管理</li><li>管理员资源分配</li><li>资源列表及管理</li><li>应用管理，部署&#x2F;更新&#x2F;下线</li><li>应用多集群部署，灰度发布、蓝绿部署</li><li>应用网络方案&#x2F;存储&#x2F;运行权限&#x2F;南北流量方案选择</li><li>NodePort端口管理</li><li>网络隔离策略控制</li><li>集群边界路由管理</li><li>DNS域名申请管理</li><li>自动化运维，集群巡检，集群扩缩容，集群备份</li><li>审批流程管理</li><li>审计管理</li><li>DevOps流水线</li><li>容器安全与镜像安全</li><li>业务网与管理网，多网络平面</li><li>外部负载均衡管理器</li><li>镜像仓库，高可用，多区域镜像仓库同步</li><li>镜像仓库漏洞扫描、镜像签名</li><li>应用日志管理</li><li>APM应用性能监控</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业级容器云平台建设之资源管理</title>
      <link href="/openshift/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E4%B9%8B%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/"/>
      <url>/openshift/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E4%B9%8B%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-12c984c7548bdfdb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="企业级容器云平台建设 资源管理"></p><h2 id="计算资源管理"><a href="#计算资源管理" class="headerlink" title="计算资源管理"></a>计算资源管理</h2><ol><li>多租户权限管理</li><li>多集群管理，及集群大小</li><li>资源配额与资源限制管理</li><li>NodePort端口号管理</li></ol><h2 id="网络资源管理"><a href="#网络资源管理" class="headerlink" title="网络资源管理"></a>网络资源管理</h2><ol><li>网络业务网、管理网、存储网分离</li><li>网卡做bond，提高网络可靠性</li><li>网络方案选型</li><li>网络策略NetworkPolicy机制</li><li>集群边界路由器管理（Ingress&#x2F;Route)</li><li>集群DNS域名服务管理</li></ol><h2 id="存储资源管理"><a href="#存储资源管理" class="headerlink" title="存储资源管理"></a>存储资源管理</h2><ol><li>存储PV选型，动态&#x2F;静态</li><li>存储类型，hostpath&#x2F;local&#x2F;NFS&#x2F;Ceph&#x2F;Solidfile等</li></ol><h2 id="镜像资源管理"><a href="#镜像资源管理" class="headerlink" title="镜像资源管理"></a>镜像资源管理</h2><ol><li>镜像生命周期管理 ，创建&#x2F;查询&#x2F;更新&#x2F;删除</li><li>镜像库多租户权限管理</li><li>远程复制管理，至少两级镜像库设置，总镜像库&#x2F;子镜像库</li><li>镜像库操作审计管理</li><li>镜像漏洞安全扫描</li><li>镜像签名</li></ol><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>在企业级容器平台建设中，资源管理只是其中的基础部分，<strong>另外还需要考虑：监控、告警、日志管理以及运维、安全、审计等方面。</strong></p><p>来自：《Kubernetes权威指南：企业级容器云实战》</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业级容器平台OpenShift介绍</title>
      <link href="/openshift/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%B9%E5%99%A8%E5%B9%B3%E5%8F%B0OpenShift%E4%BB%8B%E7%BB%8D/"/>
      <url>/openshift/%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%B9%E5%99%A8%E5%B9%B3%E5%8F%B0OpenShift%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>随着移动互联网生态的兴起，传统银行面临跨界竞争，在电子商务支付、消费金融、商业融资的新的业务场景下面临严峻的挑战，数字化转型的需求日益迫切。在这场技术转型的浪潮下，各大银行积极推进科技改革，拥抱云计算，以适应市场不断的变化。随着容器技术的成熟，一个以Kubernetes容器编排引擎为核心的生态圈已经形成，互联网、金融、汽车等各企业都积极投入容器技术的应用中。容器云平台的建设已经被认为是云计算落地的一种快捷的方式。<br>说到容器云平台，就不得不提当前容器调度与编排的事实标准——Kubernetes。Kubernetes通过定义基础资源（容器、存储、网络）的协议接口，为底层基础设施提供了统一的管理方式。研发人员通过声明的方式定义资源编排文件，Kubernetes便通过自身组件自动完成资源的申请与分配，快速实现应用的部署。Kubernetes为容器的管理调度，应用的编排提供了便利，它无所不能，但是在建设企业级容器平台时，我们需要在以Kubernetes为核心的前提下，整合其他组件，例如网络插件、应用访问入口、存储实现、监控、日志、镜像仓库等。如图一所示。OpenShift正是基于Kubernetes实现的一个企业开源容器平台。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-00be4712ed977a8e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="图一 企业级容器平台架构"></p><h2 id="OpenShift发展历史"><a href="#OpenShift发展历史" class="headerlink" title="OpenShift发展历史"></a><strong>OpenShift发展历史</strong></h2><p>OpenShift是由RedHat推出的企业级Kubernetes平台，它是从OKD项目派生的下游容器编排技术。2019 年 9 月 IHS Markit Technology 统计了商业容器软件市场收入的排名，并发布了相关的调查报告。报告中显示红帽份额为 44%，排在第1位，超过了排名第2 - 第5公司的总和。从该报告的结果可以看出，在全球容器市场中，RedHat占有着领先的优势，而RedHat企业级容器产品便是OpenShift。</p><p>目前OpenShift最新版本为4.5，生产上使用最多的是3.11版本，也是3系列的最后一个版本。大家都知道OpenShift是基于Kubernetes实现的，但很多人并不清楚OpenShift其实早于Kubernetes诞生。整个OpenShift的发展过程中经历了两次重大的变革，如图二所示。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-13a8a94ee82bc7fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="图二 OpenShift发展史"></p><p>OpenShift发布于2011年，当时Docker还未出现，容器技术并没有像现在这么普及，也没有形成标准，而是一些大厂专用的技术，各家在容器运行时与容器编排引擎都各成一套，RedHat也不例外。OpenShift在v1与v2版本中一直使用的是RedHat自己开发的容器运行时与容器编排引擎。随着2013年Docker的问世，RedHat立刻意识到了该技术将带来的革命，随即与Docker展开合作，确定了以Docker作为下一代OpenShift容器运行时。在2014年Kubernetes的发布，RedHat经过调研，便很快与Google展开合作，确认了以Kubernetes作为下一代OpenShift的编排引擎。后来的事实证明RedHat做的这两个选择都非常明智。</p><p>2015年OpenShift迎来了第一个重大的变革，OpenShift v3发布。RedHat弃用了原先自己的“Gear”和“Cartridge”技术，以Docker、Kubernetes为核心进行全新重构，并且站在开发者的角度，对产品体验进行了全面的升级与优化。OpenShift 3很快得到了开发者的认可，取得了巨大的成功，直到今天使用最多的版本仍然是v3版本。</p><p>OpenShift本可以沿着v3的路线不断升级完善，就能够保持自己在容器PaaS领域的优势，然而它的变革并未停止。2018年红帽收购了容器领域的另一巨头CoreOS，容器领域的两只领头羊合二为一，他们将各自积累多年的容器技术进行全面融合，通过Operator实现应用全生命周期的自动化管理，对OpenShift 3版本进行全面的改造，推出了功能更加丰富，更加自动化的4版本，这里不得不佩服红帽的魄力。</p><h2 id="OpenShift对Kubernetes的增强"><a href="#OpenShift对Kubernetes的增强" class="headerlink" title="OpenShift对Kubernetes的增强"></a><strong>OpenShift对Kubernetes的增强</strong></h2><p>OpenShift与Kubernetes的关系类似于Linux与Linux发行版（Rhel、Ubuntu等）的关系。OpenShift以Kubernetes为核心，实现相关的资源协议接口，对其功能进行增强，同时整合其它组件，使其成为企业级容器平台。<br>OpenShift提供稳定的容器、网络、存储等资源协议接口的实现。</p><ul><li>以Docker作为默认的容器运行时，对接Kubernetes的容器运行时接口（CRI），当然OpenShift也支持其它的容器运行时，比如CRI-O。</li><li>OpenShift默认采用OVS作为容器平台的网络插件，对接Kubernetes的容器网络接口（CNI），实现容器跨主机的网络通信及管理，同时OpenShift也支持其它的网络插件，比如Calico。</li><li>存储类型方面，除了Kubernetes默认支持的RBD、NFS、EBS、GlusterFS等，OpenShift支持更多的存储类型，如Local、iSCSI等。<br>OpenShift对原生Kubernetes的安全性及功能进行了增强。</li><li>OpenShift最早实现了集群的多租户管理，比如RBAC、Qouta、Namespace等，这些能力在Kubernetes的后期版本中才集成。</li><li>为了提高安全性，OpenShift开发了安全上下文约束（SCC），控制容器运行时默认使用最小权限。</li><li>为了方便研发人员的持续构建与部署，OpenShift开发了DeploymentConfig及BuildConfig资源，它们在Kubernetes的应用编排资源的基础上添加了更多的控制能力，比如自动触发、部署策略等。</li><li>OpenShift实现了Route资源对象，为集群提供了统一的网络入口，方便集群中的应用对外提供服务。受到Route的启发，Kubernetes目前也开发类似功能的实现Ingress。</li><li>OpenShift开发了集群内部镜像仓库，并且提供了与应用资源协调调用的能力。<br>OpenShift整合了更多的组件，增强了集群的稳定性。</li><li>基于Prometheus、Grafana、AlertManager为集群提供了整体监控与告警的方案，包括集群核心组件的可用性，容器资源使用率等，同时也提供了自定义监控项的扩展能力。</li><li>基于EFK组件，为集群组件及应用提供了整体的日志统一管理方案。<br>另外还需要提的是，OpenShift为开发者和集群管理者提供了一个非常容易使用的控制台，通过控制台可以方便完成绝大部分的使用与管理。<br>从上面可以看出，OpenShift的能力对Kubernetes较全面的增强，同时两者又是相辅相成，OpenShift基于Kubernetes实现，也同样反馈与驱动Kubernetes前进。</li></ul><h2 id="OpenShift的不足"><a href="#OpenShift的不足" class="headerlink" title="OpenShift的不足"></a><strong>OpenShift的不足</strong></h2><p>OpenShift提供了一个开箱即用的单容器高可用容器PaaS平台，它可以满足绝大部分企业容器应用部署的需求，为企业能够快速构建自己的云计算服务。但是大型企业容器平台建设需要考虑的情况往往会更复杂。</p><ul><li>应用的部署体验够用了吗？OpenShift提供了单平台web控制台，它的可定制化能力较弱，很难对其进行扩展。</li><li>多中心、多集群管理有没有？OpenShift更多的是对单集群的管理，缺乏多集群管理的能力。</li><li>生产级别的PaaS服务有没有？OpenShift提供了应用商店，更多的并没有达到生产级别的要求，只能在开发测试环境试用。</li><li>与企业流程的深度融合有没有？如果需要与企业自身系统进行深度融合，需要对OpenShift控制台进行深度化定制，往往我们还是需要独立开发门户网站。</li><li>监控集群及应用是否可以自定制？OpenShift集群提供了整体监控与告警的产品化方案，其监控展示配置是固化的，无法自定义自己的监控展示页面。</li><li>日志方案是否足够了？在日志方案上，OpenShift能够满足一般吞吐量的日志收集与管理，随着集群规模的壮大，应用日志并发数增多，OpenShift日志系统会受到性能瓶颈。</li><li>集群的网络是否有局限性？OpenShift默认采用ovs作为容器平台的网络插件，它是一种overlay网络，容器间访问需要通过封包解包，这在一定程度上降低了网络性能，同时对于集群内外服务的网络控制也增加了一定的难度。<br>另外各企业有自己的审批流程、开发流程、运维规范、更高的高可用要求、更高的性能要求、更细化的安全要求、自主可控等。而OpenShift产品化程度过高，降低了其自身的灵活性，企业对其定制能力被削弱。所以各大企业即使引入了OpenShift平台，仍然需要在它的基础上建设自己的容器平台门户，并且相关的技术方案也需要独立设计。</li></ul><h2 id="OpenShift-4——全新一代OpenShift"><a href="#OpenShift-4——全新一代OpenShift" class="headerlink" title="OpenShift 4——全新一代OpenShift"></a><strong>OpenShift 4——全新一代OpenShift</strong></h2><p>2019年5月，在完成收购CoreOS的15个月后，RedHat正式发布了OpenShift 4，将其定位为面向混合云的通用操作系统，如图三所示。它虽然依然以Kubernetes为核心，但是整个平台已经脱胎换骨，从功能，架构，到实现都有非常大的改变。其中最大的变化是在底层的操作系统及应用服务的管理方式上。</p><ul><li>采用更轻量、更安全、更紧凑的CoreOS操作系统，容器运行时也使用更轻量的CRI-O代替了Docker。CoreOS是一个基于Linux内核的轻量级操作系统，专注于自动化、轻松部署、安全、可靠及可扩缩性，它可以通过配置文件来定义底层操作系统，实现了操作系统的标准化。</li><li>全面拥抱Operator，实现应用服务自动部署、自动运维、扩展及故障转移，极大程序简化了应用的管理，同时保证了不同的集群下应用都是完全相同的，无论是内部环境还是公有环境，实现了应用管理的标准化。OpenShift集群的核心组件，运维组件，DevOps工具链等都实现了Operator化。<br>OpenShift 4自身的内功修炼也不止这些：Serverless的支持、服务网格技术的整合、多网络平面的支持、更多持续集成与持续交付功能的拓展等，为应用的全生命周期打造一个完善的生态系统。<br>除了自身的功能外，OpenShift 4与各种云平台的集成方面下足了功夫，支持了AWS、Azure Cloud、VMware vsphere、IBM Cloud等，甚至将会支持与Aliyun的集成。这也解释了为什么它的定位是面向混合云的通用操作系统。<br>虽然当前OpenShift 4还是一个较新的版本，稳定性还需要更多的生产实践进行验证。但是相信在不久的将来OpenShift 4会接过V3的大旗，成为生产上使用最为广泛的容器平台。</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-64f5949846eb90ad.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="图三 OpenShift 4展示图"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>OpenShift在过去几年的不断创新与探索，敢于自我革命，成就了现在企业级容器平台的江湖地位。虽然OpenShift的产品化降低了它的灵活性，但是它对原生Kubernetes在安全性、稳定性等多个方面进行了增强。在容器平台建设过程中，我们需要结合自身的情况，综合考虑，进行多维度的评估。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用ArgoCD实现多集群自动部署</title>
      <link href="/openshift/%E4%BD%BF%E7%94%A8ArgoCD%E5%AE%9E%E7%8E%B0%E5%A4%9A%E9%9B%86%E7%BE%A4%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"/>
      <url>/openshift/%E4%BD%BF%E7%94%A8ArgoCD%E5%AE%9E%E7%8E%B0%E5%A4%9A%E9%9B%86%E7%BE%A4%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<p>什么是Argo CD？<br>Argo CD是用于Kubernetes的声明性GitOps连续交付工具，其优势为：</p><ol><li>通过声明式定义应用、配置及环境信息，并且可以通过代码仓库实现版本控制</li><li>可通过自动或手动的方式同步应用到配置的期望状态</li><li>支持应用在多个环境、多个Kubernetes集群进行统一部署和管理</li><li>有UI及CLI多种方式，UI提供应用状态的可观测性，CLI方便与其它持续集成系统对接</li><li>支持多种SSO（OIDC，OAuth2，LDAP，SAML 2.0，GitHub，GitLab，Microsoft，LinkedIn）</li><li>支持Prometheus监控指标</li></ol><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.openshift.com/blog/openshift-authentication-integration-with-argocd">https://www.openshift.com/blog/openshift-authentication-integration-with-argocd</a><br><a href="https://www.openshift.com/blog/introduction-to-gitops-with-openshift">https://www.openshift.com/blog/introduction-to-gitops-with-openshift</a><br><a href="https://argoproj.github.io/argo-cd/">https://argoproj.github.io/argo-cd/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Vagrant+Ansible一键部署Rancher2-0</title>
      <link href="/openshift/%E4%BD%BF%E7%94%A8Vagrant+Ansible%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2Rancher2-0/"/>
      <url>/openshift/%E4%BD%BF%E7%94%A8Vagrant+Ansible%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2Rancher2-0/</url>
      
        <content type="html"><![CDATA[<ul><li>Kubernetes的流行程度就不说了，前两天关注了另一个产品Rancher。使用它可以快速部署与接管Kubernetes。而且Rancher的部署非常简单，只需要跑一个容器就完事了。</li><li>既然这么简单，那我们就使用Vagrant与Ansible让它更简单。<blockquote><p>安装Vagrant + VirtualBox</p></blockquote></li></ul><p>具体安装不表了，不是本文知识。相信大家多半都使用过，如果没有使用过，赶紧学习起来。</p><blockquote><p>导入Vagrant Box。这里使用的是Centos 7.5</p></blockquote><p>centos75-with-boxadditions.box下载链接: <a href="https://pan.baidu.com/s/1U-kJhbY2JirHgw0eP9TBXw">https://pan.baidu.com/s/1U-kJhbY2JirHgw0eP9TBXw</a> 密码: 1a6b</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant box add centos/75 centos75-with-boxadditions.box</span><br></pre></td></tr></table></figure><p>或者安装vagrant插件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant plugin install vagrant-disksize vagrant-ignition vagrant-vbguest</span></span><br></pre></td></tr></table></figure><blockquote><p>定义Vagrantfile，设置好虚拟机的配置，具体的配置可根据情况调整。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"># Vagrantfile</span><br><span class="line"># -*- mode: ruby -*-</span><br><span class="line"># vi: set ft=ruby :</span><br><span class="line"></span><br><span class="line">RANCHER_SERVER_IP = &quot;192.168.50.100&quot;</span><br><span class="line">RANCHER_AGENT_IP_1 = &quot;192.168.50.101&quot;</span><br><span class="line"></span><br><span class="line">Vagrant.configure(&quot;2&quot;) do |config|</span><br><span class="line"> </span><br><span class="line">  config.vm.box = &quot;centos/75&quot;</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;server&quot; do |server|</span><br><span class="line">    server.vm.hostname = &quot;server.rancher.local.com&quot;</span><br><span class="line">    server.vm.network &quot;public_network&quot;, ip: RANCHER_SERVER_IP</span><br><span class="line">    server.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">        v.name = &quot;server&quot;</span><br><span class="line">        v.memory = 2048</span><br><span class="line">        v.cpus = 1</span><br><span class="line">      end</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;agent1&quot; do |agent|</span><br><span class="line">    agent.vm.hostname = &quot;agent1.rancher.local.com&quot;</span><br><span class="line">    agent.vm.network &quot;public_network&quot;, ip: RANCHER_AGENT_IP_1</span><br><span class="line">    agent.vm.provider &quot;virtualbox&quot; do |v|</span><br><span class="line">        v.name = &quot;agent1&quot;</span><br><span class="line">        v.memory = 2048</span><br><span class="line">        v.cpus = 1</span><br><span class="line">      end</span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line">  config.vm.provision &quot;ansible_local&quot; do |ansible|</span><br><span class="line">    ansible.playbook = &quot;ansible/playbook.yml&quot;</span><br><span class="line">    ansible.groups = &#123;</span><br><span class="line">      &quot;servers&quot; =&gt; [&quot;server&quot;],</span><br><span class="line">      &quot;agents&quot; =&gt; [&quot;agent1&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><blockquote><p>编写ansible&#x2F;playbook.yml</p></blockquote><p>这里的过程很简单：</p><ol><li>安装docker</li><li>设置docker的镜像代理</li><li>关闭selinux  </li><li>启动docker</li><li>部署rancher2.0<blockquote><p>这里将完整的代码分享，供参考</p></blockquote></li></ol><p>Rancher Vagrant：<a href="https://gitee.com/xhua/rancher-vagrant.git">https://gitee.com/xhua/rancher-vagrant.git</a><br><code>说明：agent虚拟机只是自动安装了docker及设置了docker代理，在上面部署k8s还需要通过rancher生成对应的docker命令后在上面运行。</code><br><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c4cb7a113e32ffaccba3f4586d615506db0d6560e41b40d7a8076b30bea93f98.png" alt="Rancher登录界面展示.PNG">  </p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于容器技术构建一站式业务支撑平台——实现业务需求快速交付，应用稳定可靠运行</title>
      <link href="/openshift/%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%9E%84%E5%BB%BA%E4%B8%80%E7%AB%99%E5%BC%8F%E4%B8%9A%E5%8A%A1%E6%94%AF%E6%92%91%E5%B9%B3%E5%8F%B0%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E4%B8%9A%E5%8A%A1%E9%9C%80%E6%B1%82%E5%BF%AB%E9%80%9F%E4%BA%A4%E4%BB%98%EF%BC%8C%E5%BA%94%E7%94%A8%E7%A8%B3%E5%AE%9A%E5%8F%AF%E9%9D%A0%E8%BF%90%E8%A1%8C/"/>
      <url>/openshift/%E5%9F%BA%E4%BA%8E%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF%E6%9E%84%E5%BB%BA%E4%B8%80%E7%AB%99%E5%BC%8F%E4%B8%9A%E5%8A%A1%E6%94%AF%E6%92%91%E5%B9%B3%E5%8F%B0%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E4%B8%9A%E5%8A%A1%E9%9C%80%E6%B1%82%E5%BF%AB%E9%80%9F%E4%BA%A4%E4%BB%98%EF%BC%8C%E5%BA%94%E7%94%A8%E7%A8%B3%E5%AE%9A%E5%8F%AF%E9%9D%A0%E8%BF%90%E8%A1%8C/</url>
      
        <content type="html"><![CDATA[<p>来自2020年全国职业容器云大赛冠军队二二一队作品。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/26d848956caf03067dda8911f7608f6e382447a84c9d6ea219f4141b2fc36dda.png" alt="picture 0">  </p><p>兴业数金 二二一团队成员：潘晓华、方胜、全彬元、徐林、孙佳明</p><h1 id="1-建设背景"><a href="#1-建设背景" class="headerlink" title="1 建设背景"></a>1 <strong>建设背景</strong></h1><p>随着互联网的兴起，互联网企业依托互联网，特别是移动互联网为公众提供越来越多方便快捷、稳定高效的服务，对传统业务带来了很大冲击。作为应对，传统行业也在业务上不断创新，带来对IT基础设施和应用架构方面进行转型升级的要求。例如为了支撑电商促销活动对带来的高峰期海量支付请求，某银行很早就对支付渠道相关业务应用进行微服务架构改造，由此带来了容器技术的研究和运用。经多年实践证明，采用容器技术平台很好地支撑了新的业务模式和业务容量。</p><p>基于业务发展的需要，和快速进步的金融科技技术，越来越多的传统企业开始思考自身的互联网战略、上云规划等。其中重要内容之一，是希望从技术层面更有效地支持业务创新，如微服务架构、更好的灵活性、扩展性、高可用性、更高效的业务上线效率等，因此跟上云计算技术发展的趋势，建设并推广适合自身的基于容器技术的云平台是关键任务。</p><h1 id="2-需求分析"><a href="#2-需求分析" class="headerlink" title="2 需求分析"></a>2 <strong>需求分析</strong></h1><h2 id="2-1-业务需求"><a href="#2-1-业务需求" class="headerlink" title="2.1 业务需求"></a>2.1 <strong>业务需求</strong></h2><h3 id="2-1-1-应用架构-改造需求"><a href="#2-1-1-应用架构-改造需求" class="headerlink" title="2.1.1 应用架构****改造需求"></a>2.1.1 <strong>应用架构****改造需求</strong></h3><p>某银行的客户交互渠道系统存在以下两点架构问题，制约了其快速迭代，影响了用户体验：第一，竖井式系统架构，各模块各自开发和管理基础功能，存在大量重复开发工作；第二，非分布式架构，横向扩展效率低。</p><p>为了缩短系统的迭代周期，增强横向扩展能力，该渠道需要运用DDD思想，重构一套使用微服务架构的新系统。本文设计了一套基于容器的一站式业务支撑平台解决方案，用于部署该渠道系统的微服务版本。</p><h3 id="2-1-2-应用架构-概要设计"><a href="#2-1-2-应用架构-概要设计" class="headerlink" title="2.1.2 应用架构****概要设计"></a>2.1.2 <strong>应用架构****概要设计</strong></h3><p>基于微服务架构的新系统，将服务端在逻辑上分为业务域和通用服务域，业务域是面向客户的交互界面，主要功能是整合微服务向前端提供统一的交互视图；通用服务域是从各业务领域提炼出来的通用服务的集合，与业务域解耦，只提供单一的服务输出即原子服务，业务域可整合不同的通用域服务单元完成相应的业务逻辑处理，同时通用域还包含与业务无关的后台处理模块。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f3586a0eefdaddaef85bf3ffcc34e995a05763be06ee6791d69836536fb1c7f2.png" alt="图 1 业务设计示意图">  </p><h2 id="2-2-建设企业级容器平台"><a href="#2-2-建设企业级容器平台" class="headerlink" title="2.2 建设企业级容器平台"></a>2.2 <strong>建设企业级容器平台</strong></h2><p>容器平台作为企业的新一代IT基础设施，不仅需要为基于微服务架构的新业务提供容器化运行和管控平台之外，还必须非常重视安全需求。因此建设容器平台的需求时，需要考虑包括的方面有：</p><p>l 管理大规模容器集群能力，包括：提供容器所需的高可用集群、资源池管理、网络通信方案、存储方案、编排调度引擎、微服务运行框架、镜像管理、事件告警、集群监控和日志收集等。</p><p>l 为满足安全要求，平台需要考虑应用的高可用性和业务连续性、多租户安全隔离、不同等级业务隔离、防火墙策略、安全漏洞扫描、镜像安全、后台运维的4A纳管、审计日志；如果容器平台还对公网提供访问，那么还需要考虑访问链路加密、安全证书等。</p><p>另外，一个重要方面是，容器平台通常是企业IT整个复杂系统中的一部分，因此容器平台还要遵从企业已有IT技术规范和运维要求，例如可能还需要考虑：</p><p>l 支持企业自身的应用发布体系、持续集成系统、应用建模规范、高可用管理策略。</p><p>l 对接云计算底层资源池（例如IaaS），遵从云计算资源的统一管理和分配。</p><p>l 对接或改造容器平台的网络，以满足容器平台中应用与传统虚拟机、物理机中旧业务系统的相互通信，避免或尽可能减少对企业现有网络管理模式的冲击。</p><p>l 对接统一身份验证、和整个金融云其它系统采用统一的租户定义、角色定义、资源配额定义等。</p><p>l 对接漏洞扫描、集中监控系统、日志分析系统等已有周边系统。</p><h2 id="2-3-基于容器平台构建DevOps体系"><a href="#2-3-基于容器平台构建DevOps体系" class="headerlink" title="2.3 基于容器平台构建DevOps体系"></a>2.3 <strong>基于容器平台构建DevOps体系</strong></h2><p>业务市场竞争加剧，业务部门要求业务快速交付，业务系统就要充分复用其它业务应用系统服务：</p><p>l 作为业务部门，综合着眼关注业务进度，不关注需求之外的其它交付内容。</p><p>l 作为开发部门，期待资源得倒满足，需求明确，交付内容清晰，项目计划到位，资源充足，时间充裕；如何以更有效的方法进行需求调研，更好的架构进行开发，更有效率的测试策略及项目管理方式。</p><p>l 云资源交付部门，期待资源容量评估、架构评估、交付内容完整、时间宽裕、安全合规。</p><p>l 安全部门，所有各个阶段严格按照网络规范实施交付，并配以持续监测和更新到最新安全机制。</p><p>l 运维部门，期待支撑所有交付均考虑运维体系完备性，基于主机和服务两个维度、不同对象目标的运维体系完备；所有运维数据均可以共享互访并使用。</p><p>关注在业务场景下，对于容器平台及DevOps要求的需求上，还包括弹性要求、高可用要求、快速交付、需求变化要求等。在 Kubernetes 和容器普及之前，我们通过虚拟机也可以实现DevOps，只是速度相对较慢，因此普及性不高（想象一下通过 x86 虚拟化来实现中间件集群弹性伸缩的效率）。而正是容器的出现，为 DevOps 工具层面的落地提供非常好的承载平台：</p><p>l 容器云平台，需要DevOps以标准化和提升IT研发和交付能力。DevOps可以部署在容器云平台上。</p><p>l 基于容器化PaaS平台的DevOps，可以使用容器云的资源，譬如DevOps平台的相关技术组件，可以以容器方式部署在容器云上，以支持多pipeline流水线并发编译所需要的弹性资源。</p><p>Openshfit 以容器技术和 Kubernetes 为基础，在此之上扩展提供了软件定义网络、软件定义存储、权限管理、企业级镜像仓库、统一入口路由、持续集成流程（ S2I&#x2F;Jenkins ）、统一管理控制台、监控日志等功能，形成覆盖整个软件生命周期的解决方案，实现DevOps落地效率比较高。</p><h1 id="3-设计架构"><a href="#3-设计架构" class="headerlink" title="3 设计架构"></a>3 <strong>设计架构</strong></h1><h2 id="3-1-整体设计"><a href="#3-1-整体设计" class="headerlink" title="3.1 整体设计"></a>3.1 <strong>整体设计</strong></h2><p>一站式开发交付运行平台提供持续集成、自动部署、弹性伸缩、高可用、监控告警、微服务治理等特性，解决互联网业务爆发性强，难预测，响应要求高，需求变化快的的特点，为应用提供全生命周期的支撑管理能力，从业务需求管理、应用开发、持续构建、持续部署到应用运维保障。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c0ddee9a1a09995c25f9d164a46f779ecbeb3f171336495258f2fd5ddc5fb664.png" alt="图 2 一站式开发交付容器平台整体架构">  </p><h3 id="3-1-1-容器平台"><a href="#3-1-1-容器平台" class="headerlink" title="3.1.1 容器平台"></a>3.1.1 <strong>容器平台</strong></h3><p>l 基础设施</p><p>IT基础设施为平台提供计算、网络、存储、安全等资源，支持物理机、虚拟化、私有云和公有云等多种环境。</p><p>l 容器引擎Docker</p><p>平台使用Docker作为容器引擎层。容器技术是一种进程隔离技术，它通过namespace&#x2F;cgroup等技术从内核空间、资源和安全等方面对进程做隔离。因为容器是进程级别的，所以它非常轻量，能够实现秒级启动。另外容器镜像将运行环境与应用一起打包，实现了一处构建，处处部署，为应用的交付与运维管理提供了一种标准的方式。Docker是目前使用最为广泛的容器引擎，已被大规模生产环境验证。</p><p>l 容器编排层Openshfit</p><p>平台使用Openshfit作为容器编排层，Openshfit基于业界容器编排标准Kubernetes技术，并在安全性上进行了增强，同时为了方便开发者使用容器技术，对应用的构建与部署等集成方面也做了功能的增加，有助于快速构建一个功能全面的容器平台。</p><p>作为容器编排引擎，Openshfit具备全面的编排相关的功能：应用编排、应用部署、应用配置、应用升级、负载均衡、弹性伸缩、健康检查、权限管理、容器网络、网络存储等；除此之外，Openshfit还提供了更全面的管理功能，如应用构建、日志中心、资源监控，应用商店等。但是Openshfit自带的运维管理功能有它的局限性，平台将会对其日志中心、资源监控等功能进行全面扩展与增强。</p><p>l PaaS服务</p><p>平台基于Openshfit之上，采用Operator技术实现的可扩展PaaS服务（包括数据库、消息队列、缓存、反向代理等中间件服务）。Operator为PaaS服务提供构建、扩展、监控、备份等能力。研发与运维人员只需要在平台门户进行提交表单，就能方便快速地构建高成熟度中间件服务。</p><p>l 容器平台门户</p><p>平台基于Openshfit和Docker容器技术，并与DevOps支撑平台进行集成，提供面向应用全生命周期管理的企业级PaaS云解决方案。提供对平台与应用服配置、部署、运维及管理能力；支持多数据中心、多集群、多租户、多项目等多个维度管理；与DevOps平台集成，实现一体化的持续构建与部署的能力。</p><h3 id="3-1-2-DevOps支撑"><a href="#3-1-2-DevOps支撑" class="headerlink" title="3.1.2 DevOps支撑"></a>3.1.2 <strong>DevOps支撑</strong></h3><p>DevOps平台提供了需求管理、CICD流水线、代码配置管理、制品管理、质量管控等功能，提供了从计划到测试的问题持续集成过程，提供了从计划到测试完成的过程持续发布过程，解决了从计划到上线的持续部署过程，覆盖了用户提出价值到用户使用并且监控维护的端到端过程。</p><p>通过DevOps平台，实现了在制品的持续流动、持续反馈，进行持续优化，让质量持续提高。</p><p>通过DevOps平台，实现了研发数据的度量管理，通过对团队的研发数据进行定量分析，及时发现研发过程中的不足，有助于提高研发团队的效率和质量。</p><p>通过AIOPS的接入，通过对日志等数据的持续监控，实现常见问题的自动化运维，保证应用的持续可用。</p><h3 id="3-1-3-运维保障"><a href="#3-1-3-运维保障" class="headerlink" title="3.1.3 运维保障"></a>3.1.3 <strong>运维保障</strong></h3><p>l 资源管理</p><p>通过开发Openshfit管理门户，实时管理集群资源使用现状，通过记录资源台账（记录计算、存储、网络ip端口资源）的方式，记录并预分配准备上线的系统，保障集群配额充足，及时提出扩容需求。</p><p>租户资源：通过ResourceQuotas对租户资源进行限制，以保障租户间不相互影响。</p><p>pod资源：通过LimitRange对pod和container资源进行限制。</p><p>l 日志管理</p><p>集群日志统一由EFK组件收集、管理和展示，通过统一管理，大大提升了日志查找、故障排查的效率，同时Openshfit管理门户也开发了日志的展示和查询功能，实现了在挂历门户对集群故障的初步定位能力。</p><p>l 监控告警</p><p>除了集群内部的Prometheus，还将集群资源使用情况、集群组件状态、项目pod状态等信息以标准格式输出给集群外部的监控工具，进行统一管理、告警和展示，具备短信邮件等告警提醒等功能。</p><p>l 事件管理</p><p>容器平台上运行着成千上万个资源，每个资源在生命周期过程中状态不断变化，每一个状态变化过程中都会涉及到多条事件信息，及时获取到这些信息中有问题的部分能够帮助项目最早时间发现问题，这就是事件管理的重要意义。本方案中，将采用EventRouter收集平台所有事件，对于异常事件会在第一时间通过告警平台发出。</p><p>l 网络管理</p><p>网络管理包括两个部分：传统网络管理、集群内部网络管理。</p><p>传统网络管理，主要集群内外网络访问以及不同网络区域之间底层网络控制策略的管理，主要通过网络防火墙策略的维护。</p><p>集群内部网络管理，主要通过NetworkPolicy策略进行控制。平台支持图形化配置该策略，为管理员提供良好的操作体验。</p><p>l 数据备份</p><p>数据备份包括以下两个方面：集群数据备份、应用数据备份，其中集群数据备份包括有资源对象备份、证书与集群配置备份、集群Etcd数据库全量备份。</p><p>集群数据备份通过oc、Etcdctl命令客户端及shell命令实现资源对象、证书、配置及Etcd数据库全量数据的备份与恢复。</p><p>引入NBU（NetBackup）备份策略，为应用持久化存储做备份。Veritas NetBackup拥有Docker认证，它能为应用存储提供高效、简便、灵活的应用备份解决方案。</p><p>l 巡检机制</p><p>通过编写健康检查脚本，对集群核心组件的健康状态、核心组件运行过程中的异常日志以及平台的负载状态等按日进行巡检，将高危风险以邮件形式发送给平台运维和研发人员，并及时分析处理，以确保平台稳定运行。</p><p>l 集群升级</p><p>平台在日常运维中将定期关注集群的最新补丁与漏洞报告，并及时对集群进行升级，保证平台的安全稳定。</p><h2 id="3-2-非功能性设计"><a href="#3-2-非功能性设计" class="headerlink" title="3.2 非功能性设计"></a>3.2 <strong>非功能性设计</strong></h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/a06d33259d836f19de2271f0179cdca82ed049c42061973685be69c22ccf7d14.png" alt="图 3 非功能性展示图">  </p><h3 id="3-2-1-高可用性"><a href="#3-2-1-高可用性" class="headerlink" title="3.2.1 高可用性"></a>3.2.1 <strong>高可用性</strong></h3><p>平台高可用性涉及到五个方面：集群高可用、应用高可用、存储高可用、网络高可用以及制品库高可用。</p><p>l 集群高可用</p><p>集群的高可用主要有两部分：<strong>单集群的高可用</strong>和<strong>多集群提供双活服务</strong>两个部分。</p><p>单集群的高可用：控制节点是集群最核心的部分，其上面的组件均采用高可用部署：Etcd集群化部署、Master组件服务均为多副本部署。同时Master组件部署在支持自动迁移策略的虚拟机平台，即当底层物理机发生宕机后，其上运行的虚所机会自动漂移到备用节点，并且多个控制节点分散部署，进一步提升集群的可靠性。</p><p>双活机制提升集群服务可靠性：在同一机房部署多套集群，集群业务互为备份，同时提供服务。</p><p>l 应用高可用</p><p>应用高可用主要有两部分：应用设计和应用部署。</p><p>应用设计：应用提供对应的健康检查接口，与容器平台的检查机制配合实现应用自动恢复；容器平台支持应用生命周期控制，例如通过HTTP接口健康探测机制可实现故障的容器实例的自动重启。</p><p>应用部署：应用采用多集群多副本部署，容器具有轻量、启动快速等特性能够支持快速扩容；平台为应用提供亲和与反亲和等调度策略，应用部署可选择合适的策略以提升应用的可用性；容器平台支持应用滚动升级保证应用升级过程中服务不中断。</p><p>l 存储高可用</p><p>平台为不同场景提供多种存储方案。分布式存储、本地存储、共享存储等都考虑多副本机制提高存储的高可用性，并且对于重要数据基于NBU提供定时备份。</p><p>l 网络高可用</p><p>网络高可用主要有两部分：集群底层网络和集群内部网络。</p><p>集群底层网络：交换机、路由器等网络设备采用双活部署，主机双网口绑定bond提供可靠的本地网络；集群将数据网、业务网、管理网分离，减小不同网络数据之的干扰。</p><p>集群内部网络：集群提供多副本且支持流量分片的Ingress&#x2F;Router节点，并通过高可用负载均衡器承载外部包括TCP、HTTP协议的请求流量。平台提供全面的监控体系，对网络服务的异常进行自动监测与诊断，在满足一定的条件下，实现网络服务自动恢复。</p><p>l 制品库高可用</p><p>制品库采用单地备份、多地同步的机制。单个制品库的服务端采用多活的方案同时提供服务，底层数据则采用冷备方案对应用镜像进行定期备份。同时平台在各地分别部署制品库，各地制品库通过之前的同步机制实现多地镜像的同步，实现互为备份。</p><h3 id="3-2-2-易用性"><a href="#3-2-2-易用性" class="headerlink" title="3.2.2 易用性"></a>3.2.2 <strong>易用性</strong></h3><p>l 可视化管理</p><p>平台提供了可视化管理界面，通过界面可以直观地查看集群的状态。同时对于应用开发的整个生命周期都支持可视化，包括需求管理，开发流水线，应用的测试报告，流水线度量指标以及运行状态等。</p><p>l 自动化管理</p><p>容器平台部分提供自动化运维工具，实现集群自动化部署、自动化升级、自动化备份、定期自动巡检、服务及资源监控告警。DevOps平台部分，自动化流水线实现应用的持续构建，持续部署与持续监控。</p><p>l 交互式操作</p><p>平台提供表单交互式，实现快速创建PaaS应用以及应用部署。</p><p>l 多集群管理</p><p>研发人员通过一个入口就可以管理多中心多集群，实现多集群统一管理，同时权限与用户集中化管理，方便容器平台的使用。</p><p>l 多系统集成</p><p>与监控告警平台、日志平台、DevOps平台等系统集成，实现一站式应用全生命周期的支撑。</p><p>l 多租户管理</p><p>平台具有丰富的用户与权限管理，支持细粒度的权限控制以满足更多的安全控制的要求。</p><h3 id="3-2-3-安全性"><a href="#3-2-3-安全性" class="headerlink" title="3.2.3 安全性"></a>3.2.3 <strong>安全性</strong></h3><p>平台从主机、容器、平台自身、镜像、网络、应用及数据等方面构建全面的容器安全体系，保障平台及应用的安全。</p><p>l 主机</p><p>主机操作系统安全加固；系统安全补丁管理机制；针对不同安全要求主机划进行分组管理，不同组的应用间物理隔离。</p><p>l 容器</p><p>容器引擎漏洞管理；容器最小权限原则，禁用root等用户；容器资源限制；容器日志分析与审计；CIS容器配置基准保证。</p><p>l 平台</p><p>基于RBAC的权限管理；平台升级机制，修复平台漏洞；平台运行日志分析与审计；CIS平台配置基准保证。</p><p>l 镜像</p><p>制定安全标准镜像作为应用基础镜像；通过镜像扫描机制防范安全漏洞；镜像签名保证平台运行镜像均已被可靠认证。</p><p>l 网络</p><p>通过底层网络策略，防火墙和ACL，按照安全等级设计不同安全要求的网络区域；集群采用细粒度网络控制机制NetworkPolicy；通过路由分片实现对不同网络安全要求应用进行隔离；通过EgressIP机制实现集群间网络访问控制。</p><p>l 应用</p><p>DevOps流水线对应用代码与服务进行持续漏洞扫描，进行安全合规审查，保证应用的安全。</p><p>l 数据</p><p>对于底层存储数据采用硬件加密；对于应用的敏感配置数据采用vault管理的secret资源保存。</p><h2 id="3-3-关键模块设计"><a href="#3-3-关键模块设计" class="headerlink" title="3.3 关键模块设计"></a>3.3 <strong>关键模块设计</strong></h2><h3 id="3-3-1-容器平台"><a href="#3-3-1-容器平台" class="headerlink" title="3.3.1 容器平台"></a>3.3.1 <strong>容器平台</strong></h3><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f6239d8cb5ceb93be47678652f17338a9204d56913b41ed1bfddbcb109c30ebc.png" alt="图 4 容器平台部署设计">  </p><h4 id="3-3-1-1-服务编排与管理"><a href="#3-3-1-1-服务编排与管理" class="headerlink" title="3.3.1.1 服务编排与管理"></a>3.3.1.1 <strong>服务编排与管理</strong></h4><p>服务编排中，需要考虑资源的统一管理、应用部署及应用弹性伸缩。</p><p>资源管理：平台通过对项目配额的管理实现对集群资源的统一分配，能够快速响应开发部门的资源需求；针对不同类型应用提供不同的底层计算节点，如计算型、内存型等，以便进一步提高资源的利用率。</p><p>应用部署：应用支持多地多集群部署，通过容器平台可以同时指定应用部署的集群及各自的副本数，容器编排引擎将会自动完成应用的部署。</p><p>弹性伸缩：应用通过HPA、VPA资源配置，对应用的负载进行监控实现应用资源限制与副本数配置的扩展与收缩，以支持流量激增的互联网场景。</p><h4 id="3-3-1-2-网络"><a href="#3-3-1-2-网络" class="headerlink" title="3.3.1.2 网络"></a>3.3.1.2 <strong>网络</strong></h4><p>网络场景主要考虑以下四种场景：集群内部网络、集群间网络、集群访问外部网络以及外部访问集群间网络。对于金融行业，网络安全非常重要，该方案中充分考虑在任意种场景下的网络安全问题。</p><p>集群内部网络：采用OVS-Networkpolicy网络策略实现集群内部服务网络精细化管理，不同项目间的应用默认网络隔离。</p><p>集群间网络：平台支持多网络区域下集群的统一管理，不同的网络区域底层通过硬件实现隔离。例如，DMZ区与生产区分别部署Openshfit集群，之间通过硬件防火墙进行隔离。</p><p>集群访问外部网络：采用EgressIP机制，为每个Project指定出口IP，该Project下的所有应用都以该IP对外部发送请求，通过集群与外部系统间的防火墙控制网络的访问权限。</p><p>外部访问集群：集群服务通过Openshfit Router服务对外提供HTTP&#x2F;TCP服务。并且根据业务类型对Router进行分片，更大程度提升Router服务的性能与扩展性。</p><h4 id="3-3-1-3-存储"><a href="#3-3-1-3-存储" class="headerlink" title="3.3.1.3 存储"></a>3.3.1.3 <strong>存储</strong></h4><p>单一的存储方式无法满足复杂的业务场景，方案根据不同的场景内容提供对应的存储介质。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/f8e6243521cc52f972040a19fdc6ecfdbb1c86722c5b4e0e92bb802f997b07cb.png" alt="图 5 存储场景展示图">  </p><p>场景一：应用内部多容器共享缓存，使用容器自身临时存储。</p><p>场景二：应用不同副本间共享存储使用NFS网络存储。</p><p>场景三：对于存储IO要求较高，并且支持单节点挂载，使用Ceph RBD分布式存储作为应用持久化存储。</p><p>场景四：对于存储IO要求很高，采用本地盘存储方案，将应用与主机通过Node Label进行绑定。</p><p>场景五：采用MinIO部署独立的对象存储服务，为容器应用提供相关数据持久化</p><h4 id="3-3-1-4-镜像仓库"><a href="#3-3-1-4-镜像仓库" class="headerlink" title="3.3.1.4 镜像仓库"></a>3.3.1.4 <strong>镜像仓库</strong></h4><p>镜像仓库是一个集中存储容器镜像的空间，在企业中建立企业级的镜像仓库有利于集中管理容器镜像，并且利于实现多个环境之间的镜像资源共享。Openshfit组件中提供了镜像仓库，且它与资源对象DeploymentConfig、BuildConfig等能够联动，以快速实现自动构建与自动部署，但是它与项目强关联并且在镜像安全扫描方面有所欠缺，很难将它作为一个企业级通用的镜像仓库。基于上面的考虑，本方案中将引入Harbor作为平台的统一镜像仓库，并通过镜像仓库命名规范与制品库管理规范集中管理所有环境中的镜像。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/4f18ac1453cf9b92b18953e484e24240cf27fb6820d7145f4af7c9a3be75f967.png" alt="图 6 镜像仓库Harbor多中心多部署示意图">  </p><p>开发测试环境与生产环境网络是隔离的，分别部署独立的Harbor服务。其中项目在开发测试环境的镜像会被分别存放在不同的仓库中分别是DEV&#x2F;SIT&#x2F;UAT&#x2F;PROD，镜像只有经过严格测试达到上线标准后才能推送到PROD仓库中，PROD仓库与其它地区的开发测试环境中的PROD仓库同步，同时这与同地的生产环境中的PROD仓库同步，实现应用镜像的多地分发。</p><p>为了提高镜像的下载速度，以加快应用的部署，镜像服务还开启P2P预热，生产中将应用镜像提前分发到P2P网络。</p><h4 id="3-3-1-5-监控告警"><a href="#3-3-1-5-监控告警" class="headerlink" title="3.3.1.5 监控告警"></a>3.3.1.5 <strong>监控告警</strong></h4><p>监控告警系统是平台系统运营维护的有利保障，目前云原生生态中较为成熟也是被使用最广的方案是Prometheus套装。通过不同的exporter服务获取相关的指标数据，由Prometheus统一收集，并通过Grafana展示出图表，相关监控项状态与趋势一目了然，下图为Prometheus方案组件架构图。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/c88f2e9b851d5fed953ac0d8b76c1a3692861e4a46f9e9aa994d1c499f2df0e2.png" alt="图 7 Prometheus方案组件架构图">  </p><p>Exporters：面向全方面资源的监控指标，具体有底层节点的相关指标、平台组件状态与性能指标、集群应用容器资源状态指标、自定义应用性能指标。</p><p>Prometheus server：通过pull方式从Exporters收集底层设备、平台组件、容器资源、应用自定义所有监控指标。</p><p>Grafana：提供对Prometheus采集的监控数据进行可视化展示。</p><p>Alertmanager：接入多种告警渠道（邮件、短信、微信等），统一管理多个来源的告警信息，如Prometheus rules策略触发的告警、日志监控触发的告警、自定检查脚本触发的告警，如下图所示为Alertmanager作为统一告警系统架构。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/6bb9896189d8ca847425a5e25868c40bca6d0dc829f895075b93fae068d36488.png" alt="图 8 Alertmanager 统一告警系统架构">  </p><p>为了便于对多个集群集中监控，采用Prometheus Federation架构实现多级监控，将不同集群监控指标统一收集，并将历史监控数据持久化在MinIO S3存储中。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2d238d3623778c4ff7c32b935e76b536a84d14baa1f732d09573e43441ee9bda.png" alt="图 9 监控服务部署示意图">  </p><h4 id="3-3-1-6-日志"><a href="#3-3-1-6-日志" class="headerlink" title="3.3.1.6 日志"></a>3.3.1.6 <strong>日志</strong></h4><p>虽然Openshfit组件中提供了基于EFK的日志方案，但这种方案并不能适应所有的业务场景。它有以下不足之处：应用日志只有标准化输出才能被收集；只能有一个日志输出文件，而真实业务场景中会有多个日志文件；Fluentd的性能并不算太好；Fluented直接发送到ES，当日志量大时，很容易发生堵塞，导致日志延时大甚至丢失日志。基于以上这些考虑，本方案中将对日志方案进行性能与功能的增强。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ae86af92ed0b957bc2b6c65358f6699d72a9aab159d054683e7c12563280923f.png" alt="图 10 日志方案架构图">  </p><p>采用更轻量及性能更好的Filebeat替换掉Fluentd来收集集群组件日志及应用标准输出的日志，仍然以DaemonSet资源的形式部署。</p><p>对于没有标准输出的应用，以sidecar的形式共享日志文件并通过filebeat收集日志文件，将其发送到Kafka中，由logstash转发到ElasticSearch服务，最后由Kibana服务展示。</p><p>引入Kafka作为日志缓冲层，提高集群应用日志的吞量。应用的标准输出日志，通过DaemonSet FileBeat服务统一收集并转发到Kafka中，由后端logstash转发到Elasticsearch服务中。</p><p>该日志方案不仅满足生产业务中的各种场景，而且能够支持高并发日志量。同时使用的组件均可通过横向扩展来扩大整个系统的吞吐量。</p><h4 id="3-3-1-7-容器平台门户"><a href="#3-3-1-7-容器平台门户" class="headerlink" title="3.3.1.7 容器平台门户"></a>3.3.1.7 <strong>容器平台门户</strong></h4><p>为了让架构具有更好的扩展性，云平台设计了四层架构：展示层、业务层、驱动层、数据层，如下图所示。另外为云平台设计了平台控制器，通过它实现容器集群资源对象数据实时缓存到Redis中。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/71e67a954c6eaa5d241afe431be69a41e7e0c117ea3e47763ed62a8a8c8f8550.png" alt="图 11 容器平台门户架构图">  </p><p>l 展示层</p><p>负责平台的页面展示，它为用户提供一套可视化，交互式的界面。研发人员通过查看或者填写表单等操作，调用业务层Restful API接口，获取详细的资源与业务数据，并在页面渲染。</p><p>l 业务层</p><p>负责平台的业务逻辑，为展示层提供Restful API接口。它会对请求的权限做验证，通过调用驱动层获取请求的资源基础信息，并通过Redis获取底层资源的详细信息，最后以JSON格式数据返回给展示层。</p><p>l 驱动层</p><p>负责与底层集群的交互，它通过指定的证书可直接访问底层集群的Master API Server，进而实现对容器集群资源的管理。同时它通过Restful API为业务层提供所需的服务。</p><p>l 数据层</p><p>负责保存容器平台的业务数据，包括有项目信息、用户信息、审计信息、权限配置、集群配置信息等。</p><p>l 平台控制器</p><p>每个集群都会部署单独的平台控制器，并为它绑定获取该集群的所有资源信息的权限，使用watch API监听底层资源的变化，一旦对应集群有新增的资源，或有资源信息发生更改，或资源被删除，平台控制器都会将信息同步在Redis缓存中，从而收集所有集群的资源对象信息，并确保信息一直处于最新状态。</p><p>容器平台门户支持多集群管理，集群信息通过平台管理功能保存在数据库中。业务层请求驱动层时会带上被访问的集群名，驱动层通过查询数据库获取集群的访问信息，定位到正确的集群。</p><h3 id="3-3-2-DevOps支撑"><a href="#3-3-2-DevOps支撑" class="headerlink" title="3.3.2 DevOps支撑"></a>3.3.2 <strong>DevOps支撑</strong></h3><p>DevOps平台采用禅道做为需求管理工具，同时采用Jenkins作为流水线引擎，其它工具链通过Jenkins进行驱动，实现应用自动高效构建与自动部署。同时Jenkins引入k8s插件，所有节点，包括Master节点与slave节点均部署在容器云平台之上，充分利用容器平台的快速部署能力，实现流水线的高效执行。以下是DevOps支撑能力的整体示意图。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/9a2819b56ae9915ffe4b40b33669503bf007a6e1764961ef95dbbcf5f130bafe.png" alt="图 12 DevOps支撑能力的整体示意图">  </p><h4 id="3-3-2-1-需求管理"><a href="#3-3-2-1-需求管理" class="headerlink" title="3.3.2.1 需求管理"></a>3.3.2.1 <strong>需求管理</strong></h4><p>引入禅道开源产品进行产品需求管理，并通过禅道中的电子看板实现需求全生命周期的可视化跟踪，完成需求计划管理。<br>通过电子看板中的模块管理实现对需求所属功能模块的划分，让产品人员能够从整体上看到需求的功能划分。<br>通过计划管理实现对需求的统一规划，我们可以定义每个时间节点的目标，根据优先级、工作量等条件把需求规划到每个计划中。</p><p>团队成员根据自身情况分析每个需求的工作量大小，并将需求分配到个人，计划开启后，每个人根据需求的实际完成情况修改需求的状态。同时通过与代码库、测试平台的对接，展现需求的代码提交情况、测试情况。</p><p>    使用统计报表，图形化展现需求的完成速率、历史情况，帮助项目组进行工作回顾。</p><h4 id="3-3-2-2-开发"><a href="#3-3-2-2-开发" class="headerlink" title="3.3.2.2 开发"></a>3.3.2.2 <strong>开发</strong></h4><p>l 代码配置管理</p><p>提供组织级的gitlab平台用于研发人员对代码进行配置管理。通过制定配置管理规划能够对提交的代码进行有效管控；通过对代码提交信息的格式约束能够将代码与需求进行关联；通过对代码库的webhook进行配置，代码提交即可触发流水线，对代码进行构建、扫描、测试，能够有效管控代码质量。除此之外，对于关键代码，还进行code review、代码走查等，保证提交的代码质量。</p><p>l 代码扫描</p><p>提供组织级的静态代码扫描平台SonarQube和Fortify，基于PMD、CheckStyle、FindBugs制订了组织级的代码检查规则。研发人员代码一旦提交到代码库就会触发代码扫描流水线，能够及时发现代码中的Issues和Bugs，可视化技术债务，明确技术债务分布情况、债务点以及改进建议等，从而能够及时得到解决，提高产品质量。</p><p>l 制品管理</p><p>基于Nexus构建组织级的制品仓库，对制品进行成熟度管理，只有制品满足各项度量指标后，制品才能部署到下一阶段，最终部署生产环境。同时在制品元数据中记录制品的质量数据，确保了部署到生产环境的制品是经过严格测试的、满足质量要求的。</p><p>l 单元测试</p><p>要求代码的单元测试覆盖率满足一定要求，同时关键代码必须要有单元测试。在实际开发过程中，使用TestNG、Junit等工具进行单元测试案例的编写，并引入Jacoco进行单元测试覆盖率的收集。只有单元测试覆盖率满足一定要求后，代码才能进行打包构建并上传到制品仓库中，进而后期才能进行部署及自动化测试等。</p><h4 id="3-3-2-3-测试"><a href="#3-3-2-3-测试" class="headerlink" title="3.3.2.3 测试"></a>3.3.2.3 <strong>测试</strong></h4><p>禅道平台也作为测试管理平台，对测试案例、缺陷进行统一管理，并且与需求进行关联。同时会将测试的结果数据记录在制品的元数据中，确保部署到生产环境的制品必须要符合质量要求。</p><p>l 功能测试</p><p>采用selenium工具对于需要上线的系统进行功能测试并且生成测试报告，待评审通过以后才能进行上线。通过对系统进行白盒、黑盒、灰盒、边界值等多维度的测试，确保系统能够满足功能需求。</p><p>l 自动化测试</p><p>采用selenium工具开发实现自动化测试脚本，并作为Jenkins构建任务的一部分。自动化测试主要包含两个方面，一个是UI测试，一个是接口测试。通过CICD流水线将制品成功部署到测试环境以后，自动会触发自动化测试流水线，通过编写好的自动化测试脚本对系统进行测试。</p><h4 id="3-3-2-4-部署"><a href="#3-3-2-4-部署" class="headerlink" title="3.3.2.4 部署"></a>3.3.2.4 <strong>部署</strong></h4><p>通过打包构建生成制品以后，制品会根据事先定义好的Dockerfile构建成镜像并上传到镜像仓库中。然后使用容器平台将镜像依次部署到SIT、UAT等环境进行测试。测试通过以后将镜像提交到待发布库中。生成下发流程通过以后，触发容器平台进行生产部署。</p><h4 id="3-3-2-5-运营维护"><a href="#3-3-2-5-运营维护" class="headerlink" title="3.3.2.5 运营维护"></a>3.3.2.5 <strong>运营维护</strong></h4><p>通过容器平台，可以很便利的对其中的应用进行日志、性能等多维度的监控，同时提供了预警机制，当机器或应用性能触发阈值以后，会向应用负责人发送短信和邮件提醒。从而应用负责人能够实时掌握应用状态，对出现的一些状况能及时处理。</p><h4 id="3-3-2-6-平台度量"><a href="#3-3-2-6-平台度量" class="headerlink" title="3.3.2.6 平台度量"></a>3.3.2.6 <strong>平台度量</strong></h4><p>对各个能力子域的指标进行量化，在流水线的实际执行过程中收集这些指标，同时对收集指标进行分析、打分，得出此次执行的一个量化数据。通过收集每次流水线执行的指标数据，就可以获取到该应用的整个质量的趋势，从而能够更好的指导应用开发。</p><h1 id="4-规范指引"><a href="#4-规范指引" class="headerlink" title="4 规范指引"></a>4 <strong>规范指引</strong></h1><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/1548e5adc027fd0a0f391c5b0ca8286aa5185931f389d98d014043478f8b8404.png" alt="图 13 规范指引展示图">  </p><h2 id="4-1-业务规范"><a href="#4-1-业务规范" class="headerlink" title="4.1 业务规范"></a>4.1 <strong>业务规范</strong></h2><h3 id="4-1-1-业务需求规范"><a href="#4-1-1-业务需求规范" class="headerlink" title="4.1.1 业务需求规范"></a>4.1.1 <strong>业务需求规范</strong></h3><p>l 统一语言</p><p>业务需求应当使用统一的语言，所谓统一语言，是指项目研发过程中，产品、研发、测试、运维、管理、运营等角色在交流中，对一些专有名词理解达成统一，以保证大家在沟通中没有信息不一致或信息歧异，提高沟通效率和准确度。</p><p>l 业务需求格式</p><p>业务需求描述中应明确，清晰，不应使用可能、一般等模棱两可的描述，应当体现出业务功能的角色、活动、价值（效果）。此处不应使用技术语言来描述，要使用用户可以理解的业务语言来描述。通常格式为作为一个&lt;角色&gt;, 我想要&lt;活动&gt;,以便于&lt;商业价值。</p><p>举例：作为一个“网站管理员”，我想要“统计每天有多少人访问了我的网站”，以便于“我的赞助商了解我的网站会给他们带来什么收益。”</p><h2 id="4-2-应用上云设计规范"><a href="#4-2-应用上云设计规范" class="headerlink" title="4.2 应用上云设计规范"></a>4.2 <strong>应用上云设计规范</strong></h2><h3 id="4-2-1-应用容器化设计规范"><a href="#4-2-1-应用容器化设计规范" class="headerlink" title="4.2.1 应用容器化设计规范"></a>4.2.1 <strong>应用容器化设计规范</strong></h3><p>l 应用中不指定Pod的IP</p><p>应用容器化部署后，Pod的替换伴随着IP的变化。若应用指定Pod的IP访问目标应用，一旦目标应用的Pod发生变动，目标应用的IP也会随着变化，目标应用将无法被正常访问。为了保证应用访问服务的稳定性，应用中不直接通过Pod的IP来访问目标应用。可以通过注册中心，获得动态IP的方式来实现服务间的调用，也可以直接使用serviceIP来实现不同应用间的调用。</p><p>l 同一Pod内的不同容器间使用127.0.0.1相互访问</p><p>同一个Pod可以有多个容器，这些容器共享同一个网络命名空间，它们之间推荐直接使用127.0.0.1来实现互相访问。</p><p>l 为应用实例提供健康检查接口</p><p>应用需提供健康检测接口，用来配置容器的健康检查策略，从而保证滚动升级过程中的服务可用性。</p><p>l 应用容器需要考虑优雅退出</p><p>为了保证应用服务的稳定，应用容器需要考虑优雅退出，确保容器退出时关闭所有连接。如果应用程序未处理SIGTERM信号,可以在编排文件中设置preStop Hook,即在关闭容器前等待一段时间，让应用程序完成所有请求。</p><p>l 使用CronJob代替crontab服务设置定时任务</p><p>不建议在容器中使用crontab服务设置定时任务，推荐通过CronJob资源对象来实现定时任务的功能。</p><h3 id="4-2-2-应用部署规范"><a href="#4-2-2-应用部署规范" class="headerlink" title="4.2.2 应用部署规范"></a>4.2.2 <strong>应用部署规范</strong></h3><p>l 应用容器通过使用PV&#x2F;PVC进行持久化数据</p><p>容器本身并不带有持久化存储，被销毁时容器中存储的数据也会被清理。容器中如果需要保存数据，需要通过PV（持久化卷）与PVC（持久化卷请求）资源，使用NAS存储，实现数据持久化。</p><p>l ConfigMap挂载到容器内部的文件夹必须为空</p><p>配置文件可以保存在ConfigMap中，ConfigMap挂载到容器内部的目录会把目录下的原有文件覆盖，所以需要注意挂载的目录尽量为空目录。</p><p>l 每个系统申请一个EgressIP，作为访问外部服务的出口IP</p><p>为了对系统网络做更精细化的控制，容器云平台每个系统必须申请并绑定一个EgressIP。该系统下的应用Pod都以该IP为出口IP访问外部服务，通过防火墙设置，可以对系统下的应用访问外部服务的网络进行控制。</p><p>l 为应用实例设置健康检查</p><p>为了更好地监控应用服务的状态，充分发挥容器云平台为应用带来的自愈能力，提高应用的可靠性，应用必须设置readinessProbe与livenessProbe。其中readinessProbe将检测应用容器是否已准备好接受流量，livenessProbe将检测应用容器是否存活。</p><p>l 为应用实例设置资源限制（cpu与memory）</p><p>为了对资源进行精细化管理与控制，减少底层资源的竞争，也可避免程序因Bug占用过多底层资源，以提高应用的稳定性，容器基础平台的应用部署时必须为每个容器设置资源限制，包括：limits.cpu、limits.memory、requests.cpu、requests.memory。其中limits.cpu、limits.memory为应用运行过程中占用CPU、Memory资源的上限值；requests.cpu、requests.memory为应用运行过程中请求的CPU、Memory资源值。</p><h2 id="4-3-应用开发规范"><a href="#4-3-应用开发规范" class="headerlink" title="4.3 应用开发规范"></a>4.3 <strong>应用开发规范</strong></h2><h3 id="4-3-1-数据交互规范"><a href="#4-3-1-数据交互规范" class="headerlink" title="4.3.1 数据交互规范"></a>4.3.1 <strong>数据交互规范</strong></h3><p>l 接口格式</p><p>通常每个URI网址代表一种资源接口，网址中不应有动词，尽量使用名词（特殊情况可以使用动词）；网址名称不应大写，若需要分割时使用中杠-不用下杠 _ ；若URI中的名词表示资源集合，使用复数形式。</p><p>应当使用url来表达层级，用于按实体关联关系进行对象导航。层级不应过深，复杂场景尽量使用查询参数代替路径中的实体导航。应当将API的版本号放入到URI中。</p><p>l HTTP方法</p><p>应使用标准的HTTP方法实现对资源的CRUD，包括：</p><p>GET：查询（从服务器取出资源一项或多项）；</p><p>POST：创建单个新资源。 POST向“资源集合”型uri发起；</p><p>PUT：更新单个资源（全量），客户端提供完整的更新后的资源；</p><p>DELETE：删除。</p><p>其中GET、PUT、DELETE方法应具备幂等性，也就是执行1次和执行N次，对资源状态改变的效果应是等价的。</p><p>l HTTP状态码和提示信息</p><p>正确设置http状态码，不要自定义http状态码。服务器返回的提示信息应尽量简洁，避免嵌套，采用信息代码（用于日志&#x2F;问题追查）+错误的描述文本（展示给用户）的形式。</p><p>l 接口文档</p><p>数据交互应形成良好的接口文档，包括但不限于以下内容：</p><p>1) HTTP方法类型：也就是我们常写的GET，POST，PUT，DELETE等。</p><p>2) url调用方法：从前端调后端的方法地址。</p><p>3) 请求参数：包括字段、说明、类型、备注、是否必填。</p><p>4) 返回参数：尽量使用JSON，避免使用XML。</p><p>l 异常处理</p><p>异常应包括业务异常和非业务异常。业务异常由自己的业务代码抛出，表示一个用例的前置条件不满足、业务规则冲突等，比如参数校验不通过、权限校验失败。非业务类异常 表示不在预期内的问题，通常由类库、框架抛出，或由于自己的代码逻辑错误导致，比如数据库连接失败、空指针异常、除0错误等等。</p><p>业务异常应返回200的HTTP响应状态码，并返回指定的错误文本提示信息。非业务异常应返回500的HTTP响应状态码，异常信息应进行统一封装，如“服务器端错误，请稍后再试”，非必要情况不应将错误类型展示给用户。</p><p>l 安全</p><p>对于API的使用应当有身份认证，同时具备一定的安全手段用于预防常见的安全攻击。</p><h3 id="4-3-2-应用镜像构建规范"><a href="#4-3-2-应用镜像构建规范" class="headerlink" title="4.3.2 应用镜像构建规范"></a>4.3.2 <strong>应用镜像构建规范</strong></h3><p>l 使用统一的基础镜像</p><p>基础镜像涉及应用运行所需要的安全可靠的Linux操作系统。基础镜像由基础架构部门负责维护，定期打安全漏洞的补丁，并基于应用要求构建基础环境镜像，维护到公共镜像仓库。</p><p>l 公共依赖层</p><p>主要是包括运行时（如JDK）、中间件（如Web容器）、其它公共组件等。公共依赖层镜像由基础架构部门负责维护，定期打安全漏洞的补丁，并基于应用要求构建依赖层镜像，维护到公共镜像仓库。</p><p>l 应用层</p><p>主要包括程序包（jar包、war包）、程序依赖包（jar lib）等。程序包基于代码基线编译打包，应用层镜像由开发部门负责构建。</p><p>l 镜像一次构建，多环境部署</p><p>为了保证应用的运行环境保持一致，应用容器镜像应在研发环境下构建，在其它环境下部署进行测试与上线均使用同一个镜像。</p><p>l 使用非root用户启动应用容器</p><p>为保障容器云平台的安全性，禁止应用容器中使用root用户运行应用。</p><h3 id="4-3-3-DevOps指引"><a href="#4-3-3-DevOps指引" class="headerlink" title="4.3.3 DevOps指引"></a>4.3.3 <strong>DevOps指引</strong></h3><h4 id="4-3-3-1-开发流程自动集成"><a href="#4-3-3-1-开发流程自动集成" class="headerlink" title="4.3.3.1 开发流程自动集成"></a>4.3.3.1 <strong>开发流程自动集成</strong></h4><p>1) 项目配置好CI&#x2F;CD流水线后，开发人员提交代码；</p><p>2) 自动触发CI&#x2F;CD流水线运行，对项目代码进行代码扫描、单元测试；</p><p>3) 获取私服Maven仓库资源（非必须）进行构建；</p><p>4) 构建完成后，生成最新的镜像保存到镜像仓库。</p><p>下图为开发集成部署流程图。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2b84ca5663c4d5601dc3db56b54859a67eb4404fdf4745843a7d08884a2e9cf5.png" alt="图 14 开发集成流程图">  </p><h4 id="4-3-3-2-开发提测流程"><a href="#4-3-3-2-开发提测流程" class="headerlink" title="4.3.3.2 开发提测流程"></a>4.3.3.2 <strong>开发提测流程</strong></h4><p>1) 开发人员用gitlab给代码打上提测Tag；</p><p>2) 开发人员手动在Jenkins上提测，执行提测任务；</p><p>3) 自动触发工程指定版本代码的构建，并生成指定版本的镜像；</p><p>4) 测试人员在测试环境部署指定版本镜像，进行测试。</p><p>下图为开发提测流程图：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/d16d50ba871d16e0ad190107788a9dc7f40bdf5930f5aa41017208b6b66e2c92.png" alt="图 15 开发提测流程图">  </p><h4 id="4-3-3-3-集成测试流程"><a href="#4-3-3-3-集成测试流程" class="headerlink" title="4.3.3.3 集成测试流程"></a>4.3.3.3 <strong>集成测试流程</strong></h4><p>测试人员在测试环境部署指定版本镜像，进行测试。</p><p>下图为集成测试流程图：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/22188e613091ea4ca079ef9b364098986cf5ffeacfcdb75104653a569b661486.png" alt="图 16 集成测试流程图">  </p><p>说明：以上流程均可在开发测试PaaS集群操作，如果要上生产部署，需搭为生产环境单独部署另外一套PaaS集群，同时两个集群网络与资源隔离。</p><h4 id="4-3-3-4-生产部署流程"><a href="#4-3-3-4-生产部署流程" class="headerlink" title="4.3.3.4 生产部署流程"></a>4.3.3.4 <strong>生产部署流程</strong></h4><p>1) 运维人员从测试环境同步指定版本的镜像；</p><p>2) 运维人员在生产环境部署指定版本镜像。</p><p>下图为生产部署流程图：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/d4360df42bee3ee8f002a968f34e4217b040581e31ff361edf114c3299e8650f.png" alt="图 17 生产部署流程图">  </p><h2 id="4-4-运维规范"><a href="#4-4-运维规范" class="headerlink" title="4.4 运维规范"></a>4.4 <strong>运维规范</strong></h2><h3 id="4-4-1-容器平台运维规范"><a href="#4-4-1-容器平台运维规范" class="headerlink" title="4.4.1 容器平台运维规范"></a>4.4.1 <strong>容器平台运维规范</strong></h3><h4 id="4-4-1-1-定期巡检"><a href="#4-4-1-1-定期巡检" class="headerlink" title="4.4.1.1 定期巡检"></a>4.4.1.1 <strong>定期巡检</strong></h4><p>将Openshfit集群重要组件的健康状态检查封装在shell脚本中，设定定时任务，实现自动化巡检，按时生成巡检报告，以邮件形式发送至平台运维、研发单位。定期巡检包括：master-api、master-controller、Etcd、router、es、prometheus等组件的状态。</p><h4 id="4-4-1-2-扩容评估"><a href="#4-4-1-2-扩容评估" class="headerlink" title="4.4.1.2 扩容评估"></a>4.4.1.2 <strong>扩容评估</strong></h4><p>设计Openshfit集群资源预申请台账，结合集群管理门户查询到的集群资源实际使用情况，记录Openshfit集群当前的资源总量和计划上线的系统所需资源，根据台账的资源申请比例，安排计算、存储资源扩容。</p><h4 id="4-4-1-3-应急预案"><a href="#4-4-1-3-应急预案" class="headerlink" title="4.4.1.3 应急预案"></a>4.4.1.3 <strong>应急预案</strong></h4><p>根据Openshfit集群特点，制定应急预案：一是记录硬件资源、软件资源、集群逻辑架构、数据备份方案、关联系统、应急联系人等信息；二是记录系统节点及部署模式，便于故障发生时快速查阅节点信息；三是针对平台层11个故障场景（硬件、网络、平台组件）、应用层6个故障（管理门户、sftp等）场景的处置方案，以及故障恢复后的验证方案。</p><p>其中平台层故障处置方案主要有以下三个层面：</p><p>基础设施故障：物理主机故障、基础网络故障、存储设备故障。</p><p>平台服务故障：管理节点集群组件服务异常（Master API、Master Controller、Etcd)，工作节点服务异常（atomic-Openshfit-node、Docker服务），集群间网络异常（sdn、ovs服务）。</p><p>运维相关应用故障：监控服务异常（Prometheus服务），日志服务异常（Fluentd、ES服务）。</p><h3 id="4-4-2-应用运维规范"><a href="#4-4-2-应用运维规范" class="headerlink" title="4.4.2 应用运维规范"></a>4.4.2 <strong>应用运维规范</strong></h3><h4 id="4-4-2-1-应用发布"><a href="#4-4-2-1-应用发布" class="headerlink" title="4.4.2.1 应用发布"></a>4.4.2.1 <strong>应用发布</strong></h4><p>Openshfit集群将部署文件和镜像文件从制品库拉取至本地，再通过oc命令进行发布。该部署过程按场景编排成多个自动化流程，通过在管理端填写发布相关的参数执行。</p><h4 id="4-4-2-2-应用回退"><a href="#4-4-2-2-应用回退" class="headerlink" title="4.4.2.2 应用回退"></a>4.4.2.2 <strong>应用回退</strong></h4><p>Openshfit集群将旧版本的部署文件和镜像文件从制品库拉取至本地，再通过或oc命令进行发布。该回退过程按场景编排成自动化流程，通过在管理端填写版本tag相关的参数执行。</p><h4 id="4-4-2-3-应用监控"><a href="#4-4-2-3-应用监控" class="headerlink" title="4.4.2.3 应用监控"></a>4.4.2.3 <strong>应用监控</strong></h4><p>设计每分钟一次的定时任务，将影响应用可用性的关键指标，结合集群各宿主机节点的系统指标数据统一发送至监控平台进行集中管理、展示、和告警。</p><h4 id="4-4-2-4-应用伸缩管理"><a href="#4-4-2-4-应用伸缩管理" class="headerlink" title="4.4.2.4 应用伸缩管理"></a>4.4.2.4 <strong>应用伸缩管理</strong></h4><p>根据特定的大流量业务场景需要，平台允许在特定时间区间、在平台可以容纳的容量范围内，对应用进行扩缩容处理，扩缩容命令封装后，编排成自动化运维平台的流程，通过填入扩缩容副本数量等参数执行。</p><h4 id="4-4-2-5-日志管理"><a href="#4-4-2-5-日志管理" class="headerlink" title="4.4.2.5 日志管理"></a>4.4.2.5 <strong>日志管理</strong></h4><p>容器应用日志须落盘持久化卷存放，不同容器分不同文件进行存储。日志必须进行合理分级，按时间或大小自动分割，并依据合理的压缩和清理周期管理。</p><p>容器应用日志命名合理规范，日志内容要素齐全：时间、日志级别（INFO、WARN、ERROR）、线程名称、交易标识、用户id、日志消息体、异常堆栈等。</p><p>容器日志访问须提供两种方式：一是由平台自带的EFK组件统一管理和展示，二是通过应用系统相关虚拟机或物理机节点直接访问。</p><h3 id="4-4-3-制品管理规范"><a href="#4-4-3-制品管理规范" class="headerlink" title="4.4.3 制品管理规范"></a>4.4.3 <strong>制品管理规范</strong></h3><h4 id="4-4-3-1-镜像准入管理"><a href="#4-4-3-1-镜像准入管理" class="headerlink" title="4.4.3.1 镜像准入管理"></a>4.4.3.1 <strong>镜像准入管理</strong></h4><p>基础镜像使用RedHat操作系统。</p><p>公共镜像原则上仅包括一种中间件软件。若同一公共镜像需要包括大于一种中间件软件，必须采用多次构建方式。</p><p>应用镜像必须使用镜像仓库统一提供的基础镜像或公共镜像构建。应用镜像必须符合精简原则，应包括且仅包括针对公共镜像的配置修改、可执行的应用包、依赖包介质和启动命令，不得包括其它与应用无关的文件。应用参数配置文件不应包含在应用镜像内部。</p><h4 id="4-4-3-2-镜像命名管理"><a href="#4-4-3-2-镜像命名管理" class="headerlink" title="4.4.3.2 镜像命名管理"></a>4.4.3.2 <strong>镜像命名管理</strong></h4><p>镜像命名使用小写字母，避免下划线，最长64个字符，每段命名间使用“-”连接。</p><p>格式如下： <team>-&lt; scope &gt;-<tech>-<maturity >-<locator></p><p>其中：</p><p>1) <team>指项目组或系统，可自行定义，避免使用下划线。</p><p>2) <scope>指镜像库的依赖范围，可填选项为一方库、二方库、三方库。</p><p>3) <tech>指采用的技术或包类型。每个仓库中应保持同一种类型的二进制文件。</p><p>4) <maturity >指镜像库的开发成熟度，例如开发、测试和发布阶段。</p><p>5) <locator>指镜像库所处的物理地点，例如上海、福州、成都或远程、虚拟等。虚拟仓库不需要指定。</p><h1 id="5-分阶段实施规划"><a href="#5-分阶段实施规划" class="headerlink" title="5 分阶段实施规划"></a>5 <strong>分阶段实施规划</strong></h1><h2 id="5-1-方案验证阶段"><a href="#5-1-方案验证阶段" class="headerlink" title="5.1 方案验证阶段"></a><strong>5.1 方案验证阶段</strong></h2><h3 id="5-1-1-功能测试"><a href="#5-1-1-功能测试" class="headerlink" title="5.1.1 功能测试"></a><strong>5.1.1 功能测试</strong></h3><p>设计功能测试验证样例，在测试环境按生产1:1搭建容器云平台，详细测试容器云平台各功能点，并将DevOps体系各模块串连起来，完成持续构建与持续部署链路的验证。并设计集成测试验证样例，模拟生产环境发起业务验证，最终形成《集成测试报告》，所有业务场景验证通过。</p><h3 id="5-1-2-压力测试"><a href="#5-1-2-压力测试" class="headerlink" title="5.1.2 压力测试"></a><strong>5.1.2 压力测试</strong></h3><p>为保障基于Openshfit构建的容器平台在实际生产运行中符合非功能性要求，在准生产环境部署Openshfit集群，通过测试工具发起压力测试，测试结果满足业务运行要求。以及测试DevOps系统支持并发构建与部署的最大容量。</p><h2 id="5-2-技术推广阶段"><a href="#5-2-技术推广阶段" class="headerlink" title="5.2 技术推广阶段"></a><strong>5.2 技术推广阶段</strong></h2><p>经过功能测试和压力测试，集群满足上线部署要求，DevOps体系能够完成应用全生命周期的调度后，提交运维单位在生产环境部署集群，部署Openshfit管理门户、配置项目计算资源，对接制品库，从制品库拉取镜像部署应用。通过shell脚本实现监控信息转化，传送至统一监控告警系统，实现分钟级监控集群日常运行状态。</p><p>在此阶段中，应不断提升与优化容器平台及DevOps平台，以适应本企业各项目组的实际要求，最终形成最佳实践与标准规范。</p><h2 id="5-3-规模化推广阶段"><a href="#5-3-规模化推广阶段" class="headerlink" title="5.3 规模化推广阶段"></a><strong>5.3 规模化推广阶段</strong></h2><p>经过技术推广，验证了Openshfit集群在生产环境承载业务的能力，在本地生产环境部署了双活集群，前端业务流量通过F5负载均衡至两个集群，实现集群层面的高可用性。后续，本集群可以针对灾备要求高的信息系统，部署异地灾备集群。诸如企业级短信发送平台这类高可用要求高，但对数据查询实时性要求不高的系统，可以部署在异地双活的Openshfit集群，数据库分别部署在两地，每日日结后再将当日数据合并至历史库。根据部署类型，本方案中设计的容器云平台，可以支持本地双活、异地灾备、异地双活的多种集群部署场景。</p><p>同时根据企业在上一阶段形成的最佳实践及标准规范，全面推广DevOps体系，项目优先使用DevOps平台全面支撑应用的开发、测试及部署，并建设DevOps体系成熟度评估模型，标准化推广DevOps建设。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Openshift中的cronjob-+-zalenium实现网站监控</title>
      <link href="/openshift/%E5%88%A9%E7%94%A8Openshift%E4%B8%AD%E7%9A%84cronjob-+-zalenium%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E7%9B%91%E6%8E%A7/"/>
      <url>/openshift/%E5%88%A9%E7%94%A8Openshift%E4%B8%AD%E7%9A%84cronjob-+-zalenium%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%AB%99%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>有一个网站（pf.apps.example.com)，会获取主机的信息，但是主机信息的格式不统一，而且经常性会添加机器，但是信息又是不确定的，所以有时添加新机器会缺失字段，导致网站异常。</p><p>有两种解决方法，</p><ul><li><ol><li>优化代码，提高代码的兼容性，不致于导致页面无法显示。</li></ol></li><li><ol start="2"><li>严格规范字段的输入，必须保证字段的完整性。</li></ol></li></ul><p>不管哪种方法，我们都需要在页面出现故障时第一时间知道。这就要求编写代码自动监测网站相关页面的可用性，一旦出现问题，及时发邮件告知，第一时间恢复。</p><p><code>有使用到上篇介绍的zalenium</code> <a href="https://www.jianshu.com/p/c38abbcff5cc">Openshift部署zalenium(容器化的selenium)及Python自动测试</a></p><h2 id="编写监控脚本"><a href="#编写监控脚本" class="headerlink" title="编写监控脚本"></a>编写监控脚本</h2><p>监控脚本使用selenium控制浏览器，先模拟登录，再访问需要测试的页面，如果页面正常打开则正常，否则发邮件告警。（由于这个网站的每个页面都有id&#x3D;content的一个div，所以通过检测页面中是否存在id&#x3D;content的div来判断页面是否正常）<code>monitor.py</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">-------------------------------------------------</span><br><span class="line">   File Name：     test</span><br><span class="line">   Description :</span><br><span class="line">   Author :       潘晓华</span><br><span class="line">   date：          2018/6/5</span><br><span class="line">-------------------------------------------------</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import unittest</span><br><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.remote.remote_connection import RemoteConnection</span><br><span class="line">import smtplib</span><br><span class="line">from email.mime.text import MIMEText</span><br><span class="line">from email.header import Header</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">TEST_USERNAME = &#x27;test&#x27;</span><br><span class="line">TEST_PASSWORD = &#x27;123456&#x27;</span><br><span class="line"></span><br><span class="line">NOTICE_EMAIL = &#x27;panxiaohua@mail.com&#x27;</span><br><span class="line"></span><br><span class="line">class SeleniumTestCase(unittest.TestCase):</span><br><span class="line">    def setUp(self):</span><br><span class="line">        remoteconnection = RemoteConnection(&#x27;http://zalenium.apps.example.com/wd/hub&#x27;,</span><br><span class="line">                                            keep_alive=False,</span><br><span class="line">                                            resolve_ip=False)</span><br><span class="line"></span><br><span class="line">        self.driver = webdriver.Remote(command_executor=remoteconnection,</span><br><span class="line">                                       desired_capabilities=&#123;</span><br><span class="line">                                           &#x27;browserName&#x27;: &quot;chrome&quot;,</span><br><span class="line">                                           &#x27;video&#x27;: &#x27;False&#x27;,</span><br><span class="line">                                           &#x27;platform&#x27;: &#x27;LINUX&#x27;,</span><br><span class="line">                                           &#x27;platformName&#x27;: &#x27;LINUX&#x27;</span><br><span class="line">                                       &#125;)</span><br><span class="line">        self.driver.implicitly_wait(30)</span><br><span class="line">        self.driver.maximize_window()</span><br><span class="line"></span><br><span class="line">    def test_login_test_case(self):</span><br><span class="line">        self.driver.get(&quot;http://pf.apps.example.com&quot;)</span><br><span class="line">        username_input = self.driver.find_element_by_id(&#x27;username&#x27;)</span><br><span class="line">        password_input = self.driver.find_element_by_id(&#x27;password&#x27;)</span><br><span class="line">        login_button = self.driver.find_element_by_id(&#x27;login_btn&#x27;)</span><br><span class="line">        username_input.clear()</span><br><span class="line">        username_input.send_keys(TEST_USERNAME)</span><br><span class="line">        password_input.clear()</span><br><span class="line">        password_input.send_keys(TEST_PASSWORD)</span><br><span class="line">        login_button.click()</span><br><span class="line">        try:</span><br><span class="line">            self.driver.find_element_by_id(&#x27;content&#x27;)</span><br><span class="line"></span><br><span class="line">            self.driver.get(&quot;http://pf.apps.example.com/dashboard/dailyresource&quot;)</span><br><span class="line"></span><br><span class="line">            self.driver.find_element_by_id(&#x27;content&#x27;)</span><br><span class="line"></span><br><span class="line">        except Exception, e:</span><br><span class="line">            self.notice_by_email()</span><br><span class="line"></span><br><span class="line">    def notice_by_email(self):</span><br><span class="line">        sender = &#x27;panxiaohua@mail.com&#x27;</span><br><span class="line">        message = MIMEText(u&#x27;自动平台有故障，请检查&#x27;, &#x27;plain&#x27;, &#x27;utf-8&#x27;)</span><br><span class="line">        message[&#x27;From&#x27;] = Header(u&quot;AutoPf&quot;)  # 发送者</span><br><span class="line">        message[&#x27;To&#x27;] = Header(&quot;panxiaohua&quot;)  # 接收者</span><br><span class="line"></span><br><span class="line">        subject = u&#x27;自动化平台有故障告警&#x27;</span><br><span class="line">        message[&#x27;Subject&#x27;] = Header(subject)</span><br><span class="line"></span><br><span class="line">        try:</span><br><span class="line">            smtpObj = smtplib.SMTP()</span><br><span class="line">            smtpObj.connect(&#x27;mail.com&#x27;, 25)  # 25 为 SMTP 端口号</span><br><span class="line">            smtpObj.login(sender, &#x27;123456&#x27;)</span><br><span class="line">            smtpObj.sendmail(sender, [NOTICE_EMAIL], message.as_string())</span><br><span class="line">            print u&quot;邮件发送成功&quot;</span><br><span class="line">        except smtplib.SMTPException:</span><br><span class="line">            print u&quot;Error: 无法发送邮件&quot;</span><br><span class="line"></span><br><span class="line">    def tearDown(self):</span><br><span class="line">        self.driver.quit()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    unittest.main()</span><br></pre></td></tr></table></figure><h2 id="制作监控镜像"><a href="#制作监控镜像" class="headerlink" title="制作监控镜像"></a>制作监控镜像</h2><p>基于python27,安装相关的模块，并将monitor.py导入镜像</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Dockerfile</span><br><span class="line">FROM centos/python-27-centos7:2.7</span><br><span class="line">RUN bash -c &#x27;pip install selenium -i https://pypi.douban.com/simple/&#x27;</span><br><span class="line">COPY monitor.py ./monitor.py</span><br></pre></td></tr></table></figure><h2 id="创建定时任务"><a href="#创建定时任务" class="headerlink" title="创建定时任务"></a>创建定时任务</h2><p>通过创建Cronjob每隔一个小时，运行创建的容器，并检测对应网站的状态。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># cronjob.yaml</span><br><span class="line">kind: CronJob</span><br><span class="line">apiVersion: batch/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: monitor</span><br><span class="line">spec:</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">            - name: monitor-autopf</span><br><span class="line">              image: harbor.apps.example.com/autopf/monitor:v1</span><br><span class="line">              imagePullPolicy: Always</span><br><span class="line">              command: [&quot;bash&quot;, &quot;-c&quot;, &quot;python monitor.py&quot;]</span><br><span class="line">          restartPolicy: Never</span><br><span class="line">  schedule: &quot;0 * * * *&quot;</span><br></pre></td></tr></table></figure><h2 id="通过configmap实现通用监控"><a href="#通过configmap实现通用监控" class="headerlink" title="通过configmap实现通用监控"></a>通过configmap实现通用监控</h2><p>很明显，以上的镜像只能针对该网站的指定两个页面（一个是登录后自动跳转的页面，另一个为“<a href="http://pf.apps.example.com/dashboard/dailyresource%E2%80%9D%EF%BC%89%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%9C%89%E6%96%B0%E7%9A%84%E7%9B%91%E6%8E%A7%E9%A1%B9%E6%88%96%E8%80%85%E5%AF%B9%E5%85%B6%E5%AE%83%E7%BD%91%E7%AB%99%E6%9C%89%E7%9B%91%E6%8E%A7%EF%BC%8C%E5%B0%B1%E5%BF%85%E9%A1%BB%E9%87%8D%E6%96%B0%E5%88%B6%E4%BD%9C%E5%AF%B9%E5%BA%94%E7%9A%84%E9%95%9C%E5%83%8F%E3%80%82%E8%BF%99%E5%B0%86%E4%BC%9A%E6%98%AF%E5%A4%9A%E9%BA%BB%E7%83%A6%E3%80%82">http://pf.apps.example.com/dashboard/dailyresource”），如果有新的监控项或者对其它网站有监控，就必须重新制作对应的镜像。这将会是多麻烦。</a><br>通过ConfigMap可以将监控代码作为变动项，而保证镜像统一。也就是说将monitor.py（或者有其它依赖的文件）作为configmap资源，挂载到镜像中，最后再通过设置command来执行监控。</p><blockquote><p>创建ConfigMap将monitor.py代码放在configmap中</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  monitor.py: &quot;# -*- coding: utf-8 -*-\r\n\&quot;\&quot;\&quot;\r\n-------------代码内容---------------unittest.main()&quot;</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  name: monitor</span><br></pre></td></tr></table></figure><blockquote><p>将它挂载到Cronjob中的&#x2F;opt&#x2F;app-root&#x2F;src下</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - command:</span><br><span class="line">            - bash</span><br><span class="line">            - -c</span><br><span class="line">            - python monitor.py</span><br><span class="line">            image: harbor.apps.example.com/autopf/monitor:v1</span><br><span class="line">            imagePullPolicy: Always</span><br><span class="line">            name: monitor-autopf</span><br><span class="line">            volumeMounts:</span><br><span class="line">            - mountPath: /opt/app-root/src</span><br><span class="line">              name: monitor-cm</span><br><span class="line">          restartPolicy: Never</span><br><span class="line">          volumes:</span><br><span class="line">          - configMap:</span><br><span class="line">              defaultMode: 420</span><br><span class="line">              name: monitor</span><br><span class="line">            name: monitor-cm</span><br><span class="line">  schedule: 0 */6 * * *</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>至此便完成了通用监控镜像，如果监控有更新，只需要更改configmap中的monitor.py的代码即可。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何在Openshift中让Router-Pod独占Router节点</title>
      <link href="/openshift/%E5%A6%82%E4%BD%95%E5%9C%A8Openshift%E4%B8%AD%E8%AE%A9Router-Pod%E7%8B%AC%E5%8D%A0Router%E8%8A%82%E7%82%B9/"/>
      <url>/openshift/%E5%A6%82%E4%BD%95%E5%9C%A8Openshift%E4%B8%AD%E8%AE%A9Router-Pod%E7%8B%AC%E5%8D%A0Router%E8%8A%82%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-30e44664b5eab0cd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="如何在Openshift中让Router Pod独占Router节点.png"></p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><blockquote><p>什么是Router Pod?</p></blockquote><p>Router Pod是Openshift中管理外部流量访问集群服务的重要的入口，它是通过一个haproxy的Pod实现的。由于Router Pod的独特性，几乎所有的流量都过Router中的Pod代理到真正的服务，所以它是一个非常非常重要的服务。</p><blockquote><p>什么是Router节点</p></blockquote><p>因为集群中的Router Pod数量是有限的，外部流量通过负载均衡器到达Router的Pod，所以对于Router Pod必须固定在负载均衡器下的节点上。这些运行Router Pod的节点，我们叫做Router节点。<br>它有两个特点：</p><ol><li>运行default&#x2F;router的pod; </li><li>被外部负载均衡器监听</li></ol><h2 id="为什么需要让Router-Pod独占Router节点上"><a href="#为什么需要让Router-Pod独占Router节点上" class="headerlink" title="为什么需要让Router Pod独占Router节点上"></a>为什么需要让Router Pod独占Router节点上</h2><p>几乎所有的外部访问集群服务的流量都通过Router Pod代理，所以它是非常重要。在正式使用时，需要对它进行保护。让它独占节点，防止其它Pod抢占Router Pod的资源，以确保集群下服务的可用性。</p><h2 id="具体实施Router-Pod独占绑定Router节点"><a href="#具体实施Router-Pod独占绑定Router节点" class="headerlink" title="具体实施Router Pod独占绑定Router节点"></a>具体实施Router Pod独占绑定Router节点</h2><ol><li>Router节点上添加label<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc label node router1.it.example.com router=true</span><br></pre></td></tr></table></figure></li><li>Route节点上添加taint <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc adm taint node router2.it.example.com router=true:NoSchedule</span><br></pre></td></tr></table></figure></li><li>Router的DC上添加节点亲和配置<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">      affinity:</span><br><span class="line">        nodeAffinity:</span><br><span class="line">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            nodeSelectorTerms:</span><br><span class="line">            - matchExpressions:</span><br><span class="line">              - key: router</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                - &quot;true&quot;</span><br></pre></td></tr></table></figure></li><li>Router的DC上使用污点容忍<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">      tolerations:</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: router</span><br><span class="line">        operator: Exists</span><br></pre></td></tr></table></figure></li></ol><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul><li>最开始的时候并没有使用Node Affinity,而是使用nodeSelector来绑定Pod与Node。但是使用nodeSelector后，部署pod时集群部署pod(pod_deploy)会带上nodeSelector的属性，而并不会带上容忍污点tolerations的属性，这就导致了pod_deploy无法被调度。</li><li>解决办法 ：用nodeAffinity替换nodeSelector。pod_deploy也不会带上nodeAffinity的属性，成功被调度</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p>Pod的调度规则请参考： <a href="https://www.jianshu.com/p/40050e2a05d4">玩转Openshift中Pod调度</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何为运行OpenShift容器的数字用户设置用户名</title>
      <link href="/openshift/%E5%A6%82%E4%BD%95%E4%B8%BA%E8%BF%90%E8%A1%8COpenShift%E5%AE%B9%E5%99%A8%E7%9A%84%E6%95%B0%E5%AD%97%E7%94%A8%E6%88%B7%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%90%8D/"/>
      <url>/openshift/%E5%A6%82%E4%BD%95%E4%B8%BA%E8%BF%90%E8%A1%8COpenShift%E5%AE%B9%E5%99%A8%E7%9A%84%E6%95%B0%E5%AD%97%E7%94%A8%E6%88%B7%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7%E5%90%8D/</url>
      
        <content type="html"><![CDATA[<p>OpenShift容器平台会使用一个不带用户名，数字类型的用户ID（如：10003000）来运行容器，但是有些情况下启动应用的用户必须有用户名，比如访问sftp服务。</p><p><strong>解决思路：</strong>在容器中的&#x2F;etc&#x2F;passwd文件中添加对执行用户的相关配置：<USER NAME>:x:<UID>:<GID>:&lt;说明&gt;:<HOME>:&#x2F;sbin&#x2F;nologin。</p><p><strong>执行步骤</strong></p><ol><li>基础镜像中为&#x2F;etc&#x2F;passwd设置root组用户可写的权限<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN chmod g=u /etc/passwd</span><br></pre></td></tr></table></figure></li><li>应用启动时为用户设置用户名，要在ENTRYPOINT&#x2F;CMD的脚本中添加如下代码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">USER_NAME=$&#123;USER_NAME:-uidname&#125;</span><br><span class="line">USER_ID=$(id -u)</span><br><span class="line">if ! whoami &amp;&gt; /dev/null</span><br><span class="line">then</span><br><span class="line">    if [ -w /etc/passwd ]</span><br><span class="line">    then</span><br><span class="line">      echo &quot;$&#123;USER_NAME&#125;:x:$&#123;USER_ID&#125;:0:$&#123;USER_NAME&#125; user:$&#123;HOME&#125;:/sbin/nologin&quot; &gt;&gt; /etc/passwd</span><br><span class="line">    fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对文件目录设置acl权限</title>
      <link href="/openshift/%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E8%AE%BE%E7%BD%AEacl%E6%9D%83%E9%99%90/"/>
      <url>/openshift/%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E8%AE%BE%E7%BD%AEacl%E6%9D%83%E9%99%90/</url>
      
        <content type="html"><![CDATA[<p>尽管 sudo 可以设置某个用户有特殊权限，确实会增大这个用户的权限。</p><p>为了限制这个特殊目录只有特定用户可以读，您可以对特殊用户设置目录访问控制列表 acl。</p><p>以 user 用户为例，这样设置之后可以实现只有 user 用户可以对这个目录有读权限，其他普通用户无权限</p><p>setfacl -m u:user:r– &#x2F;目录名&#x2F;文件名</p><p>如果想要一次设置可以添加 -R 参数 递归设置整个目录，以及整个目录下的所有文件</p><p>setfacl -R -m u:user:r– &#x2F;目录名&#x2F;</p><p>这样就可以保证某个特殊普通用户对这个目录有可读权限</p><p>如果这个目录需要 user 用户可以 cd 进入的话，设置时可以增加大写 X 参数，设置 acl 的时候，大写 X 表示遇到目录给执行权限，遇到文件对象不给执行权限</p><p>setfacl -m u:user:r-X &#x2F;目录名&#x2F;<br>setfacl -m u:user:r-X &#x2F;目录名&#x2F;文件名</p><p>这样设置，可以让 user 用户能 cd 进入特殊目录</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>容器平台武林盟主争夺大战</title>
      <link href="/openshift/%E5%AE%B9%E5%99%A8%E5%B9%B3%E5%8F%B0%E6%AD%A6%E6%9E%97%E7%9B%9F%E4%B8%BB%E4%BA%89%E5%A4%BA%E5%A4%A7%E6%88%98/"/>
      <url>/openshift/%E5%AE%B9%E5%99%A8%E5%B9%B3%E5%8F%B0%E6%AD%A6%E6%9E%97%E7%9B%9F%E4%B8%BB%E4%BA%89%E5%A4%BA%E5%A4%A7%E6%88%98/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-9c74137ec2e019d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="容器平台武林盟主争夺大战"></p><p>容器技术是继虚拟化技术后又一革命性的后台技术，厂商为了争夺容器PaaS的话语权，必将发起一场声势浩大的战争。谁也没想到挑起这场革命性战争的竟然是一家仅3年的创业公司——dotCloud。</p><h2 id="2013年前：大战前夕——一片祥和"><a href="#2013年前：大战前夕——一片祥和" class="headerlink" title="2013年前：大战前夕——一片祥和"></a>2013年前：大战前夕——一片祥和</h2><ul><li>虚拟化技术已经深入人心，以aws与openstack为主的云平台已经非常成熟。</li><li>PaaS理念也得到了普及，cloud foundry成为当时PaaS的标准<blockquote><p>cloud foundry吸引了包括百度、京东、华为、IBM 等一大批国内外技术厂商，开启了以开源 PaaS 为核心构建平台层服务能力的变革。“PaaS 的时代就要来了！”</p></blockquote></li><li>PaaS公司有：Cloud foundry、Heroku、Pivotal、Red Hat</li><li>PaaS 项目被大家接纳的一个主要原因，就是它提供了一种名叫“应用托管”的能力。</li></ul><h2 id="2013年容器武林大战——一鸣惊人"><a href="#2013年容器武林大战——一鸣惊人" class="headerlink" title="2013年容器武林大战——一鸣惊人"></a>2013年容器武林大战——一鸣惊人</h2><p><img src="https://upload-images.jianshu.io/upload_images/5793257-23a2240b7a21459e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="Docker横空出世"></p><ul><li><p>2013年3月：一家创业公司dotCloud开源了它的产品Docker，解决应用构建、分发与发布的问题，它的最大改进是引入了镜像构建。</p><blockquote><p>Cloud Foundry 的首席产品经理 James Bayer 做了一次详细对比：Docker 使用的还是老技术 Cgroups 和 Namespace ，没有什么特别的新东西，掀不起什么浪。<br>Docker一经发布，便得到的社区的追捧，各大厂商也都相继合作，推出基于Docker的PaaS产品，它的一个小创新，却给迷茫已久的PaaS指明了前进的道路。</p></blockquote></li><li><p>2013年6月：Redhat开始了基于Docker的容器平台Openshift的研发</p></li><li><p>2013年10月：RedHat正式与dotCloud合作</p></li><li><p>2013年：CoreOS成为Docker项目的贡献者，并在短时间内成为了 Docker 项目中第二重要的力量。</p></li><li><p>2013年10月：Google发布了自己所用Linux容器系统的开源版本lmctfy（Let Me Container That For You）</p></li></ul><blockquote><p>面对Docker的强势崛起，Imctfy毫无招架之力，很快关停了该项目，并希望与Docker公司合作共同推进一个中立的容器运行时库作为Docker项目的核心依赖。<br>Docker拒绝了与Google的合作，不久发布了一个容器运行时库 Libcontainer。</p></blockquote><h2 id="2014年容器武林大战——三国鼎立"><a href="#2014年容器武林大战——三国鼎立" class="headerlink" title="2014年容器武林大战——三国鼎立"></a>2014年容器武林大战——三国鼎立</h2><p><img src="https://upload-images.jianshu.io/upload_images/5793257-1aeeb40d089ce837.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="三国鼎立"></p><ul><li>2014年-2015年：Docker 项目的迅速走红催生出了一个非常繁荣的“Docker 生态”<blockquote><p>Docker 生态创业公司们的春天，大量围绕着 Docker 项目的网络、存储、监控、CI&#x2F;CD，甚至 UI 项目纷纷出台，也涌现出了很多 Rancher、Tutum 这样在开源与商业上均取得了巨大成功的创业公司。</p></blockquote></li><li>2014年6月6日：Google发布了一个名叫 Kubernetes 项目，并早早与RedHat建立合作关系，共同维护推广。<blockquote><p>面对着如日中天，而又野心勃勃的Docker，Google终于坐不住了。大家一致认为：Docker作为底层技术，对终端用户影响力终究有限，容器之战最终仍旧会落在PaaS之争上。借助于RedHat在开源软件上的经验与优势，Google强势推出了自己的杀手级产品Kubernetes。</p></blockquote></li><li>2014年6月10日：Docker 1.0版本发布</li><li>2014 年 7 月：Docker 收购 Orchard 掀起了收购的序幕 ，将Fig项目更名为compose<blockquote><p>Fig 项目之所以受欢迎，在于它在开发者面前第一次提出了“容器编排”（Container Orchestration）的概念。</p></blockquote></li><li>2014年10月15日：Azure云和Docker共同举办了Docker全球开发者大会。微软与Docker正式达成合作关系。</li><li>2014年12月：Docker公司与CoreOS公司决裂，推出了自己研制的 Rocket（后来叫 rkt）容器。</li><li>2014 年12月：Docker公司发布Swarm项目，重新加入PaaS项目战场。三国鼎立形成。<blockquote><p>coreos公司的rkt打不开局面，Fleet集群管理项目更是少有人问津，coreos公司完败。<br>RedHat公司作为日期Docker的贡献者也与Docker公司决裂，只剩下Openshfit上一代Paas平台，被Mesos与Swarm碾压。</p></blockquote></li></ul><h2 id="2015年容器武林大——论持久战"><a href="#2015年容器武林大——论持久战" class="headerlink" title="2015年容器武林大——论持久战"></a>2015年容器武林大——论持久战</h2><ul><li>Mesosphere 公司发布了一个名为 Marathon 的项目，它是Mesos的私有PaaS，很快就成为了 Docker Swarm 的一个有力竞争对手。<blockquote><p>虽然不能提供像 Swarm 那样的原生 Docker API，Mesos 社区却拥有一个独特的竞争力：超大规模集群的管理经验。</p></blockquote></li><li>2015年：3月Docker公司收购SocketPlane、Kitematic，10月收购Tutum。Docker在公有市场，企业化的私有市场都有了完善的解决方案</li><li>2015年4月8日：Google和CoreOS宣布了一个新项目Tectonic。Google投资了CoreOS $1200万，CoreOS正式投入Google阵营</li><li>2015年5月：Docker公司正式进驻中国。</li><li>2015 年 6 月 22 日：由 Docker 公司牵头，CoreOS、Google、RedHat 等公司共同宣布，Docker 公司将 Libcontainer 捐出，并改名为 RunC 项目</li><li>2015年7月：谷歌与Linux基金会以及众多行业合作伙伴准备共同建立一个云计算基金会（CNCF），Kubernetes1.0发布</li><li>2015年7月：Openshift Enterprise V3发布，结合Docker与K8s</li><li>2015年：传言微软希望40亿美元收购Docker，以摆脱对K8s的依赖，最终没成</li></ul><h2 id="2016年容器武林大战——背水一战"><a href="#2016年容器武林大战——背水一战" class="headerlink" title="2016年容器武林大战——背水一战"></a>2016年容器武林大战——背水一战</h2><ul><li>2016年：微软公司也于2016年正式推出Windows容器。</li><li>2016年：Docker公司放弃现有的 Swarm 项目，将容器编排和集群管理功能全部内置到 Docker 项目当中。Docker希望利用广大的Docker用户群，实现Swarm的普及，但是适得其反，Docker变得很复杂，稳定性下降。<blockquote><p>K8s的战略则恰愉相反，整个社区推行“民主化”，从 API 到容器运行时的每一层，Kubernetes 项目都为开发者暴露出了可以扩展的插件机制，鼓励用户通过代码的方式介入到 Kubernetes 项目的每一个阶段。很快Docker的Swarm败下阵来，丢失了开发者的支持。</p></blockquote></li><li>这一次容器社区的繁荣，是一次完全以 Kubernetes 项目为核心的“百花争鸣”。<blockquote><p>istio&#x2F;Operator&#x2F;Rook等等</p></blockquote></li><li>Docker的背水一战，并没有挽回局势，败局已定。</li></ul><h2 id="2017年容器武林大战——清扫战场"><a href="#2017年容器武林大战——清扫战场" class="headerlink" title="2017年容器武林大战——清扫战场"></a>2017年容器武林大战——清扫战场</h2><ul><li>2017年1月：Kubernetes 1.5发布，引入了Container Runtime Initiative（CRI）API，支持可插拔的容器运行时</li><li>2017年3月29日：Docker将 Docker 项目的容器运行时部分 Containerd 捐赠给 CNCF 社区</li><li>2017年4月：Docker 开源社区版改名为 Moby</li><li>2017年8月10日：Openshift 3.6版本</li><li>2017年10月：Docker公司在自己的Docker 企业版中内置 Kubernetes 项目</li></ul><h2 id="2018年容器武林大战——天下一统"><a href="#2018年容器武林大战——天下一统" class="headerlink" title="2018年容器武林大战——天下一统"></a>2018年容器武林大战——天下一统</h2><ul><li>2018 年 1 月 30 日，RedHat 宣布斥资 2.5 亿美元收购 CoreOS。</li><li>2018 年 3 月 28 日，Docker 公司的 CTO Solomon Hykes 宣布辞职。</li></ul><p> 至此容器武林重归太平，K8S稳坐武林盟主之位。</p><h2 id="2019年容器武林大战——最终归属"><a href="#2019年容器武林大战——最终归属" class="headerlink" title="2019年容器武林大战——最终归属"></a>2019年容器武林大战——最终归属</h2><ul><li>2019年5月，红帽OpenShift 4发布。</li><li>2019年7月，蓝色巨人IBM官方宣布，正式完成对红帽(Red Hat)的收购，耗资340亿美元(约合人民币2340亿元)。</li><li>2019年11月，Mirantis今天收购了Docker的企业业务和团队。</li></ul><p><img src="https://upload-images.jianshu.io/upload_images/5793257-fbc872f833dbc7c4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="武林盟主"></p><p>Docker作为一家创业公司，通过开源社区的运作取得了巨大的成功之后，雄心勃勃，直面天下武林世家的竞争与围剿，孤身一人对抗整个云计算产业的压力，最后以惨败收场，前景堪忧。<br>但是也因此容器技术在短短几年间深入人心，得到了飞速的发展。</p><h2 id="各大门派旗帜"><a href="#各大门派旗帜" class="headerlink" title="各大门派旗帜"></a>各大门派旗帜</h2><p><img src="https://upload-images.jianshu.io/upload_images/5793257-4d5c4b4794354bdb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="武林世家.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>应用日志方案</title>
      <link href="/openshift/%E5%BA%94%E7%94%A8%E6%97%A5%E5%BF%97%E6%96%B9%E6%A1%88/"/>
      <url>/openshift/%E5%BA%94%E7%94%A8%E6%97%A5%E5%BF%97%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<table><thead><tr><th></th><th>原生方式</th><th>DaemonSet方式</th><th>Sidecar方式</th></tr></thead><tbody><tr><td>集日志类型</td><td>标准输出</td><td>标准输出</td><td>文件</td></tr><tr><td>部署运维</td><td>低，原生支持</td><td>一般，需维护DaemonSet</td><td>较高，需要为每个容器采集日志的</td></tr><tr><td>日志分类存储</td><td>无法实现</td><td>可通过容器、路径映射实现</td><td>每个Pod可单独配置，灵活性高</td></tr><tr><td>支持集群规模</td><td>本地存储无限制，若使用syslog&#x2F;fluentd会有单点限制</td><td>取决于配置数</td><td>无限制</td></tr><tr><td>资源占用</td><td>低，docker引擎提供</td><td>较低，每个节点运行一个容器</td><td>较高，每个Pod运行一个容器</td></tr><tr><td>查询便捷性</td><td>低，grep原始日志</td><td>较高，自定义查询、统计</td><td>高，根据业务特点定制</td></tr><tr><td>适用场景</td><td>测试、POC等非生产环境</td><td>日志分类明确的集群</td><td>大型、混合型集群</td></tr></tbody></table>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快速使用SonarQube对应用进行静态代码扫描</title>
      <link href="/openshift/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8SonarQube%E5%AF%B9%E5%BA%94%E7%94%A8%E8%BF%9B%E8%A1%8C%E9%9D%99%E6%80%81%E4%BB%A3%E7%A0%81%E6%89%AB%E6%8F%8F/"/>
      <url>/openshift/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8SonarQube%E5%AF%B9%E5%BA%94%E7%94%A8%E8%BF%9B%E8%A1%8C%E9%9D%99%E6%80%81%E4%BB%A3%E7%A0%81%E6%89%AB%E6%8F%8F/</url>
      
        <content type="html"><![CDATA[<p>1、启动SonarQube服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /sonar/&#123;conf,data,extensions&#125;</span><br><span class="line">$ docker run -v /sonar/conf:/opt/sonarqube/conf -v /sonar/data:/opt/sonarqube/data -v /sonar/extensions:/opt/sonarqube/extensions -p 9000:9000 xhuaustc/sonarqube:7.9.1</span><br></pre></td></tr></table></figure><p><code>本地目录为~/Downloads/sonar/</code><br>2、登录SonarQube服务端：<a href="http://127.0.0.1:9000/projects">http://127.0.0.1:9000/projects</a>，登录用户名：<code>admin</code>，密码：<code>admin</code><br>3、创建新的项目,获得projectKey与token值<br>4、下载对应版本的sonar scanner工具：<a href="https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/">SonarScanner下载地址</a><br>5、请在代码目录中执行扫描工具</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/xx/bin/sonar-scanner \</span><br><span class="line">  -Dsonar.projectKey=test \</span><br><span class="line">  -Dsonar.sources=. \</span><br><span class="line">  -Dsonar.host.url=http://127.0.0.1:9000 \</span><br><span class="line">  -Dsonar.login=647c09f3fc72c1b935fb06f20941833435690652 \</span><br><span class="line">  -Dsonar.exclusions=**/*R*.java，**/*Test.java,**/*(!.java),**/*.js</span><br></pre></td></tr></table></figure><p>exclusions排除文件说明：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">? 匹配单个字符 </span><br><span class="line">** 匹配0个或多个文件夹 </span><br><span class="line">* 匹配0个或多个字符</span><br></pre></td></tr></table></figure><p><code>本地目录为~/Downloads/sonar-scanner-4.2.0.1873-macosx</code><br>5、登录到SonarQube服务端，查看扫描结果。主要关注issues中的Bug与Vulnerability</p><p><code>说明</code><br>也可以直接通过docker来扫描应用，参考<a href="https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/#">https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/#</a><br>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">    --rm \</span><br><span class="line">    --user=&quot;$(id -u):$(id -g)&quot; \</span><br><span class="line">    -e SONAR_HOST_URL=&quot;http://$&#123;SONARQUBE_URL&#125;&quot;  \</span><br><span class="line">    -v &quot;$&#123;YOUR_REPO&#125;:/usr/src&quot; \</span><br><span class="line">    sonarsource/sonar-scanner-cli</span><br></pre></td></tr></table></figure><h2 id="插件补充"><a href="#插件补充" class="headerlink" title="插件补充"></a>插件补充</h2><p>1、导出pdf报告插件【适用SonarQube版本 : 5.5–7.5】<br><a href="https://gitee.com/zzulj/sonar-pdf-plugin">https://gitee.com/zzulj/sonar-pdf-plugin</a></p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://www.sonar.org.cn/install/2278.html">SonarQube中文网站</a><br><a href="https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/">SonarScanner下载地址</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>技术中台</title>
      <link href="/openshift/%E6%8A%80%E6%9C%AF%E4%B8%AD%E5%8F%B0/"/>
      <url>/openshift/%E6%8A%80%E6%9C%AF%E4%B8%AD%E5%8F%B0/</url>
      
        <content type="html"><![CDATA[<p><strong>金融机构中台战略之路</strong></p><p>在传统金融机构体系中，系统往往由各个项目组独立建设，每个机构中有成百上千套复杂的系统，它们相互调用，形成复杂的网状结构，很难进行管理。随着银行数字化转型的深入，大量业务以互联网的形式向用户开放，对系统高并发、大数据量、强一致性等需求越来越高。与此同时，为了满足用户多样化的需求，银行必须从以业务为中心向以人为中心转变，并做出快速响应。中台建设正是目前解决这些问题的新兴平台型企业架构。</p><p>企业中台为业务而生，快速敏捷地响应业务变化，以服务的形式为业务提供支撑，服务接入层以统一的路由适配转发。在整个技术构架上需要考虑可拓展性、敏捷性、轻量化，并注重与前台的交互，灵活地通过服务编排实现应用功能，满足前台需求。因此中台融合分布式、微服务、容器云、DevOps、大数据处理及高可用高性能高并发架构，遵循“高内聚、松耦合”设计原则。业务中台需要微服务、云原生、分布式事务体系支撑，并设计业务模型和微服务边界，最终形成业务单元；数据中台汇聚企业内外割裂的数据，并通过统一治理、建模加工，消除数据孤岛，实现数据资产化，为企业提供客户画像、商品智能推荐、业务实时监控，达到数据驱动业务能力。中台不是微服务，但微服务是当前数字中台建设的最佳实践。中间件服务、容器平台、DevOps、微服务是中台建设的最佳载体，也是技术中台建设的主要内容。<br><img src="https://upload-images.jianshu.io/upload_images/5793257-9ce4dafc94bf3c4a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="技术中台"></p><p>图 技术中台主要内容</p><p><strong>技术中台组成</strong></p><p><strong>容器平台</strong></p><p><strong>DevOps</strong></p><p>DevOps平台主要关注与开发效能管理，</p><p><strong>微服务治理</strong></p><p>中台建设的最大挑战</p><p>中台建设只是手段，并不是目标。以用户为中心的持续规模化创新，是中台建设的核心目标。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库写测试</title>
      <link href="/openshift/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%99%E6%B5%8B%E8%AF%95/"/>
      <url>/openshift/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%99%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<p>先出结果<br>数据库Mysql 5.7<br>数据</p><table><thead><tr><th></th><th>NetApp</th><th>Ceph</th><th>NFS-SSD</th><th>NFS-SAS</th><th>HOST PATH</th></tr></thead><tbody><tr><td>写(qtps)</td><td>33333</td><td>888</td><td>20000</td><td>3000</td><td></td></tr><tr><td>延时(us)</td><td>1029</td><td>40488</td><td>1184</td><td></td><td></td></tr></tbody></table><blockquote><ol><li>NetApp</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">2018-06-27 17:56:45 ======================== mysql_test ========================</span><br><span class="line">2018-06-27 17:56:45 SQL01  exe=5000 fail=0 row=5000 ela=5180 ms avg=1036 us</span><br><span class="line">2018-06-27 17:56:45 SQL01    1 ms  exec=    2853, ela=      2530 ms, avg=     886 us, pct= 57, 57</span><br><span class="line">2018-06-27 17:56:45 SQL01    2 ms  exec=    2122, ela=      2443 ms, avg=    1151 us, pct= 42, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01    3 ms  exec=      10, ela=        24 ms, avg=    2475 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01    4 ms  exec=       1, ela=         3 ms, avg=    3044 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01    5 ms  exec=       1, ela=         4 ms, avg=    4847 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01    7 ms  exec=       1, ela=         6 ms, avg=    6115 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01    8 ms  exec=       1, ela=         7 ms, avg=    7578 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01    9 ms  exec=       1, ela=         8 ms, avg=    8736 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01   12 ms  exec=       1, ela=        11 ms, avg=   11764 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01   13 ms  exec=       4, ela=        50 ms, avg=   12516 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01   15 ms  exec=       1, ela=        14 ms, avg=   14704 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01   18 ms  exec=       2, ela=        34 ms, avg=   17307 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01   20 ms  exec=       1, ela=        19 ms, avg=   19099 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:56:45 SQL01   21 ms  exec=       1, ela=        20 ms, avg=   20897 us, pct=  0,100</span><br><span class="line">2018-06-27 17:56:45 Total  tran=5000=964/s, qtps=5000=964/s, ela=5181 ms, avg=1036 us</span><br><span class="line">Summary: SQL01 exec=200000, rows=200000=100/e, avg=1029 us</span><br><span class="line">Summary: exec=33333/s, qtps=33333/s</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><ol start="2"><li>Ceph</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">2018-06-27 17:45:33 ======================== mysql_test ========================</span><br><span class="line">2018-06-27 17:45:33 SQL01  exe=200 fail=0 row=200 ela=8263 ms avg=41318 us</span><br><span class="line">2018-06-27 17:45:33 SQL01   31 ms  exec=       1, ela=        30 ms, avg=   30480 us, pct=  0,  0</span><br><span class="line">2018-06-27 17:45:33 SQL01   33 ms  exec=       3, ela=        98 ms, avg=   32802 us, pct=  1,  2</span><br><span class="line">2018-06-27 17:45:33 SQL01   35 ms  exec=     129, ela=      4446 ms, avg=   34468 us, pct= 64, 66</span><br><span class="line">2018-06-27 17:45:33 SQL01   36 ms  exec=       1, ela=        35 ms, avg=   35763 us, pct=  0, 67</span><br><span class="line">2018-06-27 17:45:33 SQL01   37 ms  exec=       3, ela=       108 ms, avg=   36208 us, pct=  1, 68</span><br><span class="line">2018-06-27 17:45:33 SQL01   39 ms  exec=       2, ela=        76 ms, avg=   38462 us, pct=  1, 69</span><br><span class="line">2018-06-27 17:45:33 SQL01   40 ms  exec=       2, ela=        78 ms, avg=   39477 us, pct=  1, 70</span><br><span class="line">2018-06-27 17:45:33 SQL01   41 ms  exec=      27, ela=      1088 ms, avg=   40297 us, pct= 13, 84</span><br><span class="line">2018-06-27 17:45:33 SQL01   45 ms  exec=       1, ela=        44 ms, avg=   44629 us, pct=  0, 84</span><br><span class="line">2018-06-27 17:45:33 SQL01   46 ms  exec=       2, ela=        91 ms, avg=   45957 us, pct=  1, 85</span><br><span class="line">2018-06-27 17:45:33 SQL01   47 ms  exec=       1, ela=        46 ms, avg=   46364 us, pct=  0, 86</span><br><span class="line">2018-06-27 17:45:33 SQL01   52 ms  exec=       4, ela=       206 ms, avg=   51729 us, pct=  2, 88</span><br><span class="line">2018-06-27 17:45:33 SQL01   53 ms  exec=       2, ela=       104 ms, avg=   52335 us, pct=  1, 89</span><br><span class="line">2018-06-27 17:45:33 SQL01   54 ms  exec=       1, ela=        53 ms, avg=   53647 us, pct=  0, 89</span><br><span class="line">2018-06-27 17:45:33 SQL01   58 ms  exec=       1, ela=        57 ms, avg=   57284 us, pct=  0, 90</span><br><span class="line">2018-06-27 17:45:33 SQL01   60 ms  exec=       1, ela=        59 ms, avg=   59134 us, pct=  0, 90</span><br><span class="line">2018-06-27 17:45:33 SQL01   62 ms  exec=       1, ela=        61 ms, avg=   61386 us, pct=  0, 91</span><br><span class="line">2018-06-27 17:45:33 SQL01   64 ms  exec=       2, ela=       126 ms, avg=   63084 us, pct=  1, 92</span><br><span class="line">2018-06-27 17:45:33 SQL01   69 ms  exec=       3, ela=       206 ms, avg=   68766 us, pct=  1, 93</span><br><span class="line">2018-06-27 17:45:33 SQL01   75 ms  exec=       1, ela=        74 ms, avg=   74645 us, pct=  0, 94</span><br><span class="line">2018-06-27 17:45:33 SQL01   76 ms  exec=       1, ela=        75 ms, avg=   75024 us, pct=  0, 94</span><br><span class="line">2018-06-27 17:45:33 SQL01   77 ms  exec=       2, ela=       152 ms, avg=   76125 us, pct=  1, 95</span><br><span class="line">2018-06-27 17:45:33 SQL01   84 ms  exec=       1, ela=        83 ms, avg=   83939 us, pct=  0, 96</span><br><span class="line">2018-06-27 17:45:33 SQL01   87 ms  exec=       2, ela=       172 ms, avg=   86187 us, pct=  1, 97</span><br><span class="line">2018-06-27 17:45:33 SQL01   92 ms  exec=       1, ela=        91 ms, avg=   91817 us, pct=  0, 97</span><br><span class="line">2018-06-27 17:45:33 SQL01   98 ms  exec=       1, ela=        97 ms, avg=   97461 us, pct=  0, 98</span><br><span class="line">2018-06-27 17:45:33 SQL01  109 ms  exec=       1, ela=       108 ms, avg=  108786 us, pct=  0, 98</span><br><span class="line">2018-06-27 17:45:33 SQL01  110 ms  exec=       1, ela=       109 ms, avg=  109178 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:45:33 SQL01  115 ms  exec=       1, ela=       114 ms, avg=  114209 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:45:33 SQL01  163 ms  exec=       1, ela=       162 ms, avg=  162020 us, pct=  0,100</span><br><span class="line">2018-06-27 17:45:33 Total  tran=200=24/s, qtps=200=24/s, ela=8264 ms, avg=41320 us</span><br><span class="line">Summary: SQL01 exec=8000, rows=8000=100/e, avg=40488 us</span><br><span class="line">Summary: exec=888/s, qtps=888/s</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><ol start="3"><li>NFS</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2018-06-27 17:49:03 ======================== mysql_test ========================</span><br><span class="line">2018-06-27 17:49:03 SQL01  exe=2000 fail=0 row=2000 ela=2389 ms avg=1194 us</span><br><span class="line">2018-06-27 17:49:03 SQL01    1 ms  exec=    1613, ela=      1267 ms, avg=     785 us, pct= 80, 80</span><br><span class="line">2018-06-27 17:49:03 SQL01    2 ms  exec=     380, ela=       434 ms, avg=    1144 us, pct= 19, 99</span><br><span class="line">2018-06-27 17:49:03 SQL01    3 ms  exec=       3, ela=         7 ms, avg=    2397 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:49:03 SQL01    5 ms  exec=       1, ela=         4 ms, avg=    4316 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:49:03 SQL01   13 ms  exec=       2, ela=        25 ms, avg=   12671 us, pct=  0, 99</span><br><span class="line">2018-06-27 17:49:03 SQL01  512 ms  exec=       1, ela=       650 ms, avg=  650205 us, pct=  0,100</span><br><span class="line">2018-06-27 17:49:03 Total  tran=2000=836/s, qtps=2000=836/s, ela=2389 ms, avg=1194 us</span><br><span class="line">Summary: SQL01 exec=80000, rows=80000=100/e, avg=1184 us</span><br><span class="line">Summary: exec=20000/s, qtps=20000/s</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>某股份制银行：容器云平台建设实践</title>
      <link href="/openshift/%E6%9F%90%E8%82%A1%E4%BB%BD%E5%88%B6%E9%93%B6%E8%A1%8C%EF%BC%9A%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/"/>
      <url>/openshift/%E6%9F%90%E8%82%A1%E4%BB%BD%E5%88%B6%E9%93%B6%E8%A1%8C%EF%BC%9A%E5%AE%B9%E5%99%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<p><strong>容器云平台建设行业背景</strong></p><p>当前银行业普遍的共识之一是要以金融科技为依托，通过科技创新引领银行的转型升级。云计算、大数据、人工智能成为各银行科技部门重点的投资建设领域。云计算领域的建设主要集中在IaaS和PaaS，目标是降低数据中心成本的同时，为上层应用的创新、快速迭代和稳定运行提供有效支撑。传统的IaaS调度的是虚拟机或者物理机，粒度较大，相对传统的虚拟化技术，在资源使用率、灵活性和弹性方面提升度并不高。依托传统IaaS建设而成的PaaS，也会面临同样的问题。而容器技术恰好可以比较好的解决这些问题，并且在微服务、DevOps、分布式等方面天生具备优势，因此成为数据中心新一代云基础架构的选择。</p><p><strong>建设容器云平台的意义</strong></p><p>1.让应用真正意义上弹性扩缩容</p><p>传统方式下应用和基础环境资源（计算、网络、存储、监控等） 是紧耦合的关系，应用的扩容、缩容意味着基础环境资源的扩容和缩容。基础环境的扩、缩容耗时会非常长，因为涉及到非常多需要人工介入的环境，而且都是串行的，比如创建主机、分配存储、网络接入、操作系统安装、网络访问关系开通、应用部署、监控审计部署、接入负载均衡等等。整个流程走下来通常需要数天到数周的时间。后来我们通过IaaS、虚拟化、自动化工具已经大幅度缩减了基础环境资源扩容的时间，但是整个流程下来仍然需要数个小时到数天，这对于真正需要弹性的应用来说还是不够。</p><p>容器云环境下，应用和基础环境资源是解耦的，应用的扩缩容不需要涉及基础环境资源的扩缩容，仅仅需要修改应用部署模板文件中的副本数，然后在容器云平台执行即可。容器云平台会根据副本数来自动创建或者删除副本，使得最终的副本数是部署模板文件中定义的副本数。整个扩容或缩容流程可以在数秒到数十秒内完成。这样当应用面临突发业务量增长，需要紧急扩容的时候，就可以非常快的完成，实现了真正意义上的弹性扩容。</p><p>2.为应用微服务化提供有力支撑</p><p>应用微服务化是当前应用改造的一个重点方向，因为大家都看到了微服务的好处，就是迭代效率高、资源使用率高(单一微服务可自行扩容)、单一微服务故障 对全局影响有限。但是传统方式下的应用微服务化开发运营是缺乏体系支撑的，成本高昂、便捷性差。比如一个应用由20个微服务组成，每个微服务需要2个副本保持高可用，传统方式下就需要申请20个负载均衡、40个虚拟机来确保隔离性，同时还要为这40个虚拟机分配相应的网络、存储，部署配套的监控审计等，消耗了大量的资源。传统方式下的这套架构没有弹性扩缩容能力，也缺乏自动化的部署管理工具，对运维人员来说，管理的应用从1个变为20个，大大增加了工作量和复杂度，便利性会很差。从应用开发人员的角度看，传统方式下做微服务化改造，随着微服数量的增加，服务之间依赖关系的增加，开发人员会面临很大的挑战。需要部署专门的服务注册发现系统，需要对应用层代码做侵入实现服务的注册发现机制，需要对应用代码做修改以实现服务的探活和依赖性处理。这些服务治理方面的工作牵扯了开发人员很大的精力，使得应用人员无法将精力集中在业务开发本身上，是一种低效率的做法。</p><p>容器云环境提供了一套成熟的支撑体系，可以很好的支撑应用的微服务化改造，成本低廉、便捷性好。还是以之前的应用为例，20个微服务中，仅仅对外部提供服务的微服务需要申请负载均衡，内部微服务之间的调用通过service机制即可实现。如果很多微服都需要对外提供服务，也可以通过ingress将所有服务收敛到一个入口上，这样对负载均衡的需求数量就大幅度下降。容器化的微服务都是运行在一个计算机群内，可以共享计算节点，扩容、缩容都不需要申请虚拟机，资源的使用效率可以最高。容器云也为应用的部署运行提供很好的编排工具，可以实现应用变更的完全自动化、滚动升级、一键回滚。对应用开发人员来说，容器云环境可以提供比较完善的可配置化的微服治理框架，包括服务注册发现、服务探活、依赖性处理等，不需要对应用代码做侵入修改，这样可以让应用开发人员将更多精力集中在业务开发本身。</p><p>3.让应用实现自动化故障探测、隔离和恢复</p><p>传统方式下的应用故障判断、隔离和恢复完全依赖人工介入，耗时很长。比如一旦出现某个应用节点的故障，需要运维人员人工判断是哪一个节点出了问题，然后人工将该节点从负载均衡摘除。随后人工恢复故障节点，再挂到负载均衡下面。这就导致很长的故障窗口期，对业务连续性并不友好.</p><p>容器方式下，应用的故障判别、隔离和恢复完全自动化实现，无需人工干预。容器云环境提供一套应用服务的自主探测和处理机制，同时也会检测每一个节点，一旦发现某个应用副本异常，会立即将其从service摘除，之后自动删除故障副本，并在可用的节点上新建新的副本。当探测到新建副本已经可以提供服务后，会自动将新建副本挂载到service下面。这种完全自动化的故障处理恢复机制为应用提供了故障自愈能力，将故障窗口减小到最小。</p><p>4.大幅度提升资源使用效率</p><p>在没有虚拟机之前，我们使用裸机部署应用，一个裸机部署一个应用，造成了大量的 资源闲置。后来使用虚拟机后，一个裸机上可以虚拟出多个主机，可以部署多个应用，资源使用效率得到了很大的提升。虚拟机之间可以共享CPU，但是无法共享内存和存储，比如一个虚拟机申请了32GB内存和100GB存储，这些资源只能被这个虚拟机独占，无法和其它虚拟机共享。</p><p>容器的本质是进程，进程间是可以共享宿主机的CPU、内存、存储和网络的，资源使用效率得到最充分的利用。当然做到这一点的前提是容器能够确保进程运行的基本资源不被抢占，资源层面实现良好的隔离性。同时允许设置资源使用配额上限，避免影响其它应用进程。</p><p><strong>容器云平台架构设计</strong></p><p>1.总体架构设计</p><p>总体架构图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/230b635ea964f5bd29907cdbce0df8f8cbf6d32f9122f071489c1127ec1fe57d.png" alt="某股份制银行：容器云平台建设实践">  </p><p>自服务管理平台提供8大板块服务，都是按照支持多租户的目标设计实现。其中资源申请板块是租户申请容器资源的入口，包含帐号申请，K8S和镜像库资源申请，日志接入申请。资源变更板块是租户进行资源变更的入口，包括K8S资源扩容和回收，以及帐号权限的修改。集群管理板块为云平台管理员和租户提供集群范围资源的管理，镜像库管理板块提供镜像库和镜像的管理，应用管理板块主要为租户提供K8S namespace内资源的管理，模板管理板块包含K8S资源模板和Helm模板，运维助手提供Pod历史查询以及集群健康检查管理，帐号授权管理板块为云平台管理员提供租户授权管理。</p><p>自服务管理平台南向通过K8S API和镜像库API对接多个K8S集群和两个镜像库，实现容器资源的统一纳管。最右边的是行内的运营支撑工具体系，其中统一身份认证为自服务管理平台提供租户帐号的登陆鉴权服务，流程系统(即ITOMS)通过API和自服务管理平台的资源申请板块对接，提供统一的资源申请入口。CMDB和自服务管理平台自身的CMDB交互，提供应用、容器、资源之间的关系视图；DevOps工具链可以从自服务平台获取用户和权限，然后通过K8S API和镜像库API实现应用的自动化流水线发布。ELK日志系统用于存储容器应用的日志，集中监控告警系统接收来自K8S节点和容器应用的监控数据，提供告警推送、置维护、统一监控视图的能力。</p><p>2.多集群管理设计</p><p>根据银行内网络安全的要求，K8S集群不能通过Overlay网络跨网络隔离区。因此一个K8S集群只能限定在一个网络隔离区内。目前生产和灾备数据中心的每个网络隔离区部署一套或多套K8S集群，所有集群统一由自服务管理平台纳管。同一网络隔离区内，生产和灾备数据中心各部署K8S集群，为应用提供双活容灾部署架构支撑。生产和灾备数据中心分别部署一套镜像库系统，为各自数据中心内的K8S集群提供镜像服务。允许租户跨集群管理自己的容器资源。整体示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/2b6cd8a642a29b666d96bc7a3743578219767444fc71b09c2ba88d864066d2cc.png" alt="某股份制银行：容器云平台建设实践">  </p><p>3.多租户管理设计</p><p>通过K8S命名空间和镜像库命名空间实现租户资源隔离，一个租户对应于一个或者多个命名空间。云平台管理员可以通过RBAC机制为租户授予相应命名空间的管理权限。租户对授权命名空间内的资源具有管理员权限，但是无法访问非授权命名空间。对于一个租户来说，管理员可以授予他一个K8S集群内一个或多个命名空间的管理权限，也可以授予他多个K8S集群内命名空间的管理权限。整体示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/33ecfd74c5555d9ca2d728d9c4759bd38d2f70fa21fd15ddf876a7b8f790766b.png" alt="某股份制银行：容器云平台建设实践">  </p><p>4.专用和共享计算节点</p><p>容器云平台为应用提供两种类型的K8S集群，分别是计算节点共享的K8S集群和计算节点专用的K8S集群。从资源利用率角度，首推共享计算节点的K8S集群。计算节点直接采用物理机，多个应用共享计算节点组成的资源池，资源的弹性和使用效率最高。</p><p>如应用需要调整缺省Linux Kernel参数，或者有特殊的敏感的出网络访问关系，或者有很高的安全隔离性要求，可以考虑采用计算节点专用的K8S集群。专用的计算节点考虑资源利用率，主要以虚拟机为主。特殊的应用场景（如GPU）可以使用物理机。通过给计算节点打应用标签的方式，然后在应用部署模板里指定nodeSelector的方式，实现计算节点的独占。</p><p>5.存储后端实现</p><p>使用Ceph分布式存储作为容器云平台的后端存储，为应用提供持久化的数据存储能力。在生产和灾备数据中心各部署一个Ceph集群，为所属数据中心的K8S集群提供持久化存储后端服务。每个K8S集群创建2个Storage Class。rbd-class提供ReadWriteOnce类型PVC，后台对接的是Ceph RBD；cephfs-class提供ReadWriteMany类型PVC，后台对接的是CephFS。租户可动态申请PVC，仅有创建权限，没有删除权限。整体示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/67e02135d36849f90d9f36b4a561da534992d1b137619ab1e22b69ed997e8653.png" alt="某股份制银行：容器云平台建设实践">  </p><p>6.应用监控告警</p><p>每一个计算节点上会部署一个监控Agent。应用如需监控，需要在应用部署模板的环境变量里声明监控类型。应用容器启动后，监控Agent会通过容器接口获得容器监控类型环境变量，并自动匹配监控模板(脚本)。监控Agent将监控数据发送到监控服务器。监控服务器根据触发条件判断是否发送告警信息到集中告警平台。在集中告警平台上为每个应用创建虚拟节点，和IP解耦。告警平台收到告警信息后，根据告警数据包含的应用名称字段自动匹配到虚拟节点。虚节点上可设置维护状态，应用变更的时候为了避免告警可以设置虚节点为维护状态，变更完成后可以解除维护状态。示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/be829411a196586fd4f18289ddd89f5f2efb09ed2df598d2a5d32fed09b5fdbf.png" alt="某股份制银行：容器云平台建设实践">  </p><p>目前可监控的应用指标如下：</p><p>1.应用容器状态。如果容器状态异常会触发告警;</p><p>2.应用Deployment副本数，如果副本数和期望的不一致，会触发告警;</p><p>3.应用Statefulset副本数， 如果副本数和期望的不一致，会触发告警;</p><p>4.应用Pod状态，如异常，会触发告警;</p><p>5.应用容器内部文件系统使用率，如超过80%，会触发告警;</p><p>7.应用日志处理</p><p>每个计算节点部署一个日志收集代理，该代理面向节点上所有的容器。如应用容器需要监控，就需要在Pod yaml里通过环境变量声明日志路径和kafka topic。容器启动后，日志代理会根据容器环境变量定义的日志路径自动匹配对应的宿主机日志文件路径，并将日志抓取后发送到kafka topic。当前的日志代理以换行符作为分割符，如应用的一条日志里有多行纪录，这条日志会被切分成多个消息来处理，在Kibana上也会呈现多条记录。为了适配这类一条日志有多行纪录的应用，我们也正在设计开发一种可定制化分隔符的日志引擎，可以允许应用在Pod的yaml里声明日志分隔符。</p><p>8.应用双活容灾部署架构</p><p>生产、灾备中心每个网络区都建设一个K8S集群，都有各自独立的镜像库和后端分布式存储。应用双活要求应用同时运行在生产、灾备中心的两个K8S集群上，前端可以通过负载均衡引流。任意一个数据中心的集群故障不影响应用的可用性。示意图如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/922df393e48ab09cd834ca5a5949af23e4cabaee656b1b5450bb6ae463aa7f8d.png" alt="某股份制银行：容器云平台建设实践">  </p><p>ev6i39ygdkg</p><p><strong>应用容器化最佳实践总结</strong></p><p>1.镜像和配置分离原则：制作应用镜像时，需要将配置分离出来，这样做可以让应用镜像在不同环境（比如测试和生产）都一致，变得只是配置信息。配置信息可通过环境变量或者加载卷的方式注入容器。在K8S环境下，除了环境变量注入，还可以通过ConfigMap和Serect方式注入配置。ConfigMap和Secret都支持通过卷加载的方式挂载到容器。Secret通常用于保存敏感信息（如密码）.</p><p>2.微服务原则：容器环境天生要求微服务化，一个容器只提供一种服务。每个容器原则上只对外提供一个服务监听端口。</p><p>3.使用第三方基础镜像制作应用镜像的时候必须包含必要的系统trouleshooting工具，至少包括ps、netstat、ping、curl。否则出现问题的时候会妨碍排错。</p><p>4.支持通过NodePort和Ingress对外发布服务。NodePort适用于对外服务较少场景；Ingress适用于对外服务较多，需要统一入口场景。Ingress需要作为应用的的一部分部署在应用命名空间。使用Ingress只需要对外通过一个NodePort暴露服务。</p><p>5.NodePort需要向容器平台管理员申请。请仅仅使用分配给项目组的NodePort，禁止使用未经申请的NodePort，否则容易其它项目组产生端口冲突 .</p><p>6.如使用StatefulSet部署有状态应用，副本数必须大于等于2，并且在验证了单个Pod失效不影响服务的前提下，才可以生产上线。原因是StatefulSet的Pod在宿主机故障情况下没有自动HA能力，需要人为干预杀死Pod才能触发重建。</p><p>7.Deployment&#x2F;StatefulSet&#x2F;Pod的yaml里，必须配置liveness&#x2F;readiness探测，并通过测试才能生产上线。这对于应用的可用性非常重要，请一定重视 。</p><p>8.Deployment&#x2F;StatefulSet&#x2F;Pod的yaml里，必须对Container的resources做设置。因为生产环境出于考虑极端情况（一半节点不可用）下的应用高可用。对于独占计算节点的应用，要求应用namespace下所有Pod的request总合不能超过分配总资源(CPU，内存)的50%-1，单个Pod的limit不能超过单个节点资源的60%。</p><p>9.对于可以和其它应用共享计算节点(通常是物理节点)的应用，namespace下所有Pod的request总合和limites总合不能超过分配的总资源（比如分配了16C&#x2F;64G，那么request总合&#x2F;limites总合不能超过16C&#x2F;64G）。</p><p>10.对于使用独占宿主机节点的应用，Deployment&#x2F;StatefulSet&#x2F;Pod的yaml里，必须配置NodeSelector。生产环境NodeSelector的value值是项目的英文名，测试环境统一是testapp。对于和其它应用共享宿主机节点的应用，可以不配置NodeSelector。</p><p>11.对于重要系统，Deployment&#x2F;StatefulSet里，副本(replica)数必须大于2（包含2），禁止为1。这样才能确保服务在单个副本故障的情况下依然可用。对于可靠性要求不高的系统，在资源充足的情况下尽量也保持副本数大于等于2。如资源受限，并且上线前明确说明对可靠性要求不高，可以允许副本数为1 。</p><p>12.Pod产生的日志，推荐通过直接写入stdout并配置Kafka Topic的方式，转发到ELK。如果一定要持久化保存，有如下三种方案，但是都要求首先应用层面要做好日志轮循(rotation)，控制好总量大小，因为PVC和HostPath用的宿主机目录通常是无法扩容的。目前仅写入stdout、HostPath的日志，才可以被日志引擎处理发往ELK，HostPath需要挂载到日志目录。HostPath方式受限使用，需要一事一议。写入PVC或者直接写入容器自身的日志将不能被日志引擎抓取。</p><p>a)使用StatefulSet方式部署Pod，需要在yaml里声明PVC容量和StorageClass（名字为rbd-class，提供ReadWriteOnce类型的PV），并且通过将日志同时写入stdout，且在yaml里声明stdout日志路径和Kafka Topic的方式，将日志发往ELK。一旦使用PVC，Pod的可用性就会和PVC的可用性关联起来。对于可用性要求很高的系统（A&#x2F;B类系统），如果使用PVC，前提条件是应用实现了灾备双活部署。</p><p>b)使用Deployment方式部署Pod，需要在yaml里声明共享型（ReadWriteMany类型）PVC的名字，并且通过将日志同时写入stdout，且在yaml里声明stdout日志路径和Kafka Topic的方式，将日志发往ELK。在多副本情况下，需要应用做好日志文件区分，避免多副本写同一个日志文件。一旦使用PVC，Pod的可用性就会和PVC的可用性关联起来。对于可用性要求很高的系统（A&#x2F;B类系统），如果使用PVC，前提条件是应用实现了灾备双活部署。</p><p>c)使用HostPath，将日志写入宿主机的某个目录。这需要应用在多副本的情况下，能够做好日志区分，将所有Pod的日志放到同一个父目录下。如需使用此种方式，请提前联系容器平台管理员创建目录。即使使用HostPath存放日志，可直接通过在yaml里声明日志文件路径和Kafka Topic的方式，将日志发往ELK。使用HostPath存放日志主要的问题是Pod一旦迁移到新的节点，日志写入也会迁移到新的节点，旧节点上的日志文件写入会中断。HostPath仅仅适用于专用计算节点场景，并且需要一事一议。</p><p>13.如果两个服务之间有依赖关系，必须在上线前解决启动顺序问题。可以考虑使用K8S的initcontainer机制做探测。</p><p>14.对于重要系统，原则上要求应用层面必须实现灾备双活部署，也即应用同时运行在生产、灾备的两个K8S集群上，前端可通过负载均衡引流。任意一个集群的故障不影响应用的可用性</p><p>15.生产上线前，请确保在测试环境完成应用HA测试验证，具体的要求是：</p><p>a) 杀死任意服务中的单个Pod不影响整体业务</p><p>b) 杀死任意服务中的所有Pod，待Pod重启完成后，整体业务服务不受影响</p><p>c) 节点故障不影响整体业务</p><p>16. 尽可能通过配置prestop或者处理SIGTERM信号，来实现应用容器的优雅停止。缺省情况下，没有配置优雅停止的话，K8S会在grace-period时间（缺省30秒，可在Pod Yaml里调整）到期后，通过SIGKILL杀死Pod内进程。</p><p><strong>应用容器化改造案例(某支付类系统)</strong></p><p>1.改造背景</p><p>支付类系统作为银行的核心系统之一，为了保证可用性和性能，之前都是运行在小型机上，运行成本高昂、可扩展性较差。为了解决这些问题，支付类系统需要进行分布式改造，把应用程序从小型机迁移到X86 PC服务器上，导致服务器的规模从几台扩展为几十台，使得部署环节更加复杂、容易出错。因此希望利用容器平台提供的服务注册发现、动态伸缩以及快速故障检测恢复等能力，降低分布式系统的部署和管理难度。</p><p>2.技术实现</p><p>如下是某支付类系统容器化后的部署架构，该系统的后端采用容器化方式部署运行。后端也根据微服务的方式，从一个大模块拆分成几个微服务模块，更便于分布式的部署。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/1927a60ef7472f7fd83fedb0105a47a1d5a05d723d964bf8ab95ad3809f43e81.png" alt="某股份制银行：容器云平台建设实践">  </p><p>行内现有的支付类系统大多是有状态的，因为要生成和节点相关的交易流水号。容器化改造时，为了尽可能不影响现有业务逻辑，也需要维持这种有状态的方式。可以利用K8S提供的StatefulSet实现有状态的部署，每个Pod会有固定的名字，比如payapp-01、payapp-02。这样可以根据Pod名字中的索引（01、02等）自动生成交易流水号。</p><p>由于现有前置应用和后端应用之间是长连接，只能采用一个Pod一个Service的方式提供服务。每一个Pod都要通过NodePort Service对外提供服务。后端Pod在启动后，会将Pod所在的节点IP地址和自己的NodePort注册到前置应用里，然后由前置应用校验适配后，发起到后端Pod的连接，并一直保持这个连接。为了保持较好的可扩展性，可以预先在前置应用里配置额外的服务端口，这样需要扩展的时候，只需要扩容后端的副本(Pod)数量和Service数量即可。当然，后期如果可以改造为短连接方式，就可以采用1个Service对应多个副本的方式，扩容会更方便，也可省略服务向前置应用的注册环节。</p><p>支付类系统是银行的重要系统，必须具备双活容灾能力，具体实现是在生产和同城灾备数据中心的两个K8S集群上分别部署一个多副本的StatefulSet，各副本(Pod)仅和所在数据中心的前置交互。任意数据中心的故障不影响整体业务。</p><p>3.效果总结</p><p>通过上述容器化改造，达到了如下目的和效果：</p><ol><li>支付类应用可以顺利从小型机迁移到X86的虚拟机上。之前只能纵向扩展的问题得到解决，应用得以分布式部署，横向扩展。</li><li>应用的弹性扩容能力得到大幅提供，只需要修改部署模板里的副本数即可实现横向扩展。</li><li>资源使用效率得到大幅提高，因为做了服务拆分，可以针对模块来匹配资源，扩容所需的资源力度更细，避免了资源的浪费。</li><li>应用分布式改造后的部署管理更加简便和高效、可以实现全自动化的部署、升级和回滚。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查看Java应用状态</title>
      <link href="/openshift/%E6%9F%A5%E7%9C%8BJava%E5%BA%94%E7%94%A8%E7%8A%B6%E6%80%81/"/>
      <url>/openshift/%E6%9F%A5%E7%9C%8BJava%E5%BA%94%E7%94%A8%E7%8A%B6%E6%80%81/</url>
      
        <content type="html"><![CDATA[<ol><li>jps查看<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">16 jar</span><br><span class="line">547 Jps</span><br></pre></td></tr></table></figure></li><li>jmap -heap<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jmap -heap 16</span><br></pre></td></tr></table></figure></li><li>jstat -class pid<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ jstat -class 16</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>混沌工程详细介绍——Netflix持续交付实践探寻</title>
      <link href="/openshift/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%E2%80%94%E2%80%94Netflix%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%AE%9E%E8%B7%B5%E6%8E%A2%E5%AF%BB/"/>
      <url>/openshift/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%E2%80%94%E2%80%94Netflix%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98%E5%AE%9E%E8%B7%B5%E6%8E%A2%E5%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>本篇来自于本人6月-7月参加的“DevOps案例深度研究”活动Netflix案例研究的第五部分，详细介绍了<strong>Netflix的混沌工程</strong>。<br>经过一个月的战斗，四个版本的迭代，Netflix战队最后交付了让所有人满意的战果，并获得了全场唯一的案例研究最佳小组奖杯。感谢我们的战友，还有指导老师，姚冬老师和徐磊老师。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/543c7737e422ab45ddf4d04678f7e4ad51029157ce1ae06131ef6e0e7ffee7c1.png" alt="本案例所有研究人员">  </p><h2 id="Netflix实施混沌工程的背景"><a href="#Netflix实施混沌工程的背景" class="headerlink" title="Netflix实施混沌工程的背景"></a>Netflix实施混沌工程的背景</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8015b353df2bd1f149c32215911055f49be8aa84de75dcec27dc2c6e46b00194.png" alt="混沌工程">  </p><p>08年Netflix决定把它的业务迁移到aws上，从自身运维的角度考虑，它有很多担忧的地方。</p><ol><li>很长时间内有两套系统在同时运行，运维的复杂度更高了。</li><li>NetFlix的用户量已经达到了1亿，对应用稳定性依赖很高，如果出现故障对用户的影响非常大，甚至是致命的。</li><li>它的业务不断复杂，引入微服务架构，对应用的高可用性要求越来越高。</li><li>生产环境非常复杂，是多样性的，很难在测试环境中完全模拟生产的状态。</li></ol><p>因此Netflix决心探索一种在生产环境验证应用高可用性的一种方法，这就是现在大家所熟知的混沌工程。</p><h2 id="混乱工程的发展"><a href="#混乱工程的发展" class="headerlink" title="混乱工程的发展"></a>混乱工程的发展</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/7c8e963567b7461fd13df3c96bf8f3f2f30a4e57c6d4ed062d5ed5e77ff2eaf0.png" alt="混乱工程的发展">  </p><ul><li>2010年，捣乱猴子诞生</li><li>2011年，猴子军团，有了更多场景下的工具集</li><li>2012年，开源了捣乱猴子的代码，建立社区，影响了越来越多的公司混沌工程的发展</li><li>2014年，NetFlix创建了新的工作角色，混沌工程师，代表了NetFlix将混沌工程融入了公司的运维文化中</li><li>2015年，NetFlix与社区正式提出混沌工程原则，从此混沌工程不只是一些工具的集合，而有了一套理论支撑</li><li>2016年，NetFlix前员工Kolton Andrus创立了Gremlin，正式将混沌实验工具商用化，可以看到混沌工程影响着越来越多的企业。</li><li>2017年，Chaos Monkey 2.0</li></ul><p>从一只猴子，发展成庞大的猴子军团，是NetFlix在生产实践中不断探索与不断进化的结果。</p><h2 id="NetFlix猴子军团"><a href="#NetFlix猴子军团" class="headerlink" title="NetFlix猴子军团"></a>NetFlix猴子军团</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/452e5271900843a538c98dc5c1e428624444ed9ff976873bc482c31d55a34acc.png" alt="NetFlix猴子军团">  </p><p>NetFlix猴子军团包括很多工具：</p><ol><li>Chaos Monkey，捣乱猴子，可以随机关闭生产环境中的实例，确保网站系统能够经受故障的考验，同时不会影响客户的正常使用。</li><li>Latency Monkey，延迟猴子，在RESTful服务的调用中引入人为的延时来模拟服务降级，测量上游服务是否会做出恰当响应。通过引入长时间延时，还可以模拟节点甚至整个服务不可用。</li><li>Conformity Monkey，一致性猴子，查找不符合最佳实践的实例，并将其关闭。例如，如果某个实例不在自动伸缩组里，那么就该将其关闭，让服务所有者能重新让其正常启动。</li><li>Doctor Monkey，医生猴子，查找不健康实例的工具，除了运行在每个实例上的健康检查，还会监控外部健康信号，一旦发现不健康实例就会将其移出服务组。</li><li>Janitor Monkey，守卫猴子，查找不再需要的资源，将其回收，这能在一定程度上降低云资源的浪费。</li><li>Security Monkey，安全猴子，这是Conformity Monkey的一个扩展，检查系统的安全漏洞，同时也会保证SSL和DRM证书仍然有效。</li><li>10-18 Monkey，本地化猴子，进行本地化及国际化的配置检查，确保不同地区、使用不同语言和字符集的用户能正常使用Netflix。</li><li>Chaos Gorilla，捣乱大猩猩，Chaos Monkey的升级版，可以模拟整个Amazon Availability Zone故障，以此验证在不影响用户，且无需人工干预的情况下，能够自动进行可用区的重新平衡。</li><li>Chaos Kong，捣乱金刚，Chaos Gorilla的升级版，可以模拟整个Region的故障。</li></ol><p>这些工具向我们展示了NetFlix的一套方法论，混沌工程并不是一些测试工具的集合，而是一种思想：在生产实践中遇到问题时，利用混沌工程的思想，实施自己的一些混沌实践，引入新的猴子。相信以后会有越来越多的猴子加入到猴子军团。<br>使用 Simian Army 进行混沌工程实验，看起来似乎已经很完美。在生产上做这样不可控的实验，是很危险的。</p><h2 id="混沌工程的原则"><a href="#混沌工程的原则" class="headerlink" title="混沌工程的原则"></a>混沌工程的原则</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/a4db2e5ebd0ba5e69dfde3192e149f7ed8698c6bba33f601fd78cbeac5f2eb68.png" alt="混沌工程的原则">  </p><p>引入混沌实践时需要了解混沌工程的五大原则。</p><ol><li>建立稳定状态的假设。<br>在做混沌工程实验的时候，首先得确定需要测试的指标已经做了高可用的工作，才能进行验证指标对业务的是否有影响。如果没有做好高可用工作，而引入混沌工程实验的话，对业务而言将会是一声灾难。</li><li>多样化现实世界事件<br>不能够凭空想像出一些事件来验证，而是引入那些真实存在的，频繁发生的，且影响重大的事件。对我们而言给这些事件做混沌实验才具有价值。如磁盘故障、网络延时、主机宕机等。</li><li>在生产环境运行实验<br>尽量在类生产环境中进行测试，生产环境的多样性是任何其它环境无法比拟的。混沌工程的价值就是保证生产上的业务连续不中断。</li><li>持续自动化运行实验<br>实施混沌工程实验一般最开始是人工手动操作，当我们对业务有足够的信心时，要把混沌实验做成持续自动化。在版本升级、不断迭代的过程中，持续不断自动化地做验证，最大程序保证业务的连续性验证。</li><li>最小化影响范围<br>做混沌工程的意义就是保证生产上的业务。在我们实施混沌实验时也必须保证对线上业务影响最小。在实施实验时，从小范围开始，不断扩大范围，避开高风险时段，如选择业务量最小的时候实施实验。</li></ol><h2 id="混沌工程实践步骤"><a href="#混沌工程实践步骤" class="headerlink" title="混沌工程实践步骤"></a>混沌工程实践步骤</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/6045315e5d1c0d4ad85152b98554849f5318054587aa8c1670892ec89e4cac85.png" alt="混沌工程实践步骤">  </p><p>有了这些原则，就可以根据业务的真实场景设计混沌工程实验。<br>在真实展开实验时分为两个阶段：准备阶段、执行阶段。</p><ul><li>准备阶段：</li></ul><ol><li>确认本次实验需要验证的目标。遵循建立稳定状态的假设、多样化现实世界事件的原则。例如：Redis的超时不会对系统影响。代码中已经对Redis超时的情况做了相关的工作，保证业务的可靠。实验只是用来测试验证。</li><li>选择实验范围。遵循对线上业务影响最小、尽量与生产环境相近的原则。例如先测试环境验证，生产环境选择最小量用户验证。</li><li>确认监控指标。例如：订单成交量、应用请求响应时间、应用响应错误率，做好监控实时查看状态。</li><li>团队成员沟通。遵循最小化影响范围。确保团队相关成员了解实施情况，关注业务状态。<br>准备阶段一般只是第一次实验的时候操作，一旦验证好了以后以后，后序重复执行本次工程不需要重新准备，除非对实验过程有变动。</li></ol><ul><li>执行阶段：</li></ul><ol><li>执行实验。遵循最小化影响范围。执行过程中实时关注指标，如果有异常，随时终止实验。例如，把Redis延时调大，查看监控指标是否有异常。</li><li>分析结果。遵循最小化影响范围。根据收集的指标数据确认假设Redis的超时不会对系统影响。如果验证假设不成立，则需要分析代码，确认好原因，再组织下一次的混沌工程实验。</li><li>扩大实验范围。遵循最小化影响范围。先小范围测试，再逐步扩大测试范围。</li><li>自动化。遵循持续自动化运行实验。当对代码有足够的信心之后，将混沌工程实践做成自动化，让混沌工程实验能够持续保证业务的可用性，获得最大的价值。</li></ol><h2 id="Chaos-Monkey在K8S集群下的应用"><a href="#Chaos-Monkey在K8S集群下的应用" class="headerlink" title="Chaos Monkey在K8S集群下的应用"></a>Chaos Monkey在K8S集群下的应用</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/0a29aade09b140d89db2bc102349eb5ff38bfe6450386f16031285c315d08e7b.png" alt="Chaos Monkey在K8S集群下的应用">  </p><p>Kubernetes是容器编排市场的领导者。如何保证K8S集群及运行在上面的应用能够抵御生产中动荡环境的能力和信心呢？正确地使用混沌工程实践是这里面的关键。我做了一些调研，找到了常用的三款在K8S环境下的混沌工程工具。</p><ul><li>Kube-monkey：模拟在指定时间随机删除K8s集群中的pod</li><li>Powerfulseal：控制K8S中的Pod及Node节点的状态</li><li>Gremlin：是一个商业版工具。通过web&#x2F;API&#x2F;CLI的方式对容器、主机，提供数十种攻击方式，方便与其它工具进行集成。</li></ul><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>可见混沌工程并不仅仅是在传统运维、云平台发挥着作用，在最新的基础架构设施容器平台中也发挥着它的价值。我相信会有越来越多的企业将意识到混沌工程给系统带来的各种好处，不久的将来，混沌工程实践也许会成为基础设施运维与应用运维不可或缺的一部分。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a href="https://www.infoq.cn/theme/13">Netflix 混沌工程手册</a><br><a href="https://www.ibm.com/developerworks/agile/library/a-devops4/index.html">Unleash the Chaos Monkey</a><br><a href="https://java.ctolib.com/article/wiki/25360">Netflix的Chaos Monkey的一个实现用于Kubernetes集群</a><br><a href="https://www.huxiu.com/article/258949.html?rec=similar">获得1.25亿用户以后，Netflix总结了这些系统可用性经验</a><br><a href="https://developers.redhat.com/blog/2018/04/10/istio-chaos-engineering/">Istio Chaos Engineering: I Meant to Do That</a><br><a href="https://aws.amazon.com/cn/blogs/china/aws-chaos-engineering-start/">AWS云上混沌工程实践之启动篇</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>白化Kubernetes网络</title>
      <link href="/openshift/%E7%99%BD%E5%8C%96Kubernetes%E7%BD%91%E7%BB%9C/"/>
      <url>/openshift/%E7%99%BD%E5%8C%96Kubernetes%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>引自：<a href="http://www.10tiao.com/html/217/201708/2649694873/1.html">http://www.10tiao.com/html/217/201708/2649694873/1.html</a></p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-d9b812b1ffbe27a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="林帆"></p><p>容器的网络是在CaaS集群中无法避免的话题，作为当下最主流的一种容器集群解决方案，Kubernetes对网络进行了合理的抽象，并采用了开放的CNI模型。面对各种容器网络实现，他们有什么不同，应该如何选择？本文将带大家回顾Kubernetes各种主流网络方案的发展历程，并透过现象清本质，用形象的例子展示Weave、Flannel、Calico和Romana等网络解决方案背后的原理。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-759fd12c6ae54de3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>这次讲一讲容器集群中的网络。其实不同的容器集群解决方案，在网络方面的核心原理都是相似的，只不过这次我们将以Kubernetes为线索，来窥斑见豹的一睹容器网络的发展过程。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-b8441b7c9dc0d459.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>我是来自ThoughtWorks的林帆，我们从Docker的0.x版本开始就在对容器的应用场景进行探索，积累了一线的容器运用经验。这次分享会用简洁易懂的方式告诉大家我们对容器网络方面的一些知识归纳。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-a81a65144e8fdf3a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>初入容器集群的人往往会发现，和单节点的容器运用相比，容器的网络和存储是两个让人望而却步的领域。在这些领域里，存在大量的技术名词和术语，就像是一道道拒人于门外的高门槛。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-faf663ee6055657c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>为了便于理解，我们将这些名称简单的分个类别，从简单到复杂，依次递增。今天的话题会涉及的深度大致在这个大池子的中间，希望大家看完以后会对目标线以上的内容不再陌生，目标线以下的内容我们也会依据需要适当的提及。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-65777471221b0c00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>此外，这个话题会按照Kubernetes的网络发现过程作为时间主线，其中重点介绍CNI标准和它的主流实现。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f06c7e472a6e491d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>在早期的Kubernetes中，对网络是没有什么标准的。文档中对网络的描述只有很简单的几句话，其实就是让用户在部署Kubernetes之前，预先准备好容器互联的网络解决方案。Kubernetes只对网络提出设计假设，这三条假设总结起来就是：所有容器都可以和集群里任意其他容器或者主机通信，并且通信双方看到的对方IP地址就是实际的地址（即不经过网络地址转换）。</p><p>基于这样的底层网络，Kubernetes设计了Pod - Deployment - Service的经典三层服务访问机制。</p><p>既然Kubernetes不提供底层网络实现，在业界就出现了很多企业级的以及开源的第三方解决方案，其中下面这页图中展示了这个时期的主流开源方案。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-8563a905a92275b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>我们将这些方案依据配置的复杂度，分为“全自动”和“半自动”两类，就像是汽车中的自动挡和手动挡的差别。</p><p>“全自动”的解决方案使用起来简单，适用于标准网络环境的容器跨节点通信。</p><p>“半自动”的解决方案实际上是对底层协议和内核模块功能的封装，提供了选择十分丰富的网络连接方法，但对使用者的网络原理知识有一定要求。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-145a11e88ce64617.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>在Kubernetes的1.1版本中，发生了一件很重要的变化，那就是Kubernetes全面采纳CNI网络标准。</p><p>CNI诞生于2015年4月，Kubernetes的1.1版本诞生于2015年9月，之间仅隔5个月。在这个时期，Docker也设计了一套网络标准，称为CNM（即Libnetwork）。Kubernetes采用CNI而非CNM，这背后有很长的一段故事，核心的原因就是CNI对开发者的约束更少，更开放，不依赖于Docker工具，而CNM对Docker有非常强的依赖，无法作为通用的容器网络标准。在Kubernetes的官方博客里有一篇博文详细讨论了个中细节，InfoQ上有一篇该博客的翻译，有兴趣的读者不妨一读。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-2a6171359c5dd7bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>几乎在Kubernetes宣布采纳CNI以后的1个月，之前提到的“全自动”网络方案就悉数实现了CNI的插件，这也间接说明了CNI的简单。</p><p>那么CNI到底有多简单呢？举几个数字。</p><p>实现一个CNI插件需要的内容包括一个Json配置文件和一个可执行的文件（脚本或程序），配置文件描述插件的版本、名称、描述等基本信息，可执行文件就是CNI插件本身会在容器需要建立网络和需要销毁容器的时候被调用。</p><p>当一个CNI插件被调用时，它能够通过6个环境变量以及1个命令行参数（Json格式文本）来获得需要执行的操作、目标网络Namespace、容器的网卡必要信息，每个CNI插件只需实现两种基本操作：创建网络的ADD操作，和删除网络的DEL操作（以及一个可选的VERSION查看版本操作）。</p><p>最新的CNI规范可以通过上图中的链接访问，只有一页网页的内容而已。同时Kuberntes社区也提供了一个利用“docker network”命令实现的简单CNI插件例子，只用了几十行Bash脚本。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-b173914c99163c95.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>那么面对这么多的社区CNI插件，我们怎样选择呢？</p><p>直观的说，既然是网络插件，在功能差不多的情况下，我们当然先关心哪个的速度快。</p><p>为此我此前专门做过一次对比测试，不过由于使用了公有云的网络环境（云上环境的不同主机之间相对位置不固定），在汇总数据的时候才发现测试结果偏离理论情况过于明显。</p><p>这个数据大家且当娱乐，不过对于同一种插件的不同工作模式（比如Flannel的三种模型）之间，由于是使用的相同的虚拟机测试，还是具有一定可参考性。</p><p>先抛开测试结果，从理论上说，这些CNI工具的网络速度应该可以分为3个速度等级。</p><p>最快的是Romana、Gateway模式的Flannel、BGP模式的Calico。</p><p>次一级的是IPIP模式的Calico、Swarm的Overlay网络、VxLan模式的Flannel、Fastpath模式的Weave。</p><p>最慢的是UDP模式的Flannel、Sleeve模式的Weave。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-80ac8c48838c0f36.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>这里我也提供出测试容器网络速度的具体方法，以便大家重复这个测试。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-193dbbfa923fd4ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>要解释这些网络插件和模式速度不同的原因，我们需要先回到这些工具最初要解决的问题上来。那就是跨节点的网络不通。</p><p>如果仔细观察，会发现在3种网络速度模式中都有Flannel的身影。因此我们不妨先以Flannel为例来看这些网络工具（和相应的CNI插件）是如何解决网络不通问题的。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-056b3cdd605d52c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>跨节点网络不同有几个方面的原因，首先是容器的地址重复。</p><p>由于Docker等容器工具只是利用内核的网络Namespace实现了网络隔离，各个节点上的容器是在所属节点上自动分配IP地址的，从全局来看，这种局部地址就像是不同小区里的门牌号，一旦拿到一个更大的范围上看，就可能是会重复的。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-3ab314f16420040e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>为了解决这个问题，Flannel设计了一种全局的网络地址分配机制，即使用Etcd来存储网段和节点之间的关系，然后Flannel配置各个节点上的Docker（或其他容器工具），只在分配到当前节点的网段里选择容器IP地址。</p><p>这样就确保了IP地址分配的全局唯一性。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-5110168412e8690a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>是不是地址不重复网络就可以联通了呢？</p><p>这里还有一个问题，是对于不同的主机、以及网络上的路由设备之间，并不知道这些IP容器网段的地址是如何分配的，因此数据包即使被发送到了网络中，也会因为无法进行路由而被丢掉。</p><p>虽然地址唯一了，依然无法实现真正的网络通信。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-f1ca324b6d089bc8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>为此，Flannel采用了几种处理方法（也就是Flannel的几种网络模式）。</p><p>早期时候用的比较多的一种方式是Overlay网络。</p><p>在这种方式下，所有被发送到网络中的数据包会被添加上额外的包头封装。这些包头里通常包含了主机本身的IP地址，因为只有主机的IP地址是原本就可以在网络里路由传播的。</p><p>根据不同的封包方式，Flannel提供了UDP和Vxlan两种传输方法。</p><p>UDP封包使用了Flannel自定义的一种包头协议，数据是在Linux的用户态进行封包和解包的，因此当数据进入主机后，需要经历两次内核态到用户态的转换。</p><p>VxLAN封包采用的是内置在Linux内核里的标准协议，因此虽然它的封包结构比UDP模式复杂，但由于所有数据装、解包过程均在内核中完成，实际的传输速度要比UDP模式快许多。</p><p>但比较不幸的是，在Flannel开始流行的时候，大概2014年，主流的Linux系统还是Ubuntu 14.04或者CentOS 6.x，这些发行版的内核比较低，没有包含VxLAN的内核模块。因此多数人在开始接触Flannel时候，都只能使用它的UDP模式，因此Flanned一不小心落得了一个“速度慢”的名声，特别是在之后的Calico出来以后（其实Flannel的Gateway模式与Calico速度相当，甚至理论上还要快一点点，稍后解释）。</p><p>这是第一种解决网络无法路由的方法。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-8ef1794959aaeec0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>第二种思路是，既然在无法进行路由是因为网络中的节点之间没有路由信息，但Flannel是知道这个信息的，能不能把这个信息告诉网络上的节点呢？</p><p>这就是Flannel的Host-Gateway模式，在这种模式下，Flannel通过在各个节点上的Agent进程，将容器网络的路由信息刷到主机的路由表上，这样一来所有的主机就都有整个容器网络的路由数据了。</p><p>Host-Gateway的方式没有引入像Overlay中的额外装包解包操作，完全是普通的网络路由机制，它的效率与虚拟机直接的通信相差无几。</p><p>然而，由于Flannel只能够修改各个主机的路由表，一旦主机直接隔了个其他路由设备，比如三层路由器，这个包就会在路由设备上被丢掉。</p><p>这样一来，Host-Gateway的模式就只能用于二层直接可达的网络，由于广播风暴的问题，这种网络通常是比较小规模的，但近年来也出现了一些专门的设备能够构建出大规模的二层网络（就是我们经常听到的“大二层”网络）。</p><p>那么其他的CNI插件呢？</p><p>由于Flannel几乎是最早的跨网络通信解决方案，其他的方案都可以被看做是Fannel的某种改进版。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-87c4c15ab0eb3d06.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>比如Weave的工作模式与Flannel是很相似的，它最早只提供了UDP（称为sleeve模式）的网络方式，后来又加上了fastpass方式（基于VxLAN），不过Weave消除了Flannel中用来存储网络地址的额外组件，自己集成了高可用的数据存储功能。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-298a145a73bcfb4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>Calico的设计比较新颖，之前提到Flannel的Host-Gateway模式之所以不能跨二层网络，是因为它只能修改主机的路由，Calico把改路由表的做法换成了标准的BGP路由协议。</p><p>相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，Calico模拟路由器的路由表信息就可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。</p><p>不过在现实中的网络并不总是支持BGP路由的，因此Calico也设计了一种IPIP模式，使用Overlay的方式来传输数据。IPIP的包头非常小，而且也是内置在内核中的，因此它的速度理论上比VxLAN快一点点，但安全性更差。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-e7692ebd3b7c68a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>Cannal将Calico和Flannel做了一下组合，同时支持两者的特性。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-6a391283b463abf4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>Romana只支持与Flannel相同的Host-Gateway模式，但它在网络策略方面做了比较多的增强，通过额外引入的租户概念简化了网络策略所需的IPtables规则数量。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-cc51f5d2f098689d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>这是几种主流CNI工具的横向对比。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-9c383bd99470d92f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>在Kubernetes的1.2版本以后开始引入了一个新的工具，叫做 kubernet，它实现了内置的网络地址分配功能。结合一些云平台上的内网路由表功能，就能够直接执行跨网络通信，相当于把跨网络功能内建到Kubernetes里面了。</p><p>这是一个从“只做假设”到“设定标准”到“内置实现”的很大的改变。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-51a9a62433ada415.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>在Kubernetes的1.3版本以后，开始加入网络策略相关的支持。并且在1.7版本后结束了Beta阶段，成为正式API的一部分。</p><p>值得一说的是，Kubernetes的网络策略采用了比较严格的单向流控制，即假如允许服务A访问服务B，反过来服务B并不一定能访问服务A。这与Docker内置的Network命令实现的隔离有很大不同。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-aeb2601f5a0932a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>纵向的对比一下主流的容器集群对今天提到的这些网络特性的支持情况和时间点。</p><p><img src="https://upload-images.jianshu.io/upload_images/5793257-0e125aaca128c0ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p><p>Q：Kubernetes的网络策略采用了比较严格的单向流控制，即假如允许服务A访问服务B，反过来服务B并不一定能访问服务A。为什么要设计成严格单向流呢？A：主要是安全性的原因，这是一种更精细的权限控制策略，除了方向，Kuberetes还允许对可访问的端口进行控制。</p><p>Q：Open vSwitch有测过么？</p><p>A：没有测试，Open vSwitch同样可以配置成Overlay网络或者Macvlan网络等不同的通信模式，速度也会落到相应的档位上。那个测试例子只是为了说明网络速度与采用的通信原理有关，同时引出几种主流的通信模式原理，测试数据是不准确的，建议以在自己的实际环境中测试结果为准。</p><p>Q：Calico怎么做网段间的隔离？</p><p>A：各种网络工具的网络策略基本上都是基于内核的Iptables模块实现的。比如Calico只是根据用户配置，自动管理各个节点上的Iptables规则。其他有些改进的，比如Romana设计了一种基于“租户”的规则管理机制，可以用更少的Iptables规则实现网络隔离。</p><p>Q：如果在Kubernetes里面需要做到平行网络，让每一个Pod获取一个业务IP，除了Bridge+Vlan的方式，还有更好的建议么？</p><p>A：这次讲的这些CNI插件都会让每一个Pod获得一个独立业务IP。可以根据实际网络情况和对速度的需求选择。</p><p>Q：Calico BGP IPIP NAT三种模式分别怎么配置？原理是怎样的？其中IPIP还有两种模式，区别在哪？</p><p>A：在Calico的配置中设置spec.ipip.enabled: ture就会开启IPIP模式，否则默认是纯BGP模式。IPIP的两种模式其实是指纯IPIP（ipip always模式）或者混合IPIP和BGP（ipip cross-subnet），后者指的是“同子网内路由采用BGP，跨子网路由采用IPIP”，主要用于即想在内网获得高速，又想在跨公网时能保持联通的情况。这种模式需要每个节点启动时用–ip参数预先配置节点的子网，并且所有节点版本都在v2.1以上。</p><p>Q：能麻烦具体介绍一下kube-proxy这种网络模式的优缺点吗，在测试过程中发现很不稳定，但是又没发现足够的证据。</p><p>A：kube-proxy是Kubernetes的一个组件，提供通过Service到Pod的路由，并不是一种网络模式，不同的网络插件都会使用到这个组件。</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研发项目管理实践</title>
      <link href="/openshift/%E7%A0%94%E5%8F%91%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%AE%9E%E8%B7%B5/"/>
      <url>/openshift/%E7%A0%94%E5%8F%91%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="项目的特征"><a href="#项目的特征" class="headerlink" title="项目的特征"></a>项目的特征</h2><ol><li>唯一性、2. 存在风险、3. 临时的、4. 跨部门的团队、5. 渐渐明晰</li></ol><h2 id="项目的三约束（QBT）"><a href="#项目的三约束（QBT）" class="headerlink" title="项目的三约束（QBT）"></a>项目的三约束（QBT）</h2><p>Q：质量、B：资金、T：时间</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/75b13952e67083ba55ab7ace740cf6400aac5443c065347525a14db013437d2c.png" alt="项目管理三角形">  </p><ul><li>按时、在预算之内、满足性能指标、满足或超出客户的预期完成就是一个成功的项目。</li><li>优秀的项目经理在完成一个项目的过程中，让Boss、客户、团队成员都满足。</li><li>做项目时要时刻考虑到项目的目的。</li></ul><h2 id="项目的来源"><a href="#项目的来源" class="headerlink" title="项目的来源"></a>项目的来源</h2><ol><li>合同驱动、2. 市场驱动、3. 变更Change</li></ol><h2 id="项目周期"><a href="#项目周期" class="headerlink" title="项目周期"></a>项目周期</h2><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/ff2677fca06c56cdfcbb883a2432a56e4cc0725ad6d436a1e26fe36e5bb240bd.png" alt="项目生命周期">  </p><h2 id="与不同干系人的沟通"><a href="#与不同干系人的沟通" class="headerlink" title="与不同干系人的沟通"></a>与不同干系人的沟通</h2><p>干系人指的是对项目成败有利益，对项目有影响的人。</p><ol><li>识别干系人。核心团队成员一起来识别。</li><li>分析干系人。</li><li>对不同的干系人采取不同的策略。</li></ol><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8d325b738c9221a48dff78bbb39f7991080dc3e29fdccdaae1a99c320ae73568.png" alt="干系人策略图">  </p><p>影响力来源</p><ol><li>信誉、2. 互惠、3. 说服</li></ol><h2 id="项目进展"><a href="#项目进展" class="headerlink" title="项目进展"></a>项目进展</h2><ol><li>核心团队成员融入到项目里面，能够将项目说清楚</li><li>做计划。计划的过程很重要。做计划的过程是把核心团队消化项目的过程，也是责任转移的过程。项目经理要将项目分成模块，细节让负责部分的核心团队成员来做。</li></ol><h2 id="团队建设模型（Tuckman模型）"><a href="#团队建设模型（Tuckman模型）" class="headerlink" title="团队建设模型（Tuckman模型）"></a>团队建设模型（Tuckman模型）</h2><ol><li>团队建设分为四个阶段：形成阶段、磨合阶段、规范阶段、贡献阶段</li><li>四个阶段中间不能跳过</li><li>保证核心成员的完整性</li></ol><p>项目经理，二件事：管项目，管人。根据对项目与人的管理程度，项目经理分为四种风格类型。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/114ce9179c0942925bd728e5b47b1f40ac51a7084c4c8e14e913b10d7bb8ceb4.png" alt="项目管理风格类型">  </p><p>在项目的不同阶段，项目经理需要扮演不同类型的角色。</p><ol><li>形成阶段。偏向于指挥。告知“方向在哪里”、“为什么要做”、“邀请你加入该项目的职责在哪”、“对现在项目，我很有信心”。</li><li>磨合阶段。指导。</li><li>规范阶段。支持。</li><li>贡献阶段。授权。</li></ol><h2 id="项目中的问题沟通人选择"><a href="#项目中的问题沟通人选择" class="headerlink" title="项目中的问题沟通人选择"></a>项目中的问题沟通人选择</h2><ol><li>与项目QBT相关，自己出马。<code>Must to have</code></li><li>与项目QBT间接相关，对等出马。<code>Nice to have</code></li><li>团队成员更清楚，核心团队出马。</li></ol><h2 id="变更委员会"><a href="#变更委员会" class="headerlink" title="变更委员会"></a>变更委员会</h2><p>所有变更都欢迎。</p><ol><li>变更申请单。变什么、为什么变、不变有什么不好、变更什么好？</li><li>领导签字</li><li>交给变更委员会甲、乙方确认是否执行变更。Nice to have的不做，只做Must to have的变更。</li></ol><h2 id="冲突管理（ARIA模型）"><a href="#冲突管理（ARIA模型）" class="headerlink" title="冲突管理（ARIA模型）"></a>冲突管理（ARIA模型）</h2><ol><li>对抗性阶段。谈感受、建立一个安全环境。</li><li>共鸣阶段。每个人说出需求。为什么xx那么重要。</li><li>创造。不要批评，自由发言，谈方案，头脑风暴。</li><li>行动。制定计划，确认时间、工作安排、责任、分工、资源跟踪。</li><li>感谢。加大团队凝聚力。</li></ol><p>冲突主要分为三种，资源冲突、目标冲突、个性冲突。<br>个性冲突：使用完整的ARIA模型来解决。<br>目标冲突：从共鸣阶段开始。<br>资源冲突：从创造阶段开始。</p><h2 id="有意义的点"><a href="#有意义的点" class="headerlink" title="有意义的点"></a>有意义的点</h2><ol><li>Need &#x2F; Want<br>多想想提出需求&#x2F;问题的人的需求。<br>话术：为什么你的Want对你那么重要？</li><li>Blook定律<br>复杂的项目在中后期不建议加人。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>玩转Openshift中Pod调度</title>
      <link href="/openshift/%E7%8E%A9%E8%BD%ACOpenshift%E4%B8%ADPod%E8%B0%83%E5%BA%A6/"/>
      <url>/openshift/%E7%8E%A9%E8%BD%ACOpenshift%E4%B8%ADPod%E8%B0%83%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<ul><li>大部分情况下，Openshift中的Pod只是容器的载体，通过Deployment、DaemonSet、RC、Job、Cronjob等对象来完成一组Pod的调度与自动控制功能。<br>Pod调度也是由Scheduler组件完成的。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/b5fd9dad42c4cce981e983bed752a9d3e8bde6792d5720cb106cdbe4ec7d083f.png" alt="Pod调度通过Scheduler组件实现">  </p><blockquote><p>Deployment&#x2F;RC：全自动调度</p></blockquote><p>Deployment&#x2F;RC主要是自动部署应用的多个副本，并持续监控，以维持副本的数量。默认是使用系统Master的Scheduler经过一系列算法计算来调度，用户无法干预调度过程与结果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: nginx</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br></pre></td></tr></table></figure><blockquote><p>NodeSelector：定向调度</p></blockquote><p>通过Node的标签和Pod的nodeSelector属性相匹配，可以达到将pod调度到指定的一些Node上。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oc label nodes &lt;node-name&gt; env=dev</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: nginx</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        env: &#x27;dev&#x27; </span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">      restartPolicy: Always</span><br></pre></td></tr></table></figure><blockquote><p>NodeAffinity：Node亲和性调度</p></blockquote><ul><li><p>更具表达力（不仅仅“符合全部”的简单情况）</p></li><li><p>可以使用软限制、优先采用等限制方式，使得调度在无法满足优先需求的情况下，会退而示其实，继续运行Pod</p></li><li><p>目前有两种亲和性表达</p><ul><li>RequiredDuringSchedulingIgnoreDuringExecution<br>必须满足指定的规则才可以调度Pod到Node上（与nodeSelector类似），为硬限制</li><li>PreferredDuringSchedulingIgnoreDuringExecution<br>强调优先满足指定规则，调度器优先选择合适的Node，但不强求，为软限制。多个优先级规则还可以设置权重值，以定义执行的先后顺序</li></ul></li><li><p>NodeAffinity语法支持的操作符包括In&#x2F;NotIn&#x2F;Exists&#x2F;DoesNotExist&#x2F;Gt&#x2F;Lt</p></li><li><p><strong>注意事项</strong></p><ul><li><em>同时定义了nodeSelector与nodeAffinity，那必须两个条件都满足，Pod才被调度到指定的Node上</em></li><li><em>nodeAffinity指定了多个nodeSelectorTerms，那么只需要满足其中一个就能够匹配成功就可以完成调度</em></li><li><em>nodeSelectorTerms中有多个matchExpressions，则一个节点必须满足所有的matchExpressions才能运行Pod</em><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx </span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">  affinity:</span><br><span class="line">    nodeAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        nodeSelectorTerms:</span><br><span class="line">          - matchExpressions:</span><br><span class="line">              - key: env</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                  - dev</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        - preference:</span><br><span class="line">           weight: 1</span><br><span class="line">            matchExpressions:</span><br><span class="line">              - key: disk-type</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                  - ssd</span><br></pre></td></tr></table></figure><blockquote><p>PodAffinity：Pod亲和与互斥调度策略</p></blockquote></li></ul></li><li><p>可以根据节点上正在运行的其它Pod的标签来进行限制</p></li><li><p>必须指定topologyKey：表达节点所属的topology范围</p><ul><li>kubernetes.io&#x2F;hostname</li><li>failure-domain.beta.kubernetes.io&#x2F;zone</li><li>failure-domain.beta.kubernetes.io&#x2F;region</li></ul></li><li><p><strong>注意：</strong>PodAffinity规则设置注意事项</p><ul><li>除了设置Label Selector和topologyKey，还可以指定namespaces列表来进行限制，namespaces定义与Label Selector和topologyKey同级。默认namespaces设置表示为Pod所在的namespaces，如果namespaces设置为“”则表示所有的namespaces</li><li>在所有关联requiredDuringSchedulingIgnoredDuringExecution的matchExpressions全部满足后，才将Pod调度到指定的Node上<br><em>以下例子要求新的Pod与<code>app=test</code>的Pod为同一个zone,但是不与<code>app=nginx </code>的Pod为同一个Node</em><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">  affinity:</span><br><span class="line">    podAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        - topologyKey: failure-domain.beta.kubernetes.io/zone</span><br><span class="line">          labelSelector:</span><br><span class="line">            matchExpressions:</span><br><span class="line">              - key: app</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                  - test</span><br><span class="line">        podAntiAffinity:</span><br><span class="line">          preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            - podAffinityTerm:</span><br><span class="line">                labelSelector:</span><br><span class="line">                  matchExpressions:</span><br><span class="line">                    - key: app</span><br><span class="line">                      operator: In</span><br><span class="line">                      values:</span><br><span class="line">                        - nginx</span><br><span class="line">                topologyKey: kubernetes.io/hostname</span><br><span class="line">              weight: 100</span><br></pre></td></tr></table></figure><blockquote><p>Taints与Tolerations（污点与容忍）</p></blockquote></li></ul></li><li><p>Taints与前面的Affinity相反——它让Node拒绝Pod的运行</p></li></ul><p>为node添加一个Taint，效果是NoSchedule(除了NoSchedule还可以取值PreferNoSchedule&#x2F;NoExecute)。意味着除非Pod明确声明可以容忍这个Taint，否则不会被调度到该Node上。如果Pod无法容忍NoExecute的Taint，则上面已经运行的Pod会被驱逐。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oc taint nodes &lt;node-name&gt; key1=value1:NoSchedule</span><br><span class="line">oc taint nodes &lt;node-name&gt; key1=value1:NoExecute</span><br><span class="line">oc taint nodes &lt;node-name&gt; key2=value2:NoSchedule</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">  tolerations:</span><br><span class="line">    - key: &quot;key1&quot;</span><br><span class="line">      operator: &quot;Exists&quot;</span><br><span class="line">      effect: &quot;NoSchedule&quot;</span><br><span class="line">   - key: &quot;key1&quot;</span><br><span class="line">     operatior: &quot;Equal&quot;</span><br><span class="line">     value: &quot;value1&quot;</span><br><span class="line">     effect: &quot;NoExecute&quot;</span><br><span class="line">     tolerationSeconds: 3600</span><br></pre></td></tr></table></figure><blockquote><p>DaemonSet：在每个Node上调度一个Pod</p></blockquote><ul><li><p>管理集群中每个Node上仅运行一份Pod的副本实例。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    component: fluentd</span><br><span class="line">  name: logging-fluentd</span><br><span class="line">  namespace: logging</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      component: fluentd</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        component: fluentd</span><br><span class="line">      name: fluentd-elasticsearch</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        image: docker.io/openshift/origin-logging-fluentd:latest</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: fluentd-elasticsearch</span><br><span class="line">      nodeSelector:</span><br><span class="line">        logging-infra-fluentd: &quot;true&quot;</span><br></pre></td></tr></table></figure><blockquote><p>Job：批处理调度</p></blockquote></li><li><p>定义批量任务（并行&#x2F;串行启动多个计算进程去处理一批工作项）</p></li><li><p>按照批处理任务实现方式的不同，可以分为四种模式</p><ul><li>Job Template Expansion模式：一个Job对象对应一个待处理的Work item,有几个Work item就产生几个独立的Job，通常适合Work item数量少，每个Work item要处理的数据量比较大的场景。</li><li>Queue with Pod Per Work Item模式：采用一个任务队列存放Work item，一个Job对象作为消费者去完成这些Work item，在这种模式下，Job会启动多个Pod，每个Pod对应一个Work item</li><li>Queue with Variable Pod Count模式：采用一个任务队列存放Work item，一个Job对象作为消费者去完成这些Work item，Job启动的Pod数量是可变的</li><li>Single Job with Static Work Assignment模式：采用静态方式分配任务项</li></ul></li><li><p>按批量处理的并行问题，Job分为三类</p><ul><li>Non-parallel Jobs：通常一个Job启动一个Pod，除非Pod异常才会重启Pod，一量Pod正常结束，则Job结束</li><li>Parallel Jobs with a fixed completion count：并行Job会启动多个Pod，需要设定Job的.sepc.completions，当正常结束的Pod数量达到该值后，Job结束。同时.spec.parallelism控制并行度，即同时启动几个Job来处理Work item</li><li>Parallel Jobs with a work queue：任务队列方式的并行Job，需要一个独立的Queue，Work item都在一个Queue中存放，不能设置.spec.completions参数。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">kind: Job</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: process-itme</span><br><span class="line">  labels:</span><br><span class="line">    jobgroup: jobexample</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: jobexample</span><br><span class="line">      labels:</span><br><span class="line">        jobgroup: jobexample</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: c</span><br><span class="line">          image: busybox</span><br><span class="line">          command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo jobexample &amp;&amp; sleep 5&quot;]</span><br><span class="line">      restartPolicy: Never</span><br></pre></td></tr></table></figure><blockquote><p>Cronjob：定时任务</p></blockquote></li></ul></li><li><p>类似Linux Cron的定时任务</p></li><li><p>定时表达式：Minutes Hours DayofMonth Month DayofWeek Year</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kind: CronJob</span><br><span class="line">apiVersion: batch/v2alpha1</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">spec:</span><br><span class="line">  schedule: &quot;*/1 * * * *&quot;</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">            - name: hello</span><br><span class="line">              image: busybox</span><br><span class="line">              command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo Hello &amp;&amp; sleep 5&quot;]</span><br><span class="line">          restartPolicy: OnFailure</span><br></pre></td></tr></table></figure><p>参考书目：<code>《Kubernetes权威指南》</code></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>给非技术人员说清楚容器是什么</title>
      <link href="/openshift/%E7%BB%99%E9%9D%9E%E6%8A%80%E6%9C%AF%E4%BA%BA%E5%91%98%E8%AF%B4%E6%B8%85%E6%A5%9A%E5%AE%B9%E5%99%A8%E6%98%AF%E4%BB%80%E4%B9%88/"/>
      <url>/openshift/%E7%BB%99%E9%9D%9E%E6%8A%80%E6%9C%AF%E4%BA%BA%E5%91%98%E8%AF%B4%E6%B8%85%E6%A5%9A%E5%AE%B9%E5%99%A8%E6%98%AF%E4%BB%80%E4%B9%88/</url>
      
        <content type="html"><![CDATA[<p>小明要造一个房子，开始自己买木头、砖头自己造。</p><p>出现了一个开发商，他有一个机器，可以在几分钟内造出一个毛坯房，小明只需要按照自己的风格做装修。</p><p>巫婆出现，给了小明一个魔法袋，它可以把房子的模型装入袋中，想造房子念个咒语就行。</p><p>小明造了很多模板，可以轻松地就能造出很多房子。</p><p>来了个商人，告诉小明可以把魔法袋租出去，别人也可以放入模板，也能够造房子，坐收租金。</p><h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://zhuanlan.zhihu.com/p/53260098">https://zhuanlan.zhihu.com/p/53260098</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络相关工具简单汇总</title>
      <link href="/openshift/%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7%E7%AE%80%E5%8D%95%E6%B1%87%E6%80%BB/"/>
      <url>/openshift/%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7%E7%AE%80%E5%8D%95%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="lscpi查看Mac地址和网卡带宽"><a href="#lscpi查看Mac地址和网卡带宽" class="headerlink" title="lscpi查看Mac地址和网卡带宽"></a>lscpi查看Mac地址和网卡带宽</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install pciutils -y</span><br><span class="line">[root@localhost] $ lspci -vvv</span><br></pre></td></tr></table></figure><p>里面的mac地址格式：<code>46-8d-80-6d-06-07</code></p><h2 id="ip-a查看Mac地址与IP"><a href="#ip-a查看Mac地址与IP" class="headerlink" title="ip a查看Mac地址与IP"></a>ip a查看Mac地址与IP</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install iproute</span><br><span class="line">[root@localhost] $ ip a</span><br></pre></td></tr></table></figure><p>里面的mac地址格式：<code>46:8d:80:6d:06:07</code></p><h2 id="iperf-对集群进行网络流量测试"><a href="#iperf-对集群进行网络流量测试" class="headerlink" title="iperf 对集群进行网络流量测试"></a>iperf 对集群进行网络流量测试</h2><p>启动服务端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install iperf3 -y</span><br><span class="line">[root@localhost] $ iperf3 -s</span><br></pre></td></tr></table></figure><p>客户端进行测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install iperf3 -y</span><br><span class="line">[root@localhost] $ iperf3 -c 10.2.2.2 -P 5</span><br></pre></td></tr></table></figure><p>以上默认为作<code>TCP</code>测试，如果要<code>UDP</code>测试，服务端启动与客户端测试都需要加上<code>-u</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 服务端</span><br><span class="line">iperf3 -s -u</span><br><span class="line">## 客户端</span><br><span class="line">iperf3 -c 10.2.2.2 -P 5 -u</span><br></pre></td></tr></table></figure><h2 id="qperf对集群进行网络带宽与延时测试"><a href="#qperf对集群进行网络带宽与延时测试" class="headerlink" title="qperf对集群进行网络带宽与延时测试"></a>qperf对集群进行网络带宽与延时测试</h2><p>启动服务端</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install qperf -y</span><br><span class="line">[root@localhost] $ qperf</span><br></pre></td></tr></table></figure><p>客户端进行测试网络延时</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install qperf -y</span><br><span class="line">[root@localhost] $ qperf 10.2.2.2 -t 100 -oo msg_size:8:256K:*2 tcp_lat</span><br></pre></td></tr></table></figure><p>客户端进行测试网络带宽</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ yum install qperf -y</span><br><span class="line">[root@localhost] $ qperf 10.2.2.2 -t 100 -oo msg_size:8:256K:*2 tcp_bw</span><br></pre></td></tr></table></figure><p>延时与带宽可以一起测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost] $ qperf 10.2.2.2 -t 100 -oo msg_size:8:256K:*2 tcp_bw tcp_lat</span><br></pre></td></tr></table></figure><h2 id="查看端口是否连接网线"><a href="#查看端口是否连接网线" class="headerlink" title="查看端口是否连接网线"></a>查看端口是否连接网线</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip a | grep <span class="string">&#x27;state UP&#x27;</span></span></span><br></pre></td></tr></table></figure><p>将会列出所有连接着网线的网卡<br>或者使用ethtool确认</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ethtool eno1 | grep Speed</span></span><br></pre></td></tr></table></figure><p>将会列出当前网卡的网速，如10000Mb&#x2F;s。如果未连接网线，则会显示为Unknown!</p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自定义Service添加到Openshift中的Prometheus</title>
      <link href="/openshift/%E8%87%AA%E5%AE%9A%E4%B9%89Service%E6%B7%BB%E5%8A%A0%E5%88%B0Openshift%E4%B8%AD%E7%9A%84Prometheus/"/>
      <url>/openshift/%E8%87%AA%E5%AE%9A%E4%B9%89Service%E6%B7%BB%E5%8A%A0%E5%88%B0Openshift%E4%B8%AD%E7%9A%84Prometheus/</url>
      
        <content type="html"><![CDATA[<h3 id="prometheus-yml中定义了keep-drop-update等状态"><a href="#prometheus-yml中定义了keep-drop-update等状态" class="headerlink" title="prometheus.yml中定义了keep, drop, update等状态"></a>prometheus.yml中定义了keep, drop, update等状态</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;kubernetes-service-endpoints&#x27;</span><br><span class="line"></span><br><span class="line">  tls_config:</span><br><span class="line">    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">    # TODO: this should be per target</span><br><span class="line">    insecure_skip_verify: true</span><br><span class="line"></span><br><span class="line">  kubernetes_sd_configs:</span><br><span class="line">  - role: endpoints</span><br><span class="line"></span><br><span class="line">  relabel_configs:</span><br><span class="line">    # only scrape infrastructure components</span><br><span class="line">    - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">      action: keep</span><br><span class="line">      regex: &#x27;default|logging|metrics|kube-.+|openshift|openshift-.+&#x27;</span><br><span class="line">    # drop infrastructure components managed by other scrape targets</span><br><span class="line">    - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">      action: drop</span><br><span class="line">      regex: &#x27;prometheus-node-exporter&#x27;</span><br><span class="line">    # only those that have requested scraping</span><br><span class="line">    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]</span><br><span class="line">      action: keep</span><br><span class="line">      regex: true</span><br><span class="line">    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]</span><br><span class="line">      action: replace</span><br><span class="line">      target_label: __scheme__</span><br><span class="line">      regex: (https?)</span><br><span class="line">    - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]</span><br><span class="line">      action: replace</span><br><span class="line">      target_label: __metrics_path__</span><br><span class="line">      regex: (.+)</span><br><span class="line">    - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]</span><br><span class="line">      action: replace</span><br><span class="line">      target_label: __address__</span><br><span class="line">      regex: (.+)(?::\d+);(\d+)</span><br><span class="line">      replacement: $1:$2</span><br><span class="line">    - action: labelmap</span><br><span class="line">      regex: __meta_kubernetes_service_label_(.+)</span><br><span class="line">    - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">      action: replace</span><br><span class="line">      target_label: kubernetes_namespace</span><br><span class="line">    - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">      action: replace</span><br><span class="line">      target_label: kubernetes_name</span><br></pre></td></tr></table></figure><p>创建自定义的Service，添加指定的annotations<code>prometheus.io/scrape: &quot;true&quot;</code>,<code>prometheus.io/port: &quot;9128&quot;</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-monitor</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">    prometheus.io/port: &quot;9128&quot;</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9128</span><br><span class="line">      name: ceph-monitor</span><br><span class="line">      protocol: TCP</span><br><span class="line">      targetPort: 9128</span><br><span class="line">  type: ClusterIP</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: Endpoints</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-monitor</span><br><span class="line">subsets:</span><br><span class="line">  - addresses:</span><br><span class="line">      - ip: 99.248.82.31</span><br><span class="line">    ports:</span><br><span class="line">      - port: 9128</span><br><span class="line">        name: ceph-monitor</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通过curl访问OpenShift上部署的Prometheus获取监控数据</title>
      <link href="/openshift/%E9%80%9A%E8%BF%87curl%E8%AE%BF%E9%97%AEOpenShift%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%9A%84Prometheus%E8%8E%B7%E5%8F%96%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE/"/>
      <url>/openshift/%E9%80%9A%E8%BF%87curl%E8%AE%BF%E9%97%AEOpenShift%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%9A%84Prometheus%E8%8E%B7%E5%8F%96%E7%9B%91%E6%8E%A7%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/5793257-189a78982012ffd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/860" alt="OpenShift 和 Prometheus"></p><p>Prometheus作为最常用的集群的监控组件，它收集了集群最全的状态信息。那么当我们需要将它与现有的监控告警平台打通，或者根据它开发一个自己的监控展示平台时，就不得不需要获得Prometheus的监控数据了。这时就不得不访问Prometheus的API接口。<br>根据场景的不同有两种方式能够获取到Prometheus的数据</p><ol><li>集群外部，通过访问Prometheus UI的链接来获取指标数据</li><li>集群内部，进入Prometheus容器中，获取指标数据</li></ol><h2 id="1-集群外部，curl访问Prometheus-UI地址"><a href="#1-集群外部，curl访问Prometheus-UI地址" class="headerlink" title="1. 集群外部，curl访问Prometheus UI地址"></a>1. 集群外部，curl访问Prometheus UI地址</h2><p>由于OpenShift上部署的Prometheus应用对接了OpenShift的用户认证oauth-proxy，所以必须先获取用户的Token后再通过curl访问prometheus服务获取数据，具体操作如下。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="comment">#登录</span></span></span><br><span class="line">[root@master ~]# oc login -u admin</span><br><span class="line">Authentication required for https://master.example.com:8443 (openshift)</span><br><span class="line">Username: admin</span><br><span class="line">Password:</span><br><span class="line">Login successful.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="comment">#获取Token</span></span></span><br><span class="line">[root@master ~]# oc whoami -t</span><br><span class="line">ZhzCkIUKoHpVgen65DIYQodNVdYjguD6Y4AEGiG_Z2E</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="comment">#获取prometheus数据</span></span></span><br><span class="line">[root@master ~]# curl -ks -H &#x27;Authorization: Bearer ZhzCkIUKoHpVgen65DIYQodNVdYjguD6Y4AEGiG_Z2E&#x27; \</span><br><span class="line">     &#x27;https://prometheus-k8s-openshift-monitoring.apps.example.com/api/v1/query?query=$&#123;QUERY_EXPRESSION&#125;&#x27;</span><br></pre></td></tr></table></figure><h2 id="2-集群内部，进入Prometheus容器获取数据"><a href="#2-集群内部，进入Prometheus容器获取数据" class="headerlink" title="2. 集群内部，进入Prometheus容器获取数据"></a>2. 集群内部，进入Prometheus容器获取数据</h2><p>进入Prometheus应用的容器，绕过了OpenShift的认证，直接获取数据，具体操作如下。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# oc exec -c prometheus prometheus-k8s-0 -- curl -s \</span><br><span class="line">  &#x27;http://localhost:9090/api/v1/query?query=$&#123;QUERY_EXPRESSION&#125;&#x27; \</span><br><span class="line">| python -m json.tool</span><br></pre></td></tr></table></figure><p>其中${QUERY_EXPRESSION}即为Prometheus请求表达式，如：<code>count(kube_pod_container_status_running%7Bcontainer%3D%22etcd%22%7D)</code>来获取正常运行的etcd容器的个数<br>其中<code>%7B</code>为<code>(</code>、<code>%7D</code>为<code>)</code>、<code>%3D</code>为<code>=</code>、<code>%22</code>为<code>&quot;</code>，这些都需要经过HtmlEncode编码。也可以通过Prometheus界面上通过抓包的方式，获取截取具体的QUERY_EXPRESSION表达示。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Prometheus API通过HTTP服务的方式向外提供它的监控数据，以上使用curl工具方便地获取监控指标，实际中可以通过各种开发语言进行获取需要的数据。返回数据都为json格式，根据需要可以非常方便地对数据进行格式转化处理。<br>正常情况下，返回的code为2xx，但也会有不正常的请求Code，如下：</p><ul><li>404 Bad Request：当参数错误或者缺失时</li><li>422 Unprocessable Entity 当表达式无法执行时</li><li>503 Service Unavailiable 当请求超时或者被中断时</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>镜像命名规范与Dockerfile编写规范</title>
      <link href="/openshift/%E9%95%9C%E5%83%8F%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%E4%B8%8EDockerfile%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/"/>
      <url>/openshift/%E9%95%9C%E5%83%8F%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%E4%B8%8EDockerfile%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h2 id="镜像命名规范"><a href="#镜像命名规范" class="headerlink" title="镜像命名规范"></a>镜像命名规范</h2><p>镜像地址：镜像仓库&#x2F;项目名&#x2F;镜像名:标签名</p><ol><li>项目名，公共项目使用名称：base，并设置为公开；其它项目使用英文小写项目名，设置为私有。</li><li>镜像名中应该包含使用的组件名称及版本信息，使用<code>-</code>连接。<ul><li>基础镜像命名规则<br>基础镜像命名应按照操作系统大版本：版本号-构建版本的格式命名，例如：<code>base/rehl7:7.6-1</code></li><li>公共镜像全名规则<br>公共镜像命名应按照服务名-中间件-上级中间件：服务版本号-中间件<br>版本号-上级中间件版本号-构建版本的格式命名，中间件名称可以包含大版本号，例如：<code>base/tomcat8-openjdk8:8.5.23-jre8u212-1</code></li><li>应用命名规则<br>使用格式：系统-模块:系统版本-模块版本-构建版本，例如：<code>sys/sys-rs:1.1-1.1-1</code></li></ul></li><li>同一应用镜像在以上标签的规则下，还可以根据发布流程设置多个标签，以满足部署时版本依赖的管理要求。例如<code>sys/sys-rs:v1</code>代表<code>v1.x</code>的最新版本。</li></ol><h2 id="镜像制作规范"><a href="#镜像制作规范" class="headerlink" title="镜像制作规范"></a>镜像制作规范</h2><ol><li>关键字使用大写</li><li>FROM镜像，指定明确的Tag，不要使用latest</li><li>发布向后兼容的镜像可以使用同一个Tag号，否则使用新的Tag号</li><li>尽量将命令放在同一个RUN命令下，减少层数</li><li>镜像中避免多进程，如果一定要使用，请引入<a href="https://github.com/krallin/tini">tini</a>命令，用来管理进程<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN yum install tini -y &amp;&amp; yum clean all -y</span><br><span class="line">ENTRYPOINT [&#x27;tini&#x27;, &#x27;--&#x27;]</span><br></pre></td></tr></table></figure></li><li>尽量使用exec，使真正应用的进程ID为1</li><li>清理临时文件，如yum install后需要执行yum clean all -y</li><li>优化Dockerfile命令的顺序，尽量把不变的放在前面</li><li>使用WORKDIR指定工作目录，避免绝对路径扩散</li><li>使用 set -o pipefail 避免管道错误被忽略<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number </span><br></pre></td></tr></table></figure></li><li>优先使用COPY，比ADD更简单明了</li><li>始终暴露重要端口</li><li>习惯使用环境变量，同时在Dockerfile中为环境变量设置默认值<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ENV APP_PORT=8761</span><br></pre></td></tr></table></figure></li><li>避免设置默认密码</li><li>镜像中不要安装sshd</li><li>使用volume显示设置挂载点，以方便镜像的使用者知道需要如何定义存储卷</li><li>支持任一用户运行，对于需要访问的目录文件执行以下命令更新权限<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN chgrp -R 0 /some/directory &amp;&amp; \</span><br><span class="line">    chmod -R g+rwX /some/directory</span><br></pre></td></tr></table></figure>Dockerfile的最后使用USER指定数字用户<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER 1001</span><br></pre></td></tr></table></figure></li><li>容器内部应用使用Service访问k8s&#x2F;OCP平台的其他服务。</li><li>应用基础镜像应该安装公用的依赖库</li><li>为镜像设置元数据，例如说明镜像的用途等，UI界面可以根据这些元数据进行定制功能<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">LABEL io.openshift.tags=&quot;mongodb,mongodb24,nosql&quot; \</span><br><span class="line">      io.openshift.min-memory=&quot;8Gi&quot; \</span><br><span class="line">      io.openshift.min-cpu&quot;=4&quot; \</span><br><span class="line">      io.openshift.non-scalable&quot;=true&quot; \</span><br><span class="line">      io.k8s.description=&quot;The MySQL 5.5 Server with master-slave replication support&quot; \</span><br><span class="line">      io.openshift.wants=&quot;mongodb,redis&quot;</span><br></pre></td></tr></table></figure></li><li>尽量将应用的日志以标准输出的形式输出，这样可以被容器平台统一收集管理。</li><li>镜像中为应用准备好健康检查的探针，方便容器平台对应用进行健康检查。</li></ol><p>下图为使用<code>EXEC</code>格式与<code>SHELL</code>格式，执行ENTRYPOINT CMD的区别。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/8c40079c92cb5a086cb3f8808c19f6e470617fc6429bd70a2d56c6c510d7a2b4.png" alt="使用`EXEC`格式与`SHELL`格式，执行ENTRYPOINT CMD的区别">  </p><p>docker run 执行多条命令实例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm ubuntu sh -c &quot;echo 1 &amp;&amp; echo 2&quot;</span><br><span class="line">docker run --rm --entrypoint=&quot;/bin/sh&quot; ubuntu -c &quot;echo 1 &amp;&amp; echo 2&quot;</span><br></pre></td></tr></table></figure><p><a href="https://docs.openshift.com/container-platform/3.11/creating_images/guidelines.html">OpenShift官方文档——镜像构建规范</a><br><a href="http://www.talkwithtrend.com/Article/245353">Dockerfile最佳实践</a><br><a href="https://yeasy.gitbooks.io/docker_practice/image/dockerfile/entrypoint.html">ENTRYPOINT 入口点</a><br><a href="https://embed.coggle.it/diagram/XRMuwHTTRuswFEzY/t/dockerfile%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/10ceb37829fb4c938ce91fd474ed68721b5d7fda8a383ff5a583ff398a8b4b26">dockerfile最佳实践</a><br><a href="https://github.com/docker-library">常用的Dockerfile镜像地址</a><br><a href="https://github.com/nginxinc/docker-nginx/blob/b749353968a57ebd9da17e12d23f1a5fb62f9de9/mainline/stretch/Dockerfile">nginx的Dockerfile实例</a>：把日志输出到标准输出</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN ln -sf /dev/stdout /var/log/nginx/access.log \</span><br><span class="line">&amp;&amp; ln -sf /dev/stderr /var/log/nginx/error.log</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>镜像仓库的镜像清理</title>
      <link href="/openshift/%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E7%9A%84%E9%95%9C%E5%83%8F%E6%B8%85%E7%90%86/"/>
      <url>/openshift/%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%E7%9A%84%E9%95%9C%E5%83%8F%E6%B8%85%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="1-必备条件"><a href="#1-必备条件" class="headerlink" title="1. 必备条件"></a>1. 必备条件</h2><p>镜像仓库打开可删除功能</p><h2 id="2-清理镜像"><a href="#2-清理镜像" class="headerlink" title="2. 清理镜像"></a>2. 清理镜像</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -k -I -H <span class="string">&quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot;</span> -I http://localhost:5000/v2/openshift/ocp-router/manifests/v3.11.129</span></span><br><span class="line">获取镜像层的sha256值</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl -X DELETE http://localhost:5000/v2/openshift/ocp-router/manifests/sha256:39ad17c3e10f902d8b098ee5128a87d4293b6d07cbc2d1e52ed9ddf0076e3cf9</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="comment">#登录到镜像仓库</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">registry garbage-collect /etc/docker-distribution/registry/config.yml</span></span><br></pre></td></tr></table></figure><h2 id="3-参考文档"><a href="#3-参考文档" class="headerlink" title="3. 参考文档"></a>3. 参考文档</h2><p><a href="https://cloud.tencent.com/developer/article/1640158">私有docker registry的使用–push,pull,search,delete</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《大数据时代—生活、工作与思维的大变革》读书笔记</title>
      <link href="/%E9%9A%8F%E7%AC%94/%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3%E2%80%94%E7%94%9F%E6%B4%BB%E3%80%81%E5%B7%A5%E4%BD%9C%E4%B8%8E%E6%80%9D%E7%BB%B4%E7%9A%84%E5%A4%A7%E5%8F%98%E9%9D%A9%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/%E9%9A%8F%E7%AC%94/%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3%E2%80%94%E7%94%9F%E6%B4%BB%E3%80%81%E5%B7%A5%E4%BD%9C%E4%B8%8E%E6%80%9D%E7%BB%B4%E7%9A%84%E5%A4%A7%E5%8F%98%E9%9D%A9%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/435d53ac8878c09d82bed3067b66998a61618303c2886097fa91c53c91c6d2d8.png" alt="大数据时代—生活、工作与思维的大变革">  </p><p>信息时代的到来，大数据时代为我们探索事物提供了一个非常不同的思路，并且很明显它将会帮助我们发现更多无法想象的问题及解决方法。这不仅仅是将数据量化，更是思维的一次升级。</p><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>随着信息时代的发展，数据无处不在，并高速爆炸，同时大数据时代正改变我们的思维方式。大数据告诉我们“是什么”而不是“为什么”。<br>人类一直以来探索这个世界都是建立在因果的基础上，看到事务的发生会去思考内在的原因，并从中发现规律，总结经验。也是在这种不断探索，穷追不舍的坚持下，人类发现了现在的很多理论，可以说人类的现文明是建立在不断追问“为什么”的基础上建立起来的。但是大数据时代改变了这一切。<br>我们不必关心A事物与B事物的关系，但是无法数据显示A发生了某变化，B也会跟着发生变化，那我们就可以得到A变B变的结果，而无需去探索为什么，当我们需要B作某些改变时，我们只要改变A就好了。当发现某中水果对治疗癌症有效果的时候，我们又怎么会为了不清楚之间的关联，而拒绝食用该水果呢？我们不再关心为什么，我们关心的是它是什么。<br>相反思考，恰是大数据发现是“是什么”，而让我们有了更准确的思考方向，去探究“为什么”。</p><h3 id="第一部分：大数据时代的思维变革"><a href="#第一部分：大数据时代的思维变革" class="headerlink" title="第一部分：大数据时代的思维变革"></a>第一部分：大数据时代的思维变革</h3><p>像引言中所说的，大数据时代，我们需要有思维上的变革，关心的是“是什么”，而不是“为什么”。我们不再追寻之间的因果，而关注表现出的相关关系。</p><ul><li><ol><li>要分析与某事物相关的所有数据，而不是依靠分析少量的数据样本</li></ol></li><li><ol start="2"><li>乐于接受数据的纷繁复杂，而不再追求精确性</li></ol></li><li><ol start="3"><li>思维发生了转变，不再探求因果关系，转而关注事物的相关关系。</li></ol></li></ul><blockquote><p>更多，不是随机样本，而是全体数据</p></blockquote><p>大数据时代使用全量数据能够发现很多意外的关系，而这些关系在以前的抽样分析环境下是无法想像的。慢慢地，我们会完全抛弃样本分析。</p><blockquote><p>更杂，不是精确性，而是混杂性</p></blockquote><p>大数据时代，数据并不统一格式化，同时也可能有错误的地方，网络传输过程中，也可能有延迟，甚至丢失。我们为了获得广泛数据而牺牲精确性，为了高频率放弃精确性，结果可以观察到一些有可能被错过的变化。为了扩大规模，接受适量的数据错误。</p><blockquote><p>更好，不是因果关系，而是相关关系</p></blockquote><p>大数据时代，我们需要让数据发声。相关关系没有绝对，只是一个可能性。建立在相关关系分析法基础上的预测是大数据的核心。通过找出一个关联物并监控它，我们就能预测未来。</p><h3 id="第二部分：大数据时代的商业变革"><a href="#第二部分：大数据时代的商业变革" class="headerlink" title="第二部分：大数据时代的商业变革"></a>第二部分：大数据时代的商业变革</h3><blockquote><p>数据化，一切皆可“量化”</p></blockquote><p>数据化就是一种把现象转变为可制表分析的量化形式的过程。</p><ol><li>文字变成数据：Google翻译</li><li>方位变成数据：预测交通情况</li><li>沟通变成数据：微博、twitter、Facebook用户数据</li><li>世间万物数据化：我们不会再将世界看作是一边串我们认为或是自然或社会现象的事件，我们会意识到本质上世界是由信息构成的。<blockquote><p>价值，“取之不尽，用之不竭“的数据创新</p></blockquote></li></ol><p> 数据的价值不会随着它的使用而减少，而是可以不断地被处理，产生更多的价值</p><ol><li><p>数据的再利用：对用户搜索关键词分析用户喜好</p></li><li><p>重组数据：将多个数据集的总和重组在一起，扩大价值</p></li><li><p>可扩展数据：一开始考虑好数据的可扩展性</p></li><li><p>数据的折旧值：随着时间的推移，大多数据会失去一部分价值，但潜在价值依然强大</p></li><li><p>数据废气：用户在线交互的副产品，包括浏览了哪些页面、停留了多久，鼠标光标停留的位置、输入了什么信息等</p></li><li><p>开放数据：开放数据，挖掘数据的潜在价值</p><blockquote><p>角色定位，数据、技术与思维的三足鼎立</p></blockquote></li><li><p>掌握大数据的公司</p></li><li><p>拥有技术和专业技能的公司</p></li><li><p>有着大数据思维的公司和个人</p></li><li><p>全新的数据中间商：从各地方搜集数据进行聚合，提取有用的信息进行利</p></li><li><p>大数据决定企业竞争力：大数据对中等规模公司帮助不大，超大型的公司占据了规模优势，小公司则具有灵活性。大数据让处于行业两端的公司受益良多，而中等规模的公司要么向两端转换，要么破产</p></li></ol><p>###第三部分：在数据时代的管理变革</p><blockquote><p>风险，让数据主宰一切的隐忧</p></blockquote><ol><li><p>被“第三只眼”时刻“监视”</p></li><li><p>隐私被二次利用：目前有法律法规规范数据的用途，但数据更多的价值在于它的二次利用，最终产生了很多创新性的用户</p></li><li><p>预测与惩罚，不是因为“所做”，而是因为“将做”：如果大数据足够精确，未来我们将失去选择的权利</p></li><li><p>数据独裁：对数据的盲目崇拜，会导致收集数据的不可靠性</p><blockquote><p>掌控，责任与自由并举的信息管理</p></blockquote></li><li><p>个人隐私保护：从个人许可到数据使用者承担责任</p></li><li><p>个人动机 VS 预测分析：个人有选择自我行为的自由，不就为行为倾向负责</p></li><li><p>击碎黑盒子，大数据算法师的崛起：监督大数据活动，对数据结果进行审查</p></li><li><p>反数据垄断大亨</p></li></ol><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>大数据时代，是名副其实的“信息社会”，以前我们寻找事物发生原因的想法可能被高估了，很多情况下，弄清“是什么”比寻找“为什么”更加重要。<br>我们尽可能收集数据，不再追求数据的精确性，我们的思维也需要升级。<br>大数据时代，一切皆可数据化，挖掘数据的价值，发现事务发展的规范，为更好的决策做判断依据<br>应对大数据时代，个人信息容易被滥用，我们要建立规范制度来保护我们的数据，规范大数据的使用</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubefwd——Openshift-K8S-本地开发的福音</title>
      <link href="/openshift/Kubefwd/"/>
      <url>/openshift/Kubefwd/</url>
      
        <content type="html"><![CDATA[<p>小志：“kubefwd 本地开发的福音啊，本地环境直接连接 svc。”<br>当小志推荐这个工具的时候，我正在 Kubecon 大会的现场，听着 Kubernetes 近一年的各种成就和各种新特性。我无法看到微信另一头小志的表情，也许平静，也许跟我现在一样激动。<br>kubefwd，这是第一次听到这个工具，“本地环境直接连接 svc”，openshift 的 port-fowrward 命令就能做到，没什么也不起的吧。<br>我回复道：“openshift 的 port-forward，再加个自动更新本地 hosts 文件”。<br>小志发来了 kubefwd 请求流向图。</p><p><img src="https://cdn.jsdelivr.net/gh/xhuaustc/images@main/131045874b5f63548f32c7206962fc25048b4931bf29c615c539e2fa5904f3bd.png" alt="kubefwd"></p><p>服务 api 与服务 auth 提供的都是 80 端口，但是它们能够同时被本地访问，这是 port-forward 无法做到的！我意识到这个工具很不简单，刚才的想法太草率了。<br>我马上回复：“我刚才理解得不对，它可以做到一个 port 对应多个 service！”<br>此刻的心情其实已经非常激动了，因为意识到 kubefwd 这个工具也许解决了困扰我多天的问题。</p><blockquote><p>近一周一直在脑中徘徊的是徐磊老师介绍微软的 TFS 时的演示：开发人员本地修改代码，可以在开发环境独立的 namespace 下实时查看代码生效的结果，当时我为之震惊。因为之前想的各种流程，终究是需要开发者提交代码才能进行下一步测试的。<br>“创建一个环境，让开发者能够以最方便的形式进行开发，这是最直接地提高效率的方式。”<br>于是我开始寻找一种在 openshift&#x2F;k8s 环境下的开源解决方案，测试了 openshift-connector，虽然它跟 TFS 中的代码同步功能有些类似，但是一直没有测试成功，这个插件的关注者很少。后来找了 redhat 的朋友确认，他告诉我这个项目也许已经停止了。我继续寻找，但终究没有新的收获。</p></blockquote><p>我跟一起参会的小伙伴说：“对我而言，也许这次大会的内容，都不及知道了这个工具。”</p><p>晚上回到家，我赶紧做测试。</p><ul><li>第一个要验证的就是 kubefwd 对 Openshift 是否支持，毕竟我们开发测试环境，甚至有些项目的生产环境是在 Openshift 上。</li><li>第二个要验证的就是 kubefwd 是否支持在 windows 系统上运行，毕竟研发几乎都在 windows 上做开发。</li></ul><p>测试结论</p><ul><li>kubefwd 对 Openshift 完全支持</li><li>kubefwd 在 windows 系统上运行正常</li></ul><p>我为什么会如此激动？或者说使用 kubefwd 带来什么样的改变？</p><ul><li>开发人员无需在本地模拟一套完整的线上应用环境就能够测试与其他应用的集成效果</li><li>本地开发应用也能使用远端集群下的中间件，同时使用的配置与集群中的应用完成一样，无需专门做本地访问的配置管理</li><li>开发人员无需提交代码就能与其他应用集成，查看代码生效后的效果</li><li>开发环境变成了相对稳定的集成环境，每个开发者本地版本不会互相影响，降低多个应用同时开发的相互干扰</li></ul><p>对于 kubefwd 如何使用，看它的帮助说明就够了，非常简单。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Usage:</span><br><span class="line">  kubefwd services [flags]</span><br><span class="line"></span><br><span class="line">Aliases:</span><br><span class="line">  services, svcs, svc</span><br><span class="line"></span><br><span class="line">Examples:</span><br><span class="line">  kubefwd svc -n the-project</span><br><span class="line">  kubefwd svc -n the-project -l env=dev,component=api</span><br><span class="line">  kubefwd svc -n default -l &quot;app in (ws, api)&quot;</span><br><span class="line">  kubefwd svc -n default -n the-project</span><br><span class="line">  kubefwd svc -n default -d internal.example.com</span><br><span class="line">  kubefwd svc -n the-project -x prod-cluster</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Flags:</span><br><span class="line">  -x, --context strings     specify a context to override the current context</span><br><span class="line">  -d, --domain string       Append a pseudo domain name to generated host names.</span><br><span class="line">      --exitonfailure       Exit(1) on failure. Useful for forcing a container restart.</span><br><span class="line">  -h, --help                help for services</span><br><span class="line">  -c, --kubeconfig string   absolute path to a kubectl config fil (default &quot;/Users/cjimti/.kube/config&quot;)</span><br><span class="line">  -n, --namespace strings   Specify a namespace. Specify multiple namespaces by duplicating this argument.</span><br><span class="line">  -l, --selector string     Selector (label query) to filter on; supports &#x27;=&#x27;, &#x27;==&#x27;, and &#x27;!=&#x27; (e.g. -l key1=value1,key2=value2).</span><br><span class="line">  -v, --verbose             Verbose output.</span><br></pre></td></tr></table></figure><h2 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h2><p>kubefwd <a href="https://github.com/txn2/kubefwd">https://github.com/txn2/kubefwd</a></p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>小志还分享了个方便端口转发的应用，“oc port-forward 的图形化应用”。地址：<a href="https://kube-forwarder.pixelpoint.io/">https://kube-forwarder.pixelpoint.io/</a></p><p>进一步发现了一个新的工具<a href="https://alibaba.github.io/kt-connect/#/zh-cn/">kt-connect</a> ，一个可以让开发环境访问 K8S 集群下应用的工具，可以直接访问容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 检查依赖环境</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ktctl check</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># 1. 安装sshuttle</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo pip install sshuttle -i https://pypi.douban.com/simple</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="comment"># openshift中，先创建一个project</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc new-project ktconnect</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">oc adm policy add-scc-to-user anyuid -z default <span class="comment">#因为默认kt-connect-daemon需要root用户启动</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ktctl -n ktconnect connect</span></span><br><span class="line"></span><br><span class="line">11:15AM INF Connect Start At 67595</span><br><span class="line">11:15AM INF Client address 192.168.0.138</span><br><span class="line">11:15AM INF deploy shadow deployment kt-connect-daemon-yuiaq in namespace ktconnect</span><br><span class="line"></span><br><span class="line">11:15AM INF pod label: kt=kt-connect-daemon-yuiaq</span><br><span class="line">11:15AM INF pod: kt-connect-daemon-yuiaq-665dd6bc55-tzb74 is running,but not ready</span><br><span class="line">11:15AM INF pod: kt-connect-daemon-yuiaq-665dd6bc55-tzb74 is running,but not ready</span><br><span class="line">11:15AM INF pod: kt-connect-daemon-yuiaq-665dd6bc55-tzb74 is running,but not ready</span><br><span class="line">11:15AM INF pod: kt-connect-daemon-yuiaq-665dd6bc55-tzb74 is running,but not ready</span><br><span class="line">11:15AM INF Shadow pod: kt-connect-daemon-yuiaq-665dd6bc55-tzb74 is ready.</span><br><span class="line">11:15AM INF Fail to get pod cidr from node.Spec.PODCIDR, try to get with pod sample</span><br><span class="line">Forwarding from 127.0.0.1:2222 -&gt; 22</span><br><span class="line">Forwarding from [::1]:2222 -&gt; 22</span><br><span class="line">11:16AM INF port-forward start at pid: 67596</span><br><span class="line">Handling connection for 2222</span><br><span class="line">Warning: Permanently added &#x27;[127.0.0.1]:2222&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">client: Connected.</span><br><span class="line">11:16AM INF vpn(sshuttle) start at pid: 67597</span><br><span class="line">11:16AM INF KT proxy start successful</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> openshift </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
